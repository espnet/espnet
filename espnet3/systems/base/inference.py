"""Inference entrypoint for ESPnet3 systems."""

import logging
import time
from pathlib import Path

from omegaconf import DictConfig

from espnet3.parallel.parallel import set_parallel
from espnet3.systems.asr.inference import InferenceProvider, InferenceRunner
from espnet3.systems.base.inference_runner import AbsInferenceRunner

logger = logging.getLogger(__name__)


def _flatten_results(results):
    flat = []
    for item in results:
        if isinstance(item, list):
            flat.extend(item)
        else:
            flat.append(item)
    return flat


def _collect_scp_lines(results, *, idx_key: str, hyp_keys, ref_keys):
    scp_lines = {}
    hyp_keys = list(hyp_keys) if isinstance(hyp_keys, (list, tuple)) else [hyp_keys]
    ref_keys = list(ref_keys) if isinstance(ref_keys, (list, tuple)) else [ref_keys]
    list_sizes = {key: None for key in (*hyp_keys, *ref_keys)}

    for result in results:
        if not isinstance(result, dict):
            raise TypeError(
                f"Expected dict output, got {type(result).__name__}: {result}"
            )

        idx_value = result[idx_key]
        if isinstance(idx_value, (list, tuple)):
            raise TypeError(
                f"'{idx_key}' must be a scalar, got {type(idx_value).__name__}"
            )

        for field_key in (*ref_keys, *hyp_keys):
            value = result[field_key]
            if isinstance(value, (list, tuple)):
                if list_sizes[field_key] is None:
                    list_sizes[field_key] = len(value)
                elif list_sizes[field_key] != len(value):
                    raise ValueError(
                        f"List length mismatch for '{field_key}': "
                        f"expected {list_sizes[field_key]}, got {len(value)}"
                    )
                for i, entry in enumerate(value):
                    if isinstance(entry, (list, tuple)):
                        raise TypeError(f"Nested list is not allowed for '{field_key}'")
                    scp_key = f"{field_key}{i}"
                    scp_lines.setdefault(scp_key, []).append(f"{idx_value} {entry}")
            else:
                if list_sizes[field_key] is not None:
                    raise TypeError(
                        f"'{field_key}' must be a list when list outputs are used"
                    )
                scp_lines.setdefault(field_key, []).append(f"{idx_value} {value}")

    return scp_lines


def inference(config: DictConfig):
    """Run inference over all configured test sets and write SCP files.

    Args:
        config: Hydra/omegaconf configuration with dataset and inference settings.
    """
    start = time.perf_counter()
    set_parallel(config.parallel)

    test_sets = [test_set.name for test_set in config.dataset.test]
    assert len(test_sets) > 0, "No test set found in dataset"
    assert len(test_sets) == len(set(test_sets)), "Duplicate test key found."

    logger.info(
        "Starting inference | infer_dir=%s test_sets=%s",
        getattr(config, "infer_dir", None),
        test_sets,
    )

    for test_name in test_sets:
        logger.info("===> Processing test set: %s", test_name)
        config.test_set = test_name
        provider = InferenceProvider(config)
        runner = InferenceRunner(provider=provider, async_mode=False)
        if not isinstance(runner, AbsInferenceRunner):
            raise TypeError(
                f"{type(runner).__name__} must inherit from AbsInferenceRunner"
            )
        dataset_length = len(provider.build_dataset(config))
        logger.info("===> Processing %d samples..", dataset_length)
        out = runner(list(range(dataset_length)))
        if out is None:
            raise RuntimeError("Async inference is not supported in this entrypoint.")
        results = _flatten_results(out)
        scp_lines = _collect_scp_lines(
            results,
            idx_key=runner.idx_key,
            hyp_keys=runner.hyp_key,
            ref_keys=runner.ref_key,
        )

        # create scp files
        output_dir = Path(config.infer_dir) / test_name
        output_dir.mkdir(parents=True, exist_ok=True)
        for key, lines in scp_lines.items():
            with open(output_dir / f"{key}.scp", "w", encoding="utf-8") as f:
                f.write("\n".join(lines))
        logger.info(
            "Finished test set %s | outputs=%s",
            test_name,
            output_dir,
        )

    logger.info("Inference finished in %.2fs", time.perf_counter() - start)
