<!doctype html>
<html lang="en-US" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.14" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.51" />
    <style>
      html {
        background: var(--bg-color, #fff);
      }

      html[data-theme="dark"] {
        background: var(--bg-color, #1d1e1f);
      }

      body {
        background: var(--bg-color);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <link rel="icon" href="/espnet/assets/image/espnet.png"><title></title><meta name="description" content="A documentation for ESPnet">
    <link rel="preload" href="/espnet/assets/style-CiXYLHjk.css" as="style"><link rel="stylesheet" href="/espnet/assets/style-CiXYLHjk.css">
    <link rel="modulepreload" href="/espnet/assets/app-B6Ithpv3.js">
    
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">Skip to main content</a><!--]--><!--[--><div class="theme-container external-link-icon"><!--[--><header id="navbar" class="vp-navbar"><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!----><!--[--><a class="route-link vp-brand" href="/espnet/"><img class="vp-nav-logo" src="/espnet/assets/image/espnet_logo1.png" alt><!----><!----></a><!--]--><!----></div><div class="vp-navbar-center"><!----><!--[--><nav class="vp-nav-links"><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="Demos"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="fa-solid:laptop-code" width="1em" height="1em"></iconify-icon>Demos<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/notebook/" aria-label="Roadmap"><!---->Roadmap<!----></a></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">ESPnet2</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/notebook/ESPnet2/Demo/" aria-label="Demo"><!---->Demo<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/notebook/ESPnet2/Course/" aria-label="Course"><!---->Course<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">ESPnet-EZ</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/notebook/ESPnetEZ/" aria-label="ESPnet EZ"><!---->ESPnet EZ<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">ESPnet1 (Legacy)</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/notebook/ESPnet1/" aria-label="ESPnet1"><!---->ESPnet1<!----></a></li></ul></li></ul></button></div></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="Recipes"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="fa-solid:mug-hot" width="1em" height="1em"></iconify-icon>Recipes<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/" aria-label="What is a recipe template?"><!---->What is a recipe template?<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/asr1.html" aria-label="Automatic Speech Recognition (Multi-tasking)"><!---->Automatic Speech Recognition (Multi-tasking)<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/asr2.html" aria-label="Automatic Speech Recognition with Discrete Units"><!---->Automatic Speech Recognition with Discrete Units<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/asvspoof1.html" aria-label="Speaker Verification Spoofing and Countermeasures"><!---->Speaker Verification Spoofing and Countermeasures<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/codec1.html" aria-label="Speech Codec"><!---->Speech Codec<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/diar1.html" aria-label="Speaker Diarisation"><!---->Speaker Diarisation<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/enh1.html" aria-label="Speech Enhancement"><!---->Speech Enhancement<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/enh_asr1.html" aria-label="Speech Recognition with Speech Enhancement"><!---->Speech Recognition with Speech Enhancement<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/enh_diar1.html" aria-label="Speaker Diarisation with Speech Enhancement"><!---->Speaker Diarisation with Speech Enhancement<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/enh_st1.html" aria-label="Speech-to-Text Translation with Speech Enhancement"><!---->Speech-to-Text Translation with Speech Enhancement<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/lm1.html" aria-label="Language Modeling"><!---->Language Modeling<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/mt1.html" aria-label="Machine Translation"><!---->Machine Translation<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/s2st1.html" aria-label="Speech-to-Speech Translation"><!---->Speech-to-Speech Translation<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/s2t1.html" aria-label="Weakly-supervised Learning (Speech-to-Text)"><!---->Weakly-supervised Learning (Speech-to-Text)<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/slu1.html" aria-label="Spoken Language Understanding"><!---->Spoken Language Understanding<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/speechlm1.html" aria-label="Speech Language Model"><!---->Speech Language Model<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/spk1.html" aria-label="Speaker Representation"><!---->Speaker Representation<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/ssl1.html" aria-label="Self-supervised Learning"><!---->Self-supervised Learning<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/st1.html" aria-label="Speech-to-Text Translation"><!---->Speech-to-Text Translation<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/svs1.html" aria-label="Singing Voice Synthesis"><!---->Singing Voice Synthesis<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/tts1.html" aria-label="Text-to-Speech"><!---->Text-to-Speech<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/tts2.html" aria-label="Text-to-Speech with Discrete Units"><!---->Text-to-Speech with Discrete Units<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/uasr1.html" aria-label="Unsupervised Automatic Speech Recognition"><!---->Unsupervised Automatic Speech Recognition<!----></a></li></ul></button></div></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="Python API"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="fa-solid:book" width="1em" height="1em"></iconify-icon>Python API<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">espnet</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet/asr/" aria-label="asr"><!---->asr<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet/distributed/" aria-label="distributed"><!---->distributed<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet/lm/" aria-label="lm"><!---->lm<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet/mt/" aria-label="mt"><!---->mt<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet/nets/" aria-label="nets"><!---->nets<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet/optimizer/" aria-label="optimizer"><!---->optimizer<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet/scheduler/" aria-label="scheduler"><!---->scheduler<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet/st/" aria-label="st"><!---->st<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet/transform/" aria-label="transform"><!---->transform<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet/tts/" aria-label="tts"><!---->tts<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet/utils/" aria-label="utils"><!---->utils<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet/vc/" aria-label="vc"><!---->vc<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">espnet2</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/asr/" aria-label="asr"><!---->asr<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/asr_transducer/" aria-label="asr_transducer"><!---->asr_transducer<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/asvspoof/" aria-label="asvspoof"><!---->asvspoof<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/diar/" aria-label="diar"><!---->diar<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/enh/" aria-label="enh"><!---->enh<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/fileio/" aria-label="fileio"><!---->fileio<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/fst/" aria-label="fst"><!---->fst<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/gan_codec/" aria-label="gan_codec"><!---->gan_codec<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/gan_svs/" aria-label="gan_svs"><!---->gan_svs<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/gan_tts/" aria-label="gan_tts"><!---->gan_tts<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/hubert/" aria-label="hubert"><!---->hubert<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/iterators/" aria-label="iterators"><!---->iterators<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/layers/" aria-label="layers"><!---->layers<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/lm/" aria-label="lm"><!---->lm<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/main_funcs/" aria-label="main_funcs"><!---->main_funcs<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/mt/" aria-label="mt"><!---->mt<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/optimizers/" aria-label="optimizers"><!---->optimizers<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/s2st/" aria-label="s2st"><!---->s2st<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/s2t/" aria-label="s2t"><!---->s2t<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/samplers/" aria-label="samplers"><!---->samplers<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/schedulers/" aria-label="schedulers"><!---->schedulers<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/slu/" aria-label="slu"><!---->slu<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/speechlm/" aria-label="speechlm"><!---->speechlm<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/spk/" aria-label="spk"><!---->spk<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/st/" aria-label="st"><!---->st<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/svs/" aria-label="svs"><!---->svs<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/tasks/" aria-label="tasks"><!---->tasks<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/text/" aria-label="text"><!---->text<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/torch_utils/" aria-label="torch_utils"><!---->torch_utils<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/train/" aria-label="train"><!---->train<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/tts/" aria-label="tts"><!---->tts<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/tts2/" aria-label="tts2"><!---->tts2<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/uasr/" aria-label="uasr"><!---->uasr<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/utils/" aria-label="utils"><!---->utils<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">espnetez</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnetez/config/" aria-label="config"><!---->config<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnetez/data/" aria-label="data"><!---->data<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnetez/dataloader/" aria-label="dataloader"><!---->dataloader<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnetez/dataset/" aria-label="dataset"><!---->dataset<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnetez/preprocess/" aria-label="preprocess"><!---->preprocess<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnetez/task/" aria-label="task"><!---->task<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnetez/trainer/" aria-label="trainer"><!---->trainer<!----></a></li></ul></li></ul></button></div></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="Shell API"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="fa-solid:wrench" width="1em" height="1em"></iconify-icon>Shell API<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/tools/espnet2_bin/" aria-label="espnet2_bin"><!---->espnet2_bin<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/tools/espnet_bin/" aria-label="espnet_bin"><!---->espnet_bin<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/tools/spm/" aria-label="spm"><!---->spm<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/tools/utils/" aria-label="utils"><!---->utils<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/tools/utils_py/" aria-label="utils_py"><!---->utils_py<!----></a></li></ul></button></div></div></nav><!--]--><!----></div><div class="vp-navbar-end"><!----><!--[--><!----><div class="vp-nav-item vp-action"><a class="vp-action-link" href="https://github.com/espnet/espnet" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" name="github" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><!----><!--[--><button type="button" class="search-pro-button" aria-label="Search"><svg xmlns="http://www.w3.org/2000/svg" class="icon search-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="search icon" name="search"><path d="M192 480a256 256 0 1 1 512 0 256 256 0 0 1-512 0m631.776 362.496-143.2-143.168A318.464 318.464 0 0 0 768 480c0-176.736-143.264-320-320-320S128 303.264 128 480s143.264 320 320 320a318.016 318.016 0 0 0 184.16-58.592l146.336 146.368c12.512 12.48 32.768 12.48 45.28 0 12.48-12.512 12.48-32.768 0-45.28"></path></svg><div class="search-pro-placeholder">Search</div><div class="search-pro-key-hints"><kbd class="search-pro-key">Ctrl</kbd><kbd class="search-pro-key">K</kbd></div></button><!--]--><!--]--><!----><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar"><!----><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><p class="vp-sidebar-header"><iconify-icon class="font-icon icon" style="" mode="style" inline icon="fa-solid:laptop-code" width="1em" height="1em"></iconify-icon><span class="vp-sidebar-title">Demos</span><!----></p><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/notebook/" aria-label="ESPnet Notebooks"><!---->ESPnet Notebooks<!----></a></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">ESPnet EZ</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">ESPnet1</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">ESPnet2</span><span class="vp-arrow end"></span></button><!----></section></li></ul></section></li><li><section class="vp-sidebar-group"><p class="vp-sidebar-header"><iconify-icon class="font-icon icon" style="" mode="style" inline icon="fa-solid:mug-hot" width="1em" height="1em"></iconify-icon><span class="vp-sidebar-title">Recipes</span><!----></p><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/" aria-label="Recipe Template"><!---->Recipe Template<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/asr1.html" aria-label="Automatic Speech Recognition (Multi-tasking)"><!---->Automatic Speech Recognition (Multi-tasking)<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/asr2.html" aria-label="Automatic Speech Recognition with Discrete Units"><!---->Automatic Speech Recognition with Discrete Units<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/lm1.html" aria-label="Language Modeling"><!---->Language Modeling<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/mt1.html" aria-label="Machine Translation"><!---->Machine Translation<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/ssl1.html" aria-label="Self-supervised Learning"><!---->Self-supervised Learning<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/svs1.html" aria-label="Singing Voice Synthesis"><!---->Singing Voice Synthesis<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/diar1.html" aria-label="Speaker Diarisation"><!---->Speaker Diarisation<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/enh_diar1.html" aria-label="Speaker Diarisation with Speech Enhancement"><!---->Speaker Diarisation with Speech Enhancement<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/spk1.html" aria-label="Speaker Representation"><!---->Speaker Representation<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/asvspoof1.html" aria-label="Speaker Verification Spoofing and Countermeasures"><!---->Speaker Verification Spoofing and Countermeasures<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/codec1.html" aria-label="Speech Codec"><!---->Speech Codec<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/enh1.html" aria-label="Speech Enhancement"><!---->Speech Enhancement<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/speechlm1.html" aria-label="Speech Language Model"><!---->Speech Language Model<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/enh_asr1.html" aria-label="Speech Recognition with Speech Enhancement"><!---->Speech Recognition with Speech Enhancement<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/s2st1.html" aria-label="Speech-to-Speech Translation"><!---->Speech-to-Speech Translation<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/st1.html" aria-label="Speech-to-Text Translation"><!---->Speech-to-Text Translation<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/enh_st1.html" aria-label="Speech-to-Text Translation with Speech Enhancement"><!---->Speech-to-Text Translation with Speech Enhancement<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/slu1.html" aria-label="Spoken Language Understanding"><!---->Spoken Language Understanding<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/tts1.html" aria-label="Text-to-Speech"><!---->Text-to-Speech<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/tts2.html" aria-label="Text-to-Speech with Discrete Units"><!---->Text-to-Speech with Discrete Units<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/uasr1.html" aria-label="Unsupervised Automatic Speech Recognition"><!---->Unsupervised Automatic Speech Recognition<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/s2t1.html" aria-label="Weakly-supervised Learning (Speech-to-Text)"><!---->Weakly-supervised Learning (Speech-to-Text)<!----></a></li></ul></section></li><li><section class="vp-sidebar-group"><p class="vp-sidebar-header"><iconify-icon class="font-icon icon" style="" mode="style" inline icon="fa-solid:book" width="1em" height="1em"></iconify-icon><span class="vp-sidebar-title">Python API</span><!----></p><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Espnet</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Espnet2</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Espnetez</span><span class="vp-arrow end"></span></button><!----></section></li></ul></section></li><li><section class="vp-sidebar-group"><p class="vp-sidebar-header"><iconify-icon class="font-icon icon" style="" mode="style" inline icon="fa-solid:wrench" width="1em" height="1em"></iconify-icon><span class="vp-sidebar-title">Shell API</span><!----></p><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Espnet Bin</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Espnet2 Bin</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Spm</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Utils</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Utils Py</span><span class="vp-arrow end"></span></button><!----></section></li></ul></section></li></ul><!----></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!----><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><!----></h1><div class="page-info"><!----><!----><!----><!----><span class="page-reading-time-info" aria-label="Reading TimeâŒ›" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon" name="timer"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>About 10 min</span><meta property="timeRequired" content="PT10M"></span><!----><!----></div><hr></div><!----><!----><div class="theme-hope-content"><h2 id="usage" tabindex="-1"><a class="header-anchor" href="#usage"><span>Usage</span></a></h2><p>If you&#39;re a new user, we suggest checking out the <a class="route-link" href="/espnet/espnet2_tutorial.html">ESPnet2 tutorial</a> as ESPnet1 is an older implementation. The majority of the development has now shifted to ESPnet2. Please be aware that certain information in this document may be outdated due to this shift.</p><h3 id="directory-structure" tabindex="-1"><a class="header-anchor" href="#directory-structure"><span>Directory structure</span></a></h3><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span>espnet/              # Python modules</span></span>
<span class="line"><span>utils/               # Utility scripts of ESPnet</span></span>
<span class="line"><span>test/                # Unit test</span></span>
<span class="line"><span>test_utils/          # Unit test for executable scripts</span></span>
<span class="line"><span>egs/                 # The complete recipe for each corpora</span></span>
<span class="line"><span>    an4/             # AN4 is tiny corpus and can be obtained freely, so it might be suitable for tutorial</span></span>
<span class="line"><span>      asr1/          # ASR recipe</span></span>
<span class="line"><span>          - run.sh   # Executable script</span></span>
<span class="line"><span>          - cmd.sh   # To select the backend for job scheduler</span></span>
<span class="line"><span>          - path.sh  # Setup script for environment variables</span></span>
<span class="line"><span>          - conf/    # Containing Configuration files</span></span>
<span class="line"><span>          - steps/   # The steps scripts from Kaldi</span></span>
<span class="line"><span>          - utils/   # The utils scripts from Kaldi</span></span>
<span class="line"><span>      tts1/          # TTS recipe</span></span>
<span class="line"><span>    ...</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="execution-of-example-scripts" tabindex="-1"><a class="header-anchor" href="#execution-of-example-scripts"><span>Execution of example scripts</span></a></h3><p>Move to an example directory under the <code>egs</code> directory. We prepare several major ASR benchmarks including WSJ, CHiME-4, and TED. The following directory is an example of performing ASR experiment with the CMU Census Database (AN4) recipe.</p><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" data-title="sh" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">$</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> cd</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> egs/an4/asr1</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>Once move to the directory, then, execute the following main script with a <strong>chainer</strong> backend:</p><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" data-title="sh" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">$</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> ./run.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --backend</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> chainer</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>or execute the following main script with a <strong>pytorch</strong> backend:</p><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" data-title="sh" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">$</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> ./run.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --backend</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> pytorch</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>With this main script, you can perform a full procedure of ASR experiments including</p><ul><li>Data download</li><li><a href="http://kaldi-asr.org/doc/data_prep.html" target="_blank" rel="noopener noreferrer">Data preparation</a> (Kaldi style)</li><li><a href="http://kaldi-asr.org/doc/feat.html" target="_blank" rel="noopener noreferrer">Feature extraction</a> (Kaldi style)</li><li>Dictionary and JSON format data preparation</li><li>Training based on <a href="https://chainer.org/" target="_blank" rel="noopener noreferrer">chainer</a> or <a href="http://pytorch.org/" target="_blank" rel="noopener noreferrer">pytorch</a>.</li><li>Recognition and scoring</li></ul><h3 id="logging" tabindex="-1"><a class="header-anchor" href="#logging"><span>Logging</span></a></h3><p>The training progress (loss and accuracy for training and validation data) can be monitored with the following command</p><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" data-title="sh" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">$</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> tail</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> -f</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> exp/</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">${</span><span style="--shiki-light:#24292E;--shiki-dark:#E06C75;">expdir</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">/train.log</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>When we use <code>./run.sh --verbose 0</code> (<code>--verbose 0</code> is default in most recipes), it gives you the following information</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span>epoch       iteration   main/loss   main/loss_ctc  main/loss_att  validation/main/loss  validation/main/loss_ctc  validation/main/loss_att  main/acc    validation/main/acc  elapsed_time  eps</span></span>
<span class="line"><span>:</span></span>
<span class="line"><span>:</span></span>
<span class="line"><span>6           89700       63.7861     83.8041        43.768                                                                                   0.731425                         136184        1e-08</span></span>
<span class="line"><span>6           89800       71.5186     93.9897        49.0475                                                                                  0.72843                          136320        1e-08</span></span>
<span class="line"><span>6           89900       72.1616     94.3773        49.9459                                                                                  0.730052                         136473        1e-08</span></span>
<span class="line"><span>7           90000       64.2985     84.4583        44.1386        72.506                94.9823                   50.0296                   0.740617    0.72476              137936        1e-08</span></span>
<span class="line"><span>7           90100       81.6931     106.74         56.6462                                                                                  0.733486                         138049        1e-08</span></span>
<span class="line"><span>7           90200       74.6084     97.5268        51.6901                                                                                  0.731593                         138175        1e-08</span></span>
<span class="line"><span>     total [#################.................................] 35.54%</span></span>
<span class="line"><span>this epoch [#####.............................................] 10.84%</span></span>
<span class="line"><span>     91300 iter, 7 epoch / 20 epochs</span></span>
<span class="line"><span>   0.71428 iters/sec. Estimated time to finish: 2 days, 16:23:34.613215.</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>Note that the an4 recipe uses <code>--verbose 1</code> as default since this recipe is often used for a debugging purpose.</p><p>In addition <a href="https://www.tensorflow.org/guide/summaries_and_tensorboard" target="_blank" rel="noopener noreferrer">Tensorboard</a> events are automatically logged in the <code>tensorboard/${expname}</code> folder. Therefore, when you install Tensorboard, you can easily compare several experiments by using</p><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" data-title="sh" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">$</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> tensorboard</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --logdir</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> tensorboard</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>and connecting to the given address (default : localhost:6006). This will provide the following information: <img src="https://user-images.githubusercontent.com/14289171/50175839-2491e280-02fe-11e9-8dfc-de303804034d.png" alt="2018-12-18_19h49_48" loading="lazy"> Note that we would not include the installation of Tensorboard to simplify our installation process. Please install it manually (<code>pip install tensorflow; pip install tensorboard</code>) when you want to use Tensorboard.</p><h3 id="change-options-in-run-sh" tabindex="-1"><a class="header-anchor" href="#change-options-in-run-sh"><span>Change options in run.sh</span></a></h3><p>We rely on <a href="https://github.com/kaldi-asr/kaldi/blob/master/egs/wsj/s5/utils/parse_options.sh" target="_blank" rel="noopener noreferrer">utils/parse_options.sh</a> to paser command line arguments in shell script and it&#39;s used in run.sh:</p><p>e.g. If the script has <code>ngpu</code> option</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" data-title="bash" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">#!/usr/bin/env bash</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># run.sh</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E06C75;">ngpu</span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">1</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;">.</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> utils/parse_options.sh</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;">echo</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> ${</span><span style="--shiki-light:#24292E;--shiki-dark:#E06C75;">ngpu</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">}</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>Then you can change the value as following:</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" data-title="bash" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">$</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> ./run.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --ngpu</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 2</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;">echo</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 2</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="use-of-gpu" tabindex="-1"><a class="header-anchor" href="#use-of-gpu"><span>Use of GPU</span></a></h3><ul><li>Training: If you want to use GPUs in your experiment, please set <code>--ngpu</code> option in <code>run.sh</code> appropriately, e.g.,<div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" data-title="bash" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">  # use single gpu</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">  $</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> ./run.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --ngpu</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 1</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">  # use multi-gpu</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">  $</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> ./run.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --ngpu</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 3</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">  # if you want to specify gpus, set CUDA_VISIBLE_DEVICES as follows</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">  # (Note that if you use slurm, this specification is not needed)</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">  $</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> CUDA_VISIBLE_DEVICES=0,1,2</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> ./run.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --ngpu</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 3</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">  # use cpu</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">  $</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> ./run.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --ngpu</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 0</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>Default setup uses a single GPU (<code>--ngpu 1</code>).</li></ul></li><li>ASR decoding: ESPnet also supports the GPU-based decoding for fast recognition. <ul><li>Please manually remove the following lines in <code>run.sh</code>:<div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" data-title="bash" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">#### use CPU for decoding</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E06C75;">ngpu</span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">0</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div></li><li>Set 1 or more values for <code>--batchsize</code> option in <code>asr_recog.py</code> to enable GPU decoding</li><li>And execute the script (e.g., <code>run.sh --stage 5 --ngpu 1</code>)</li><li>You&#39;ll achieve significant speed improvement by using the GPU decoding</li></ul></li></ul><h3 id="espnet1-transducer" tabindex="-1"><a class="header-anchor" href="#espnet1-transducer"><span>ESPnet1 Transducer</span></a></h3><p><em><strong>Important: If you encounter any issue related to Transducer loss, please open an issue in <a href="https://github.com/b-flo/warp-transducer" target="_blank" rel="noopener noreferrer">our fork of warp-transducer</a>.</strong></em></p><p>ESPnet supports models trained with Transducer loss, aka Transducer models. To train such model, the following should be set in the training config:</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span>criterion: loss</span></span>
<span class="line"><span>model-module: &quot;espnet.nets.pytorch_backend.e2e_asr_transducer:E2E&quot;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="architecture" tabindex="-1"><a class="header-anchor" href="#architecture"><span>Architecture</span></a></h4><p>Several Transducer architectures are currently available in ESPnet:</p><ul><li>RNN-Transducer (default, e.g.: <code>etype: blstm</code> with <code>dtype: lstm</code>)</li><li>Custom-Transducer (e.g.: <code>etype: custom</code> and <code>dtype: custom</code>)</li><li>Mixed Custom/RNN-Transducer (e.g: <code>etype: custom</code> with <code>dtype: lstm</code>)</li></ul><p>The architecture specification is separated for the encoder and decoder part, and defined by the user through, respectively, <code>etype</code> and <code>dtype</code> in the training config. If <code>custom</code> is specified for either, a customizable architecture will be used for the corresponding part. Otherwise, an RNN-based architecture will be selected.</p><p>Here, the <em>custom</em> architecture is a unique feature of the Transducer model in ESPnet. It was made available to add some flexibility in the architecture definition and ease the reproduction of some SOTA Transducer models mixing different layers types or parameters within the same model part (encoder or decoder). As such, the architecture definition is different compared to the RNN architecture :</p><ol><li><p>Each block (or layer) of the custom architecture should be specified individually through <code>enc-block-arch</code> or/and <code>dec-block-arch</code> parameters:</p><pre><code> # e.g: Conv-Transformer encoder
 etype: custom
 enc-block-arch:
         - type: conv1d
           idim: 80
           odim: 32
           kernel_size: [3, 7]
           stride: [1, 2]
         - type: conv1d
           idim: 32
           odim: 32
           kernel_size: 3
           stride: 2
         - type: conv1d
           idim: 32
           odim: 384
           kernel_size: 3
           stride: 1
         - type: transformer
           d_hidden: 384
           d_ff: 1536
           heads: 4
</code></pre></li><li><p>Different block types are allowed for the custom encoder (<code>tdnn</code>, <code>conformer</code> or <code>transformer</code>) and the custom decoder (<code>causal-conv1d</code> or <code>transformer</code>). Each one has a set of mandatory and optional parameters :</p><pre><code> # 1D convolution (TDNN) block
 - type: conv1d
   idim: [Input dimension. (int)]
   odim: [Output dimension. (int)]
   kernel_size: [Size of the context window. (int or tuple)]
   stride (optional): [Stride of the sliding blocks. (int or tuple, default = 1)]
   dilation (optional): [Parameter to control the stride of elements within the neighborhood. (int or tuple, default = 1)]
   groups (optional): [Number of blocked connections from input channels to output channels. (int, default = 1)
   bias (optional): [Whether to add a learnable bias to the output. (bool, default = True)]
   use-relu (optional): [Whether to use a ReLU activation after convolution. (bool, default = True)]
   use-batchnorm: [Whether to use batch normalization after convolution. (bool, default = False)]
   dropout-rate (optional): [Dropout-rate for TDNN block. (float, default = 0.0)]

 # Transformer
 - type: transformer
   d_hidden: [Input/output dimension of Transformer block. (int)]
   d_ff: [Hidden dimension of the Feed-forward module. (int)]
   heads: [Number of heads in multi-head attention. (int)]
   dropout-rate (optional): [Dropout-rate for Transformer block. (float, default = 0.0)]
   pos-dropout-rate (optional): [Dropout-rate for positional encoding module. (float, default = 0.0)]
   att-dropout-rate (optional): [Dropout-rate for attention module. (float, default = 0.0)]

 # Conformer
 - type: conformer
   d_hidden: [Input/output dimension of Conformer block (int)]
   d_ff: [Hidden dimension of the Feed-forward module. (int)]
   heads: [Number of heads in multi-head attention. (int)]
   macaron_style: [Whether to use macaron style. (bool)]
   use_conv_mod: [Whether to use convolutional module. (bool)]
   conv_mod_kernel (required if use_conv_mod = True): [Number of kernel in convolutional module. (int)]
   dropout-rate (optional): [Dropout-rate for Transformer block. (float, default = 0.0)]
   pos-dropout-rate (optional): [Dropout-rate for positional encoding module. (float, default = 0.0)]
   att-dropout-rate (optional): [Dropout-rate for attention module. (float, default = 0.0)]

 # Causal Conv1d
 - type: causal-conv1d
   idim: [Input dimension. (int)]
   odim: [Output dimension. (int)]
   kernel_size: [Size of the context window. (int)]
   stride (optional): [Stride of the sliding blocks. (int, default = 1)]
   dilation (optional): [Parameter to control the stride of elements within the neighborhood. (int, default = 1)]
   groups (optional): [Number of blocked connections from input channels to output channels. (int, default = 1)
   bias (optional): [Whether to add a learnable bias to the output. (bool, default = True)]
   use-relu (optional): [Whether to use a ReLU activation after convolution. (bool, default = True)]
   use-batchnorm: [Whether to use batch normalization after convolution. (bool, default = False)]
   dropout-rate (optional): [Dropout-rate for TDNN block. (float, default = 0.0)]
</code></pre></li><li><p>The defined architecture can be repeated by specifying the total number of blocks/layers in the architecture through <code>enc-block-repeat</code> or/and <code>dec-block-repeat</code> parameters:</p><pre><code> # e.g.: 2x (Causal-Conv1d + Transformer) decoder
 dtype: transformer
 dec-block-arch:
         - type: causal-conv1d
           idim: 256
           odim: 256
           kernel_size: 5
         - type: transformer
           d_hidden: 256
           d_ff: 256
           heads: 4
           dropout-rate: 0.1
           att-dropout-rate: 0.4
 dec-block-repeat: 2
</code></pre></li></ol><h4 id="multi-task-learning" tabindex="-1"><a class="header-anchor" href="#multi-task-learning"><span>Multi-task learning</span></a></h4><p>We also support multi-task learning with various auxiliary losses, such as: CTC, cross-entropy w/ label-smoothing (LM loss), auxiliary Transducer, and symmetric KL divergence. The four losses can be simultaneously trained with main Transducer loss to jointly optimize the total loss defined as:</p><figure><img src="http://www.sciweavers.org/tex2img.php?eq=\mathcal{L}_{tot} %3D \lambda_{1}\mathcal{L}_{1} %2B \lambda_{2}\mathcal{L}_{2} %2B \lambda_{3}\mathcal{L}_{3} %2B \lambda_{4} \mathcal{L}_{4} %2B \lambda_{5} \mathcal{L}_{5}&amp;bc=White&amp;fc=Black&amp;im=jpg&amp;fs=12&amp;ff=arev&amp;edit=" alt="augmented Transducer training" tabindex="0" loading="lazy"><figcaption>augmented Transducer training</figcaption></figure><p>where the losses are respectively, in order: The main Transducer loss, the CTC loss, the auxiliary Transducer loss, the symmetric KL divergence loss, and the LM loss. Lambda values define their respective contribution to the overall loss. Additionally, each loss can be independently selected or omitted depending on the task.</p><p>Each loss can be defined in the training config alongside its specific options, such as follow:</p><pre><code>    # Transducer loss (L1)
    transducer-loss-weight: [Weight of the main Transducer loss (float)]

    # CTC loss (L2)
    use-ctc-loss: True
    ctc-loss-weight (optional): [Weight of the CTC loss. (float, default = 0.5)]
    ctc-loss-dropout-rate (optional): [Dropout rate for encoder output representation. (float, default = 0.0)]

    # Auxiliary Transducer loss (L3)
    use-aux-transducer-loss: True
    aux-transducer-loss-weight (optional): [Weight of the auxiliary Transducer loss. (float, default = 0.4)]
    aux-transducer-loss-enc-output-layers (required if use-aux-transducer-loss = True): [List of intermediate encoder layer IDs to compute auxiliary Transducer loss(es). (list)]
    aux-transducer-loss-mlp-dim (optional): [Hidden dimension for the MLP network. (int, default = 320)]
    aux-transducer-loss-mlp-dropout-rate: [Dropout rate for the MLP network. (float, default = 0.0)]

    # Symmetric KL divergence loss (L4)
    # Note: It can be only used in addition to the auxiliary Transducer loss.
    use-symm-kl-div-loss: True
    symm-kl-div-loss-weight (optional): [Weight of the symmetric KL divergence loss. (float, default = 0.2)]

    # LM loss (L5)
    use-lm-loss: True
    lm-loss-weight (optional): [Weight of the LM loss. (float, default = 0.2)]
    lm-loss-smoothing-rate: [Smoothing rate for LM loss. If &gt; 0, label smoothing is enabled. (float, default = 0.0)]
</code></pre><h4 id="inference" tabindex="-1"><a class="header-anchor" href="#inference"><span>Inference</span></a></h4><p>Various decoding algorithms are also available for Transducer by setting <code>beam-size</code> and <code>search-type</code> parameters in decode config.</p><ul><li>Greedy search constrained to one emission by timestep (<code>beam-size: 1</code>).</li><li>Beam search algorithm without prefix search (<code>beam-size: &gt;1</code> and <code>search-type: default</code>).</li><li>Time Synchronous Decoding <a href="https://ieeexplore.ieee.org/abstract/document/9053040" target="_blank" rel="noopener noreferrer">[Saon et al., 2020]</a> (<code>beam-size: &gt;1</code> and <code>search-type: tsd</code>).</li><li>Alignment-Length Synchronous Decoding <a href="https://ieeexplore.ieee.org/abstract/document/9053040" target="_blank" rel="noopener noreferrer">[Saon et al., 2020]</a> (<code>beam-size: &gt;1</code> and <code>search-type: alsd</code>).</li><li>N-step Constrained beam search modified from <a href="https://arxiv.org/abs/2002.03577" target="_blank" rel="noopener noreferrer">[Kim et al., 2020]</a> (<code>beam-size: &gt;1</code> and <code>search-type: default</code>).</li><li>modified Adaptive Expansion Search, based on <a href="https://ieeexplore.ieee.org/abstract/document/9250505" target="_blank" rel="noopener noreferrer">[Kim et al., 2021]</a> and NSC (<code>beam-size: &gt;1</code> and <code>search-type: maes</code>).</li></ul><p>The algorithms share two parameters to control beam size (<code>beam-size</code>) and final hypotheses normalization (<code>score-norm-transducer</code>). The specific parameters for each algorithm are:</p><pre><code>    # Default beam search
    search-type: default

    # Time-synchronous decoding
    search-type: tsd
    max-sym-exp: [Number of maximum symbol expansions at each time step (int)]

    # Alignement-length decoding
    search-type: alsd
    u-max: [Maximum output sequence length (int)]

    # N-step Constrained beam search
    search-type: nsc
    nstep: [Number of maximum expansion steps at each time step (int)]
           # nstep = max-sym-exp + 1 (blank)
    prefix-alpha: [Maximum prefix length in prefix search (int)]

    # modified Adaptive Expansion Search
    search-type: maes
    nstep: [Number of maximum expansion steps at each time step (int, &gt; 1)]
    prefix-alpha: [Maximum prefix length in prefix search (int)]
    expansion-gamma: [Number of additional candidates in expanded hypotheses selection (int)]
    expansion-beta: [Allowed logp difference for prune-by-value method (float, &gt; 0)]
</code></pre><p>Except for the default algorithm, the described parameters are used to control the performance and decoding speed. The optimal values for each parameter are task-dependent; a high value will typically increase decoding time to focus on performance while a low value will improve decoding time at the expense of performance.</p><h4 id="additional-notes" tabindex="-1"><a class="header-anchor" href="#additional-notes"><span>Additional notes</span></a></h4><ul><li>Similarly to training with CTC, Transducer does not output the validation accuracy. Thus, the optimum model is selected with its loss value (i.e., --recog_model model.loss.best).</li><li>There are several differences between MTL and Transducer training/decoding options. The users should refer to <code>espnet/espnet/nets/pytorch_backend/e2e_asr_transducer.py</code> for an overview and <code>espnet/espnet/nets/pytorch_backend/transducer/arguments</code> for all possible arguments.</li><li>FastEmit regularization <a href="https://arxiv.org/pdf/2010.11148" target="_blank" rel="noopener noreferrer">[Yu et al., 2021]</a> is available through <code>--fastemit-lambda</code> training parameter (default = 0.0).</li><li>RNN-decoder pre-initialization using an LM is supported. Note that regular decoder keys are expected. The LM state dict keys (<code>predictor.*</code>) will be renamed according to AM state dict keys (<code>dec.*</code>).</li><li>Transformer-decoder pre-initialization using a Transformer LM is not supported yet.</li></ul><h3 id="changing-the-training-configuration" tabindex="-1"><a class="header-anchor" href="#changing-the-training-configuration"><span>Changing the training configuration</span></a></h3><p>The default configurations for training and decoding are written in <code>conf/train.yaml</code> and <code>conf/decode.yaml</code> respectively. It can be overwritten by specific arguments: e.g.</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" data-title="bash" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># e.g.</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">asr_train.py</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --config</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> conf/train.yaml</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --batch-size</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 24</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># e.g.--config2 and --config3 are also provided and the latter option can overwrite the former.</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">asr_train.py</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --config</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> conf/train.yaml</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --config2</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> conf/new.yaml</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>In this way, you need to edit <code>run.sh</code> and it might be inconvenient sometimes. Instead of giving arguments directly, we recommend you to modify the yaml file and give it to <code>run.sh</code>:</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" data-title="bash" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># e.g.</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">./run.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --train-config</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> conf/train_modified.yaml</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># e.g.</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">./run.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --train-config</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> conf/train_modified.yaml</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --decode-config</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> conf/decode_modified.yaml</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>We also provide a utility to generate a yaml file from the input yaml file:</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" data-title="bash" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># e.g. You can give any parameters as &#39;-a key=value&#39; and &#39;-a&#39; is repeatable.</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">#      This generates new file at &#39;conf/train_batch-size24_epochs10.yaml&#39;</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">./run.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --train-config</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> $(</span><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">change_yaml.py</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> conf/train.yaml</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> -a</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> batch-size=</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">24</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> -a</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> epochs=</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">10</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># e.g. &#39;-o&#39; option specifies the output file name instead of auto named file.</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">./run.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --train-config</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> $(</span><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">change_yaml.py</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> conf/train.yaml</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> -o</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> conf/train2.yaml</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> -a</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> batch-size=</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">24</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="how-to-set-minibatch" tabindex="-1"><a class="header-anchor" href="#how-to-set-minibatch"><span>How to set minibatch</span></a></h3><p>From espnet v0.4.0, we have three options in <code>--batch-count</code> to specify minibatch size (see <code>espnet.utils.batchfy</code> for implementation);</p><ol><li><p><code>--batch-count seq --batch-seqs 32 --batch-seq-maxlen-in 800 --batch-seq-maxlen-out 150</code>.</p><p>This option is compatible to the old setting before v0.4.0. This counts the minibatch size as the number of sequences and reduces the size when the maximum length of the input or output sequences is greater than 800 or 150, respectively.</p></li><li><p><code>--batch-count bin --batch-bins 100000</code>.</p><p>This creates the minibatch that has the maximum number of bins under 100 in the padded input/output minibatch tensor (i.e., <code>max(ilen) * idim + max(olen) * odim</code>). Basically, this option makes training iteration faster than <code>--batch-count seq</code>. If you already has the best <code>--batch-seqs x</code> config, try <code>--batch-bins $((x * (mean(ilen) * idim + mean(olen) * odim)))</code>.</p></li><li><p><code>--batch-count frame --batch-frames-in 800 --batch-frames-out 100 --batch-frames-inout 900</code>.</p><p>This creates the minibatch that has the maximum number of input, output and input+output frames under 800, 100 and 900, respectively. You can set one of <code>--batch-frames-xxx</code> partially. Like <code>--batch-bins</code>, this option makes training iteration faster than <code>--batch-count seq</code>. If you already has the best <code>--batch-seqs x</code> config, try <code>--batch-frames-in $((x * (mean(ilen) * idim)) --batch-frames-out $((x * mean(olen) * odim))</code>.</p></li></ol><h3 id="how-to-use-finetuning" tabindex="-1"><a class="header-anchor" href="#how-to-use-finetuning"><span>How to use finetuning</span></a></h3><p>ESPnet currently supports two finetuning operations: transfer learning and freezing. We expect the user to define the following options in its main training config (e.g.: conf/train*.yaml). If needed, they can be directly passed to <code>(asr|tts|vc)_train.py</code> by adding the prefix <code>--</code> to the options.</p><h4 id="transfer-learning" tabindex="-1"><a class="header-anchor" href="#transfer-learning"><span>Transfer learning</span></a></h4><ul><li><p>Transfer learning option is split between encoder initialization (<code>enc-init</code>) and decoder initialization (<code>dec-init</code>). However, the same model can be specified for both options.</p></li><li><p>Each option takes a snapshot path (e.g.: <code>[espnet_model_path]/results/snapshot.ep.1</code>) or model path (e.g.: <code>[espnet_model_path]/results/model.loss.best</code>) as argument.</p></li><li><p>Additionally, a list of encoder and decoder modules (separated by a comma) can also be specified to control the modules to transfer with the options <code>enc-init-mods</code> and <code>dec-init-mods</code>.</p></li><li><p>For each specified module, we only expect a partial match with the start of the target model module name. Thus, multiple modules can be specified with the same key if they share a common prefix.</p><blockquote><p>Mandatory: <code>enc-init: /home/usr/espnet/egs/vivos/asr1/exp/train_nodev_pytorch_train/results/model.loss.best</code> -&gt; specify a pre-trained model on VIVOS for transfer learning. Example 1: <code>enc-init-mods: &#39;enc.&#39;</code> -&gt; transfer all encoder parameters. Example 2: <code>enc-init-mods: &#39;enc.embed.,enc.0.&#39;</code> -&gt; transfer encoder embedding layer and first layer parameters.</p></blockquote></li></ul><h4 id="freezing" tabindex="-1"><a class="header-anchor" href="#freezing"><span>Freezing</span></a></h4><ul><li><p>Freezing option can be enabled with <code>freeze-mods</code>, (<code>freeze_param</code> in espnet2).</p></li><li><p>The option take a list of model modules (separated by a comma) as argument. As previously, we do not expect a complete match for the specified modules.</p><blockquote><p>Example 1: <code>freeze-mods: &#39;enc.embed.&#39;</code> -&gt; freeze encoder embedding layer parameters. Example 2: <code>freeze-mods: &#39;dec.embed,dec.0.&#39;</code> -&gt; freeze decoder embedding layer and first layer parameters. Example 3 (espnet2): <code>freeze_param: &#39;encoder.embed&#39;</code> -&gt; freeze encoder embedding layer parameters.</p></blockquote></li></ul><h3 id="important-notes" tabindex="-1"><a class="header-anchor" href="#important-notes"><span>Important notes</span></a></h3><ul><li>Given a pre-trained source model, the modules specified for transfer learning are expected to have the same parameters (i.e.: layers and units) as the target model modules.</li><li>We also support initialization with a pre-trained RNN LM for the RNN-Transducer decoder.</li><li>RNN models use different key names for encoder and decoder parts compared to Transformer, Conformer or Custom models: <ul><li>RNN model use <code>enc.</code> for encoder part and <code>dec.</code> for decoder part.</li><li>Transformer/Conformer/Custom model use <code>encoder.</code> for encoder part and <code>decoder.</code> for decoder part.</li></ul></li></ul><h3 id="chainer-and-pytorch-backends" tabindex="-1"><a class="header-anchor" href="#chainer-and-pytorch-backends"><span>Chainer and Pytorch backends</span></a></h3><table><thead><tr><th></th><th style="text-align:center;">Chainer</th><th style="text-align:center;">Pytorch</th></tr></thead><tbody><tr><td>Performance</td><td style="text-align:center;">â—Ž</td><td style="text-align:center;">â—Ž</td></tr><tr><td>Speed</td><td style="text-align:center;">â—‹</td><td style="text-align:center;">â—Ž</td></tr><tr><td>Multi-GPU</td><td style="text-align:center;">supported</td><td style="text-align:center;">supported</td></tr><tr><td>VGG-like encoder</td><td style="text-align:center;">supported</td><td style="text-align:center;">supported</td></tr><tr><td>Transformer</td><td style="text-align:center;">supported</td><td style="text-align:center;">supported</td></tr><tr><td>RNNLM integration</td><td style="text-align:center;">supported</td><td style="text-align:center;">supported</td></tr><tr><td>#Attention types</td><td style="text-align:center;">3 (no attention, dot, location)</td><td style="text-align:center;">12 including variants of multihead</td></tr><tr><td>TTS recipe support</td><td style="text-align:center;">no support</td><td style="text-align:center;">supported</td></tr></tbody></table></div><!----><footer class="vp-page-meta"><!----><div class="vp-meta-item git-info"><!----><!----></div></footer><!----><!----><!----><!--]--></main><!--]--><footer class="vp-footer-wrapper"><div class="vp-footer">Copyright Â© 2024 ESPnet Community. All rights reserved.</div><!----></footer></div><!--]--><!--]--><!--[--><!----><!----><!--]--><!--]--></div>
    <script type="module" src="/espnet/assets/app-B6Ithpv3.js" defer></script>
  </body>
</html>
