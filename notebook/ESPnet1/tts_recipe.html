<!doctype html>
<html lang="en-US" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.14" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.51" />
    <style>
      html {
        background: var(--bg-color, #fff);
      }

      html[data-theme="dark"] {
        background: var(--bg-color, #1d1e1f);
      }

      body {
        background: var(--bg-color);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <link rel="icon" href="/espnet/assets/image/espnet.png"><title>Text-to-Speech (Recipe)</title><meta name="description" content="A documentation for ESPnet">
    <link rel="preload" href="/espnet/assets/style-CiXYLHjk.css" as="style"><link rel="stylesheet" href="/espnet/assets/style-CiXYLHjk.css">
    <link rel="modulepreload" href="/espnet/assets/app-B6Ithpv3.js">
    
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">Skip to main content</a><!--]--><!--[--><div class="theme-container external-link-icon"><!--[--><header id="navbar" class="vp-navbar"><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!----><!--[--><a class="route-link vp-brand" href="/espnet/"><img class="vp-nav-logo" src="/espnet/assets/image/espnet_logo1.png" alt><!----><!----></a><!--]--><!----></div><div class="vp-navbar-center"><!----><!--[--><nav class="vp-nav-links"><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="Demos"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="fa-solid:laptop-code" width="1em" height="1em"></iconify-icon>Demos<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link route-link-active auto-link" href="/espnet/notebook/" aria-label="Roadmap"><!---->Roadmap<!----></a></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">ESPnet2</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/notebook/ESPnet2/Demo/" aria-label="Demo"><!---->Demo<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/notebook/ESPnet2/Course/" aria-label="Course"><!---->Course<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">ESPnet-EZ</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/notebook/ESPnetEZ/" aria-label="ESPnet EZ"><!---->ESPnet EZ<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">ESPnet1 (Legacy)</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link route-link-active auto-link" href="/espnet/notebook/ESPnet1/" aria-label="ESPnet1"><!---->ESPnet1<!----></a></li></ul></li></ul></button></div></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="Recipes"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="fa-solid:mug-hot" width="1em" height="1em"></iconify-icon>Recipes<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/" aria-label="What is a recipe template?"><!---->What is a recipe template?<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/asr1.html" aria-label="Automatic Speech Recognition (Multi-tasking)"><!---->Automatic Speech Recognition (Multi-tasking)<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/asr2.html" aria-label="Automatic Speech Recognition with Discrete Units"><!---->Automatic Speech Recognition with Discrete Units<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/asvspoof1.html" aria-label="Speaker Verification Spoofing and Countermeasures"><!---->Speaker Verification Spoofing and Countermeasures<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/codec1.html" aria-label="Speech Codec"><!---->Speech Codec<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/diar1.html" aria-label="Speaker Diarisation"><!---->Speaker Diarisation<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/enh1.html" aria-label="Speech Enhancement"><!---->Speech Enhancement<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/enh_asr1.html" aria-label="Speech Recognition with Speech Enhancement"><!---->Speech Recognition with Speech Enhancement<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/enh_diar1.html" aria-label="Speaker Diarisation with Speech Enhancement"><!---->Speaker Diarisation with Speech Enhancement<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/enh_st1.html" aria-label="Speech-to-Text Translation with Speech Enhancement"><!---->Speech-to-Text Translation with Speech Enhancement<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/lm1.html" aria-label="Language Modeling"><!---->Language Modeling<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/mt1.html" aria-label="Machine Translation"><!---->Machine Translation<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/s2st1.html" aria-label="Speech-to-Speech Translation"><!---->Speech-to-Speech Translation<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/s2t1.html" aria-label="Weakly-supervised Learning (Speech-to-Text)"><!---->Weakly-supervised Learning (Speech-to-Text)<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/slu1.html" aria-label="Spoken Language Understanding"><!---->Spoken Language Understanding<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/speechlm1.html" aria-label="Speech Language Model"><!---->Speech Language Model<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/spk1.html" aria-label="Speaker Representation"><!---->Speaker Representation<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/ssl1.html" aria-label="Self-supervised Learning"><!---->Self-supervised Learning<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/st1.html" aria-label="Speech-to-Text Translation"><!---->Speech-to-Text Translation<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/svs1.html" aria-label="Singing Voice Synthesis"><!---->Singing Voice Synthesis<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/tts1.html" aria-label="Text-to-Speech"><!---->Text-to-Speech<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/tts2.html" aria-label="Text-to-Speech with Discrete Units"><!---->Text-to-Speech with Discrete Units<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/uasr1.html" aria-label="Unsupervised Automatic Speech Recognition"><!---->Unsupervised Automatic Speech Recognition<!----></a></li></ul></button></div></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="Python API"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="fa-solid:book" width="1em" height="1em"></iconify-icon>Python API<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">espnet</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet/asr/" aria-label="asr"><!---->asr<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet/distributed/" aria-label="distributed"><!---->distributed<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet/lm/" aria-label="lm"><!---->lm<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet/mt/" aria-label="mt"><!---->mt<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet/nets/" aria-label="nets"><!---->nets<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet/optimizer/" aria-label="optimizer"><!---->optimizer<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet/scheduler/" aria-label="scheduler"><!---->scheduler<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet/st/" aria-label="st"><!---->st<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet/transform/" aria-label="transform"><!---->transform<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet/tts/" aria-label="tts"><!---->tts<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet/utils/" aria-label="utils"><!---->utils<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet/vc/" aria-label="vc"><!---->vc<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">espnet2</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/asr/" aria-label="asr"><!---->asr<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/asr_transducer/" aria-label="asr_transducer"><!---->asr_transducer<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/asvspoof/" aria-label="asvspoof"><!---->asvspoof<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/diar/" aria-label="diar"><!---->diar<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/enh/" aria-label="enh"><!---->enh<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/fileio/" aria-label="fileio"><!---->fileio<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/fst/" aria-label="fst"><!---->fst<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/gan_codec/" aria-label="gan_codec"><!---->gan_codec<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/gan_svs/" aria-label="gan_svs"><!---->gan_svs<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/gan_tts/" aria-label="gan_tts"><!---->gan_tts<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/hubert/" aria-label="hubert"><!---->hubert<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/iterators/" aria-label="iterators"><!---->iterators<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/layers/" aria-label="layers"><!---->layers<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/lm/" aria-label="lm"><!---->lm<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/main_funcs/" aria-label="main_funcs"><!---->main_funcs<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/mt/" aria-label="mt"><!---->mt<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/optimizers/" aria-label="optimizers"><!---->optimizers<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/s2st/" aria-label="s2st"><!---->s2st<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/s2t/" aria-label="s2t"><!---->s2t<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/samplers/" aria-label="samplers"><!---->samplers<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/schedulers/" aria-label="schedulers"><!---->schedulers<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/slu/" aria-label="slu"><!---->slu<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/speechlm/" aria-label="speechlm"><!---->speechlm<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/spk/" aria-label="spk"><!---->spk<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/st/" aria-label="st"><!---->st<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/svs/" aria-label="svs"><!---->svs<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/tasks/" aria-label="tasks"><!---->tasks<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/text/" aria-label="text"><!---->text<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/torch_utils/" aria-label="torch_utils"><!---->torch_utils<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/train/" aria-label="train"><!---->train<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/tts/" aria-label="tts"><!---->tts<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/tts2/" aria-label="tts2"><!---->tts2<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/uasr/" aria-label="uasr"><!---->uasr<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/utils/" aria-label="utils"><!---->utils<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">espnetez</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnetez/config/" aria-label="config"><!---->config<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnetez/data/" aria-label="data"><!---->data<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnetez/dataloader/" aria-label="dataloader"><!---->dataloader<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnetez/dataset/" aria-label="dataset"><!---->dataset<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnetez/preprocess/" aria-label="preprocess"><!---->preprocess<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnetez/task/" aria-label="task"><!---->task<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnetez/trainer/" aria-label="trainer"><!---->trainer<!----></a></li></ul></li></ul></button></div></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="Shell API"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="fa-solid:wrench" width="1em" height="1em"></iconify-icon>Shell API<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/tools/espnet2_bin/" aria-label="espnet2_bin"><!---->espnet2_bin<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/tools/espnet_bin/" aria-label="espnet_bin"><!---->espnet_bin<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/tools/spm/" aria-label="spm"><!---->spm<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/tools/utils/" aria-label="utils"><!---->utils<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/tools/utils_py/" aria-label="utils_py"><!---->utils_py<!----></a></li></ul></button></div></div></nav><!--]--><!----></div><div class="vp-navbar-end"><!----><!--[--><!----><div class="vp-nav-item vp-action"><a class="vp-action-link" href="https://github.com/espnet/espnet" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" name="github" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><!----><!--[--><button type="button" class="search-pro-button" aria-label="Search"><svg xmlns="http://www.w3.org/2000/svg" class="icon search-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="search icon" name="search"><path d="M192 480a256 256 0 1 1 512 0 256 256 0 0 1-512 0m631.776 362.496-143.2-143.168A318.464 318.464 0 0 0 768 480c0-176.736-143.264-320-320-320S128 303.264 128 480s143.264 320 320 320a318.016 318.016 0 0 0 184.16-58.592l146.336 146.368c12.512 12.48 32.768 12.48 45.28 0 12.48-12.512 12.48-32.768 0-45.28"></path></svg><div class="search-pro-placeholder">Search</div><div class="search-pro-key-hints"><kbd class="search-pro-key">Ctrl</kbd><kbd class="search-pro-key">K</kbd></div></button><!--]--><!--]--><!----><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar"><!----><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><p class="vp-sidebar-header active"><iconify-icon class="font-icon icon" style="" mode="style" inline icon="fa-solid:laptop-code" width="1em" height="1em"></iconify-icon><span class="vp-sidebar-title">Demos</span><!----></p><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/notebook/" aria-label="ESPnet Notebooks"><!---->ESPnet Notebooks<!----></a></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">ESPnet EZ</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable active" type="button"><!----><span class="vp-sidebar-title">ESPnet1</span><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/notebook/ESPnet1/tts_realtime_demo.html" aria-label="ESPnet real time E2E-TTS demonstration"><!---->ESPnet real time E2E-TTS demonstration<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/notebook/ESPnet1/st_demo.html" aria-label="ESPnet Speech Translation Demonstration"><!---->ESPnet Speech Translation Demonstration<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/notebook/ESPnet1/pretrained.html" aria-label="Pretrained Model"><!---->Pretrained Model<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/notebook/ESPnet1/asr_library.html" aria-label="Speech Recognition (Library)"><!---->Speech Recognition (Library)<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/notebook/ESPnet1/asr_recipe.html" aria-label="Speech Recognition (Recipe)"><!---->Speech Recognition (Recipe)<!----></a></li><li><a class="route-link route-link-active auto-link vp-sidebar-link active" href="/espnet/notebook/ESPnet1/tts_recipe.html" aria-label="Text-to-Speech (Recipe)"><!---->Text-to-Speech (Recipe)<!----></a></li></ul></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">ESPnet2</span><span class="vp-arrow end"></span></button><!----></section></li></ul></section></li><li><section class="vp-sidebar-group"><p class="vp-sidebar-header"><iconify-icon class="font-icon icon" style="" mode="style" inline icon="fa-solid:mug-hot" width="1em" height="1em"></iconify-icon><span class="vp-sidebar-title">Recipes</span><!----></p><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/" aria-label="Recipe Template"><!---->Recipe Template<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/asr1.html" aria-label="Automatic Speech Recognition (Multi-tasking)"><!---->Automatic Speech Recognition (Multi-tasking)<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/asr2.html" aria-label="Automatic Speech Recognition with Discrete Units"><!---->Automatic Speech Recognition with Discrete Units<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/lm1.html" aria-label="Language Modeling"><!---->Language Modeling<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/mt1.html" aria-label="Machine Translation"><!---->Machine Translation<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/ssl1.html" aria-label="Self-supervised Learning"><!---->Self-supervised Learning<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/svs1.html" aria-label="Singing Voice Synthesis"><!---->Singing Voice Synthesis<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/diar1.html" aria-label="Speaker Diarisation"><!---->Speaker Diarisation<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/enh_diar1.html" aria-label="Speaker Diarisation with Speech Enhancement"><!---->Speaker Diarisation with Speech Enhancement<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/spk1.html" aria-label="Speaker Representation"><!---->Speaker Representation<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/asvspoof1.html" aria-label="Speaker Verification Spoofing and Countermeasures"><!---->Speaker Verification Spoofing and Countermeasures<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/codec1.html" aria-label="Speech Codec"><!---->Speech Codec<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/enh1.html" aria-label="Speech Enhancement"><!---->Speech Enhancement<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/speechlm1.html" aria-label="Speech Language Model"><!---->Speech Language Model<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/enh_asr1.html" aria-label="Speech Recognition with Speech Enhancement"><!---->Speech Recognition with Speech Enhancement<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/s2st1.html" aria-label="Speech-to-Speech Translation"><!---->Speech-to-Speech Translation<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/st1.html" aria-label="Speech-to-Text Translation"><!---->Speech-to-Text Translation<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/enh_st1.html" aria-label="Speech-to-Text Translation with Speech Enhancement"><!---->Speech-to-Text Translation with Speech Enhancement<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/slu1.html" aria-label="Spoken Language Understanding"><!---->Spoken Language Understanding<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/tts1.html" aria-label="Text-to-Speech"><!---->Text-to-Speech<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/tts2.html" aria-label="Text-to-Speech with Discrete Units"><!---->Text-to-Speech with Discrete Units<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/uasr1.html" aria-label="Unsupervised Automatic Speech Recognition"><!---->Unsupervised Automatic Speech Recognition<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/s2t1.html" aria-label="Weakly-supervised Learning (Speech-to-Text)"><!---->Weakly-supervised Learning (Speech-to-Text)<!----></a></li></ul></section></li><li><section class="vp-sidebar-group"><p class="vp-sidebar-header"><iconify-icon class="font-icon icon" style="" mode="style" inline icon="fa-solid:book" width="1em" height="1em"></iconify-icon><span class="vp-sidebar-title">Python API</span><!----></p><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Espnet</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Espnet2</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Espnetez</span><span class="vp-arrow end"></span></button><!----></section></li></ul></section></li><li><section class="vp-sidebar-group"><p class="vp-sidebar-header"><iconify-icon class="font-icon icon" style="" mode="style" inline icon="fa-solid:wrench" width="1em" height="1em"></iconify-icon><span class="vp-sidebar-title">Shell API</span><!----></p><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Espnet Bin</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Espnet2 Bin</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Spm</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Utils</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Utils Py</span><span class="vp-arrow end"></span></button><!----></section></li></ul></section></li></ul><!----></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!----><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><!---->Text-to-Speech (Recipe)</h1><div class="page-info"><!----><!----><!----><!----><span class="page-reading-time-info" aria-label="Reading TimeâŒ›" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon" name="timer"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>About 5 min</span><meta property="timeRequired" content="PT5M"></span><!----><!----></div><hr></div><!----><!----><div class="theme-hope-content"><h1 id="text-to-speech-recipe" tabindex="-1"><a class="header-anchor" href="#text-to-speech-recipe"><span>Text-to-Speech (Recipe)</span></a></h1><p>This is the example notebook of how-to-run the ESPnet TTS recipe using an4 dataset.<br> You can understand the overview of TTS recipe through this notebook within an hour!</p><p>See also:</p><ul><li>Documentaion: <a href="https://espnet.github.io/espnet" target="_blank" rel="noopener noreferrer">https://espnet.github.io/espnet</a></li><li>Github: <a href="https://github.com/espnet" target="_blank" rel="noopener noreferrer">https://github.com/espnet</a></li></ul><p>Author: <a href="https://github.com/kan-bayashi" target="_blank" rel="noopener noreferrer">Tomoki Hayashi</a></p><p>Last update: 2019/07/25</p><h2 id="setup-envrionment" tabindex="-1"><a class="header-anchor" href="#setup-envrionment"><span>Setup envrionment</span></a></h2><p>First, let&#39;s setup the environmet to run the recipe.<br> It take around 10 minues. Please keep waiting for a while.</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span># OS setup</span></span>
<span class="line"><span>!sudo apt-get install bc tree</span></span>
<span class="line"><span>!cat /etc/os-release</span></span>
<span class="line"><span></span></span>
<span class="line"><span># espnet setup</span></span>
<span class="line"><span>!git clone https://github.com/espnet/espnet</span></span>
<span class="line"><span>!cd espnet; pip install -e .</span></span>
<span class="line"><span></span></span>
<span class="line"><span># warp ctc setup</span></span>
<span class="line"><span>!git clone https://github.com/espnet/warp-ctc -b pytorch-1.1</span></span>
<span class="line"><span>!cd warp-ctc &amp;&amp; mkdir build &amp;&amp; cd build &amp;&amp; cmake .. &amp;&amp; make -j</span></span>
<span class="line"><span>!cd warp-ctc/pytorch_binding &amp;&amp; python setup.py install </span></span>
<span class="line"><span></span></span>
<span class="line"><span># kaldi setup</span></span>
<span class="line"><span>!cd /content/espnet/tools; git clone https://github.com/kaldi-asr/kaldi</span></span>
<span class="line"><span>!echo &quot;&quot; &gt; ./espnet/tools/kaldi/tools/extras/check_dependencies.sh # ignore check</span></span>
<span class="line"><span>!chmod +x ./espnet/tools/kaldi/tools/extras/check_dependencies.sh</span></span>
<span class="line"><span>!cd ./espnet/tools/kaldi/tools; make sph2pipe sclite</span></span>
<span class="line"><span>!rm -rf espnet/tools/kaldi/tools/python</span></span>
<span class="line"><span>!wget https://18-198329952-gh.circle-artifacts.com/0/home/circleci/repo/ubuntu16-featbin.tar.gz</span></span>
<span class="line"><span>!tar -xf ./ubuntu16-featbin.tar.gz # take a few minutes</span></span>
<span class="line"><span>!cp featbin/* espnet/tools/kaldi/src/featbin/</span></span>
<span class="line"><span></span></span>
<span class="line"><span># make dummy activate</span></span>
<span class="line"><span>!mkdir -p espnet/tools/venv/bin</span></span>
<span class="line"><span>!touch espnet/tools/venv/bin/activate</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="run-the-recipe" tabindex="-1"><a class="header-anchor" href="#run-the-recipe"><span>Run the recipe</span></a></h2><p>Now ready to run the recipe!<br> We use the most simplest recipe <code>egs/an4/tts1</code> as an example.</p><blockquote><p>Unfortunately, <code>egs/an4/tts1</code> is too small to generate reasonable speech.<br> But you can understand the flow or TTS recipe through this recipe since all of the TTS recipes has the exactly same flow.</p></blockquote><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span># Let&#39;s go to an4 recipe!</span></span>
<span class="line"><span>import os</span></span>
<span class="line"><span>os.chdir(&quot;/content/espnet/egs/an4/tts1&quot;)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>Before running the recipe, let us check the recipe structure.</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span>!tree -L 1</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>Each recipe has the same structure and files.</p><ul><li><strong>run.sh</strong>: Main script of the recipe. Once you run this script, all of the processing will be conducted from data download, preparation, feature extraction, training, and decoding.</li><li><strong>cmd.sh</strong>: Command configuration source file about how-to-run each processing. You can modify this script if you want to run the script through job control system e.g. Slurm or Torque.</li><li><strong>path.sh</strong>: Path configuration source file. Basically, we do not have to touch.</li><li><strong>conf/</strong>: Directory containing configuration files.</li><li><strong>local/</strong>: Directory containing the recipe-specific scripts e.g. data preparation.</li><li><strong>steps/</strong> and <strong>utils/</strong>: Directory containing kaldi tools.</li></ul><p>Main script <strong>run.sh</strong> consists of several stages:</p><ul><li><strong>stage -1</strong>: Download data if the data is available online.</li><li><strong>stage 0</strong>: Prepare data to make kaldi-stype data directory.</li><li><strong>stage 1</strong>: Extract feature vector, calculate statistics, and perform normalization.</li><li><strong>stage 2</strong>: Prepare a dictionary and make json files for training.</li><li><strong>stage 3</strong>: Train the E2E-TTS network.</li><li><strong>stage 4</strong>: Decode mel-spectrogram using the trained network.</li><li><strong>stage 5</strong>: Generate a waveform from a generated mel-spectrogram using Griffin-Lim.</li></ul><p>Currently, we support the following networks:</p><ul><li>Tacotron2: <a href="https://arxiv.org/abs/1712.05884" target="_blank" rel="noopener noreferrer">Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions</a></li><li>Transformer: <a href="https://arxiv.org/pdf/1809.08895.pdf" target="_blank" rel="noopener noreferrer">Neural Speech Synthesis with Transformer Network</a></li><li>FastSpeech: <a href="https://arxiv.org/pdf/1905.09263.pdf" target="_blank" rel="noopener noreferrer">FastSpeech: Fast, Robust and Controllable Text to Speech</a></li></ul><p>Let us check each stage step-by-step via <strong>--stage</strong> and <strong>--stop_stage</strong> options!</p><h3 id="stage-1-data-download" tabindex="-1"><a class="header-anchor" href="#stage-1-data-download"><span>Stage -1: Data download</span></a></h3><p>This stage downloads dataset if the dataset is available online.</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span>!./run.sh --stage -1 --stop_stage -1</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span>!tree -L 1</span></span>
<span class="line"><span>!ls downloads/</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><p>You can see <strong>downloads</strong> directory is cretead, which containing donwloaded an4 dataset.</p><h3 id="stage-0-data-preparation" tabindex="-1"><a class="header-anchor" href="#stage-0-data-preparation"><span>Stage 0: Data preparation</span></a></h3><p>This stage creates kaldi-style data directories.</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span>!./run.sh --stage 0 --stop_stage 0</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span>!tree -L 1 data</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>Through the data preparation stage, kaldi-style data directories will be created.<br> Here, <strong>data/train/</strong> is corresponding to training set, and <strong>data/test</strong> is corresponding to evaluation set.<br> Each directory has the same following files:</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span>!ls data/*</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>The above four files are all we have to prepare to create new recipes.<br> Let&#39;s check each file.</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span>!head -n 3 data/train/{wav.scp,text,utt2spk,spk2utt}</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>Each file contains the following information:</p><ul><li><strong>wav.scp</strong>: List of audio path. Each line has <code>&lt;utt_id&gt; &lt;wavfile_path or command pipe&gt;</code>. <code>&lt;utt_id&gt;</code> must be unique.</li><li><strong>text</strong>: List of transcriptions. Each line has <code>&lt;utt_id&gt; &lt;transcription&gt;</code>. In the case of TTS, we assume that <code>&lt;transcription&gt;</code> is cleaned.</li><li><strong>utt2spk</strong>: List of correspondence table between utterances and speakers. Each line has <code>&lt;utt_id&gt; &lt;speaker_id&gt;</code>.</li><li><strong>spk2utt</strong>: List of correspondence table between speakers and utterances. Each lien has <code>&lt;speaker_id&gt; &lt;utt_id&gt; ... &lt;utt_id&gt; </code>. This file can be automatically created from <strong>utt2spk</strong>.</li></ul><p>In the ESPnet, speaker information is not used for any processing.<br> Therefore, <strong>utt2spk</strong> and <strong>spk2utt</strong> can be a dummy.</p><h3 id="stage-1-feature-extration" tabindex="-1"><a class="header-anchor" href="#stage-1-feature-extration"><span>Stage 1: Feature extration</span></a></h3><p>This stage performs the following processing:</p><ol><li>Mel-spectrogram extraction</li><li>Data split into training and validation set</li><li>Statistics (mean and variance) calculation</li><li>Normalization</li></ol><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span>!./run.sh --stage 1 --stop_stage 1 --nj 4</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>Raw filterbanks are saved in <strong>fbank/</strong> directory with ark/scp format.</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span>!ls fbank</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p><strong>.ark</strong> is binary file and <strong>.scp</strong> contain the correspondence between <code>&lt;utt_id&gt;</code> and <code>&lt;path_in_ark&gt;</code>.<br> Since feature extraction can be performed for split small sets in parallel, raw_fbank is split into <code>raw_fbank_*.{1..N}.{scp,ark}.</code></p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span>!head -n 3 fbank/raw_fbank_train.1.scp</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>These files can be loaded in python via <strong>kaldiio</strong> as follows:</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span>import kaldiio</span></span>
<span class="line"><span>import matplotlib.pyplot as plt</span></span>
<span class="line"><span></span></span>
<span class="line"><span># load scp file</span></span>
<span class="line"><span>scp_dict = kaldiio.load_scp(&quot;fbank/raw_fbank_train.1.scp&quot;)</span></span>
<span class="line"><span>for key in scp_dict:</span></span>
<span class="line"><span>    plt.imshow(scp_dict[key].T[::-1])</span></span>
<span class="line"><span>    plt.title(key)</span></span>
<span class="line"><span>    plt.colorbar()</span></span>
<span class="line"><span>    plt.show()</span></span>
<span class="line"><span>    break</span></span>
<span class="line"><span>    </span></span>
<span class="line"><span># load ark file</span></span>
<span class="line"><span>ark_generator = kaldiio.load_ark(&quot;fbank/raw_fbank_train.1.ark&quot;)</span></span>
<span class="line"><span>for key, array in ark_generator:</span></span>
<span class="line"><span>    plt.imshow(array.T[::-1])</span></span>
<span class="line"><span>    plt.title(key)</span></span>
<span class="line"><span>    plt.colorbar()</span></span>
<span class="line"><span>    plt.show()</span></span>
<span class="line"><span>    break</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>After raw mel-spectrogram extraction, some files are added in <strong>data/train/</strong>.<br><strong>feats.scp</strong> is concatenated scp file of <strong>fbank/raw_fbank_train.{1..N}.scp</strong>.<br><strong>utt2num_frames</strong> has the number of feature frames of each <code>&lt;utt_id&gt;</code>.</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span>!ls data/train</span></span>
<span class="line"><span>!head -n 3 data/train/{feats.scp,utt2num_frames}</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><p>And <strong>data/train/</strong> directory is split into two directory:</p><ul><li><strong>data/train_nodev/</strong>: data directory for training</li><li><strong>data/train_dev/</strong>: data directory for validation</li></ul><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span>!ls data</span></span>
<span class="line"><span>!ls data/train_*</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><p>You can find <strong>cmvn.ark</strong> in <strong>data/train_nodev</strong>, which is the calculated statistics file.<br> This file also can be loaded in python via kaldiio.</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span># load cmvn.ark file (Be careful not load_ark, but load_mat)</span></span>
<span class="line"><span>cmvn = kaldiio.load_mat(&quot;data/train_nodev/cmvn.ark&quot;)</span></span>
<span class="line"><span></span></span>
<span class="line"><span># cmvn consists of mean and variance, the last dimension of mean represents the number of frames.</span></span>
<span class="line"><span>print(&quot;cmvn shape = &quot;+ str(cmvn.shape))</span></span>
<span class="line"><span></span></span>
<span class="line"><span># calculate mean and variance</span></span>
<span class="line"><span>mu = cmvn[0, :-1] / cmvn[0, -1]</span></span>
<span class="line"><span>var = cmvn[1, :-1] / cmvn[0, -1]</span></span>
<span class="line"><span></span></span>
<span class="line"><span># show mean</span></span>
<span class="line"><span>print(&quot;mean = &quot; + str(mu))</span></span>
<span class="line"><span>print(&quot;variance = &quot; + str(var))</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>Normalzed features for training, validation and evaluation set are dumped in <strong>dump/{train_nodev,train_dev,test}/</strong>.<br> There ark and scp can be loaded as the same as the above procedure.</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span>!ls dump/*</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h3 id="stage-2-dictionary-and-json-preparation" tabindex="-1"><a class="header-anchor" href="#stage-2-dictionary-and-json-preparation"><span>Stage 2: Dictionary and json preparation</span></a></h3><p>This stage creates dictrionary from <strong>data/train_nodev/text</strong> and makes json file for training.</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span>!./run.sh --stage 2 --stop_stage 2</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>Dictrionary file will be created in <strong>data/lang_1char/</strong>.<br> Dictionary file consists of <code>&lt;token&gt;</code> <code>&lt;token index&gt;</code>.<br> Here, <code>&lt;token index&gt;</code> starts from 1 because 0 is used as padding index.</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span>!ls data</span></span>
<span class="line"><span>!cat data/lang_1char/train_nodev_units.txt</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><p>Json file will be created for training / validation /evaludation sets and they are saved as <strong>dump/{train_nodev,train_dev,test}/data.json</strong>.</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span>!ls dump/*/*.json</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>Each json file contains all of the information in the data directory.</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span>!head -n 27 dump/train_nodev/data.json</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><ul><li>&quot;shape&quot;: Shape of the input or output sequence. Here input shape [63, 80] represents the number of frames = 63 and the dimension of mel-spectrogram = 80.</li><li>&quot;text&quot;: Original transcription.</li><li>&quot;token&quot;: Token sequence of original transcription.</li><li>&quot;tokenid&quot; Token id sequence of original transcription, which is converted using the dictionary.</li></ul><p>Now ready to start training!</p><h3 id="stage-3-network-training" tabindex="-1"><a class="header-anchor" href="#stage-3-network-training"><span>Stage 3: Network training</span></a></h3><p>This stage performs training of the network.<br> Network training configurations are written as <strong>.yaml</strong> format file.<br> Let us check the default cofiguration <strong>conf/train_pytroch_tacotron2.yaml</strong>.</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span>!cat conf/train_pytorch_tacotron2.yaml</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>You can modify this configuration file to change the hyperparameters.<br> Here, let&#39;s change the number of epochs for this demonstration.</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span># TODO(kan-bayashi): Change here to use change_yaml.py</span></span>
<span class="line"><span>!cat conf/train_pytorch_tacotron2.yaml | sed -e &quot;s/epochs: 50/epochs: 3/g&quot; &gt; conf/train_pytorch_tacotron2_sample.yaml</span></span>
<span class="line"><span>!cat conf/train_pytorch_tacotron2_sample.yaml</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>Let&#39;s train the network.<br> You can specify the config file via <strong>--train_config</strong> option. It takes several minutes.</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span>!./run.sh --stage 3 --stop_stage 3 --train_config conf/train_pytorch_tacotron2_sample.yaml --verbose 1</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>You can see the training log in <code>exp/train_*/train.log</code>.</p><p>The models are saved in <code>exp/train_*/results/</code> directory.</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span>!ls exp/train_nodev_pytorch_train_pytorch_tacotron2_sample/{results,results/att_ws}</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p><code>exp/train_*/results/*.png</code> are the figures of training curve.</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span>from IPython.display import Image, display_png</span></span>
<span class="line"><span>print(&quot;all loss curve&quot;)</span></span>
<span class="line"><span>display_png(Image(&quot;exp/train_nodev_pytorch_train_pytorch_tacotron2_sample/results/all_loss.png&quot;))</span></span>
<span class="line"><span>print(&quot;l1 loss curve&quot;)</span></span>
<span class="line"><span>display_png(Image(&quot;exp/train_nodev_pytorch_train_pytorch_tacotron2_sample/results/l1_loss.png&quot;))</span></span>
<span class="line"><span>print(&quot;mse loss curve&quot;)</span></span>
<span class="line"><span>display_png(Image(&quot;exp/train_nodev_pytorch_train_pytorch_tacotron2_sample/results/mse_loss.png&quot;))</span></span>
<span class="line"><span>print(&quot;bce loss curve&quot;)</span></span>
<span class="line"><span>display_png(Image(&quot;exp/train_nodev_pytorch_train_pytorch_tacotron2_sample/results/bce_loss.png&quot;))</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><code>exp/train_*/results/att_ws/.png</code> are the figures of attention weights in each epoch.</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span>print(&quot;Attention weights of initial epoch&quot;)</span></span>
<span class="line"><span>display_png(Image(&quot;exp/train_nodev_pytorch_train_pytorch_tacotron2_sample/results/att_ws/fash-cen1-b.ep.1.png&quot;))</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><p><code>exp/train_*/results/model.loss.best</code> contains only the model parameters.<br> On the other hand, <code>exp/train_*/results/snapshot</code> contains the model parameters, optimizer states, and iterator states.<br> So you can restart from the training by specifying the snapshot file with <strong>--resume</strong> option.</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span># resume training from snapshot.ep.2</span></span>
<span class="line"><span>!./run.sh --stage 3 --stop_stage 3 --train_config conf/train_pytorch_tacotron2_sample.yaml --resume exp/train_nodev_pytorch_train_pytorch_tacotron2_sample/results/snapshot.ep.2 --verbose 1</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span>!cat exp/train_nodev_pytorch_train_pytorch_tacotron2_sample/train.log</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>Also, we support tensorboard.<br> You can see the training log through tensorboard.</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span>%load_ext tensorboard</span></span>
<span class="line"><span>%tensorboard --logdir tensorboard/train_nodev_pytorch_train_pytorch_tacotron2_sample/</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="stage-4-network-decoding" tabindex="-1"><a class="header-anchor" href="#stage-4-network-decoding"><span>Stage 4: Network decoding</span></a></h3><p>This stage performs decoding using the trained model to generate mel-spectrogram from a given text.</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span>!./run.sh --stage 4 --stop_stage 4 --nj 8 --train_config conf/train_pytorch_tacotron2_sample.yaml</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>Generated features are saved as ark/scp format.</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span>!ls exp/train_nodev_pytorch_train_pytorch_tacotron2_sample/outputs_model.loss.best_decode/*</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>We can specify the model or snapshot to be used for decoding via <strong>--model</strong>.</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span>!./run.sh --stage 4 --stop_stage 4 --nj 8 --train_config conf/train_pytorch_tacotron2_sample.yaml --model snapshot.ep.2</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span>!ls exp/train_nodev_pytorch_train_pytorch_tacotron2_sample/outputs_snapshot.ep.2_decode/*</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h3 id="stage-5-waveform-synthesis" tabindex="-1"><a class="header-anchor" href="#stage-5-waveform-synthesis"><span>Stage 5: Waveform synthesis</span></a></h3><p>Finally, in this stage, we generate waveform using Grrifin-Lim algorithm.<br> First, we perform de-normalization to convert the generated mel-spectrogram into the original scale.<br> Then we apply Grrifin-Lim algorithm to restore phase components and apply inverse STFT to generate waveforms.</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span>!./run.sh --stage 5 --stop_stage 5 --nj 8 --train_config conf/train_pytorch_tacotron2_sample.yaml --griffin_lim_iters 50</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>Generated wav files are saved in <code>exp/train_nodev_pytorch_train_pytorch_tacotron2_sample/outputs_model.loss.best_decode_denorm/*/wav</code></p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span>!ls exp/train_nodev_pytorch_train_pytorch_tacotron2_sample/outputs_model.loss.best_decode_denorm/*/wav</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span>!tree -L 3</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h2 id="next-step" tabindex="-1"><a class="header-anchor" href="#next-step"><span>NEXT step</span></a></h2><ul><li>Try pretrained model to generate speech.</li><li>Try a large single speaker dataset recipe <strong>egs/ljspeech/tts1</strong>.</li><li>Try a large multi-speaker recipe <strong>egs/libritts/tts1</strong>.</li><li>Make the original recipe using your own dataset.</li></ul></div><!----><footer class="vp-page-meta"><!----><div class="vp-meta-item git-info"><!----><!----></div></footer><nav class="vp-page-nav"><a class="route-link auto-link prev" href="/espnet/notebook/ESPnet1/asr_recipe.html" aria-label="Speech Recognition (Recipe)"><div class="hint"><span class="arrow start"></span>Prev</div><div class="link"><!---->Speech Recognition (Recipe)</div></a><!----></nav><!----><!----><!--]--></main><!--]--><footer class="vp-footer-wrapper"><div class="vp-footer">Copyright Â© 2024 ESPnet Community. All rights reserved.</div><!----></footer></div><!--]--><!--]--><!--[--><!----><!----><!--]--><!--]--></div>
    <script type="module" src="/espnet/assets/app-B6Ithpv3.js" defer></script>
  </body>
</html>
