<!doctype html>
<html lang="en-US" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.14" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.51" />
    <style>
      html {
        background: var(--bg-color, #fff);
      }

      html[data-theme="dark"] {
        background: var(--bg-color, #1d1e1f);
      }

      body {
        background: var(--bg-color);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <link rel="icon" href="/espnet/assets/image/espnet.png"><title>ESPnet real time E2E-TTS demonstration</title><meta name="description" content="A documentation for ESPnet">
    <link rel="preload" href="/espnet/assets/style-CiXYLHjk.css" as="style"><link rel="stylesheet" href="/espnet/assets/style-CiXYLHjk.css">
    <link rel="modulepreload" href="/espnet/assets/app-B6Ithpv3.js">
    
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">Skip to main content</a><!--]--><!--[--><div class="theme-container external-link-icon"><!--[--><header id="navbar" class="vp-navbar"><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!----><!--[--><a class="route-link vp-brand" href="/espnet/"><img class="vp-nav-logo" src="/espnet/assets/image/espnet_logo1.png" alt><!----><!----></a><!--]--><!----></div><div class="vp-navbar-center"><!----><!--[--><nav class="vp-nav-links"><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="Demos"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="fa-solid:laptop-code" width="1em" height="1em"></iconify-icon>Demos<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link route-link-active auto-link" href="/espnet/notebook/" aria-label="Roadmap"><!---->Roadmap<!----></a></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">ESPnet2</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/notebook/ESPnet2/Demo/" aria-label="Demo"><!---->Demo<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/notebook/ESPnet2/Course/" aria-label="Course"><!---->Course<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">ESPnet-EZ</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/notebook/ESPnetEZ/" aria-label="ESPnet EZ"><!---->ESPnet EZ<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">ESPnet1 (Legacy)</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link route-link-active auto-link" href="/espnet/notebook/ESPnet1/" aria-label="ESPnet1"><!---->ESPnet1<!----></a></li></ul></li></ul></button></div></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="Recipes"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="fa-solid:mug-hot" width="1em" height="1em"></iconify-icon>Recipes<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/" aria-label="What is a recipe template?"><!---->What is a recipe template?<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/asr1.html" aria-label="Automatic Speech Recognition (Multi-tasking)"><!---->Automatic Speech Recognition (Multi-tasking)<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/asr2.html" aria-label="Automatic Speech Recognition with Discrete Units"><!---->Automatic Speech Recognition with Discrete Units<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/asvspoof1.html" aria-label="Speaker Verification Spoofing and Countermeasures"><!---->Speaker Verification Spoofing and Countermeasures<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/codec1.html" aria-label="Speech Codec"><!---->Speech Codec<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/diar1.html" aria-label="Speaker Diarisation"><!---->Speaker Diarisation<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/enh1.html" aria-label="Speech Enhancement"><!---->Speech Enhancement<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/enh_asr1.html" aria-label="Speech Recognition with Speech Enhancement"><!---->Speech Recognition with Speech Enhancement<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/enh_diar1.html" aria-label="Speaker Diarisation with Speech Enhancement"><!---->Speaker Diarisation with Speech Enhancement<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/enh_st1.html" aria-label="Speech-to-Text Translation with Speech Enhancement"><!---->Speech-to-Text Translation with Speech Enhancement<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/lm1.html" aria-label="Language Modeling"><!---->Language Modeling<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/mt1.html" aria-label="Machine Translation"><!---->Machine Translation<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/s2st1.html" aria-label="Speech-to-Speech Translation"><!---->Speech-to-Speech Translation<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/s2t1.html" aria-label="Weakly-supervised Learning (Speech-to-Text)"><!---->Weakly-supervised Learning (Speech-to-Text)<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/slu1.html" aria-label="Spoken Language Understanding"><!---->Spoken Language Understanding<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/speechlm1.html" aria-label="Speech Language Model"><!---->Speech Language Model<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/spk1.html" aria-label="Speaker Representation"><!---->Speaker Representation<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/ssl1.html" aria-label="Self-supervised Learning"><!---->Self-supervised Learning<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/st1.html" aria-label="Speech-to-Text Translation"><!---->Speech-to-Text Translation<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/svs1.html" aria-label="Singing Voice Synthesis"><!---->Singing Voice Synthesis<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/tts1.html" aria-label="Text-to-Speech"><!---->Text-to-Speech<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/tts2.html" aria-label="Text-to-Speech with Discrete Units"><!---->Text-to-Speech with Discrete Units<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/uasr1.html" aria-label="Unsupervised Automatic Speech Recognition"><!---->Unsupervised Automatic Speech Recognition<!----></a></li></ul></button></div></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="Python API"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="fa-solid:book" width="1em" height="1em"></iconify-icon>Python API<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">espnet</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet/asr/" aria-label="asr"><!---->asr<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet/distributed/" aria-label="distributed"><!---->distributed<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet/lm/" aria-label="lm"><!---->lm<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet/mt/" aria-label="mt"><!---->mt<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet/nets/" aria-label="nets"><!---->nets<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet/optimizer/" aria-label="optimizer"><!---->optimizer<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet/scheduler/" aria-label="scheduler"><!---->scheduler<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet/st/" aria-label="st"><!---->st<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet/transform/" aria-label="transform"><!---->transform<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet/tts/" aria-label="tts"><!---->tts<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet/utils/" aria-label="utils"><!---->utils<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet/vc/" aria-label="vc"><!---->vc<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">espnet2</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/asr/" aria-label="asr"><!---->asr<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/asr_transducer/" aria-label="asr_transducer"><!---->asr_transducer<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/asvspoof/" aria-label="asvspoof"><!---->asvspoof<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/diar/" aria-label="diar"><!---->diar<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/enh/" aria-label="enh"><!---->enh<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/fileio/" aria-label="fileio"><!---->fileio<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/fst/" aria-label="fst"><!---->fst<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/gan_codec/" aria-label="gan_codec"><!---->gan_codec<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/gan_svs/" aria-label="gan_svs"><!---->gan_svs<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/gan_tts/" aria-label="gan_tts"><!---->gan_tts<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/hubert/" aria-label="hubert"><!---->hubert<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/iterators/" aria-label="iterators"><!---->iterators<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/layers/" aria-label="layers"><!---->layers<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/lm/" aria-label="lm"><!---->lm<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/main_funcs/" aria-label="main_funcs"><!---->main_funcs<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/mt/" aria-label="mt"><!---->mt<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/optimizers/" aria-label="optimizers"><!---->optimizers<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/s2st/" aria-label="s2st"><!---->s2st<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/s2t/" aria-label="s2t"><!---->s2t<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/samplers/" aria-label="samplers"><!---->samplers<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/schedulers/" aria-label="schedulers"><!---->schedulers<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/slu/" aria-label="slu"><!---->slu<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/speechlm/" aria-label="speechlm"><!---->speechlm<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/spk/" aria-label="spk"><!---->spk<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/st/" aria-label="st"><!---->st<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/svs/" aria-label="svs"><!---->svs<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/tasks/" aria-label="tasks"><!---->tasks<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/text/" aria-label="text"><!---->text<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/torch_utils/" aria-label="torch_utils"><!---->torch_utils<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/train/" aria-label="train"><!---->train<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/tts/" aria-label="tts"><!---->tts<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/tts2/" aria-label="tts2"><!---->tts2<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/uasr/" aria-label="uasr"><!---->uasr<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/utils/" aria-label="utils"><!---->utils<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">espnetez</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnetez/config/" aria-label="config"><!---->config<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnetez/data/" aria-label="data"><!---->data<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnetez/dataloader/" aria-label="dataloader"><!---->dataloader<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnetez/dataset/" aria-label="dataset"><!---->dataset<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnetez/preprocess/" aria-label="preprocess"><!---->preprocess<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnetez/task/" aria-label="task"><!---->task<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnetez/trainer/" aria-label="trainer"><!---->trainer<!----></a></li></ul></li></ul></button></div></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="Shell API"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="fa-solid:wrench" width="1em" height="1em"></iconify-icon>Shell API<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/tools/espnet2_bin/" aria-label="espnet2_bin"><!---->espnet2_bin<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/tools/espnet_bin/" aria-label="espnet_bin"><!---->espnet_bin<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/tools/spm/" aria-label="spm"><!---->spm<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/tools/utils/" aria-label="utils"><!---->utils<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/tools/utils_py/" aria-label="utils_py"><!---->utils_py<!----></a></li></ul></button></div></div></nav><!--]--><!----></div><div class="vp-navbar-end"><!----><!--[--><!----><div class="vp-nav-item vp-action"><a class="vp-action-link" href="https://github.com/espnet/espnet" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" name="github" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><!----><!--[--><button type="button" class="search-pro-button" aria-label="Search"><svg xmlns="http://www.w3.org/2000/svg" class="icon search-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="search icon" name="search"><path d="M192 480a256 256 0 1 1 512 0 256 256 0 0 1-512 0m631.776 362.496-143.2-143.168A318.464 318.464 0 0 0 768 480c0-176.736-143.264-320-320-320S128 303.264 128 480s143.264 320 320 320a318.016 318.016 0 0 0 184.16-58.592l146.336 146.368c12.512 12.48 32.768 12.48 45.28 0 12.48-12.512 12.48-32.768 0-45.28"></path></svg><div class="search-pro-placeholder">Search</div><div class="search-pro-key-hints"><kbd class="search-pro-key">Ctrl</kbd><kbd class="search-pro-key">K</kbd></div></button><!--]--><!--]--><!----><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar"><!----><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><p class="vp-sidebar-header active"><iconify-icon class="font-icon icon" style="" mode="style" inline icon="fa-solid:laptop-code" width="1em" height="1em"></iconify-icon><span class="vp-sidebar-title">Demos</span><!----></p><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/notebook/" aria-label="ESPnet Notebooks"><!---->ESPnet Notebooks<!----></a></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">ESPnet EZ</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable active" type="button"><!----><span class="vp-sidebar-title">ESPnet1</span><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><a class="route-link route-link-active auto-link vp-sidebar-link active" href="/espnet/notebook/ESPnet1/tts_realtime_demo.html" aria-label="ESPnet real time E2E-TTS demonstration"><!---->ESPnet real time E2E-TTS demonstration<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/notebook/ESPnet1/st_demo.html" aria-label="ESPnet Speech Translation Demonstration"><!---->ESPnet Speech Translation Demonstration<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/notebook/ESPnet1/pretrained.html" aria-label="Pretrained Model"><!---->Pretrained Model<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/notebook/ESPnet1/asr_library.html" aria-label="Speech Recognition (Library)"><!---->Speech Recognition (Library)<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/notebook/ESPnet1/asr_recipe.html" aria-label="Speech Recognition (Recipe)"><!---->Speech Recognition (Recipe)<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/notebook/ESPnet1/tts_recipe.html" aria-label="Text-to-Speech (Recipe)"><!---->Text-to-Speech (Recipe)<!----></a></li></ul></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">ESPnet2</span><span class="vp-arrow end"></span></button><!----></section></li></ul></section></li><li><section class="vp-sidebar-group"><p class="vp-sidebar-header"><iconify-icon class="font-icon icon" style="" mode="style" inline icon="fa-solid:mug-hot" width="1em" height="1em"></iconify-icon><span class="vp-sidebar-title">Recipes</span><!----></p><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/" aria-label="Recipe Template"><!---->Recipe Template<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/asr1.html" aria-label="Automatic Speech Recognition (Multi-tasking)"><!---->Automatic Speech Recognition (Multi-tasking)<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/asr2.html" aria-label="Automatic Speech Recognition with Discrete Units"><!---->Automatic Speech Recognition with Discrete Units<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/lm1.html" aria-label="Language Modeling"><!---->Language Modeling<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/mt1.html" aria-label="Machine Translation"><!---->Machine Translation<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/ssl1.html" aria-label="Self-supervised Learning"><!---->Self-supervised Learning<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/svs1.html" aria-label="Singing Voice Synthesis"><!---->Singing Voice Synthesis<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/diar1.html" aria-label="Speaker Diarisation"><!---->Speaker Diarisation<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/enh_diar1.html" aria-label="Speaker Diarisation with Speech Enhancement"><!---->Speaker Diarisation with Speech Enhancement<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/spk1.html" aria-label="Speaker Representation"><!---->Speaker Representation<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/asvspoof1.html" aria-label="Speaker Verification Spoofing and Countermeasures"><!---->Speaker Verification Spoofing and Countermeasures<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/codec1.html" aria-label="Speech Codec"><!---->Speech Codec<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/enh1.html" aria-label="Speech Enhancement"><!---->Speech Enhancement<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/speechlm1.html" aria-label="Speech Language Model"><!---->Speech Language Model<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/enh_asr1.html" aria-label="Speech Recognition with Speech Enhancement"><!---->Speech Recognition with Speech Enhancement<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/s2st1.html" aria-label="Speech-to-Speech Translation"><!---->Speech-to-Speech Translation<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/st1.html" aria-label="Speech-to-Text Translation"><!---->Speech-to-Text Translation<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/enh_st1.html" aria-label="Speech-to-Text Translation with Speech Enhancement"><!---->Speech-to-Text Translation with Speech Enhancement<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/slu1.html" aria-label="Spoken Language Understanding"><!---->Spoken Language Understanding<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/tts1.html" aria-label="Text-to-Speech"><!---->Text-to-Speech<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/tts2.html" aria-label="Text-to-Speech with Discrete Units"><!---->Text-to-Speech with Discrete Units<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/uasr1.html" aria-label="Unsupervised Automatic Speech Recognition"><!---->Unsupervised Automatic Speech Recognition<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/s2t1.html" aria-label="Weakly-supervised Learning (Speech-to-Text)"><!---->Weakly-supervised Learning (Speech-to-Text)<!----></a></li></ul></section></li><li><section class="vp-sidebar-group"><p class="vp-sidebar-header"><iconify-icon class="font-icon icon" style="" mode="style" inline icon="fa-solid:book" width="1em" height="1em"></iconify-icon><span class="vp-sidebar-title">Python API</span><!----></p><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Espnet</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Espnet2</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Espnetez</span><span class="vp-arrow end"></span></button><!----></section></li></ul></section></li><li><section class="vp-sidebar-group"><p class="vp-sidebar-header"><iconify-icon class="font-icon icon" style="" mode="style" inline icon="fa-solid:wrench" width="1em" height="1em"></iconify-icon><span class="vp-sidebar-title">Shell API</span><!----></p><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Espnet Bin</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Espnet2 Bin</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Spm</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Utils</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Utils Py</span><span class="vp-arrow end"></span></button><!----></section></li></ul></section></li></ul><!----></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!----><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><!---->ESPnet real time E2E-TTS demonstration</h1><div class="page-info"><!----><!----><!----><!----><span class="page-reading-time-info" aria-label="Reading TimeâŒ›" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon" name="timer"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>About 4 min</span><meta property="timeRequired" content="PT4M"></span><!----><!----></div><hr></div><!----><!----><div class="theme-hope-content"><figure><a href="https://colab.research.google.com/github/espnet/notebook/blob/master/tts_realtime_demo.ipynb" target="_blank" rel="noopener noreferrer"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" tabindex="0" loading="lazy"></a><figcaption>Open In Colab</figcaption></figure><h1 id="espnet-real-time-e2e-tts-demonstration" tabindex="-1"><a class="header-anchor" href="#espnet-real-time-e2e-tts-demonstration"><span>ESPnet real time E2E-TTS demonstration</span></a></h1><p>This notebook provides a demonstration of the realtime E2E-TTS using ESPnet-TTS and ParallelWaveGAN (+ MelGAN).</p><ul><li>ESPnet: https://github.com/espnet/espnet</li><li>ParallelWaveGAN: https://github.com/kan-bayashi/ParallelWaveGAN</li></ul><p>Author: Tomoki Hayashi (<a href="https://github.com/kan-bayashi" target="_blank" rel="noopener noreferrer">@kan-bayashi</a>)</p><h2 id="install" tabindex="-1"><a class="header-anchor" href="#install"><span>Install</span></a></h2><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span># install minimal components</span></span>
<span class="line"><span>!pip install -q parallel_wavegan PyYaml unidecode ConfigArgparse g2p_en espnet_tts_frontend</span></span>
<span class="line"><span>!pip install --upgrade --no-cache-dir gdown</span></span>
<span class="line"><span>!git clone -q https://github.com/espnet/espnet.git</span></span>
<span class="line"><span>!cd espnet &amp;&amp; git fetch &amp;&amp; git checkout -b v.0.9.1 refs/tags/v.0.9.1</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><hr><h2 id="english-demo" tabindex="-1"><a class="header-anchor" href="#english-demo"><span>English demo</span></a></h2><h3 id="download-pretrained-feature-generation-model" tabindex="-1"><a class="header-anchor" href="#download-pretrained-feature-generation-model"><span>Download pretrained feature generation model</span></a></h3><p>You can select one from three models. Please only run the seletected model cells.</p><h4 id="a-tacotron2" tabindex="-1"><a class="header-anchor" href="#a-tacotron2"><span>(a) Tacotron2</span></a></h4><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span># download pretrained model</span></span>
<span class="line"><span>import os</span></span>
<span class="line"><span>if not os.path.exists(&quot;downloads/en/tacotron2&quot;):</span></span>
<span class="line"><span>    !./espnet/utils/download_from_google_drive.sh \</span></span>
<span class="line"><span>        https://drive.google.com/open?id=1lFfeyewyOsxaNO-DEWy9iSz6qB9ZS1UR downloads/en/tacotron2 tar.gz</span></span>
<span class="line"><span></span></span>
<span class="line"><span># set path</span></span>
<span class="line"><span>trans_type = &quot;phn&quot;</span></span>
<span class="line"><span>dict_path = &quot;downloads/en/tacotron2/data/lang_1phn/phn_train_no_dev_units.txt&quot;</span></span>
<span class="line"><span>model_path = &quot;downloads/en/tacotron2/exp/phn_train_no_dev_pytorch_train_pytorch_tacotron2.v3/results/model.last1.avg.best&quot;</span></span>
<span class="line"><span></span></span>
<span class="line"><span>print(&quot;sucessfully finished download.&quot;)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="b-transformer" tabindex="-1"><a class="header-anchor" href="#b-transformer"><span>(b) Transformer</span></a></h4><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span># download pretrained model</span></span>
<span class="line"><span>import os</span></span>
<span class="line"><span>if not os.path.exists(&quot;downloads/en/transformer&quot;):</span></span>
<span class="line"><span>    !./espnet/utils/download_from_google_drive.sh \</span></span>
<span class="line"><span>        https://drive.google.com/open?id=1z8KSOWVBjK-_Ws4RxVN4NTx-Buy03-7c downloads/en/transformer tar.gz</span></span>
<span class="line"><span></span></span>
<span class="line"><span># set path</span></span>
<span class="line"><span>trans_type = &quot;phn&quot;</span></span>
<span class="line"><span>dict_path = &quot;downloads/en/transformer/data/lang_1phn/phn_train_no_dev_units.txt&quot;</span></span>
<span class="line"><span>model_path = &quot;downloads/en/transformer/exp/phn_train_no_dev_pytorch_train_pytorch_transformer.v3.single/results/model.last1.avg.best&quot;</span></span>
<span class="line"><span></span></span>
<span class="line"><span>print(&quot;sucessfully finished download.&quot;)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="c-fastspeech" tabindex="-1"><a class="header-anchor" href="#c-fastspeech"><span>(c) FastSpeech</span></a></h4><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span># download pretrained model</span></span>
<span class="line"><span>import os</span></span>
<span class="line"><span>if not os.path.exists(&quot;downloads/en/fastspeech&quot;):</span></span>
<span class="line"><span>    !./espnet/utils/download_from_google_drive.sh \</span></span>
<span class="line"><span>        https://drive.google.com/open?id=1P9I4qag8wAcJiTCPawt6WCKBqUfJFtFp downloads/en/fastspeech tar.gz</span></span>
<span class="line"><span></span></span>
<span class="line"><span># set path</span></span>
<span class="line"><span>trans_type = &quot;phn&quot;</span></span>
<span class="line"><span>dict_path = &quot;downloads/en/fastspeech/data/lang_1phn/phn_train_no_dev_units.txt&quot;</span></span>
<span class="line"><span>model_path = &quot;downloads/en/fastspeech/exp/phn_train_no_dev_pytorch_train_tacotron2.v3_fastspeech.v4.single/results/model.last1.avg.best&quot;</span></span>
<span class="line"><span></span></span>
<span class="line"><span>print(&quot;Sucessfully finished download.&quot;)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="download-pretrained-vocoder-model" tabindex="-1"><a class="header-anchor" href="#download-pretrained-vocoder-model"><span>Download pretrained vocoder model</span></a></h3><p>You can select one from two models. Please only run the seletected model cells.</p><h4 id="a-parallel-wavegan" tabindex="-1"><a class="header-anchor" href="#a-parallel-wavegan"><span>(a) Parallel WaveGAN</span></a></h4><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span># download pretrained model</span></span>
<span class="line"><span>import os</span></span>
<span class="line"><span>if not os.path.exists(&quot;downloads/en/parallel_wavegan&quot;):</span></span>
<span class="line"><span>    !./espnet/utils/download_from_google_drive.sh \</span></span>
<span class="line"><span>        https://drive.google.com/open?id=1Grn7X9wD35UcDJ5F7chwdTqTa4U7DeVB downloads/en/parallel_wavegan tar.gz</span></span>
<span class="line"><span></span></span>
<span class="line"><span># set path</span></span>
<span class="line"><span>vocoder_path = &quot;downloads/en/parallel_wavegan/ljspeech.parallel_wavegan.v2/checkpoint-400000steps.pkl&quot;</span></span>
<span class="line"><span></span></span>
<span class="line"><span>print(&quot;Sucessfully finished download.&quot;)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="b-melgan" tabindex="-1"><a class="header-anchor" href="#b-melgan"><span>(b) MelGAN</span></a></h4><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span># download pretrained model</span></span>
<span class="line"><span>import os</span></span>
<span class="line"><span>if not os.path.exists(&quot;downloads/en/melgan&quot;):</span></span>
<span class="line"><span>    !./espnet/utils/download_from_google_drive.sh \</span></span>
<span class="line"><span>        https://drive.google.com/open?id=1_a8faVA5OGCzIcJNw4blQYjfG4oA9VEt downloads/en/melgan tar.gz</span></span>
<span class="line"><span></span></span>
<span class="line"><span># set path</span></span>
<span class="line"><span>vocoder_path = &quot;downloads/en/melgan/train_nodev_ljspeech_melgan.v3.long/checkpoint-4000000steps.pkl&quot;</span></span>
<span class="line"><span></span></span>
<span class="line"><span>print(&quot;Sucessfully finished download.&quot;)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="c-multi-band-melgan" tabindex="-1"><a class="header-anchor" href="#c-multi-band-melgan"><span>(c) Multi-band MelGAN</span></a></h4><p>This is an <strong>EXPERIMENTAL</strong> model.</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span># download pretrained model</span></span>
<span class="line"><span>import os</span></span>
<span class="line"><span>if not os.path.exists(&quot;downloads/en/mb-melgan&quot;):</span></span>
<span class="line"><span>    !./espnet/utils/download_from_google_drive.sh \</span></span>
<span class="line"><span>        https://drive.google.com/open?id=1rGG5y15uy4WZ-lJy8NPVTkmB_6VhC20V downloads/en/mb-melgan tar.gz</span></span>
<span class="line"><span></span></span>
<span class="line"><span># set path</span></span>
<span class="line"><span>vocoder_path = &quot;downloads/en/mb-melgan/train_nodev_ljspeech_multi_band_melgan.v1/checkpoint-1000000steps.pkl&quot;</span></span>
<span class="line"><span></span></span>
<span class="line"><span>print(&quot;Sucessfully finished download.&quot;)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="setup" tabindex="-1"><a class="header-anchor" href="#setup"><span>Setup</span></a></h3><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span># add path</span></span>
<span class="line"><span>import sys</span></span>
<span class="line"><span>sys.path.append(&quot;espnet&quot;)</span></span>
<span class="line"><span></span></span>
<span class="line"><span># define device</span></span>
<span class="line"><span>import torch</span></span>
<span class="line"><span>device = torch.device(&quot;cuda&quot;)</span></span>
<span class="line"><span></span></span>
<span class="line"><span># define E2E-TTS model</span></span>
<span class="line"><span>from argparse import Namespace</span></span>
<span class="line"><span>from espnet.asr.asr_utils import get_model_conf</span></span>
<span class="line"><span>from espnet.asr.asr_utils import torch_load</span></span>
<span class="line"><span>from espnet.utils.dynamic_import import dynamic_import</span></span>
<span class="line"><span>idim, odim, train_args = get_model_conf(model_path)</span></span>
<span class="line"><span>model_class = dynamic_import(train_args.model_module)</span></span>
<span class="line"><span>model = model_class(idim, odim, train_args)</span></span>
<span class="line"><span>torch_load(model_path, model)</span></span>
<span class="line"><span>model = model.eval().to(device)</span></span>
<span class="line"><span>inference_args = Namespace(**{</span></span>
<span class="line"><span>    &quot;threshold&quot;: 0.5,&quot;minlenratio&quot;: 0.0, &quot;maxlenratio&quot;: 10.0,</span></span>
<span class="line"><span>    # Only for Tacotron 2</span></span>
<span class="line"><span>    &quot;use_attention_constraint&quot;: True, &quot;backward_window&quot;: 1,&quot;forward_window&quot;:3,</span></span>
<span class="line"><span>    # Only for fastspeech (lower than 1.0 is faster speech, higher than 1.0 is slower speech)</span></span>
<span class="line"><span>    &quot;fastspeech_alpha&quot;: 1.0,</span></span>
<span class="line"><span>    })</span></span>
<span class="line"><span></span></span>
<span class="line"><span># define neural vocoder</span></span>
<span class="line"><span>from parallel_wavegan.utils import load_model</span></span>
<span class="line"><span>fs = 22050</span></span>
<span class="line"><span>vocoder = load_model(vocoder_path)</span></span>
<span class="line"><span>vocoder.remove_weight_norm()</span></span>
<span class="line"><span>vocoder = vocoder.eval().to(device)</span></span>
<span class="line"><span></span></span>
<span class="line"><span># define text frontend</span></span>
<span class="line"><span>from tacotron_cleaner.cleaners import custom_english_cleaners</span></span>
<span class="line"><span>from g2p_en import G2p</span></span>
<span class="line"><span>with open(dict_path) as f:</span></span>
<span class="line"><span>    lines = f.readlines()</span></span>
<span class="line"><span>lines = [line.replace(&quot;\n&quot;, &quot;&quot;).split(&quot; &quot;) for line in lines]</span></span>
<span class="line"><span>char_to_id = {c: int(i) for c, i in lines}</span></span>
<span class="line"><span>g2p = G2p()</span></span>
<span class="line"><span>def frontend(text):</span></span>
<span class="line"><span>    &quot;&quot;&quot;Clean text and then convert to id sequence.&quot;&quot;&quot;</span></span>
<span class="line"><span>    text = custom_english_cleaners(text)</span></span>
<span class="line"><span>    </span></span>
<span class="line"><span>    if trans_type == &quot;phn&quot;:</span></span>
<span class="line"><span>        text = filter(lambda s: s != &quot; &quot;, g2p(text))</span></span>
<span class="line"><span>        text = &quot; &quot;.join(text)</span></span>
<span class="line"><span>        print(f&quot;Cleaned text: {text}&quot;)</span></span>
<span class="line"><span>        charseq = text.split(&quot; &quot;)</span></span>
<span class="line"><span>    else:</span></span>
<span class="line"><span>        print(f&quot;Cleaned text: {text}&quot;)</span></span>
<span class="line"><span>        charseq = list(text)</span></span>
<span class="line"><span>    idseq = []</span></span>
<span class="line"><span>    for c in charseq:</span></span>
<span class="line"><span>        if c.isspace():</span></span>
<span class="line"><span>            idseq += [char_to_id[&quot;&lt;space&gt;&quot;]]</span></span>
<span class="line"><span>        elif c not in char_to_id.keys():</span></span>
<span class="line"><span>            idseq += [char_to_id[&quot;&lt;unk&gt;&quot;]]</span></span>
<span class="line"><span>        else:</span></span>
<span class="line"><span>            idseq += [char_to_id[c]]</span></span>
<span class="line"><span>    idseq += [idim - 1]  # &lt;eos&gt;</span></span>
<span class="line"><span>    return torch.LongTensor(idseq).view(-1).to(device)</span></span>
<span class="line"><span></span></span>
<span class="line"><span>import nltk</span></span>
<span class="line"><span>nltk.download(&#39;punkt&#39;)</span></span>
<span class="line"><span>print(&quot;Now ready to synthesize!&quot;)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="synthesis" tabindex="-1"><a class="header-anchor" href="#synthesis"><span>Synthesis</span></a></h3><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span>import time</span></span>
<span class="line"><span>print(&quot;Input your favorite sentence in English!&quot;)</span></span>
<span class="line"><span>input_text = input()</span></span>
<span class="line"><span>with torch.no_grad():</span></span>
<span class="line"><span>    start = time.time()</span></span>
<span class="line"><span>    x = frontend(input_text)</span></span>
<span class="line"><span>    c, _, _ = model.inference(x, inference_args)</span></span>
<span class="line"><span>    y = vocoder.inference(c)</span></span>
<span class="line"><span>rtf = (time.time() - start) / (len(y) / fs)</span></span>
<span class="line"><span>print(f&quot;RTF = {rtf:5f}&quot;)</span></span>
<span class="line"><span></span></span>
<span class="line"><span>from IPython.display import display, Audio</span></span>
<span class="line"><span>display(Audio(y.view(-1).cpu().numpy(), rate=fs))</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><hr><h2 id="japanese-demo" tabindex="-1"><a class="header-anchor" href="#japanese-demo"><span>Japanese demo</span></a></h2><h3 id="install-japanese-dependencies" tabindex="-1"><a class="header-anchor" href="#install-japanese-dependencies"><span>Install Japanese dependencies</span></a></h3><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span>!pip install pyopenjtalk</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h3 id="download-pretrained-models" tabindex="-1"><a class="header-anchor" href="#download-pretrained-models"><span>Download pretrained models</span></a></h3><p>Here we select Tacotron2 or Transformer. The vocoder model is Parallel WaveGAN.</p><h4 id="a-tacotron-2" tabindex="-1"><a class="header-anchor" href="#a-tacotron-2"><span>(a) Tacotron 2</span></a></h4><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span># download pretrained models</span></span>
<span class="line"><span>import os</span></span>
<span class="line"><span>if not os.path.exists(&quot;downloads/jp/tacotron2&quot;):</span></span>
<span class="line"><span>    !./espnet/utils/download_from_google_drive.sh \</span></span>
<span class="line"><span>        https://drive.google.com/open?id=1OwrUQzAmvjj1x9cDhnZPp6dqtsEqGEJM downloads/jp/tacotron2 tar.gz</span></span>
<span class="line"><span>    !./espnet/utils/download_from_google_drive.sh \</span></span>
<span class="line"><span>        https://drive.google.com/open?id=1kp5M4VvmagDmYckFJa78WGqh1drb_P9t downloads/jp/tacotron2 tar.gz</span></span>
<span class="line"><span></span></span>
<span class="line"><span># set path</span></span>
<span class="line"><span>dict_path = &quot;downloads/jp/tacotron2/data/lang_1phn/train_no_dev_units.txt&quot;</span></span>
<span class="line"><span>model_path = &quot;downloads/jp/tacotron2/exp/train_no_dev_pytorch_train_pytorch_tacotron2_phn/results/model.last1.avg.best&quot;</span></span>
<span class="line"><span>vocoder_path = &quot;downloads/jp/tacotron2/jsut.parallel_wavegan.v1/checkpoint-400000steps.pkl&quot;</span></span>
<span class="line"><span></span></span>
<span class="line"><span>print(&quot;sucessfully finished download.&quot;)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="b-transformer-1" tabindex="-1"><a class="header-anchor" href="#b-transformer-1"><span>(b) Transformer</span></a></h4><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span># download pretrained models</span></span>
<span class="line"><span>import os</span></span>
<span class="line"><span>if not os.path.exists(&quot;downloads/jp/transformer&quot;):</span></span>
<span class="line"><span>    !./espnet/utils/download_from_google_drive.sh \</span></span>
<span class="line"><span>        https://drive.google.com/open?id=1OwrUQzAmvjj1x9cDhnZPp6dqtsEqGEJM downloads/jp/transformer tar.gz</span></span>
<span class="line"><span>    !./espnet/utils/download_from_google_drive.sh \</span></span>
<span class="line"><span>        https://drive.google.com/open?id=1mEnZfBKqA4eT6Bn0eRZuP6lNzL-IL3VD downloads/jp/transformer tar.gz</span></span>
<span class="line"><span></span></span>
<span class="line"><span># set path</span></span>
<span class="line"><span>dict_path = &quot;downloads/jp/transformer/data/lang_1phn/train_no_dev_units.txt&quot;</span></span>
<span class="line"><span>model_path = &quot;downloads/jp/transformer/exp/train_no_dev_pytorch_train_pytorch_transformer_phn/results/model.last1.avg.best&quot;</span></span>
<span class="line"><span>vocoder_path = &quot;downloads/jp/transformer/jsut.parallel_wavegan.v1/checkpoint-400000steps.pkl&quot;</span></span>
<span class="line"><span></span></span>
<span class="line"><span>print(&quot;sucessfully finished download.&quot;)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="setup-1" tabindex="-1"><a class="header-anchor" href="#setup-1"><span>Setup</span></a></h3><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span># add path</span></span>
<span class="line"><span>import sys</span></span>
<span class="line"><span>sys.path.append(&quot;espnet&quot;)</span></span>
<span class="line"><span></span></span>
<span class="line"><span># define device</span></span>
<span class="line"><span>import torch</span></span>
<span class="line"><span>device = torch.device(&quot;cuda&quot;)</span></span>
<span class="line"><span></span></span>
<span class="line"><span># define E2E-TTS model</span></span>
<span class="line"><span>from argparse import Namespace</span></span>
<span class="line"><span>from espnet.asr.asr_utils import get_model_conf</span></span>
<span class="line"><span>from espnet.asr.asr_utils import torch_load</span></span>
<span class="line"><span>from espnet.utils.dynamic_import import dynamic_import</span></span>
<span class="line"><span>idim, odim, train_args = get_model_conf(model_path)</span></span>
<span class="line"><span>model_class = dynamic_import(train_args.model_module)</span></span>
<span class="line"><span>model = model_class(idim, odim, train_args)</span></span>
<span class="line"><span>torch_load(model_path, model)</span></span>
<span class="line"><span>model = model.eval().to(device)</span></span>
<span class="line"><span>inference_args = Namespace(**{&quot;threshold&quot;: 0.5, &quot;minlenratio&quot;: 0.0, &quot;maxlenratio&quot;: 10.0})</span></span>
<span class="line"><span></span></span>
<span class="line"><span># define neural vocoder</span></span>
<span class="line"><span>from parallel_wavegan.utils import load_model</span></span>
<span class="line"><span>fs = 24000</span></span>
<span class="line"><span>vocoder = load_model(vocoder_path)</span></span>
<span class="line"><span>vocoder.remove_weight_norm()</span></span>
<span class="line"><span>vocoder = vocoder.eval().to(device)</span></span>
<span class="line"><span></span></span>
<span class="line"><span># define text frontend</span></span>
<span class="line"><span>import pyopenjtalk</span></span>
<span class="line"><span>with open(dict_path) as f:</span></span>
<span class="line"><span>    lines = f.readlines()</span></span>
<span class="line"><span>lines = [line.replace(&quot;\n&quot;, &quot;&quot;).split(&quot; &quot;) for line in lines]</span></span>
<span class="line"><span>char_to_id = {c: int(i) for c, i in lines}</span></span>
<span class="line"><span>def frontend(text):</span></span>
<span class="line"><span>    &quot;&quot;&quot;Clean text and then convert to id sequence.&quot;&quot;&quot;</span></span>
<span class="line"><span>    text = pyopenjtalk.g2p(text, kana=False)</span></span>
<span class="line"><span>    print(f&quot;Cleaned text: {text}&quot;)</span></span>
<span class="line"><span>    charseq = text.split(&quot; &quot;)</span></span>
<span class="line"><span>    idseq = []</span></span>
<span class="line"><span>    for c in charseq:</span></span>
<span class="line"><span>        if c.isspace():</span></span>
<span class="line"><span>            idseq += [char_to_id[&quot;&lt;space&gt;&quot;]]</span></span>
<span class="line"><span>        elif c not in char_to_id.keys():</span></span>
<span class="line"><span>            idseq += [char_to_id[&quot;&lt;unk&gt;&quot;]]</span></span>
<span class="line"><span>        else:</span></span>
<span class="line"><span>            idseq += [char_to_id[c]]</span></span>
<span class="line"><span>    idseq += [idim - 1]  # &lt;eos&gt;</span></span>
<span class="line"><span>    return torch.LongTensor(idseq).view(-1).to(device)</span></span>
<span class="line"><span></span></span>
<span class="line"><span>frontend(&quot;åˆå›žã®è¾žæ›¸ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãŒå¿…è¦ã§ã™&quot;)</span></span>
<span class="line"><span>print(&quot;Now ready to synthesize!&quot;)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="synthesis-1" tabindex="-1"><a class="header-anchor" href="#synthesis-1"><span>Synthesis</span></a></h3><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span>import time</span></span>
<span class="line"><span>print(&quot;æ—¥æœ¬èªžã§å¥½ããªæ–‡ç« ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„&quot;)</span></span>
<span class="line"><span>input_text = input()</span></span>
<span class="line"><span></span></span>
<span class="line"><span>with torch.no_grad():</span></span>
<span class="line"><span>    start = time.time()</span></span>
<span class="line"><span>    x = frontend(input_text)</span></span>
<span class="line"><span>    c, _, _ = model.inference(x, inference_args)</span></span>
<span class="line"><span>    y = vocoder.inference(c)</span></span>
<span class="line"><span>rtf = (time.time() - start) / (len(y) / fs)</span></span>
<span class="line"><span>print(f&quot;RTF = {rtf:5f}&quot;)</span></span>
<span class="line"><span></span></span>
<span class="line"><span>from IPython.display import display, Audio</span></span>
<span class="line"><span>display(Audio(y.view(-1).cpu().numpy(), rate=fs))</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><hr><h2 id="mandarin-demo" tabindex="-1"><a class="header-anchor" href="#mandarin-demo"><span>Mandarin demo</span></a></h2><p><strong>IMPORTANT NOTE</strong>: The author cannot understand Mandarin. The text front-end part might have some bugs.</p><h3 id="install-mandarin-dependencies" tabindex="-1"><a class="header-anchor" href="#install-mandarin-dependencies"><span>Install Mandarin dependencies</span></a></h3><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span>!pip install pypinyin</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h3 id="download-pretrained-models-1" tabindex="-1"><a class="header-anchor" href="#download-pretrained-models-1"><span>Download pretrained models</span></a></h3><p>You can select Transformer or FastSpeech.</p><h4 id="a-transformer" tabindex="-1"><a class="header-anchor" href="#a-transformer"><span>(a) Transformer</span></a></h4><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span># download pretrained models</span></span>
<span class="line"><span>import os</span></span>
<span class="line"><span>if not os.path.exists(&quot;downloads/zh/transformer&quot;):</span></span>
<span class="line"><span>    !./espnet/utils/download_from_google_drive.sh \</span></span>
<span class="line"><span>        https://drive.google.com/open?id=10M6H88jEUGbRWBmU1Ff2VaTmOAeL8CEy downloads/zh/transformer tar.gz</span></span>
<span class="line"><span>    !./espnet/utils/download_from_google_drive.sh \</span></span>
<span class="line"><span>        https://drive.google.com/open?id=1bTSygvonv5TS6-iuYsOIUWpN2atGnyhZ downloads/zh/transformer tar.gz</span></span>
<span class="line"><span></span></span>
<span class="line"><span># set path</span></span>
<span class="line"><span>dict_path = &quot;downloads/zh/transformer/data/lang_phn/train_no_dev_units.txt&quot;</span></span>
<span class="line"><span>model_path = &quot;downloads/zh/transformer/exp/train_no_dev_pytorch_train_pytorch_transformer.v1.single/results/model.last1.avg.best&quot;</span></span>
<span class="line"><span>vocoder_path = &quot;downloads/zh/transformer/csmsc.parallel_wavegan.v1/checkpoint-400000steps.pkl&quot;</span></span>
<span class="line"><span></span></span>
<span class="line"><span>print(&quot;sucessfully finished download.&quot;)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="b-fastspeech" tabindex="-1"><a class="header-anchor" href="#b-fastspeech"><span>(b) FastSpeech</span></a></h4><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span># download pretrained models</span></span>
<span class="line"><span>import os</span></span>
<span class="line"><span>if not os.path.exists(&quot;downloads/zh/fastspeech&quot;):</span></span>
<span class="line"><span>    !./espnet/utils/download_from_google_drive.sh \</span></span>
<span class="line"><span>        https://drive.google.com/open?id=10M6H88jEUGbRWBmU1Ff2VaTmOAeL8CEy downloads/zh/fastspeech tar.gz</span></span>
<span class="line"><span>    !./espnet/utils/download_from_google_drive.sh \</span></span>
<span class="line"><span>        https://drive.google.com/open?id=1T8thxkAxjGFPXPWPTcKLvHnd6lG0-82R downloads/zh/fastspeech tar.gz </span></span>
<span class="line"><span></span></span>
<span class="line"><span># set path</span></span>
<span class="line"><span>dict_path = &quot;downloads/zh/fastspeech/data/lang_phn/train_no_dev_units.txt&quot;</span></span>
<span class="line"><span>model_path = &quot;downloads/zh/fastspeech/exp/train_no_dev_pytorch_train_fastspeech.v3.single/results/model.last1.avg.best&quot;</span></span>
<span class="line"><span>vocoder_path = &quot;downloads/zh/fastspeech/csmsc.parallel_wavegan.v1/checkpoint-400000steps.pkl&quot;</span></span>
<span class="line"><span></span></span>
<span class="line"><span>print(&quot;sucessfully finished download.&quot;)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="setup-2" tabindex="-1"><a class="header-anchor" href="#setup-2"><span>Setup</span></a></h3><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span># add path</span></span>
<span class="line"><span>import sys</span></span>
<span class="line"><span>sys.path.append(&quot;espnet&quot;)</span></span>
<span class="line"><span></span></span>
<span class="line"><span># define device</span></span>
<span class="line"><span>import torch</span></span>
<span class="line"><span>device = torch.device(&quot;cuda&quot;)</span></span>
<span class="line"><span></span></span>
<span class="line"><span># define E2E-TTS model</span></span>
<span class="line"><span>from argparse import Namespace</span></span>
<span class="line"><span>from espnet.asr.asr_utils import get_model_conf</span></span>
<span class="line"><span>from espnet.asr.asr_utils import torch_load</span></span>
<span class="line"><span>from espnet.utils.dynamic_import import dynamic_import</span></span>
<span class="line"><span>idim, odim, train_args = get_model_conf(model_path)</span></span>
<span class="line"><span>model_class = dynamic_import(train_args.model_module)</span></span>
<span class="line"><span>model = model_class(idim, odim, train_args)</span></span>
<span class="line"><span>torch_load(model_path, model)</span></span>
<span class="line"><span>model = model.eval().to(device)</span></span>
<span class="line"><span>inference_args = Namespace(**{&quot;threshold&quot;: 0.5, &quot;minlenratio&quot;: 0.0, &quot;maxlenratio&quot;: 10.0})</span></span>
<span class="line"><span></span></span>
<span class="line"><span># define neural vocoder</span></span>
<span class="line"><span>from parallel_wavegan.utils import load_model</span></span>
<span class="line"><span>fs = 24000</span></span>
<span class="line"><span>vocoder = load_model(vocoder_path)</span></span>
<span class="line"><span>vocoder.remove_weight_norm()</span></span>
<span class="line"><span>vocoder = vocoder.eval().to(device)</span></span>
<span class="line"><span></span></span>
<span class="line"><span># define text frontend</span></span>
<span class="line"><span>from pypinyin import pinyin, Style</span></span>
<span class="line"><span>from pypinyin.style._utils import get_initials, get_finals</span></span>
<span class="line"><span>with open(dict_path) as f:</span></span>
<span class="line"><span>    lines = f.readlines()</span></span>
<span class="line"><span>lines = [line.replace(&quot;\n&quot;, &quot;&quot;).split(&quot; &quot;) for line in lines]</span></span>
<span class="line"><span>char_to_id = {c: int(i) for c, i in lines}</span></span>
<span class="line"><span>def frontend(text):</span></span>
<span class="line"><span>    &quot;&quot;&quot;Clean text and then convert to id sequence.&quot;&quot;&quot;</span></span>
<span class="line"><span>    text = pinyin(text, style=Style.TONE3)</span></span>
<span class="line"><span>    text = [c[0] for c in text]</span></span>
<span class="line"><span>    print(f&quot;Cleaned text: {text}&quot;)</span></span>
<span class="line"><span>    idseq = []</span></span>
<span class="line"><span>    for x in text:</span></span>
<span class="line"><span>        c_init = get_initials(x, strict=True)</span></span>
<span class="line"><span>        c_final = get_finals(x, strict=True)</span></span>
<span class="line"><span>        for c in [c_init, c_final]:</span></span>
<span class="line"><span>            if len(c) == 0:</span></span>
<span class="line"><span>                continue</span></span>
<span class="line"><span>            c = c.replace(&quot;Ã¼&quot;, &quot;v&quot;)</span></span>
<span class="line"><span>            c = c.replace(&quot;ui&quot;, &quot;uei&quot;)</span></span>
<span class="line"><span>            c = c.replace(&quot;un&quot;, &quot;uen&quot;)</span></span>
<span class="line"><span>            c = c.replace(&quot;iu&quot;, &quot;iou&quot;)</span></span>
<span class="line"><span>            # Special rule: &quot;e5n&quot; -&gt; &quot;en5&quot;</span></span>
<span class="line"><span>            if &quot;5&quot; in c:</span></span>
<span class="line"><span>                c = c.replace(&quot;5&quot;, &quot;&quot;) + &quot;5&quot;</span></span>
<span class="line"><span>            if c not in char_to_id.keys():</span></span>
<span class="line"><span>                print(f&quot;WARN: {c} is not included in dict.&quot;)</span></span>
<span class="line"><span>                idseq += [char_to_id[&quot;&lt;unk&gt;&quot;]]</span></span>
<span class="line"><span>            else:</span></span>
<span class="line"><span>                idseq += [char_to_id[c]]</span></span>
<span class="line"><span>    idseq += [idim - 1]  # &lt;eos&gt;</span></span>
<span class="line"><span>    return torch.LongTensor(idseq).view(-1).to(device)</span></span>
<span class="line"><span></span></span>
<span class="line"><span>print(&quot;now ready to synthesize!&quot;)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="synthesis-2" tabindex="-1"><a class="header-anchor" href="#synthesis-2"><span>Synthesis</span></a></h3><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span>import time</span></span>
<span class="line"><span>print(&quot;è«‹ç”¨ä¸­æ–‡è¼¸å…¥æ‚¨å–œæ­¡çš„å¥å­!&quot;)</span></span>
<span class="line"><span>input_text = input()</span></span>
<span class="line"><span></span></span>
<span class="line"><span>with torch.no_grad():</span></span>
<span class="line"><span>    start = time.time()</span></span>
<span class="line"><span>    x = frontend(input_text)</span></span>
<span class="line"><span>    c, _, _ = model.inference(x, inference_args)</span></span>
<span class="line"><span>    y = vocoder.inference(c)</span></span>
<span class="line"><span>rtf = (time.time() - start) / (len(y) / fs)</span></span>
<span class="line"><span>print(f&quot;RTF = {rtf:5f}&quot;)</span></span>
<span class="line"><span></span></span>
<span class="line"><span>from IPython.display import display, Audio</span></span>
<span class="line"><span>display(Audio(y.view(-1).cpu().numpy(), rate=fs))</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></div><!----><footer class="vp-page-meta"><!----><div class="vp-meta-item git-info"><!----><!----></div></footer><nav class="vp-page-nav"><!----><a class="route-link auto-link next" href="/espnet/notebook/ESPnet1/st_demo.html" aria-label="ESPnet Speech Translation Demonstration"><div class="hint">Next<span class="arrow end"></span></div><div class="link">ESPnet Speech Translation Demonstration<!----></div></a></nav><!----><!----><!--]--></main><!--]--><footer class="vp-footer-wrapper"><div class="vp-footer">Copyright Â© 2024 ESPnet Community. All rights reserved.</div><!----></footer></div><!--]--><!--]--><!--[--><!----><!----><!--]--><!--]--></div>
    <script type="module" src="/espnet/assets/app-B6Ithpv3.js" defer></script>
  </body>
</html>
