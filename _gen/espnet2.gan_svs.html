<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>espnet2.gan_svs package &mdash; ESPnet 202304 documentation</title><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/language_data.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "tex2jax_ignore|mathjax_ignore|document", "processClass": "tex2jax_process|mathjax_process|math|output_area"}})</script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="espnet2.asr_transducer package" href="espnet2.asr_transducer.html" />
    <link rel="prev" title="espnet2.spk package" href="espnet2.spk.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            ESPnet
          </a>
              <div class="version">
                202304
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p><span class="caption-text">Tutorial:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorial.html">Common usages</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallelization.html">Using job scheduling system</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">FAQ</a></li>
<li class="toctree-l1"><a class="reference internal" href="../docker.html">Docker</a></li>
</ul>
<p><span class="caption-text">ESPnet1:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../espnet1_tutorial.html">Usage</a></li>
</ul>
<p><span class="caption-text">ESPnet2:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../espnet2_tutorial.html">ESPnet2</a></li>
<li class="toctree-l1"><a class="reference internal" href="../espnet2_tutorial.html#instruction-for-run-sh">Instruction for run.sh</a></li>
<li class="toctree-l1"><a class="reference internal" href="../espnet2_training_option.html">Change the configuration for training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../espnet2_format_wav_scp.html">Converting audio file formats using format_wav_scp.py</a></li>
<li class="toctree-l1"><a class="reference internal" href="../espnet2_task.html">Task class and data input system for training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../espnet2_distributed.html">Distributed training</a></li>
</ul>
<p><span class="caption-text">Notebook:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../notebook/DataPreparation_CMU_11492_692_Spring2023(Assignment0).html">CMU 11492/11692 Spring 2023: Data preparation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/DataPreparation_CMU_11492_692_Spring2023(Assignment0).html#Data-preparation-in-ESPnet">Data preparation in ESPnet</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/SpeechEnhancement_CMU_11492_692_Spring2023(Assignment7).html">CMU 11492/11692 Spring 2023: Speech Enhancement</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/SpeechEnhancement_CMU_11492_692_Spring2023(Assignment7).html#Contents">Contents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/SpokenLanguageUnderstanding_CMU_11492_692_Spring2023(Assignment6).html">CMU 11492/11692 Spring 2023: Spoken Language Understanding</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/TextToSpeech_CMU_11492_692_Spring2023(Assignment8).html">CMU 11492/11692 Spring 2023: Text to Speech</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/asr_cli.html">Speech Recognition (Recipe)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/asr_library.html">Speech Recognition (Library)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_2pass_slu_demo.html">ESPNET 2 pass SLU Demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_asr_realtime_demo.html">ESPnet2-ASR realtime demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_asr_transfer_learning_demo.html"><strong>Use transfer learning for ASR in ESPnet2</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_asr_transfer_learning_demo.html#Abstract">Abstract</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_asr_transfer_learning_demo.html#ESPnet-installation-(about-10-minutes-in-total)">ESPnet installation (about 10 minutes in total)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_asr_transfer_learning_demo.html#mini_an4-recipe-as-a-transfer-learning-example">mini_an4 recipe as a transfer learning example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_new_task_tutorial_CMU_11751_18781_Fall2022.html">CMU 11751/18781 Fall 2022: ESPnet Tutorial2 (New task)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_new_task_tutorial_CMU_11751_18781_Fall2022.html#Install-ESPnet-(Almost-same-procedure-as-your-first-tutorial)">Install ESPnet (Almost same procedure as your first tutorial)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_new_task_tutorial_CMU_11751_18781_Fall2022.html#What-we-provide-you-and-what-you-need-to-proceed">What we provide you and what you need to proceed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_recipe_tutorial_CMU_11751_18781_Fall2022.html">CMU 11751/18781 Fall 2022: ESPnet Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_recipe_tutorial_CMU_11751_18781_Fall2022.html#Install-ESPnet">Install ESPnet</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_recipe_tutorial_CMU_11751_18781_Fall2022.html#Run-an-existing-recipe">Run an existing recipe</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_recipe_tutorial_CMU_11751_18781_Fall2022.html#Make-a-new-recipe">Make a new recipe</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_recipe_tutorial_CMU_11751_18781_Fall2022.html#Additional-resources">Additional resources</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_streaming_asr_demo.html">ESPnet2 real streaming Transformer demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_tts_realtime_demo.html">ESPnet2-TTS realtime demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_tutorial_2021_CMU_11751_18781.html">CMU 11751/18781 2021: ESPnet Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_tutorial_2021_CMU_11751_18781.html#Run-an-inference-example">Run an inference example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_tutorial_2021_CMU_11751_18781.html#Full-installation">Full installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_tutorial_2021_CMU_11751_18781.html#Run-a-recipe-example">Run a recipe example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet_se_demonstration_for_waspaa_2021.html">ESPnet Speech Enhancement Demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet_se_demonstration_for_waspaa_2021.html#Contents">Contents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet_se_demonstration_for_waspaa_2021.html#(1)-Tutorials-on-the-Basic-Usage">(1) Tutorials on the Basic Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet_se_demonstration_for_waspaa_2021.html#(2)-Tutorials-on-Contributing-to-ESPNet-SE-Project">(2) Tutorials on Contributing to ESPNet-SE Project</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/onnx_conversion_demo.html">espnet_onnx demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/onnx_conversion_demo.html#Install-Dependency">Install Dependency</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/onnx_conversion_demo.html#Export-your-model">Export your model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/onnx_conversion_demo.html#Inference-with-onnx">Inference with onnx</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/onnx_conversion_demo.html#Using-streaming-model">Using streaming model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/pretrained.html">Pretrained Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/se_demo.html">ESPnet Speech Enhancement Demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/st_demo.html">ESPnet Speech Translation Demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/tts_cli.html">Text-to-Speech (Recipe)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/tts_realtime_demo.html">ESPnet real time E2E-TTS demonstration</a></li>
</ul>
<p><span class="caption-text">Package Reference:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="espnet.distributed.html">espnet.distributed package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.asr.html">espnet.asr package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.st.html">espnet.st package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.nets.html">espnet.nets package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.utils.html">espnet.utils package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.transform.html">espnet.transform package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.vc.html">espnet.vc package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.bin.html">espnet.bin package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.mt.html">espnet.mt package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.tts.html">espnet.tts package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.optimizer.html">espnet.optimizer package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.lm.html">espnet.lm package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.scheduler.html">espnet.scheduler package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.layers.html">espnet2.layers package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.asr.html">espnet2.asr package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.svs.html">espnet2.svs package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.fileio.html">espnet2.fileio package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.optimizers.html">espnet2.optimizers package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.spk.html">espnet2.spk package</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">espnet2.gan_svs package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-svs-espnet-model-1">espnet2.gan_svs.espnet_model</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-svs-abs-gan-svs-1">espnet2.gan_svs.abs_gan_svs</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-svs-init-1">espnet2.gan_svs.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-svs-pits-modules-1">espnet2.gan_svs.pits.modules</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-svs-pits-ying-decoder-1">espnet2.gan_svs.pits.ying_decoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-svs-vits-phoneme-predictor-1">espnet2.gan_svs.vits.phoneme_predictor</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-svs-vits-pitch-predictor-1">espnet2.gan_svs.vits.pitch_predictor</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-svs-vits-modules-1">espnet2.gan_svs.vits.modules</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-svs-vits-length-regulator-1">espnet2.gan_svs.vits.length_regulator</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-svs-vits-duration-predictor-1">espnet2.gan_svs.vits.duration_predictor</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-svs-vits-vits-1">espnet2.gan_svs.vits.vits</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-svs-vits-generator-1">espnet2.gan_svs.vits.generator</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-svs-vits-prior-decoder-1">espnet2.gan_svs.vits.prior_decoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-svs-vits-init-1">espnet2.gan_svs.vits.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-svs-vits-text-encoder-1">espnet2.gan_svs.vits.text_encoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-svs-avocodo-avocodo-1">espnet2.gan_svs.avocodo.avocodo</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-svs-avocodo-init-1">espnet2.gan_svs.avocodo.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-svs-uhifigan-sine-generator-1">espnet2.gan_svs.uhifigan.sine_generator</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-svs-uhifigan-init-1">espnet2.gan_svs.uhifigan.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-svs-uhifigan-uhifigan-1">espnet2.gan_svs.uhifigan.uhifigan</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-svs-utils-expand-f0-1">espnet2.gan_svs.utils.expand_f0</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-svs-utils-init-1">espnet2.gan_svs.utils.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-svs-visinger2-ddsp-1">espnet2.gan_svs.visinger2.ddsp</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-svs-visinger2-init-1">espnet2.gan_svs.visinger2.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-svs-visinger2-visinger2-vocoder-1">espnet2.gan_svs.visinger2.visinger2_vocoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-svs-joint-init-1">espnet2.gan_svs.joint.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-svs-joint-joint-score2wav-1">espnet2.gan_svs.joint.joint_score2wav</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.asr_transducer.html">espnet2.asr_transducer package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.hubert.html">espnet2.hubert package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.train.html">espnet2.train package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.st.html">espnet2.st package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.uasr.html">espnet2.uasr package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.samplers.html">espnet2.samplers package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.utils.html">espnet2.utils package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.iterators.html">espnet2.iterators package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.text.html">espnet2.text package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.tasks.html">espnet2.tasks package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.bin.html">espnet2.bin package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.mt.html">espnet2.mt package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.gan_tts.html">espnet2.gan_tts package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.tts.html">espnet2.tts package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.enh.html">espnet2.enh package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.slu.html">espnet2.slu package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.torch_utils.html">espnet2.torch_utils package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.schedulers.html">espnet2.schedulers package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.fst.html">espnet2.fst package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.asvspoof.html">espnet2.asvspoof package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.diar.html">espnet2.diar package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.lm.html">espnet2.lm package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.main_funcs.html">espnet2.main_funcs package</a></li>
</ul>
<p><span class="caption-text">Tool Reference:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../apis/espnet_bin.html">core tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../apis/espnet2_bin.html">core tools (espnet2)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../apis/utils_py.html">python utility tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../apis/utils_sh.html">bash utility tools</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">ESPnet</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">espnet2.gan_svs package</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/_gen/espnet2.gan_svs.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="espnet2-gan-svs-package">
<h1>espnet2.gan_svs package<a class="headerlink" href="#espnet2-gan-svs-package" title="Permalink to this headline">¶</a></h1>
<section id="espnet2-gan-svs-espnet-model-1">
<span id="espnet2-gan-svs-espnet-model"></span><h2>espnet2.gan_svs.espnet_model<a class="headerlink" href="#espnet2-gan-svs-espnet-model-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_svs.espnet_model"></span><p>GAN-based Singing-voice-synthesis ESPnet model.</p>
<dl class="class">
<dt id="espnet2.gan_svs.espnet_model.ESPnetGANSVSModel">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_svs.espnet_model.</code><code class="sig-name descname">ESPnetGANSVSModel</code><span class="sig-paren">(</span><em class="sig-param">text_extract: Optional[espnet2.tts.feats_extract.abs_feats_extract.AbsFeatsExtract], feats_extract: Optional[espnet2.tts.feats_extract.abs_feats_extract.AbsFeatsExtract], score_feats_extract: Optional[espnet2.tts.feats_extract.abs_feats_extract.AbsFeatsExtract], label_extract: Optional[espnet2.tts.feats_extract.abs_feats_extract.AbsFeatsExtract], pitch_extract: Optional[espnet2.tts.feats_extract.abs_feats_extract.AbsFeatsExtract], ying_extract: Optional[espnet2.tts.feats_extract.abs_feats_extract.AbsFeatsExtract], duration_extract: Optional[espnet2.tts.feats_extract.abs_feats_extract.AbsFeatsExtract], energy_extract: Optional[espnet2.tts.feats_extract.abs_feats_extract.AbsFeatsExtract], normalize: Optional[espnet2.layers.inversible_interface.InversibleInterface], pitch_normalize: Optional[espnet2.layers.inversible_interface.InversibleInterface], energy_normalize: Optional[espnet2.layers.inversible_interface.InversibleInterface], svs: espnet2.gan_svs.abs_gan_svs.AbsGANSVS</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/espnet_model.html#ESPnetGANSVSModel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.espnet_model.ESPnetGANSVSModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="espnet2.train.html#espnet2.train.abs_gan_espnet_model.AbsGANESPnetModel" title="espnet2.train.abs_gan_espnet_model.AbsGANESPnetModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.train.abs_gan_espnet_model.AbsGANESPnetModel</span></code></a></p>
<p>ESPnet model for GAN-based singing voice synthesis task.</p>
<p>Initialize ESPnetGANSVSModel module.</p>
<dl class="method">
<dt id="espnet2.gan_svs.espnet_model.ESPnetGANSVSModel.collect_feats">
<code class="sig-name descname">collect_feats</code><span class="sig-paren">(</span><em class="sig-param">text: torch.Tensor</em>, <em class="sig-param">text_lengths: torch.Tensor</em>, <em class="sig-param">singing: torch.Tensor</em>, <em class="sig-param">singing_lengths: torch.Tensor</em>, <em class="sig-param">label: Optional[torch.Tensor] = None</em>, <em class="sig-param">label_lengths: Optional[torch.Tensor] = None</em>, <em class="sig-param">phn_cnt: Optional[torch.Tensor] = None</em>, <em class="sig-param">midi: Optional[torch.Tensor] = None</em>, <em class="sig-param">midi_lengths: Optional[torch.Tensor] = None</em>, <em class="sig-param">duration_phn: Optional[torch.Tensor] = None</em>, <em class="sig-param">duration_phn_lengths: Optional[torch.Tensor] = None</em>, <em class="sig-param">duration_ruled_phn: Optional[torch.Tensor] = None</em>, <em class="sig-param">duration_ruled_phn_lengths: Optional[torch.Tensor] = None</em>, <em class="sig-param">duration_syb: Optional[torch.Tensor] = None</em>, <em class="sig-param">duration_syb_lengths: Optional[torch.Tensor] = None</em>, <em class="sig-param">slur: Optional[torch.Tensor] = None</em>, <em class="sig-param">pitch: Optional[torch.Tensor] = None</em>, <em class="sig-param">pitch_lengths: Optional[torch.Tensor] = None</em>, <em class="sig-param">energy: Optional[torch.Tensor] = None</em>, <em class="sig-param">energy_lengths: Optional[torch.Tensor] = None</em>, <em class="sig-param">ying: Optional[torch.Tensor] = None</em>, <em class="sig-param">ying_lengths: Optional[torch.Tensor] = None</em>, <em class="sig-param">spembs: Optional[torch.Tensor] = None</em>, <em class="sig-param">sids: Optional[torch.Tensor] = None</em>, <em class="sig-param">lids: Optional[torch.Tensor] = None</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span> &#x2192; Dict[str, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/gan_svs/espnet_model.html#ESPnetGANSVSModel.collect_feats"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.espnet_model.ESPnetGANSVSModel.collect_feats" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate features and return them as a dict.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>Tensor</em>) – Text index tensor (B, T_text).</p></li>
<li><p><strong>text_lengths</strong> (<em>Tensor</em>) – Text length tensor (B,).</p></li>
<li><p><strong>singing</strong> (<em>Tensor</em>) – Singing waveform tensor (B, T_wav).</p></li>
<li><p><strong>singing_lengths</strong> (<em>Tensor</em>) – Singing length tensor (B,).</p></li>
<li><p><strong>label</strong> (<em>Option</em><em>[</em><em>Tensor</em><em>]</em>) – Label tensor (B, T_label).</p></li>
<li><p><strong>label_lengths</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Label lrngth tensor (B,).</p></li>
<li><p><strong>phn_cnt</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Number of phones in each syllable (B, T_syb)</p></li>
<li><p><strong>midi</strong> (<em>Option</em><em>[</em><em>Tensor</em><em>]</em>) – Midi tensor (B, T_label).</p></li>
<li><p><strong>midi_lengths</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Midi lrngth tensor (B,).</p></li>
<li><p><strong>duration_phn</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – duration tensor (T_label).</p></li>
<li><p><strong>duration_ruled_phn</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – duration tensor (T_phone).</p></li>
<li><p><strong>duration_syb</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – duration tensor (T_phone).</p></li>
<li><p><strong>slur</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – slur tensor (B, T_slur).</p></li>
<li><p><strong>pitch</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Pitch tensor (B, T_wav). - f0 sequence</p></li>
<li><p><strong>pitch_lengths</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Pitch length tensor (B,).</p></li>
<li><p><strong>energy</strong> (<em>Optional</em><em>[</em><em>Tensor</em>) – Energy tensor.</p></li>
<li><p><strong>energy_lengths</strong> (<em>Optional</em><em>[</em><em>Tensor</em>) – Energy length tensor (B,).</p></li>
<li><p><strong>spembs</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Speaker embedding tensor (B, D).</p></li>
<li><p><strong>sids</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Speaker ID tensor (B, 1).</p></li>
<li><p><strong>lids</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Language ID tensor (B, 1).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Dict of features.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Dict[str, Tensor]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_svs.espnet_model.ESPnetGANSVSModel.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">text: torch.Tensor</em>, <em class="sig-param">text_lengths: torch.Tensor</em>, <em class="sig-param">singing: torch.Tensor</em>, <em class="sig-param">singing_lengths: torch.Tensor</em>, <em class="sig-param">feats: Optional[torch.Tensor] = None</em>, <em class="sig-param">feats_lengths: Optional[torch.Tensor] = None</em>, <em class="sig-param">label: Optional[torch.Tensor] = None</em>, <em class="sig-param">label_lengths: Optional[torch.Tensor] = None</em>, <em class="sig-param">phn_cnt: Optional[torch.Tensor] = None</em>, <em class="sig-param">midi: Optional[torch.Tensor] = None</em>, <em class="sig-param">midi_lengths: Optional[torch.Tensor] = None</em>, <em class="sig-param">duration_phn: Optional[torch.Tensor] = None</em>, <em class="sig-param">duration_phn_lengths: Optional[torch.Tensor] = None</em>, <em class="sig-param">duration_ruled_phn: Optional[torch.Tensor] = None</em>, <em class="sig-param">duration_ruled_phn_lengths: Optional[torch.Tensor] = None</em>, <em class="sig-param">duration_syb: Optional[torch.Tensor] = None</em>, <em class="sig-param">duration_syb_lengths: Optional[torch.Tensor] = None</em>, <em class="sig-param">slur: Optional[torch.Tensor] = None</em>, <em class="sig-param">pitch: Optional[torch.Tensor] = None</em>, <em class="sig-param">pitch_lengths: Optional[torch.Tensor] = None</em>, <em class="sig-param">energy: Optional[torch.Tensor] = None</em>, <em class="sig-param">energy_lengths: Optional[torch.Tensor] = None</em>, <em class="sig-param">ying: Optional[torch.Tensor] = None</em>, <em class="sig-param">ying_lengths: Optional[torch.Tensor] = None</em>, <em class="sig-param">spembs: Optional[torch.Tensor] = None</em>, <em class="sig-param">sids: Optional[torch.Tensor] = None</em>, <em class="sig-param">lids: Optional[torch.Tensor] = None</em>, <em class="sig-param">forward_generator: bool = True</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span> &#x2192; Dict[str, Any]<a class="reference internal" href="../_modules/espnet2/gan_svs/espnet_model.html#ESPnetGANSVSModel.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.espnet_model.ESPnetGANSVSModel.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Return generator or discriminator loss with dict format.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>Tensor</em>) – Text index tensor (B, T_text).</p></li>
<li><p><strong>text_lengths</strong> (<em>Tensor</em>) – Text length tensor (B,).</p></li>
<li><p><strong>singing</strong> (<em>Tensor</em>) – Singing waveform tensor (B, T_wav).</p></li>
<li><p><strong>singing_lengths</strong> (<em>Tensor</em>) – Singing length tensor (B,).</p></li>
<li><p><strong>label</strong> (<em>Option</em><em>[</em><em>Tensor</em><em>]</em>) – Label tensor (B, T_label).</p></li>
<li><p><strong>label_lengths</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Label lrngth tensor (B,).</p></li>
<li><p><strong>phn_cnt</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Number of phones in each syllable (B, T_syb)</p></li>
<li><p><strong>midi</strong> (<em>Option</em><em>[</em><em>Tensor</em><em>]</em>) – Midi tensor (B, T_label).</p></li>
<li><p><strong>midi_lengths</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Midi lrngth tensor (B,).</p></li>
<li><p><strong>duration_phn</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – duration tensor (B, T_label).</p></li>
<li><p><strong>duration_phn_lengths</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – duration length tensor (B,).</p></li>
<li><p><strong>duration_ruled_phn</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – duration tensor (B, T_phone).</p></li>
<li><p><strong>duration_ruled_phn_lengths</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – duration length tensor (B,).</p></li>
<li><p><strong>duration_syb</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – duration tensor (B, T_syllable).</p></li>
<li><p><strong>duration_syb_lengths</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – duration length tensor (B,).</p></li>
<li><p><strong>slur</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – slur tensor (B, T_slur).</p></li>
<li><p><strong>pitch</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Pitch tensor (B, T_wav). - f0 sequence</p></li>
<li><p><strong>pitch_lengths</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Pitch length tensor (B,).</p></li>
<li><p><strong>energy</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Energy tensor.</p></li>
<li><p><strong>energy_lengths</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Energy length tensor (B,).</p></li>
<li><p><strong>spembs</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Speaker embedding tensor (B, D).</p></li>
<li><p><strong>sids</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Speaker ID tensor (B, 1).</p></li>
<li><p><strong>lids</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Language ID tensor (B, 1).</p></li>
<li><p><strong>forward_generator</strong> (<em>bool</em>) – Whether to forward generator.</p></li>
<li><p><strong>kwargs</strong> – “utt_id” is among the input.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p>loss (Tensor): Loss scalar tensor.</p></li>
<li><p>stats (Dict[str, float]): Statistics to be monitored.</p></li>
<li><p>weight (Tensor): Weight tensor to summarize losses.</p></li>
<li><p>optim_idx (int): Optimizer index (0 for G and 1 for D).</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Dict[str, Any]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-gan-svs-abs-gan-svs-1">
<span id="espnet2-gan-svs-abs-gan-svs"></span><h2>espnet2.gan_svs.abs_gan_svs<a class="headerlink" href="#espnet2-gan-svs-abs-gan-svs-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_svs.abs_gan_svs"></span><p>GAN-based SVS abstrast class.</p>
<dl class="class">
<dt id="espnet2.gan_svs.abs_gan_svs.AbsGANSVS">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_svs.abs_gan_svs.</code><code class="sig-name descname">AbsGANSVS</code><a class="reference internal" href="../_modules/espnet2/gan_svs/abs_gan_svs.html#AbsGANSVS"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.abs_gan_svs.AbsGANSVS" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="espnet2.svs.html#espnet2.svs.abs_svs.AbsSVS" title="espnet2.svs.abs_svs.AbsSVS"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.svs.abs_svs.AbsSVS</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code></p>
<p>GAN-based SVS model abstract class.</p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="method">
<dt id="espnet2.gan_svs.abs_gan_svs.AbsGANSVS.forward">
<em class="property">abstract </em><code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">forward_generator</em>, <em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span> &#x2192; Dict[str, Union[torch.Tensor, Dict[str, torch.Tensor], int]]<a class="reference internal" href="../_modules/espnet2/gan_svs/abs_gan_svs.html#AbsGANSVS.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.abs_gan_svs.AbsGANSVS.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Return generator or discriminator loss.</p>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-gan-svs-init-1">
<span id="espnet2-gan-svs-init"></span><h2>espnet2.gan_svs.__init__<a class="headerlink" href="#espnet2-gan-svs-init-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_svs.__init__"></span></section>
<section id="espnet2-gan-svs-pits-modules-1">
<span id="espnet2-gan-svs-pits-modules"></span><h2>espnet2.gan_svs.pits.modules<a class="headerlink" href="#espnet2-gan-svs-pits-modules-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_svs.pits.modules"></span><dl class="class">
<dt id="espnet2.gan_svs.pits.modules.WN">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_svs.pits.modules.</code><code class="sig-name descname">WN</code><span class="sig-paren">(</span><em class="sig-param">hidden_channels</em>, <em class="sig-param">kernel_size</em>, <em class="sig-param">dilation_rate</em>, <em class="sig-param">n_layers</em>, <em class="sig-param">gin_channels=0</em>, <em class="sig-param">p_dropout=0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/pits/modules.html#WN"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.pits.modules.WN" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="method">
<dt id="espnet2.gan_svs.pits.modules.WN.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">x_mask</em>, <em class="sig-param">g=None</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/pits/modules.html#WN.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.pits.modules.WN.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</aside>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_svs.pits.modules.WN.fused_add_tanh_sigmoid_multiply">
<code class="sig-name descname">fused_add_tanh_sigmoid_multiply</code><span class="sig-paren">(</span><em class="sig-param">input_a</em>, <em class="sig-param">input_b</em>, <em class="sig-param">n_channels</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/pits/modules.html#WN.fused_add_tanh_sigmoid_multiply"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.pits.modules.WN.fused_add_tanh_sigmoid_multiply" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="espnet2.gan_svs.pits.modules.WN.remove_weight_norm">
<code class="sig-name descname">remove_weight_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/pits/modules.html#WN.remove_weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.pits.modules.WN.remove_weight_norm" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="espnet2-gan-svs-pits-ying-decoder-1">
<span id="espnet2-gan-svs-pits-ying-decoder"></span><h2>espnet2.gan_svs.pits.ying_decoder<a class="headerlink" href="#espnet2-gan-svs-pits-ying-decoder-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_svs.pits.ying_decoder"></span><dl class="class">
<dt id="espnet2.gan_svs.pits.ying_decoder.YingDecoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_svs.pits.ying_decoder.</code><code class="sig-name descname">YingDecoder</code><span class="sig-paren">(</span><em class="sig-param">hidden_channels</em>, <em class="sig-param">kernel_size</em>, <em class="sig-param">dilation_rate</em>, <em class="sig-param">n_layers</em>, <em class="sig-param">yin_start</em>, <em class="sig-param">yin_scope</em>, <em class="sig-param">yin_shift_range</em>, <em class="sig-param">gin_channels=0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/pits/ying_decoder.html#YingDecoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.pits.ying_decoder.YingDecoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Ying decoder module.</p>
<p>Initialize the YingDecoder module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hidden_channels</strong> (<em>int</em>) – Number of hidden channels.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – Size of the convolutional kernel.</p></li>
<li><p><strong>dilation_rate</strong> (<em>int</em>) – Dilation rate of the convolutional layers.</p></li>
<li><p><strong>n_layers</strong> (<em>int</em>) – Number of convolutional layers.</p></li>
<li><p><strong>yin_start</strong> (<em>int</em>) – Start point of the yin target signal.</p></li>
<li><p><strong>yin_scope</strong> (<em>int</em>) – Scope of the yin target signal.</p></li>
<li><p><strong>yin_shift_range</strong> (<em>int</em>) – Maximum number of frames to shift the yin
target signal.</p></li>
<li><p><strong>gin_channels</strong> (<em>int</em><em>, </em><em>optional</em>) – Number of global conditioning channels.
Defaults to 0.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_svs.pits.ying_decoder.YingDecoder.crop_scope">
<code class="sig-name descname">crop_scope</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">yin_start</em>, <em class="sig-param">scope_shift</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/pits/ying_decoder.html#YingDecoder.crop_scope"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.pits.ying_decoder.YingDecoder.crop_scope" title="Permalink to this definition">¶</a></dt>
<dd><p>Crop the input tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>torch.Tensor</em>) – Input tensor of shape [B, C, T].</p></li>
<li><p><strong>yin_start</strong> (<em>int</em>) – Starting point of the yin target signal.</p></li>
<li><p><strong>scope_shift</strong> (<em>torch.Tensor</em>) – Shift tensor of shape [B].</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Cropped tensor of shape [B, C, yin_scope].</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_svs.pits.ying_decoder.YingDecoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">z_yin</em>, <em class="sig-param">yin_gt</em>, <em class="sig-param">z_mask</em>, <em class="sig-param">g=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/pits/ying_decoder.html#YingDecoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.pits.ying_decoder.YingDecoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward pass of the decoder.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>z_yin</strong> (<em>torch.Tensor</em>) – The input yin note sequence of shape (B, C, T_yin).</p></li>
<li><p><strong>yin_gt</strong> (<em>torch.Tensor</em>) – The ground truth yin note sequence of shape
(B, C, T_yin).</p></li>
<li><p><strong>z_mask</strong> (<em>torch.Tensor</em>) – The mask tensor of shape (B, 1, T_yin).</p></li>
<li><p><strong>g</strong> (<em>torch.Tensor</em>) – The global conditioning tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p>The predicted yin note sequence of shape (B, C, T_yin).
torch.Tensor: The shifted ground truth yin note sequence of shape</p>
<blockquote>
<div><p>(B, C, T_yin).</p>
</div></blockquote>
<dl class="simple">
<dt>torch.Tensor: The cropped ground truth yin note sequence of shape</dt><dd><p>(B, C, T_yin).</p>
</dd>
</dl>
<p>torch.Tensor: The cropped input yin note sequence of shape (B, C, T_yin).
torch.Tensor: The scope shift tensor of shape (B,).</p>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_svs.pits.ying_decoder.YingDecoder.infer">
<code class="sig-name descname">infer</code><span class="sig-paren">(</span><em class="sig-param">z_yin</em>, <em class="sig-param">z_mask</em>, <em class="sig-param">g=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/pits/ying_decoder.html#YingDecoder.infer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.pits.ying_decoder.YingDecoder.infer" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate yin prediction.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>z_yin</strong> (<em>torch.Tensor</em>) – Input yin target tensor of shape [B, yin_scope, C].</p></li>
<li><p><strong>z_mask</strong> (<em>torch.Tensor</em>) – Input mask tensor of shape [B, yin_scope, 1].</p></li>
<li><p><strong>g</strong> (<em>torch.Tensor</em><em>, </em><em>optional</em>) – Global conditioning tensor of shape
[B, gin_channels, 1]. Defaults to None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Predicted yin tensor of shape [B, yin_scope, C].</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-gan-svs-vits-phoneme-predictor-1">
<span id="espnet2-gan-svs-vits-phoneme-predictor"></span><h2>espnet2.gan_svs.vits.phoneme_predictor<a class="headerlink" href="#espnet2-gan-svs-vits-phoneme-predictor-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_svs.vits.phoneme_predictor"></span><dl class="class">
<dt id="espnet2.gan_svs.vits.phoneme_predictor.PhonemePredictor">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_svs.vits.phoneme_predictor.</code><code class="sig-name descname">PhonemePredictor</code><span class="sig-paren">(</span><em class="sig-param">vocabs: int</em>, <em class="sig-param">hidden_channels: int = 192</em>, <em class="sig-param">attention_dim: int = 192</em>, <em class="sig-param">attention_heads: int = 2</em>, <em class="sig-param">linear_units: int = 768</em>, <em class="sig-param">blocks: int = 2</em>, <em class="sig-param">positionwise_layer_type: str = 'conv1d'</em>, <em class="sig-param">positionwise_conv_kernel_size: int = 3</em>, <em class="sig-param">positional_encoding_layer_type: str = 'rel_pos'</em>, <em class="sig-param">self_attention_layer_type: str = 'rel_selfattn'</em>, <em class="sig-param">activation_type: str = 'swish'</em>, <em class="sig-param">normalize_before: bool = True</em>, <em class="sig-param">use_macaron_style: bool = False</em>, <em class="sig-param">use_conformer_conv: bool = False</em>, <em class="sig-param">conformer_kernel_size: int = 7</em>, <em class="sig-param">dropout_rate: float = 0.1</em>, <em class="sig-param">positional_dropout_rate: float = 0.0</em>, <em class="sig-param">attention_dropout_rate: float = 0.0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/vits/phoneme_predictor.html#PhonemePredictor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.vits.phoneme_predictor.PhonemePredictor" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Phoneme Predictor module in VISinger.</p>
<p>Initialize PhonemePredictor module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>vocabs</strong> (<em>int</em>) – The number of vocabulary.</p></li>
<li><p><strong>hidden_channels</strong> (<em>int</em>) – The number of hidden channels.</p></li>
<li><p><strong>attention_dim</strong> (<em>int</em>) – The number of attention dimension.</p></li>
<li><p><strong>attention_heads</strong> (<em>int</em>) – The number of attention heads.</p></li>
<li><p><strong>linear_units</strong> (<em>int</em>) – The number of linear units.</p></li>
<li><p><strong>blocks</strong> (<em>int</em>) – The number of encoder blocks.</p></li>
<li><p><strong>positionwise_layer_type</strong> (<em>str</em>) – The type of position-wise layer.</p></li>
<li><p><strong>positionwise_conv_kernel_size</strong> (<em>int</em>) – The size of position-wise
convolution kernel.</p></li>
<li><p><strong>positional_encoding_layer_type</strong> (<em>str</em>) – The type of positional encoding layer.</p></li>
<li><p><strong>self_attention_layer_type</strong> (<em>str</em>) – The type of self-attention layer.</p></li>
<li><p><strong>activation_type</strong> (<em>str</em>) – The type of activation function.</p></li>
<li><p><strong>normalize_before</strong> (<em>bool</em>) – Whether to apply normalization before the
position-wise layer or not.</p></li>
<li><p><strong>use_macaron_style</strong> (<em>bool</em>) – Whether to use macaron style or not.</p></li>
<li><p><strong>use_conformer_conv</strong> (<em>bool</em>) – Whether to use Conformer convolution or not.</p></li>
<li><p><strong>conformer_kernel_size</strong> (<em>int</em>) – The size of Conformer kernel.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>) – The dropout rate.</p></li>
<li><p><strong>positional_dropout_rate</strong> (<em>float</em>) – The dropout rate for positional encoding.</p></li>
<li><p><strong>attention_dropout_rate</strong> (<em>float</em>) – The dropout rate for attention.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_svs.vits.phoneme_predictor.PhonemePredictor.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">x_mask</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/vits/phoneme_predictor.html#PhonemePredictor.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.vits.phoneme_predictor.PhonemePredictor.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – The input tensor of shape (B, dim, length).</p></li>
<li><p><strong>x_mask</strong> (<em>Tensor</em>) – The mask tensor for the input tensor of shape (B, length).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The predicted phoneme tensor of shape (length, B, vocab_size).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-gan-svs-vits-pitch-predictor-1">
<span id="espnet2-gan-svs-vits-pitch-predictor"></span><h2>espnet2.gan_svs.vits.pitch_predictor<a class="headerlink" href="#espnet2-gan-svs-vits-pitch-predictor-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_svs.vits.pitch_predictor"></span><dl class="class">
<dt id="espnet2.gan_svs.vits.pitch_predictor.Decoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_svs.vits.pitch_predictor.</code><code class="sig-name descname">Decoder</code><span class="sig-paren">(</span><em class="sig-param">out_channels: int = 192</em>, <em class="sig-param">attention_dim: int = 192</em>, <em class="sig-param">attention_heads: int = 2</em>, <em class="sig-param">linear_units: int = 768</em>, <em class="sig-param">blocks: int = 6</em>, <em class="sig-param">pw_layer_type: str = 'conv1d'</em>, <em class="sig-param">pw_conv_kernel_size: int = 3</em>, <em class="sig-param">pos_enc_layer_type: str = 'rel_pos'</em>, <em class="sig-param">self_attention_layer_type: str = 'rel_selfattn'</em>, <em class="sig-param">activation_type: str = 'swish'</em>, <em class="sig-param">normalize_before: bool = True</em>, <em class="sig-param">use_macaron_style: bool = False</em>, <em class="sig-param">use_conformer_conv: bool = False</em>, <em class="sig-param">conformer_kernel_size: int = 7</em>, <em class="sig-param">dropout_rate: float = 0.1</em>, <em class="sig-param">positional_dropout_rate: float = 0.0</em>, <em class="sig-param">attention_dropout_rate: float = 0.0</em>, <em class="sig-param">global_channels: int = -1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/vits/pitch_predictor.html#Decoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.vits.pitch_predictor.Decoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Pitch or Mel decoder module in VISinger 2.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>out_channels</strong> (<em>int</em>) – The output dimension of the module.</p></li>
<li><p><strong>attention_dim</strong> (<em>int</em>) – The dimension of the attention mechanism.</p></li>
<li><p><strong>attention_heads</strong> (<em>int</em>) – The number of attention heads.</p></li>
<li><p><strong>linear_units</strong> (<em>int</em>) – The number of units in the linear layer.</p></li>
<li><p><strong>blocks</strong> (<em>int</em>) – The number of encoder blocks.</p></li>
<li><p><strong>pw_layer_type</strong> (<em>str</em>) – The type of position-wise layer to use.</p></li>
<li><p><strong>pw_conv_kernel_size</strong> (<em>int</em>) – The kernel size of the position-wise
convolutional layer.</p></li>
<li><p><strong>pos_enc_layer_type</strong> (<em>str</em>) – The type of positional encoding layer to use.</p></li>
<li><p><strong>self_attention_layer_type</strong> (<em>str</em>) – The type of self-attention layer to use.</p></li>
<li><p><strong>activation_type</strong> (<em>str</em>) – The type of activation function to use.</p></li>
<li><p><strong>normalize_before</strong> (<em>bool</em>) – Whether to normalize the data before the
position-wise layer or after.</p></li>
<li><p><strong>use_macaron_style</strong> (<em>bool</em>) – Whether to use the macaron style or not.</p></li>
<li><p><strong>use_conformer_conv</strong> (<em>bool</em>) – Whether to use Conformer style conv or not.</p></li>
<li><p><strong>conformer_kernel_size</strong> (<em>int</em>) – The kernel size of the conformer
convolutional layer.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>) – The dropout rate to use.</p></li>
<li><p><strong>positional_dropout_rate</strong> (<em>float</em>) – The positional dropout rate to use.</p></li>
<li><p><strong>attention_dropout_rate</strong> (<em>float</em>) – The attention dropout rate to use.</p></li>
<li><p><strong>global_channels</strong> (<em>int</em>) – The number of channels to use for global
conditioning.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_svs.vits.pitch_predictor.Decoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">x_lengths</em>, <em class="sig-param">g=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/vits/pitch_predictor.html#Decoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.vits.pitch_predictor.Decoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward pass of the Decoder.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – Input tensor (B, 2 + attention_dim, T).</p></li>
<li><p><strong>x_lengths</strong> (<em>Tensor</em>) – Length tensor (B,).</p></li>
<li><p><strong>g</strong> (<em>Tensor</em><em>, </em><em>optional</em>) – Global conditioning tensor (B, global_channels, 1).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Output tensor (B, 1, T).
Tensor: Output mask (B, 1, T).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-gan-svs-vits-modules-1">
<span id="espnet2-gan-svs-vits-modules"></span><h2>espnet2.gan_svs.vits.modules<a class="headerlink" href="#espnet2-gan-svs-vits-modules-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_svs.vits.modules"></span><dl class="class">
<dt id="espnet2.gan_svs.vits.modules.Projection">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_svs.vits.modules.</code><code class="sig-name descname">Projection</code><span class="sig-paren">(</span><em class="sig-param">hidden_channels</em>, <em class="sig-param">out_channels</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/vits/modules.html#Projection"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.vits.modules.Projection" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="method">
<dt id="espnet2.gan_svs.vits.modules.Projection.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">x_mask</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/vits/modules.html#Projection.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.vits.modules.Projection.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</aside>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="espnet2.gan_svs.vits.modules.sequence_mask">
<code class="sig-prename descclassname">espnet2.gan_svs.vits.modules.</code><code class="sig-name descname">sequence_mask</code><span class="sig-paren">(</span><em class="sig-param">length</em>, <em class="sig-param">max_length=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/vits/modules.html#sequence_mask"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.vits.modules.sequence_mask" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</section>
<section id="espnet2-gan-svs-vits-length-regulator-1">
<span id="espnet2-gan-svs-vits-length-regulator"></span><h2>espnet2.gan_svs.vits.length_regulator<a class="headerlink" href="#espnet2-gan-svs-vits-length-regulator-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_svs.vits.length_regulator"></span><p>Length regulator related modules.</p>
<dl class="class">
<dt id="espnet2.gan_svs.vits.length_regulator.LengthRegulator">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_svs.vits.length_regulator.</code><code class="sig-name descname">LengthRegulator</code><span class="sig-paren">(</span><em class="sig-param">pad_value=0.0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/vits/length_regulator.html#LengthRegulator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.vits.length_regulator.LengthRegulator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Length Regulator</p>
<p>Initilize length regulator module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>pad_value</strong> (<em>float</em><em>, </em><em>optional</em>) – Value used for padding.</p>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_svs.vits.length_regulator.LengthRegulator.LR">
<code class="sig-name descname">LR</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">duration</em>, <em class="sig-param">use_state_info=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/vits/length_regulator.html#LengthRegulator.LR"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.vits.length_regulator.LengthRegulator.LR" title="Permalink to this definition">¶</a></dt>
<dd><p>Length regulates input mel-spectrograms to match duration.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – Input tensor (B, dim, T).</p></li>
<li><p><strong>duration</strong> (<em>Tensor</em>) – Duration tensor (B, T).</p></li>
<li><p><strong>use_state_info</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to use position information or not.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Output tensor (B, dim, D_frame).
Tensor: Output length (B,).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_svs.vits.length_regulator.LengthRegulator.expand">
<code class="sig-name descname">expand</code><span class="sig-paren">(</span><em class="sig-param">batch</em>, <em class="sig-param">predicted</em>, <em class="sig-param">use_state_info=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/vits/length_regulator.html#LengthRegulator.expand"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.vits.length_regulator.LengthRegulator.expand" title="Permalink to this definition">¶</a></dt>
<dd><p>Expand input mel-spectrogram based on the predicted duration.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<em>Tensor</em>) – Input tensor (T, dim).</p></li>
<li><p><strong>predicted</strong> (<em>Tensor</em>) – Predicted duration tensor (T,).</p></li>
<li><p><strong>use_state_info</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to use position information or not.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Output tensor (D_frame, dim).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_svs.vits.length_regulator.LengthRegulator.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">duration</em>, <em class="sig-param">use_state_info=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/vits/length_regulator.html#LengthRegulator.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.vits.length_regulator.LengthRegulator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward pass through the length regulator module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – Input tensor (B, dim, T).</p></li>
<li><p><strong>duration</strong> (<em>Tensor</em>) – Duration tensor (B, T).</p></li>
<li><p><strong>use_state_info</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to use position information or not.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Output tensor (B, dim, D_frame).
Tensor: Output length (B,).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-gan-svs-vits-duration-predictor-1">
<span id="espnet2-gan-svs-vits-duration-predictor"></span><h2>espnet2.gan_svs.vits.duration_predictor<a class="headerlink" href="#espnet2-gan-svs-vits-duration-predictor-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_svs.vits.duration_predictor"></span><p>Duration predictor modules in VISinger.</p>
<dl class="class">
<dt id="espnet2.gan_svs.vits.duration_predictor.DurationPredictor">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_svs.vits.duration_predictor.</code><code class="sig-name descname">DurationPredictor</code><span class="sig-paren">(</span><em class="sig-param">channels</em>, <em class="sig-param">filter_channels</em>, <em class="sig-param">kernel_size</em>, <em class="sig-param">dropout_rate</em>, <em class="sig-param">global_channels=0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/vits/duration_predictor.html#DurationPredictor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.vits.duration_predictor.DurationPredictor" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Initialize duration predictor module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>channels</strong> (<em>int</em>) – Number of input channels.</p></li>
<li><p><strong>filter_channels</strong> (<em>int</em>) – Number of filter channels.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – Size of the convolutional kernel.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>) – Dropout rate.</p></li>
<li><p><strong>global_channels</strong> (<em>int</em><em>, </em><em>optional</em>) – Number of global conditioning channels.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_svs.vits.duration_predictor.DurationPredictor.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">x_mask</em>, <em class="sig-param">g=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/vits/duration_predictor.html#DurationPredictor.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.vits.duration_predictor.DurationPredictor.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward pass through the duration predictor module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – Input tensor (B, in_channels, T).</p></li>
<li><p><strong>x_mask</strong> (<em>Tensor</em>) – Mask tensor (B, 1, T).</p></li>
<li><p><strong>g</strong> (<em>Tensor</em><em>, </em><em>optional</em>) – Global condition tensor (B, global_channels, 1).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Predicted duration tensor (B, 2, T).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-gan-svs-vits-vits-1">
<span id="espnet2-gan-svs-vits-vits"></span><h2>espnet2.gan_svs.vits.vits<a class="headerlink" href="#espnet2-gan-svs-vits-vits-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_svs.vits.vits"></span><p>VITS/VISinger module for GAN-SVS task.</p>
<dl class="class">
<dt id="espnet2.gan_svs.vits.vits.VITS">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_svs.vits.vits.</code><code class="sig-name descname">VITS</code><span class="sig-paren">(</span><em class="sig-param">idim: int, odim: int, sampling_rate: int = 22050, generator_type: str = 'visinger', vocoder_generator_type: str = 'hifigan', generator_params: Dict[str, Any] = {'decoder_channels': 512, 'decoder_kernel_size': 7, 'decoder_resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'decoder_resblock_kernel_sizes': [3, 7, 11], 'decoder_upsample_kernel_sizes': [16, 16, 4, 4], 'decoder_upsample_scales': [8, 8, 2, 2], 'expand_f0_method': 'repeat', 'flow_base_dilation': 1, 'flow_dropout_rate': 0.0, 'flow_flows': 4, 'flow_kernel_size': 5, 'flow_layers': 4, 'global_channels': -1, 'hidden_channels': 192, 'langs': None, 'posterior_encoder_base_dilation': 1, 'posterior_encoder_dropout_rate': 0.0, 'posterior_encoder_kernel_size': 5, 'posterior_encoder_layers': 16, 'posterior_encoder_stacks': 1, 'projection_filters': [0, 1, 1, 1], 'projection_kernels': [0, 5, 7, 11], 'segment_size': 32, 'spk_embed_dim': None, 'spks': None, 'text_encoder_activation_type': 'swish', 'text_encoder_attention_dropout_rate': 0.0, 'text_encoder_attention_heads': 2, 'text_encoder_blocks': 6, 'text_encoder_conformer_kernel_size': 7, 'text_encoder_dropout_rate': 0.1, 'text_encoder_ffn_expand': 4, 'text_encoder_normalize_before': True, 'text_encoder_positional_dropout_rate': 0.0, 'text_encoder_positional_encoding_layer_type': 'rel_pos', 'text_encoder_positionwise_conv_kernel_size': 1, 'text_encoder_positionwise_layer_type': 'conv1d', 'text_encoder_self_attention_layer_type': 'rel_selfattn', 'use_conformer_conv_in_text_encoder': True, 'use_macaron_style_in_text_encoder': True, 'use_only_mean_in_flow': True, 'use_phoneme_predictor': False, 'use_weight_norm_in_decoder': True, 'use_weight_norm_in_flow': True, 'use_weight_norm_in_posterior_encoder': True}, discriminator_type: str = 'hifigan_multi_scale_multi_period_discriminator', discriminator_params: Dict[str, Any] = {'avocodo': {'combd': {'combd_d_d': [[1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1]], 'combd_d_g': [[1, 4, 16, 64, 256, 1], [1, 4, 16, 64, 256, 1], [1, 4, 16, 64, 256, 1]], 'combd_d_k': [[7, 11, 11, 11, 11, 5], [11, 21, 21, 21, 21, 5], [15, 41, 41, 41, 41, 5]], 'combd_d_p': [[3, 5, 5, 5, 5, 2], [5, 10, 10, 10, 10, 2], [7, 20, 20, 20, 20, 2]], 'combd_d_s': [[1, 1, 4, 4, 4, 1], [1, 1, 4, 4, 4, 1], [1, 1, 4, 4, 4, 1]], 'combd_h_u': [[16, 64, 256, 1024, 1024, 1024], [16, 64, 256, 1024, 1024, 1024], [16, 64, 256, 1024, 1024, 1024]], 'combd_op_f': [1, 1, 1], 'combd_op_g': [1, 1, 1], 'combd_op_k': [3, 3, 3]}, 'pqmf_config': {'lv1': [2, 256, 0.25, 10.0], 'lv2': [4, 192, 0.13, 10.0]}, 'sbd': {'pqmf_config': {'fsbd': [64, 256, 0.1, 9.0], 'sbd': [16, 256, 0.03, 10.0]}, 'sbd_band_ranges': [[0, 6], [0, 11], [0, 16], [0, 64]], 'sbd_dilations': [[[5, 7, 11], [5, 7, 11], [5, 7, 11], [5, 7, 11], [5, 7, 11]], [[3, 5, 7], [3, 5, 7], [3, 5, 7], [3, 5, 7], [3, 5, 7]], [[1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3]], [[1, 2, 3], [1, 2, 3], [1, 2, 3], [2, 3, 5], [2, 3, 5]]], 'sbd_filters': [[64, 128, 256, 256, 256], [64, 128, 256, 256, 256], [64, 128, 256, 256, 256], [32, 64, 128, 128, 128]], 'sbd_kernel_sizes': [[[7, 7, 7], [7, 7, 7], [7, 7, 7], [7, 7, 7], [7, 7, 7]], [[5, 5, 5], [5, 5, 5], [5, 5, 5], [5, 5, 5], [5, 5, 5]], [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], [[5, 5, 5], [5, 5, 5], [5, 5, 5], [5, 5, 5], [5, 5, 5]]], 'sbd_strides': [[1, 1, 3, 3, 1], [1, 1, 3, 3, 1], [1, 1, 3, 3, 1], [1, 1, 3, 3, 1]], 'sbd_transpose': [False, False, False, True], 'use_sbd': True}}, 'hifigan_multi_scale_multi_period_discriminator': {'follow_official_norm': False, 'period_discriminator_params': {'bias': True, 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'in_channels': 1, 'kernel_sizes': [5, 3], 'max_downsample_channels': 1024, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'out_channels': 1, 'use_spectral_norm': False, 'use_weight_norm': True}, 'periods': [2, 3, 5, 7, 11], 'scale_discriminator_params': {'bias': True, 'channels': 128, 'downsample_scales': [2, 2, 4, 4, 1], 'in_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'max_downsample_channels': 1024, 'max_groups': 16, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'out_channels': 1, 'use_spectral_norm': False, 'use_weight_norm': True}, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'padding': 2, 'stride': 2}, 'scales': 1}}, generator_adv_loss_params: Dict[str, Any] = {'average_by_discriminators': False, 'loss_type': 'mse'}, discriminator_adv_loss_params: Dict[str, Any] = {'average_by_discriminators': False, 'loss_type': 'mse'}, feat_match_loss_params: Dict[str, Any] = {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, mel_loss_params: Dict[str, Any] = {'fmax': None, 'fmin': 0, 'fs': 22050, 'hop_length': 256, 'log_base': None, 'n_fft': 1024, 'n_mels': 80, 'win_length': None, 'window': 'hann'}, lambda_adv: float = 1.0, lambda_mel: float = 45.0, lambda_feat_match: float = 2.0, lambda_dur: float = 0.1, lambda_kl: float = 1.0, lambda_pitch: float = 10.0, lambda_phoneme: float = 1.0, lambda_c_yin: float = 45.0, cache_generator_outputs: bool = True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/vits/vits.html#VITS"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.vits.vits.VITS" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.gan_svs.abs_gan_svs.AbsGANSVS" title="espnet2.gan_svs.abs_gan_svs.AbsGANSVS"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.gan_svs.abs_gan_svs.AbsGANSVS</span></code></a></p>
<p>VITS module (generator + discriminator).</p>
<p>This is a module of VITS described in <a class="reference external" href="https://arxiv.org/abs/2006.04558">Conditional Variational Autoencoder
with Adversarial Learning for End-to-End Text-to-Speech</a>.</p>
<p>Initialize VITS module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> (<em>int</em>) – Input vocabrary size.</p></li>
<li><p><strong>odim</strong> (<em>int</em>) – Acoustic feature dimension. The actual output channels will
be 1 since VITS is the end-to-end text-to-wave model but for the
compatibility odim is used to indicate the acoustic feature dimension.</p></li>
<li><p><strong>sampling_rate</strong> (<em>int</em>) – Sampling rate, not used for the training but it will
be referred in saving waveform during the inference.</p></li>
<li><p><strong>generator_type</strong> (<em>str</em>) – Generator type.</p></li>
<li><p><strong>vocoder_generator_type</strong> (<em>str</em>) – Type of vocoder generator to use in the model.</p></li>
<li><p><strong>generator_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Parameter dict for generator.</p></li>
<li><p><strong>discriminator_type</strong> (<em>str</em>) – Discriminator type.</p></li>
<li><p><strong>discriminator_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Parameter dict for discriminator.</p></li>
<li><p><strong>generator_adv_loss_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Parameter dict for generator
adversarial loss.</p></li>
<li><p><strong>discriminator_adv_loss_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Parameter dict for
discriminator adversarial loss.</p></li>
<li><p><strong>feat_match_loss_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Parameter dict for feat match loss.</p></li>
<li><p><strong>mel_loss_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Parameter dict for mel loss.</p></li>
<li><p><strong>lambda_adv</strong> (<em>float</em>) – Loss scaling coefficient for adversarial loss.</p></li>
<li><p><strong>lambda_mel</strong> (<em>float</em>) – Loss scaling coefficient for mel spectrogram loss.</p></li>
<li><p><strong>lambda_feat_match</strong> (<em>float</em>) – Loss scaling coefficient for feat match loss.</p></li>
<li><p><strong>lambda_dur</strong> (<em>float</em>) – Loss scaling coefficient for duration loss.</p></li>
<li><p><strong>lambda_kl</strong> (<em>float</em>) – Loss scaling coefficient for KL divergence loss.</p></li>
<li><p><strong>lambda_pitch</strong> (<em>float</em>) – Loss scaling coefficient for pitch loss.</p></li>
<li><p><strong>lambda_phoneme</strong> (<em>float</em>) – Loss scaling coefficient for phoneme loss.</p></li>
<li><p><strong>lambda_c_yin</strong> (<em>float</em>) – Loss scaling coefficient for yin loss.</p></li>
<li><p><strong>cache_generator_outputs</strong> (<em>bool</em>) – Whether to cache generator outputs.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_svs.vits.vits.VITS.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">text: torch.Tensor</em>, <em class="sig-param">text_lengths: torch.Tensor</em>, <em class="sig-param">feats: torch.Tensor</em>, <em class="sig-param">feats_lengths: torch.Tensor</em>, <em class="sig-param">singing: torch.Tensor</em>, <em class="sig-param">singing_lengths: torch.Tensor</em>, <em class="sig-param">label: Optional[Dict[str</em>, <em class="sig-param">torch.Tensor]] = None</em>, <em class="sig-param">label_lengths: Optional[Dict[str</em>, <em class="sig-param">torch.Tensor]] = None</em>, <em class="sig-param">melody: Optional[Dict[str</em>, <em class="sig-param">torch.Tensor]] = None</em>, <em class="sig-param">pitch: torch.LongTensor = None</em>, <em class="sig-param">ying: torch.Tensor = None</em>, <em class="sig-param">duration: Optional[Dict[str</em>, <em class="sig-param">torch.Tensor]] = None</em>, <em class="sig-param">slur: torch.LongTensor = None</em>, <em class="sig-param">spembs: Optional[torch.Tensor] = None</em>, <em class="sig-param">sids: Optional[torch.Tensor] = None</em>, <em class="sig-param">lids: Optional[torch.Tensor] = None</em>, <em class="sig-param">forward_generator: bool = True</em><span class="sig-paren">)</span> &#x2192; Dict[str, Any]<a class="reference internal" href="../_modules/espnet2/gan_svs/vits/vits.html#VITS.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.vits.vits.VITS.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform generator forward.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>LongTensor</em>) – Batch of padded character ids (B, T_text).</p></li>
<li><p><strong>text_lengths</strong> (<em>LongTensor</em>) – Batch of lengths of each input batch (B,).</p></li>
<li><p><strong>feats</strong> (<em>Tensor</em>) – Batch of padded target features (B, Lmax, odim).</p></li>
<li><p><strong>feats_lengths</strong> (<em>LongTensor</em>) – Batch of the lengths of each target (B,).</p></li>
<li><p><strong>singing</strong> (<em>Tensor</em>) – Singing waveform tensor (B, T_wav).</p></li>
<li><p><strong>singing_lengths</strong> (<em>Tensor</em>) – Singing length tensor (B,).</p></li>
<li><p><strong>label</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>]</em>) – key is “lab” or “score”;
value (LongTensor): Batch of padded label ids (B, T_text).</p></li>
<li><p><strong>label_lengths</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>]</em>) – key is “lab” or “score”;
value (LongTensor): Batch of the lengths of padded label ids (B, ).</p></li>
<li><p><strong>melody</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>]</em>) – key is “lab” or “score”;
value (LongTensor): Batch of padded melody (B, T_text).</p></li>
<li><p><strong>pitch</strong> (<em>FloatTensor</em>) – Batch of padded f0 (B, T_feats).</p></li>
<li><p><strong>duration</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>]</em>) – key is “lab”, “score_phn” or “score_syb”;
value (LongTensor): Batch of padded duration (B, T_text).</p></li>
<li><p><strong>slur</strong> (<em>FloatTensor</em>) – Batch of padded slur (B, T_text).</p></li>
<li><p><strong>spembs</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Batch of speaker embeddings (B, spk_embed_dim).</p></li>
<li><p><strong>sids</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Batch of speaker IDs (B, 1).</p></li>
<li><p><strong>lids</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Batch of language IDs (B, 1).</p></li>
<li><p><strong>forward_generator</strong> (<em>bool</em>) – Whether to forward generator.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p>loss (Tensor): Loss scalar tensor.</p></li>
<li><p>stats (Dict[str, float]): Statistics to be monitored.</p></li>
<li><p>weight (Tensor): Weight tensor to summarize losses.</p></li>
<li><p>optim_idx (int): Optimizer index (0 for G and 1 for D).</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Dict[str, Any]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_svs.vits.vits.VITS.inference">
<code class="sig-name descname">inference</code><span class="sig-paren">(</span><em class="sig-param">text: torch.Tensor</em>, <em class="sig-param">feats: Optional[torch.Tensor] = None</em>, <em class="sig-param">label: Optional[Dict[str</em>, <em class="sig-param">torch.Tensor]] = None</em>, <em class="sig-param">melody: Optional[Dict[str</em>, <em class="sig-param">torch.Tensor]] = None</em>, <em class="sig-param">pitch: Optional[torch.Tensor] = None</em>, <em class="sig-param">duration: Optional[Dict[str</em>, <em class="sig-param">torch.Tensor]] = None</em>, <em class="sig-param">slur: Optional[Dict[str</em>, <em class="sig-param">torch.Tensor]] = None</em>, <em class="sig-param">spembs: Optional[torch.Tensor] = None</em>, <em class="sig-param">sids: Optional[torch.Tensor] = None</em>, <em class="sig-param">lids: Optional[torch.Tensor] = None</em>, <em class="sig-param">noise_scale: float = 0.667</em>, <em class="sig-param">noise_scale_dur: float = 0.8</em>, <em class="sig-param">alpha: float = 1.0</em>, <em class="sig-param">max_len: Optional[int] = None</em>, <em class="sig-param">use_teacher_forcing: bool = False</em><span class="sig-paren">)</span> &#x2192; Dict[str, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/gan_svs/vits/vits.html#VITS.inference"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.vits.vits.VITS.inference" title="Permalink to this definition">¶</a></dt>
<dd><p>Run inference.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>Tensor</em>) – Input text index tensor (T_text,).</p></li>
<li><p><strong>feats</strong> (<em>Tensor</em>) – Feature tensor (T_feats, aux_channels).</p></li>
<li><p><strong>label</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>]</em>) – key is “lab” or “score”;
value (LongTensor): Batch of padded label ids (B, T_text).</p></li>
<li><p><strong>melody</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>]</em>) – key is “lab” or “score”;
value (LongTensor): Batch of padded melody (B, T_text).</p></li>
<li><p><strong>pitch</strong> (<em>FloatTensor</em>) – Batch of padded f0 (B, T_feats).</p></li>
<li><p><strong>slur</strong> (<em>LongTensor</em>) – Batch of padded slur (B, T_text).</p></li>
<li><p><strong>sids</strong> (<em>Tensor</em>) – Speaker index tensor (1,).</p></li>
<li><p><strong>spembs</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Speaker embedding tensor (spk_embed_dim,).</p></li>
<li><p><strong>lids</strong> (<em>Tensor</em>) – Language index tensor (1,).</p></li>
<li><p><strong>noise_scale</strong> (<em>float</em>) – Noise scale value for flow.</p></li>
<li><p><strong>noise_scale_dur</strong> (<em>float</em>) – Noise scale value for duration predictor.</p></li>
<li><p><strong>alpha</strong> (<em>float</em>) – Alpha parameter to control the speed of generated singing.</p></li>
<li><p><strong>max_len</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – Maximum length.</p></li>
<li><p><strong>use_teacher_forcing</strong> (<em>bool</em>) – Whether to use teacher forcing.</p></li>
<li><p><strong>duration</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>]</em>) – key is “lab”, “score_phn” or “score_syb”;
value (LongTensor): Batch of padded duration (B, T_text).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p>wav (Tensor): Generated waveform tensor (T_wav,).</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Dict[str, Tensor]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_svs.vits.vits.VITS.require_raw_singing">
<em class="property">property </em><code class="sig-name descname">require_raw_singing</code><a class="headerlink" href="#espnet2.gan_svs.vits.vits.VITS.require_raw_singing" title="Permalink to this definition">¶</a></dt>
<dd><p>Return whether or not singing is required.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_svs.vits.vits.VITS.require_vocoder">
<em class="property">property </em><code class="sig-name descname">require_vocoder</code><a class="headerlink" href="#espnet2.gan_svs.vits.vits.VITS.require_vocoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Return whether or not vocoder is required.</p>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-gan-svs-vits-generator-1">
<span id="espnet2-gan-svs-vits-generator"></span><h2>espnet2.gan_svs.vits.generator<a class="headerlink" href="#espnet2-gan-svs-vits-generator-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_svs.vits.generator"></span><p>Generator module in VISinger.</p>
<p>This code is based on <a class="reference external" href="https://github.com/jaywalnut310/vits">https://github.com/jaywalnut310/vits</a>.</p>
<blockquote>
<div><dl class="simple">
<dt>This is a module of VISinger described in <a href="#system-message-1"><span class="problematic" id="problematic-1">`</span></a>VISinger: Variational Inference</dt><dd><p>with Adversarial Learning for End-to-End Singing Voice Synthesis`_.</p>
</dd>
</dl>
</div></blockquote>
<dl class="class">
<dt id="espnet2.gan_svs.vits.generator.VISingerGenerator">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_svs.vits.generator.</code><code class="sig-name descname">VISingerGenerator</code><span class="sig-paren">(</span><em class="sig-param">vocabs: int, aux_channels: int = 513, hidden_channels: int = 192, spks: Optional[int] = None, langs: Optional[int] = None, spk_embed_dim: Optional[int] = None, global_channels: int = -1, segment_size: int = 32, text_encoder_attention_heads: int = 2, text_encoder_ffn_expand: int = 4, text_encoder_blocks: int = 6, text_encoder_positionwise_layer_type: str = 'conv1d', text_encoder_positionwise_conv_kernel_size: int = 1, text_encoder_positional_encoding_layer_type: str = 'rel_pos', text_encoder_self_attention_layer_type: str = 'rel_selfattn', text_encoder_activation_type: str = 'swish', text_encoder_normalize_before: bool = True, text_encoder_dropout_rate: float = 0.1, text_encoder_positional_dropout_rate: float = 0.0, text_encoder_attention_dropout_rate: float = 0.0, text_encoder_conformer_kernel_size: int = 7, use_macaron_style_in_text_encoder: bool = True, use_conformer_conv_in_text_encoder: bool = True, decoder_kernel_size: int = 7, decoder_channels: int = 512, decoder_downsample_scales: List[int] = [2, 2, 8, 8], decoder_downsample_kernel_sizes: List[int] = [4, 4, 16, 16], decoder_upsample_scales: List[int] = [8, 8, 2, 2], decoder_upsample_kernel_sizes: List[int] = [16, 16, 4, 4], decoder_resblock_kernel_sizes: List[int] = [3, 7, 11], decoder_resblock_dilations: List[List[int]] = [[1, 3, 5], [1, 3, 5], [1, 3, 5]], use_avocodo=False, projection_filters: List[int] = [0, 1, 1, 1], projection_kernels: List[int] = [0, 5, 7, 11], n_harmonic: int = 64, use_weight_norm_in_decoder: bool = True, posterior_encoder_kernel_size: int = 5, posterior_encoder_layers: int = 16, posterior_encoder_stacks: int = 1, posterior_encoder_base_dilation: int = 1, posterior_encoder_dropout_rate: float = 0.0, use_weight_norm_in_posterior_encoder: bool = True, flow_flows: int = 4, flow_kernel_size: int = 5, flow_base_dilation: int = 1, flow_layers: int = 4, flow_dropout_rate: float = 0.0, use_weight_norm_in_flow: bool = True, use_only_mean_in_flow: bool = True, generator_type: str = 'visinger', vocoder_generator_type: str = 'hifigan', fs: int = 22050, hop_length: int = 256, win_length: int = 1024, n_fft: int = 1024, use_phoneme_predictor: bool = False, expand_f0_method: str = 'repeat'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/vits/generator.html#VISingerGenerator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.vits.generator.VISingerGenerator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Generator module in VISinger.</p>
<p>Initialize VITS generator module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>vocabs</strong> (<em>int</em>) – Input vocabulary size.</p></li>
<li><p><strong>aux_channels</strong> (<em>int</em>) – Number of acoustic feature channels.</p></li>
<li><p><strong>hidden_channels</strong> (<em>int</em>) – Number of hidden channels.</p></li>
<li><p><strong>spks</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – Number of speakers. If set to &gt; 1, assume that the
sids will be provided as the input and use sid embedding layer.</p></li>
<li><p><strong>langs</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – Number of languages. If set to &gt; 1, assume that the
lids will be provided as the input and use sid embedding layer.</p></li>
<li><p><strong>spk_embed_dim</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – Speaker embedding dimension. If set to &gt; 0,
assume that spembs will be provided as the input.</p></li>
<li><p><strong>global_channels</strong> (<em>int</em>) – Number of global conditioning channels.</p></li>
<li><p><strong>segment_size</strong> (<em>int</em>) – Segment size for decoder.</p></li>
<li><p><strong>text_encoder_attention_heads</strong> (<em>int</em>) – Number of heads in conformer block
of text encoder.</p></li>
<li><p><strong>text_encoder_ffn_expand</strong> (<em>int</em>) – Expansion ratio of FFN in conformer block
of text encoder.</p></li>
<li><p><strong>text_encoder_blocks</strong> (<em>int</em>) – Number of conformer blocks in text encoder.</p></li>
<li><p><strong>text_encoder_positionwise_layer_type</strong> (<em>str</em>) – Position-wise layer type in
conformer block of text encoder.</p></li>
<li><p><strong>text_encoder_positionwise_conv_kernel_size</strong> (<em>int</em>) – Position-wise convolution
kernel size in conformer block of text encoder. Only used when the
above layer type is conv1d or conv1d-linear.</p></li>
<li><p><strong>text_encoder_positional_encoding_layer_type</strong> (<em>str</em>) – Positional encoding layer
type in conformer block of text encoder.</p></li>
<li><p><strong>text_encoder_self_attention_layer_type</strong> (<em>str</em>) – Self-attention layer type in
conformer block of text encoder.</p></li>
<li><p><strong>text_encoder_activation_type</strong> (<em>str</em>) – Activation function type in conformer
block of text encoder.</p></li>
<li><p><strong>text_encoder_normalize_before</strong> (<em>bool</em>) – Whether to apply layer norm before
self-attention in conformer block of text encoder.</p></li>
<li><p><strong>text_encoder_dropout_rate</strong> (<em>float</em>) – Dropout rate in conformer block of
text encoder.</p></li>
<li><p><strong>text_encoder_positional_dropout_rate</strong> (<em>float</em>) – Dropout rate for positional
encoding in conformer block of text encoder.</p></li>
<li><p><strong>text_encoder_attention_dropout_rate</strong> (<em>float</em>) – Dropout rate for attention in
conformer block of text encoder.</p></li>
<li><p><strong>text_encoder_conformer_kernel_size</strong> (<em>int</em>) – Conformer conv kernel size. It
will be used when only use_conformer_conv_in_text_encoder = True.</p></li>
<li><p><strong>use_macaron_style_in_text_encoder</strong> (<em>bool</em>) – Whether to use macaron style FFN
in conformer block of text encoder.</p></li>
<li><p><strong>use_conformer_conv_in_text_encoder</strong> (<em>bool</em>) – Whether to use covolution in
conformer block of text encoder.</p></li>
<li><p><strong>decoder_kernel_size</strong> (<em>int</em>) – Decoder kernel size.</p></li>
<li><p><strong>decoder_channels</strong> (<em>int</em>) – Number of decoder initial channels.</p></li>
<li><p><strong>decoder_downsample_scales</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of downsampling scales in
decoder.</p></li>
<li><p><strong>decoder_downsample_kernel_sizes</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of kernel sizes for
downsampling layers in decoder.</p></li>
<li><p><strong>decoder_upsample_scales</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of upsampling scales in decoder.</p></li>
<li><p><strong>decoder_upsample_kernel_sizes</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of kernel sizes for
upsampling layers in decoder.</p></li>
<li><p><strong>decoder_resblock_kernel_sizes</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of kernel sizes for
resblocks in decoder.</p></li>
<li><p><strong>decoder_resblock_dilations</strong> (<em>List</em><em>[</em><em>List</em><em>[</em><em>int</em><em>]</em><em>]</em>) – List of list of dilations for
resblocks in decoder.</p></li>
<li><p><strong>use_avocodo</strong> (<em>bool</em>) – Whether to use Avocodo model in the generator.</p></li>
<li><p><strong>projection_filters</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of projection filter sizes.</p></li>
<li><p><strong>projection_kernels</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of projection kernel sizes.</p></li>
<li><p><strong>n_harmonic</strong> (<em>int</em>) – Number of harmonic components.</p></li>
<li><p><strong>use_weight_norm_in_decoder</strong> (<em>bool</em>) – Whether to apply weight normalization in
decoder.</p></li>
<li><p><strong>posterior_encoder_kernel_size</strong> (<em>int</em>) – Posterior encoder kernel size.</p></li>
<li><p><strong>posterior_encoder_layers</strong> (<em>int</em>) – Number of layers of posterior encoder.</p></li>
<li><p><strong>posterior_encoder_stacks</strong> (<em>int</em>) – Number of stacks of posterior encoder.</p></li>
<li><p><strong>posterior_encoder_base_dilation</strong> (<em>int</em>) – Base dilation of posterior encoder.</p></li>
<li><p><strong>posterior_encoder_dropout_rate</strong> (<em>float</em>) – Dropout rate for posterior encoder.</p></li>
<li><p><strong>use_weight_norm_in_posterior_encoder</strong> (<em>bool</em>) – Whether to apply weight
normalization in posterior encoder.</p></li>
<li><p><strong>flow_flows</strong> (<em>int</em>) – Number of flows in flow.</p></li>
<li><p><strong>flow_kernel_size</strong> (<em>int</em>) – Kernel size in flow.</p></li>
<li><p><strong>flow_base_dilation</strong> (<em>int</em>) – Base dilation in flow.</p></li>
<li><p><strong>flow_layers</strong> (<em>int</em>) – Number of layers in flow.</p></li>
<li><p><strong>flow_dropout_rate</strong> (<em>float</em>) – Dropout rate in flow</p></li>
<li><p><strong>use_weight_norm_in_flow</strong> (<em>bool</em>) – Whether to apply weight normalization in
flow.</p></li>
<li><p><strong>use_only_mean_in_flow</strong> (<em>bool</em>) – Whether to use only mean in flow.</p></li>
<li><p><strong>generator_type</strong> (<em>str</em>) – Type of generator to use for the model.</p></li>
<li><p><strong>vocoder_generator_type</strong> (<em>str</em>) – Type of vocoder generator to use for the
model.</p></li>
<li><p><strong>fs</strong> (<em>int</em>) – Sample rate of the audio.</p></li>
<li><p><strong>hop_length</strong> (<em>int</em>) – Number of samples between successive frames in STFT.</p></li>
<li><p><strong>win_length</strong> (<em>int</em>) – Window size of the STFT.</p></li>
<li><p><strong>n_fft</strong> (<em>int</em>) – Length of the FFT window to be used.</p></li>
<li><p><strong>use_phoneme_predictor</strong> (<em>bool</em>) – Whether to use phoneme predictor in the model.</p></li>
<li><p><strong>expand_f0_method</strong> (<em>str</em>) – The method used to expand F0. Use “repeat” or
“interpolation”.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_svs.vits.generator.VISingerGenerator.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">text: torch.Tensor</em>, <em class="sig-param">text_lengths: torch.Tensor</em>, <em class="sig-param">feats: torch.Tensor</em>, <em class="sig-param">feats_lengths: torch.Tensor</em>, <em class="sig-param">label: torch.Tensor = None</em>, <em class="sig-param">label_lengths: torch.Tensor = None</em>, <em class="sig-param">melody: torch.Tensor = None</em>, <em class="sig-param">gt_dur: torch.Tensor = None</em>, <em class="sig-param">score_dur: torch.Tensor = None</em>, <em class="sig-param">slur: torch.Tensor = None</em>, <em class="sig-param">pitch: torch.Tensor = None</em>, <em class="sig-param">ying: Optional[torch.Tensor] = None</em>, <em class="sig-param">sids: Optional[torch.Tensor] = None</em>, <em class="sig-param">spembs: Optional[torch.Tensor] = None</em>, <em class="sig-param">lids: Optional[torch.Tensor] = None</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]]<a class="reference internal" href="../_modules/espnet2/gan_svs/vits/generator.html#VISingerGenerator.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.vits.generator.VISingerGenerator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>LongTensor</em>) – Batch of padded character ids (B, Tmax).</p></li>
<li><p><strong>text_lengths</strong> (<em>LongTensor</em>) – Batch of lengths of each input batch (B,).</p></li>
<li><p><strong>feats</strong> (<em>Tensor</em>) – Batch of padded target features (B, Lmax, odim).</p></li>
<li><p><strong>feats_lengths</strong> (<em>LongTensor</em>) – Batch of the lengths of each target (B,).</p></li>
<li><p><strong>label</strong> (<em>LongTensor</em>) – Batch of padded label ids (B, Tmax).</p></li>
<li><p><strong>label_lengths</strong> (<em>LongTensor</em>) – Batch of the lengths of padded label ids (B, ).</p></li>
<li><p><strong>melody</strong> (<em>LongTensor</em>) – Batch of padded midi (B, Tmax).</p></li>
<li><p><strong>gt_dur</strong> (<em>LongTensor</em>) – Batch of padded ground truth duration (B, Tmax).</p></li>
<li><p><strong>score_dur</strong> (<em>LongTensor</em>) – Batch of padded score duration (B, Tmax).</p></li>
<li><p><strong>pitch</strong> (<em>FloatTensor</em>) – Batch of padded f0 (B, Tmax).</p></li>
<li><p><strong>ying</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Batch of padded ying (B, Tmax).</p></li>
<li><p><strong>spembs</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Batch of speaker embeddings (B, spk_embed_dim).</p></li>
<li><p><strong>sids</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Batch of speaker IDs (B, 1).</p></li>
<li><p><strong>lids</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Batch of language IDs (B, 1).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p>Waveform tensor (B, 1, segment_size * upsample_factor).
Tensor: Duration negative log-likelihood (NLL) tensor (B,).
Tensor: Monotonic attention weight tensor (B, 1, T_feats, T_text).
Tensor: Segments start index tensor (B,).
Tensor: Text mask tensor (B, 1, T_text).
Tensor: Feature mask tensor (B, 1, T_feats).
tuple[Tensor, Tensor, Tensor, Tensor, Tensor, Tensor]:</p>
<blockquote>
<div><ul class="simple">
<li><p>Tensor: Posterior encoder hidden representation (B, H, T_feats).</p></li>
<li><p>Tensor: Flow hidden representation (B, H, T_feats).</p></li>
<li><p>Tensor: Expanded text encoder projected mean (B, H, T_feats).</p></li>
<li><p>Tensor: Expanded text encoder projected scale (B, H, T_feats).</p></li>
<li><p>Tensor: Posterior encoder projected mean (B, H, T_feats).</p></li>
<li><p>Tensor: Posterior encoder projected scale (B, H, T_feats).</p></li>
</ul>
</div></blockquote>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_svs.vits.generator.VISingerGenerator.inference">
<code class="sig-name descname">inference</code><span class="sig-paren">(</span><em class="sig-param">text: torch.Tensor</em>, <em class="sig-param">text_lengths: torch.Tensor</em>, <em class="sig-param">feats: Optional[torch.Tensor] = None</em>, <em class="sig-param">feats_lengths: Optional[torch.Tensor] = None</em>, <em class="sig-param">label: torch.Tensor = None</em>, <em class="sig-param">label_lengths: torch.Tensor = None</em>, <em class="sig-param">melody: torch.Tensor = None</em>, <em class="sig-param">score_dur: torch.Tensor = None</em>, <em class="sig-param">slur: torch.Tensor = None</em>, <em class="sig-param">gt_dur: Optional[torch.Tensor] = None</em>, <em class="sig-param">pitch: Optional[torch.Tensor] = None</em>, <em class="sig-param">sids: Optional[torch.Tensor] = None</em>, <em class="sig-param">spembs: Optional[torch.Tensor] = None</em>, <em class="sig-param">lids: Optional[torch.Tensor] = None</em>, <em class="sig-param">noise_scale: float = 0.667</em>, <em class="sig-param">noise_scale_dur: float = 0.8</em>, <em class="sig-param">alpha: float = 1.0</em>, <em class="sig-param">max_len: Optional[int] = None</em>, <em class="sig-param">use_teacher_forcing: bool = False</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/gan_svs/vits/generator.html#VISingerGenerator.inference"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.vits.generator.VISingerGenerator.inference" title="Permalink to this definition">¶</a></dt>
<dd><p>Run inference.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>LongTensor</em>) – Batch of padded character ids (B, Tmax).</p></li>
<li><p><strong>text_lengths</strong> (<em>LongTensor</em>) – Batch of lengths of each input batch (B,).</p></li>
<li><p><strong>feats</strong> (<em>Tensor</em>) – Batch of padded target features (B, Lmax, odim).</p></li>
<li><p><strong>feats_lengths</strong> (<em>LongTensor</em>) – Batch of the lengths of each target (B,).</p></li>
<li><p><strong>label</strong> (<em>LongTensor</em>) – Batch of padded label ids (B, Tmax).</p></li>
<li><p><strong>label_lengths</strong> (<em>LongTensor</em>) – Batch of the lengths of padded label ids (B, ).</p></li>
<li><p><strong>melody</strong> (<em>LongTensor</em>) – Batch of padded midi (B, Tmax).</p></li>
<li><p><strong>gt_dur</strong> (<em>LongTensor</em>) – Batch of padded ground truth duration (B, Tmax).</p></li>
<li><p><strong>score_dur</strong> (<em>LongTensor</em>) – Batch of padded score duration (B, Tmax).</p></li>
<li><p><strong>pitch</strong> (<em>FloatTensor</em>) – Batch of padded f0 (B, Tmax).</p></li>
<li><p><strong>ying</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Batch of padded ying (B, Tmax).</p></li>
<li><p><strong>spembs</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Batch of speaker embeddings (B, spk_embed_dim).</p></li>
<li><p><strong>sids</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Batch of speaker IDs (B, 1).</p></li>
<li><p><strong>lids</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Batch of language IDs (B, 1).</p></li>
<li><p><strong>noise_scale</strong> (<em>float</em>) – Noise scale parameter for flow.</p></li>
<li><p><strong>noise_scale_dur</strong> (<em>float</em>) – Noise scale parameter for duration predictor.</p></li>
<li><p><strong>alpha</strong> (<em>float</em>) – Alpha parameter to control the speed of generated speech.</p></li>
<li><p><strong>max_len</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – Maximum length of acoustic feature sequence.</p></li>
<li><p><strong>use_teacher_forcing</strong> (<em>bool</em>) – Whether to use teacher forcing.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Generated waveform tensor (B, T_wav).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-gan-svs-vits-prior-decoder-1">
<span id="espnet2-gan-svs-vits-prior-decoder"></span><h2>espnet2.gan_svs.vits.prior_decoder<a class="headerlink" href="#espnet2-gan-svs-vits-prior-decoder-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_svs.vits.prior_decoder"></span><dl class="class">
<dt id="espnet2.gan_svs.vits.prior_decoder.PriorDecoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_svs.vits.prior_decoder.</code><code class="sig-name descname">PriorDecoder</code><span class="sig-paren">(</span><em class="sig-param">out_channels: int = 384</em>, <em class="sig-param">attention_dim: int = 192</em>, <em class="sig-param">attention_heads: int = 2</em>, <em class="sig-param">linear_units: int = 768</em>, <em class="sig-param">blocks: int = 6</em>, <em class="sig-param">positionwise_layer_type: str = 'conv1d'</em>, <em class="sig-param">positionwise_conv_kernel_size: int = 3</em>, <em class="sig-param">positional_encoding_layer_type: str = 'rel_pos'</em>, <em class="sig-param">self_attention_layer_type: str = 'rel_selfattn'</em>, <em class="sig-param">activation_type: str = 'swish'</em>, <em class="sig-param">normalize_before: bool = True</em>, <em class="sig-param">use_macaron_style: bool = False</em>, <em class="sig-param">use_conformer_conv: bool = False</em>, <em class="sig-param">conformer_kernel_size: int = 7</em>, <em class="sig-param">dropout_rate: float = 0.1</em>, <em class="sig-param">positional_dropout_rate: float = 0.0</em>, <em class="sig-param">attention_dropout_rate: float = 0.0</em>, <em class="sig-param">global_channels: int = 0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/vits/prior_decoder.html#PriorDecoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.vits.prior_decoder.PriorDecoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Initialize prior decoder module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>out_channels</strong> (<em>int</em>) – Output channels of the prior decoder. Defaults to 384.</p></li>
<li><p><strong>attention_dim</strong> (<em>int</em>) – Dimension of the attention mechanism. Defaults to 192.</p></li>
<li><p><strong>attention_heads</strong> (<em>int</em>) – Number of attention heads. Defaults to 2.</p></li>
<li><p><strong>linear_units</strong> (<em>int</em>) – Number of units in the linear layer. Defaults to 768.</p></li>
<li><p><strong>blocks</strong> (<em>int</em>) – Number of blocks in the encoder. Defaults to 6.</p></li>
<li><p><strong>positionwise_layer_type</strong> (<em>str</em>) – Type of the positionwise layer.
Defaults to “conv1d”.</p></li>
<li><p><strong>positionwise_conv_kernel_size</strong> (<em>int</em>) – Kernel size of the positionwise
convolutional layer. Defaults to 3.</p></li>
<li><p><strong>positional_encoding_layer_type</strong> (<em>str</em>) – Type of positional encoding layer.
Defaults to “rel_pos”.</p></li>
<li><p><strong>self_attention_layer_type</strong> (<em>str</em>) – Type of self-attention layer.
Defaults to “rel_selfattn”.</p></li>
<li><p><strong>activation_type</strong> (<em>str</em>) – Type of activation. Defaults to “swish”.</p></li>
<li><p><strong>normalize_before</strong> (<em>bool</em>) – Flag for normalization. Defaults to True.</p></li>
<li><p><strong>use_macaron_style</strong> (<em>bool</em>) – Flag for macaron style. Defaults to False.</p></li>
<li><p><strong>use_conformer_conv</strong> (<em>bool</em>) – Flag for using conformer convolution.
Defaults to False.</p></li>
<li><p><strong>conformer_kernel_size</strong> (<em>int</em>) – Kernel size for conformer convolution.
Defaults to 7.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>) – Dropout rate. Defaults to 0.1.</p></li>
<li><p><strong>positional_dropout_rate</strong> (<em>float</em>) – Dropout rate for positional encoding.
Defaults to 0.0.</p></li>
<li><p><strong>attention_dropout_rate</strong> (<em>float</em>) – Dropout rate for attention.
Defaults to 0.0.</p></li>
<li><p><strong>global_channels</strong> (<em>int</em>) – Number of global channels. Defaults to 0.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_svs.vits.prior_decoder.PriorDecoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">x_lengths</em>, <em class="sig-param">g=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/vits/prior_decoder.html#PriorDecoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.vits.prior_decoder.PriorDecoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward pass of the PriorDecoder module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – Input tensor (B, attention_dim + 2, T).</p></li>
<li><p><strong>x_lengths</strong> (<em>Tensor</em>) – Length tensor (B,).</p></li>
<li><p><strong>g</strong> (<em>Tensor</em>) – Tensor for multi-singer. (B, global_channels, 1)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Output tensor (B, out_channels, T).
Tensor: Output mask tensor (B, 1, T).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-gan-svs-vits-init-1">
<span id="espnet2-gan-svs-vits-init"></span><h2>espnet2.gan_svs.vits.__init__<a class="headerlink" href="#espnet2-gan-svs-vits-init-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_svs.vits.__init__"></span></section>
<section id="espnet2-gan-svs-vits-text-encoder-1">
<span id="espnet2-gan-svs-vits-text-encoder"></span><h2>espnet2.gan_svs.vits.text_encoder<a class="headerlink" href="#espnet2-gan-svs-vits-text-encoder-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_svs.vits.text_encoder"></span><p>Text encoder module in VISinger.</p>
<p>This code is based on <a class="reference external" href="https://github.com/jaywalnut310/vits">https://github.com/jaywalnut310/vits</a>
and <a class="reference external" href="https://github.com/zhangyongmao/VISinger2">https://github.com/zhangyongmao/VISinger2</a>.</p>
<dl class="class">
<dt id="espnet2.gan_svs.vits.text_encoder.TextEncoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_svs.vits.text_encoder.</code><code class="sig-name descname">TextEncoder</code><span class="sig-paren">(</span><em class="sig-param">vocabs: int</em>, <em class="sig-param">attention_dim: int = 192</em>, <em class="sig-param">attention_heads: int = 2</em>, <em class="sig-param">linear_units: int = 768</em>, <em class="sig-param">blocks: int = 6</em>, <em class="sig-param">positionwise_layer_type: str = 'conv1d'</em>, <em class="sig-param">positionwise_conv_kernel_size: int = 3</em>, <em class="sig-param">positional_encoding_layer_type: str = 'rel_pos'</em>, <em class="sig-param">self_attention_layer_type: str = 'rel_selfattn'</em>, <em class="sig-param">activation_type: str = 'swish'</em>, <em class="sig-param">normalize_before: bool = True</em>, <em class="sig-param">use_macaron_style: bool = False</em>, <em class="sig-param">use_conformer_conv: bool = False</em>, <em class="sig-param">conformer_kernel_size: int = 7</em>, <em class="sig-param">dropout_rate: float = 0.1</em>, <em class="sig-param">positional_dropout_rate: float = 0.0</em>, <em class="sig-param">attention_dropout_rate: float = 0.0</em>, <em class="sig-param">use_slur=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/vits/text_encoder.html#TextEncoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.vits.text_encoder.TextEncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Text encoder module in VISinger.</p>
<p>This is a module of text encoder described in <a class="reference external" href="https://arxiv.org/abs/2006.04558">Conditional Variational Autoencoder
with Adversarial Learning for End-to-End Text-to-Speech</a>.</p>
<p>Instead of the relative positional Transformer, we use conformer architecture as
the encoder module, which contains additional convolution layers.</p>
<p>Initialize TextEncoder module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>vocabs</strong> (<em>int</em>) – Vocabulary size.</p></li>
<li><p><strong>attention_dim</strong> (<em>int</em>) – Attention dimension.</p></li>
<li><p><strong>attention_heads</strong> (<em>int</em>) – Number of attention heads.</p></li>
<li><p><strong>linear_units</strong> (<em>int</em>) – Number of linear units of positionwise layers.</p></li>
<li><p><strong>blocks</strong> (<em>int</em>) – Number of encoder blocks.</p></li>
<li><p><strong>positionwise_layer_type</strong> (<em>str</em>) – Positionwise layer type.</p></li>
<li><p><strong>positionwise_conv_kernel_size</strong> (<em>int</em>) – Positionwise layer’s kernel size.</p></li>
<li><p><strong>positional_encoding_layer_type</strong> (<em>str</em>) – Positional encoding layer type.</p></li>
<li><p><strong>self_attention_layer_type</strong> (<em>str</em>) – Self-attention layer type.</p></li>
<li><p><strong>activation_type</strong> (<em>str</em>) – Activation function type.</p></li>
<li><p><strong>normalize_before</strong> (<em>bool</em>) – Whether to apply LayerNorm before attention.</p></li>
<li><p><strong>use_macaron_style</strong> (<em>bool</em>) – Whether to use macaron style components.</p></li>
<li><p><strong>use_conformer_conv</strong> (<em>bool</em>) – Whether to use conformer conv layers.</p></li>
<li><p><strong>conformer_kernel_size</strong> (<em>int</em>) – Conformer’s conv kernel size.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>) – Dropout rate.</p></li>
<li><p><strong>positional_dropout_rate</strong> (<em>float</em>) – Dropout rate for positional encoding.</p></li>
<li><p><strong>attention_dropout_rate</strong> (<em>float</em>) – Dropout rate for attention.</p></li>
<li><p><strong>use_slur</strong> (<em>bool</em>) – Whether to use slur embedding.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_svs.vits.text_encoder.TextEncoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">phone: torch.Tensor</em>, <em class="sig-param">phone_lengths: torch.Tensor</em>, <em class="sig-param">midi_id: torch.Tensor</em>, <em class="sig-param">dur: torch.Tensor</em>, <em class="sig-param">slur: Optional[torch.Tensor] = None</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/gan_svs/vits/text_encoder.html#TextEncoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.vits.text_encoder.TextEncoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>phone</strong> (<em>Tensor</em>) – Input index tensor (B, T_text).</p></li>
<li><p><strong>phone_lengths</strong> (<em>Tensor</em>) – Length tensor (B,).</p></li>
<li><p><strong>midi_id</strong> (<em>Tensor</em>) – Input midi tensor (B, T_text).</p></li>
<li><p><strong>dur</strong> (<em>Tensor</em>) – Input duration tensor (B, T_text).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p>Encoded hidden representation (B, attention_dim, T_text).
Tensor: Mask tensor for padded part (B, 1, T_text).
Tensor: Encoded hidden representation for duration</p>
<blockquote>
<div><p>(B, attention_dim, T_text).</p>
</div></blockquote>
<dl class="simple">
<dt>Tensor: Encoded hidden representation for pitch</dt><dd><p>(B, attention_dim, T_text).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-gan-svs-avocodo-avocodo-1">
<span id="espnet2-gan-svs-avocodo-avocodo"></span><h2>espnet2.gan_svs.avocodo.avocodo<a class="headerlink" href="#espnet2-gan-svs-avocodo-avocodo-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_svs.avocodo.avocodo"></span><p>Avocodo Modules.</p>
<p>This code is modified from <a class="reference external" href="https://github.com/ncsoft/avocodo">https://github.com/ncsoft/avocodo</a>.</p>
<dl class="class">
<dt id="espnet2.gan_svs.avocodo.avocodo.AvocodoDiscriminator">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_svs.avocodo.avocodo.</code><code class="sig-name descname">AvocodoDiscriminator</code><span class="sig-paren">(</span><em class="sig-param">combd: Dict[str, Any] = {'combd_d_d': [[1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1]], 'combd_d_g': [[1, 4, 16, 64, 256, 1], [1, 4, 16, 64, 256, 1], [1, 4, 16, 64, 256, 1]], 'combd_d_k': [[7, 11, 11, 11, 11, 5], [11, 21, 21, 21, 21, 5], [15, 41, 41, 41, 41, 5]], 'combd_d_p': [[3, 5, 5, 5, 5, 2], [5, 10, 10, 10, 10, 2], [7, 20, 20, 20, 20, 2]], 'combd_d_s': [[1, 1, 4, 4, 4, 1], [1, 1, 4, 4, 4, 1], [1, 1, 4, 4, 4, 1]], 'combd_h_u': [[16, 64, 256, 1024, 1024, 1024], [16, 64, 256, 1024, 1024, 1024], [16, 64, 256, 1024, 1024, 1024]], 'combd_op_f': [1, 1, 1], 'combd_op_g': [1, 1, 1], 'combd_op_k': [3, 3, 3]}, sbd: Dict[str, Any] = {'pqmf_config': {'fsbd': [64, 256, 0.1, 9.0], 'sbd': [16, 256, 0.03, 10.0]}, 'sbd_band_ranges': [[0, 6], [0, 11], [0, 16], [0, 64]], 'sbd_dilations': [[[5, 7, 11], [5, 7, 11], [5, 7, 11], [5, 7, 11], [5, 7, 11]], [[3, 5, 7], [3, 5, 7], [3, 5, 7], [3, 5, 7], [3, 5, 7]], [[1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3]], [[1, 2, 3], [1, 2, 3], [1, 2, 3], [2, 3, 5], [2, 3, 5]]], 'sbd_filters': [[64, 128, 256, 256, 256], [64, 128, 256, 256, 256], [64, 128, 256, 256, 256], [32, 64, 128, 128, 128]], 'sbd_kernel_sizes': [[[7, 7, 7], [7, 7, 7], [7, 7, 7], [7, 7, 7], [7, 7, 7]], [[5, 5, 5], [5, 5, 5], [5, 5, 5], [5, 5, 5], [5, 5, 5]], [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], [[5, 5, 5], [5, 5, 5], [5, 5, 5], [5, 5, 5], [5, 5, 5]]], 'sbd_strides': [[1, 1, 3, 3, 1], [1, 1, 3, 3, 1], [1, 1, 3, 3, 1], [1, 1, 3, 3, 1]], 'sbd_transpose': [False, False, False, True], 'segment_size': 8192, 'use_sbd': True}, pqmf_config: Dict[str, Any] = {'lv1': [2, 256, 0.25, 10.0], 'lv2': [4, 192, 0.13, 10.0]}, projection_filters: List[int] = [0, 1, 1, 1]</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/avocodo/avocodo.html#AvocodoDiscriminator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.avocodo.avocodo.AvocodoDiscriminator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Avocodo Discriminator module</p>
<dl class="method">
<dt id="espnet2.gan_svs.avocodo.avocodo.AvocodoDiscriminator.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">y: torch.Tensor</em>, <em class="sig-param">y_hats: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; List[List[torch.Tensor]]<a class="reference internal" href="../_modules/espnet2/gan_svs/avocodo/avocodo.html#AvocodoDiscriminator.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.avocodo.avocodo.AvocodoDiscriminator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</aside>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_svs.avocodo.avocodo.AvocodoDiscriminatorPlus">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_svs.avocodo.avocodo.</code><code class="sig-name descname">AvocodoDiscriminatorPlus</code><span class="sig-paren">(</span><em class="sig-param">combd: Dict[str, Any] = {'combd_d_d': [[1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1]], 'combd_d_g': [[1, 4, 16, 64, 256, 1], [1, 4, 16, 64, 256, 1], [1, 4, 16, 64, 256, 1]], 'combd_d_k': [[7, 11, 11, 11, 11, 5], [11, 21, 21, 21, 21, 5], [15, 41, 41, 41, 41, 5]], 'combd_d_p': [[3, 5, 5, 5, 5, 2], [5, 10, 10, 10, 10, 2], [7, 20, 20, 20, 20, 2]], 'combd_d_s': [[1, 1, 4, 4, 4, 1], [1, 1, 4, 4, 4, 1], [1, 1, 4, 4, 4, 1]], 'combd_h_u': [[16, 64, 256, 1024, 1024, 1024], [16, 64, 256, 1024, 1024, 1024], [16, 64, 256, 1024, 1024, 1024]], 'combd_op_f': [1, 1, 1], 'combd_op_g': [1, 1, 1], 'combd_op_k': [3, 3, 3]}, sbd: Dict[str, Any] = {'pqmf_config': {'fsbd': [64, 256, 0.1, 9.0], 'sbd': [16, 256, 0.03, 10.0]}, 'sbd_band_ranges': [[0, 6], [0, 11], [0, 16], [0, 64]], 'sbd_dilations': [[[5, 7, 11], [5, 7, 11], [5, 7, 11], [5, 7, 11], [5, 7, 11]], [[3, 5, 7], [3, 5, 7], [3, 5, 7], [3, 5, 7], [3, 5, 7]], [[1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3]], [[1, 2, 3], [1, 2, 3], [1, 2, 3], [2, 3, 5], [2, 3, 5]]], 'sbd_filters': [[64, 128, 256, 256, 256], [64, 128, 256, 256, 256], [64, 128, 256, 256, 256], [32, 64, 128, 128, 128]], 'sbd_kernel_sizes': [[[7, 7, 7], [7, 7, 7], [7, 7, 7], [7, 7, 7], [7, 7, 7]], [[5, 5, 5], [5, 5, 5], [5, 5, 5], [5, 5, 5], [5, 5, 5]], [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], [[5, 5, 5], [5, 5, 5], [5, 5, 5], [5, 5, 5], [5, 5, 5]]], 'sbd_strides': [[1, 1, 3, 3, 1], [1, 1, 3, 3, 1], [1, 1, 3, 3, 1], [1, 1, 3, 3, 1]], 'sbd_transpose': [False, False, False, True], 'segment_size': 8192, 'use_sbd': True}, pqmf_config: Dict[str, Any] = {'lv1': [2, 256, 0.25, 10.0], 'lv2': [4, 192, 0.13, 10.0]}, projection_filters: List[int] = [0, 1, 1, 1], sample_rate: int = 22050, multi_freq_disc_params: Dict[str, Any] = {'divisors': [32, 16, 8, 4, 2, 1, 1], 'domain': 'double', 'hidden_channels': [256, 512, 512], 'hop_length_factors': [4, 8, 16], 'mel_scale': True, 'strides': [1, 2, 1, 2, 1, 2, 1]}</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/avocodo/avocodo.html#AvocodoDiscriminatorPlus"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.avocodo.avocodo.AvocodoDiscriminatorPlus" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Avocodo discriminator with additional MFD.</p>
<dl class="method">
<dt id="espnet2.gan_svs.avocodo.avocodo.AvocodoDiscriminatorPlus.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">y: torch.Tensor</em>, <em class="sig-param">y_hats: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; List[List[torch.Tensor]]<a class="reference internal" href="../_modules/espnet2/gan_svs/avocodo/avocodo.html#AvocodoDiscriminatorPlus.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.avocodo.avocodo.AvocodoDiscriminatorPlus.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</aside>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_svs.avocodo.avocodo.AvocodoGenerator">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_svs.avocodo.avocodo.</code><code class="sig-name descname">AvocodoGenerator</code><span class="sig-paren">(</span><em class="sig-param">in_channels: int = 80, out_channels: int = 1, channels: int = 512, global_channels: int = -1, kernel_size: int = 7, upsample_scales: List[int] = [8, 8, 2, 2], upsample_kernel_sizes: List[int] = [16, 16, 4, 4], resblock_kernel_sizes: List[int] = [3, 7, 11], resblock_dilations: List[List[int]] = [[1, 3, 5], [1, 3, 5], [1, 3, 5]], projection_filters: List[int] = [0, 1, 1, 1], projection_kernels: List[int] = [0, 5, 7, 11], use_additional_convs: bool = True, bias: bool = True, nonlinear_activation: str = 'LeakyReLU', nonlinear_activation_params: Dict[str, Any] = {'negative_slope': 0.2}, use_weight_norm: bool = True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/avocodo/avocodo.html#AvocodoGenerator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.avocodo.avocodo.AvocodoGenerator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Avocodo generator module.</p>
<p>Initialize AvocodoGenerator module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<em>int</em>) – Number of input channels.</p></li>
<li><p><strong>out_channels</strong> (<em>int</em>) – Number of output channels.</p></li>
<li><p><strong>channels</strong> (<em>int</em>) – Number of hidden representation channels.</p></li>
<li><p><strong>global_channels</strong> (<em>int</em>) – Number of global conditioning channels.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – Kernel size of initial and final conv layer.</p></li>
<li><p><strong>upsample_scales</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of upsampling scales.</p></li>
<li><p><strong>upsample_kernel_sizes</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of kernel sizes for upsample layers.</p></li>
<li><p><strong>resblock_kernel_sizes</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of kernel sizes for residual blocks.</p></li>
<li><p><strong>resblock_dilations</strong> (<em>List</em><em>[</em><em>List</em><em>[</em><em>int</em><em>]</em><em>]</em>) – List of list of dilations for residual
blocks.</p></li>
<li><p><strong>use_additional_convs</strong> (<em>bool</em>) – Whether to use additional conv layers in
residual blocks.</p></li>
<li><p><strong>bias</strong> (<em>bool</em>) – Whether to add bias parameter in convolution layers.</p></li>
<li><p><strong>nonlinear_activation</strong> (<em>str</em>) – Activation function module name.</p></li>
<li><p><strong>nonlinear_activation_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Hyperparameters for activation
function.</p></li>
<li><p><strong>use_weight_norm</strong> (<em>bool</em>) – Whether to use weight norm. If set to true, it will
be applied to all of the conv layers.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_svs.avocodo.avocodo.AvocodoGenerator.apply_weight_norm">
<code class="sig-name descname">apply_weight_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/avocodo/avocodo.html#AvocodoGenerator.apply_weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.avocodo.avocodo.AvocodoGenerator.apply_weight_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply weight normalization module from all of the layers.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_svs.avocodo.avocodo.AvocodoGenerator.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">c: torch.Tensor</em>, <em class="sig-param">g: Optional[torch.Tensor] = None</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_svs/avocodo/avocodo.html#AvocodoGenerator.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.avocodo.avocodo.AvocodoGenerator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>c</strong> (<em>Tensor</em>) – Input tensor (B, in_channels, T).</p></li>
<li><p><strong>g</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Global conditioning tensor (B, global_channels, 1).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>List of output tensors (B, out_channels, T).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>List[Tensor]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_svs.avocodo.avocodo.AvocodoGenerator.remove_weight_norm">
<code class="sig-name descname">remove_weight_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/avocodo/avocodo.html#AvocodoGenerator.remove_weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.avocodo.avocodo.AvocodoGenerator.remove_weight_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Remove weight normalization module from all of the layers.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_svs.avocodo.avocodo.AvocodoGenerator.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/avocodo/avocodo.html#AvocodoGenerator.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.avocodo.avocodo.AvocodoGenerator.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Reset parameters.</p>
<p>This initialization follows the official implementation manner.
<a class="reference external" href="https://github.com/jik876/hifi-gan/blob/master/models.py">https://github.com/jik876/hifi-gan/blob/master/models.py</a></p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_svs.avocodo.avocodo.CoMBD">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_svs.avocodo.avocodo.</code><code class="sig-name descname">CoMBD</code><span class="sig-paren">(</span><em class="sig-param">h</em>, <em class="sig-param">pqmf_list=None</em>, <em class="sig-param">use_spectral_norm=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/avocodo/avocodo.html#CoMBD"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.avocodo.avocodo.CoMBD" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>CoMBD (Collaborative Multi-band Discriminator) module
from from <a class="reference external" href="https://arxiv.org/abs/2206.13404">https://arxiv.org/abs/2206.13404</a></p>
<dl class="method">
<dt id="espnet2.gan_svs.avocodo.avocodo.CoMBD.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">ys</em>, <em class="sig-param">ys_hat</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/avocodo/avocodo.html#CoMBD.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.avocodo.avocodo.CoMBD.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ys</strong> (<em>List</em><em>[</em><em>Tensor</em><em>]</em>) – List of ground truth signals of shape (B, 1, T).</p></li>
<li><p><strong>ys_hat</strong> (<em>List</em><em>[</em><em>Tensor</em><em>]</em>) – List of predicted signals of shape (B, 1, T).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Tuple containing the list of output tensors of shape (B, C_out, T_out)
for real and fake, respectively, and the list of feature maps of shape
(B, C, T) at each Conv1d layer for real and fake, respectively.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple[List[Tensor], List[Tensor], List[List[Tensor]], List[List[Tensor]]]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_svs.avocodo.avocodo.CoMBDBlock">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_svs.avocodo.avocodo.</code><code class="sig-name descname">CoMBDBlock</code><span class="sig-paren">(</span><em class="sig-param">h_u: List[int], d_k: List[int], d_s: List[int], d_d: List[int], d_g: List[int], d_p: List[int], op_f: int, op_k: int, op_g: int, use_spectral_norm=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/avocodo/avocodo.html#CoMBDBlock"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.avocodo.avocodo.CoMBDBlock" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>CoMBD (Collaborative Multi-band Discriminator) block module</p>
<dl class="method">
<dt id="espnet2.gan_svs.avocodo.avocodo.CoMBDBlock.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/avocodo/avocodo.html#CoMBDBlock.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.avocodo.avocodo.CoMBDBlock.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward pass through the CoMBD block.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>) – Input tensor of shape (B, C_in, T_in).</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>Tuple containing the output tensor of</dt><dd><p>shape (B, C_out, T_out)</p>
</dd>
</dl>
<p>and a list of feature maps of shape (B, C, T) at each Conv1d layer.</p>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple[Tensor, List[Tensor]]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_svs.avocodo.avocodo.MDC">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_svs.avocodo.avocodo.</code><code class="sig-name descname">MDC</code><span class="sig-paren">(</span><em class="sig-param">in_channels</em>, <em class="sig-param">out_channels</em>, <em class="sig-param">strides</em>, <em class="sig-param">kernel_size</em>, <em class="sig-param">dilations</em>, <em class="sig-param">use_spectral_norm=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/avocodo/avocodo.html#MDC"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.avocodo.avocodo.MDC" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Multiscale Dilated Convolution from <a class="reference external" href="https://arxiv.org/pdf/1609.07093.pdf">https://arxiv.org/pdf/1609.07093.pdf</a></p>
<dl class="method">
<dt id="espnet2.gan_svs.avocodo.avocodo.MDC.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/avocodo/avocodo.html#MDC.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.avocodo.avocodo.MDC.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</aside>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_svs.avocodo.avocodo.MDCDConfig">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_svs.avocodo.avocodo.</code><code class="sig-name descname">MDCDConfig</code><span class="sig-paren">(</span><em class="sig-param">h</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/avocodo/avocodo.html#MDCDConfig"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.avocodo.avocodo.MDCDConfig" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
</dd></dl>

<dl class="class">
<dt id="espnet2.gan_svs.avocodo.avocodo.SBD">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_svs.avocodo.avocodo.</code><code class="sig-name descname">SBD</code><span class="sig-paren">(</span><em class="sig-param">h</em>, <em class="sig-param">use_spectral_norm=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/avocodo/avocodo.html#SBD"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.avocodo.avocodo.SBD" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>SBD (Sub-band Discriminator) from <a class="reference external" href="https://arxiv.org/pdf/2206.13404.pdf">https://arxiv.org/pdf/2206.13404.pdf</a></p>
<dl class="method">
<dt id="espnet2.gan_svs.avocodo.avocodo.SBD.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">y</em>, <em class="sig-param">y_hat</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/avocodo/avocodo.html#SBD.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.avocodo.avocodo.SBD.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</aside>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_svs.avocodo.avocodo.SBDBlock">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_svs.avocodo.avocodo.</code><code class="sig-name descname">SBDBlock</code><span class="sig-paren">(</span><em class="sig-param">segment_dim</em>, <em class="sig-param">strides</em>, <em class="sig-param">filters</em>, <em class="sig-param">kernel_size</em>, <em class="sig-param">dilations</em>, <em class="sig-param">use_spectral_norm=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/avocodo/avocodo.html#SBDBlock"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.avocodo.avocodo.SBDBlock" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>SBD (Sub-band Discriminator) Block</p>
<dl class="method">
<dt id="espnet2.gan_svs.avocodo.avocodo.SBDBlock.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/avocodo/avocodo.html#SBDBlock.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.avocodo.avocodo.SBDBlock.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</aside>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="espnet2.gan_svs.avocodo.avocodo.get_padding">
<code class="sig-prename descclassname">espnet2.gan_svs.avocodo.avocodo.</code><code class="sig-name descname">get_padding</code><span class="sig-paren">(</span><em class="sig-param">kernel_size</em>, <em class="sig-param">dilation=1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/avocodo/avocodo.html#get_padding"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.avocodo.avocodo.get_padding" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</section>
<section id="espnet2-gan-svs-avocodo-init-1">
<span id="espnet2-gan-svs-avocodo-init"></span><h2>espnet2.gan_svs.avocodo.__init__<a class="headerlink" href="#espnet2-gan-svs-avocodo-init-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_svs.avocodo.__init__"></span><dl class="class">
<dt id="espnet2.gan_svs.avocodo.__init__.MDC">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_svs.avocodo.__init__.</code><code class="sig-name descname">MDC</code><span class="sig-paren">(</span><em class="sig-param">in_channels</em>, <em class="sig-param">out_channels</em>, <em class="sig-param">strides</em>, <em class="sig-param">kernel_size</em>, <em class="sig-param">dilations</em>, <em class="sig-param">use_spectral_norm=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/avocodo/avocodo.html#MDC"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.avocodo.__init__.MDC" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Multiscale Dilated Convolution from <a class="reference external" href="https://arxiv.org/pdf/1609.07093.pdf">https://arxiv.org/pdf/1609.07093.pdf</a></p>
<dl class="method">
<dt id="espnet2.gan_svs.avocodo.__init__.MDC.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/avocodo/avocodo.html#MDC.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.avocodo.__init__.MDC.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</aside>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_svs.avocodo.__init__.SBD">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_svs.avocodo.__init__.</code><code class="sig-name descname">SBD</code><span class="sig-paren">(</span><em class="sig-param">h</em>, <em class="sig-param">use_spectral_norm=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/avocodo/avocodo.html#SBD"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.avocodo.__init__.SBD" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>SBD (Sub-band Discriminator) from <a class="reference external" href="https://arxiv.org/pdf/2206.13404.pdf">https://arxiv.org/pdf/2206.13404.pdf</a></p>
<dl class="method">
<dt id="espnet2.gan_svs.avocodo.__init__.SBD.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">y</em>, <em class="sig-param">y_hat</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/avocodo/avocodo.html#SBD.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.avocodo.__init__.SBD.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</aside>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_svs.avocodo.__init__.AvocodoDiscriminator">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_svs.avocodo.__init__.</code><code class="sig-name descname">AvocodoDiscriminator</code><span class="sig-paren">(</span><em class="sig-param">combd: Dict[str, Any] = {'combd_d_d': [[1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1]], 'combd_d_g': [[1, 4, 16, 64, 256, 1], [1, 4, 16, 64, 256, 1], [1, 4, 16, 64, 256, 1]], 'combd_d_k': [[7, 11, 11, 11, 11, 5], [11, 21, 21, 21, 21, 5], [15, 41, 41, 41, 41, 5]], 'combd_d_p': [[3, 5, 5, 5, 5, 2], [5, 10, 10, 10, 10, 2], [7, 20, 20, 20, 20, 2]], 'combd_d_s': [[1, 1, 4, 4, 4, 1], [1, 1, 4, 4, 4, 1], [1, 1, 4, 4, 4, 1]], 'combd_h_u': [[16, 64, 256, 1024, 1024, 1024], [16, 64, 256, 1024, 1024, 1024], [16, 64, 256, 1024, 1024, 1024]], 'combd_op_f': [1, 1, 1], 'combd_op_g': [1, 1, 1], 'combd_op_k': [3, 3, 3]}, sbd: Dict[str, Any] = {'pqmf_config': {'fsbd': [64, 256, 0.1, 9.0], 'sbd': [16, 256, 0.03, 10.0]}, 'sbd_band_ranges': [[0, 6], [0, 11], [0, 16], [0, 64]], 'sbd_dilations': [[[5, 7, 11], [5, 7, 11], [5, 7, 11], [5, 7, 11], [5, 7, 11]], [[3, 5, 7], [3, 5, 7], [3, 5, 7], [3, 5, 7], [3, 5, 7]], [[1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3]], [[1, 2, 3], [1, 2, 3], [1, 2, 3], [2, 3, 5], [2, 3, 5]]], 'sbd_filters': [[64, 128, 256, 256, 256], [64, 128, 256, 256, 256], [64, 128, 256, 256, 256], [32, 64, 128, 128, 128]], 'sbd_kernel_sizes': [[[7, 7, 7], [7, 7, 7], [7, 7, 7], [7, 7, 7], [7, 7, 7]], [[5, 5, 5], [5, 5, 5], [5, 5, 5], [5, 5, 5], [5, 5, 5]], [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], [[5, 5, 5], [5, 5, 5], [5, 5, 5], [5, 5, 5], [5, 5, 5]]], 'sbd_strides': [[1, 1, 3, 3, 1], [1, 1, 3, 3, 1], [1, 1, 3, 3, 1], [1, 1, 3, 3, 1]], 'sbd_transpose': [False, False, False, True], 'segment_size': 8192, 'use_sbd': True}, pqmf_config: Dict[str, Any] = {'lv1': [2, 256, 0.25, 10.0], 'lv2': [4, 192, 0.13, 10.0]}, projection_filters: List[int] = [0, 1, 1, 1]</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/avocodo/avocodo.html#AvocodoDiscriminator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.avocodo.__init__.AvocodoDiscriminator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Avocodo Discriminator module</p>
<dl class="method">
<dt id="espnet2.gan_svs.avocodo.__init__.AvocodoDiscriminator.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">y: torch.Tensor</em>, <em class="sig-param">y_hats: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; List[List[torch.Tensor]]<a class="reference internal" href="../_modules/espnet2/gan_svs/avocodo/avocodo.html#AvocodoDiscriminator.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.avocodo.__init__.AvocodoDiscriminator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</aside>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_svs.avocodo.__init__.AvocodoDiscriminatorPlus">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_svs.avocodo.__init__.</code><code class="sig-name descname">AvocodoDiscriminatorPlus</code><span class="sig-paren">(</span><em class="sig-param">combd: Dict[str, Any] = {'combd_d_d': [[1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1]], 'combd_d_g': [[1, 4, 16, 64, 256, 1], [1, 4, 16, 64, 256, 1], [1, 4, 16, 64, 256, 1]], 'combd_d_k': [[7, 11, 11, 11, 11, 5], [11, 21, 21, 21, 21, 5], [15, 41, 41, 41, 41, 5]], 'combd_d_p': [[3, 5, 5, 5, 5, 2], [5, 10, 10, 10, 10, 2], [7, 20, 20, 20, 20, 2]], 'combd_d_s': [[1, 1, 4, 4, 4, 1], [1, 1, 4, 4, 4, 1], [1, 1, 4, 4, 4, 1]], 'combd_h_u': [[16, 64, 256, 1024, 1024, 1024], [16, 64, 256, 1024, 1024, 1024], [16, 64, 256, 1024, 1024, 1024]], 'combd_op_f': [1, 1, 1], 'combd_op_g': [1, 1, 1], 'combd_op_k': [3, 3, 3]}, sbd: Dict[str, Any] = {'pqmf_config': {'fsbd': [64, 256, 0.1, 9.0], 'sbd': [16, 256, 0.03, 10.0]}, 'sbd_band_ranges': [[0, 6], [0, 11], [0, 16], [0, 64]], 'sbd_dilations': [[[5, 7, 11], [5, 7, 11], [5, 7, 11], [5, 7, 11], [5, 7, 11]], [[3, 5, 7], [3, 5, 7], [3, 5, 7], [3, 5, 7], [3, 5, 7]], [[1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3]], [[1, 2, 3], [1, 2, 3], [1, 2, 3], [2, 3, 5], [2, 3, 5]]], 'sbd_filters': [[64, 128, 256, 256, 256], [64, 128, 256, 256, 256], [64, 128, 256, 256, 256], [32, 64, 128, 128, 128]], 'sbd_kernel_sizes': [[[7, 7, 7], [7, 7, 7], [7, 7, 7], [7, 7, 7], [7, 7, 7]], [[5, 5, 5], [5, 5, 5], [5, 5, 5], [5, 5, 5], [5, 5, 5]], [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], [[5, 5, 5], [5, 5, 5], [5, 5, 5], [5, 5, 5], [5, 5, 5]]], 'sbd_strides': [[1, 1, 3, 3, 1], [1, 1, 3, 3, 1], [1, 1, 3, 3, 1], [1, 1, 3, 3, 1]], 'sbd_transpose': [False, False, False, True], 'segment_size': 8192, 'use_sbd': True}, pqmf_config: Dict[str, Any] = {'lv1': [2, 256, 0.25, 10.0], 'lv2': [4, 192, 0.13, 10.0]}, projection_filters: List[int] = [0, 1, 1, 1], sample_rate: int = 22050, multi_freq_disc_params: Dict[str, Any] = {'divisors': [32, 16, 8, 4, 2, 1, 1], 'domain': 'double', 'hidden_channels': [256, 512, 512], 'hop_length_factors': [4, 8, 16], 'mel_scale': True, 'strides': [1, 2, 1, 2, 1, 2, 1]}</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/avocodo/avocodo.html#AvocodoDiscriminatorPlus"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.avocodo.__init__.AvocodoDiscriminatorPlus" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Avocodo discriminator with additional MFD.</p>
<dl class="method">
<dt id="espnet2.gan_svs.avocodo.__init__.AvocodoDiscriminatorPlus.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">y: torch.Tensor</em>, <em class="sig-param">y_hats: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; List[List[torch.Tensor]]<a class="reference internal" href="../_modules/espnet2/gan_svs/avocodo/avocodo.html#AvocodoDiscriminatorPlus.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.avocodo.__init__.AvocodoDiscriminatorPlus.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</aside>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_svs.avocodo.__init__.AvocodoGenerator">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_svs.avocodo.__init__.</code><code class="sig-name descname">AvocodoGenerator</code><span class="sig-paren">(</span><em class="sig-param">in_channels: int = 80, out_channels: int = 1, channels: int = 512, global_channels: int = -1, kernel_size: int = 7, upsample_scales: List[int] = [8, 8, 2, 2], upsample_kernel_sizes: List[int] = [16, 16, 4, 4], resblock_kernel_sizes: List[int] = [3, 7, 11], resblock_dilations: List[List[int]] = [[1, 3, 5], [1, 3, 5], [1, 3, 5]], projection_filters: List[int] = [0, 1, 1, 1], projection_kernels: List[int] = [0, 5, 7, 11], use_additional_convs: bool = True, bias: bool = True, nonlinear_activation: str = 'LeakyReLU', nonlinear_activation_params: Dict[str, Any] = {'negative_slope': 0.2}, use_weight_norm: bool = True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/avocodo/avocodo.html#AvocodoGenerator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.avocodo.__init__.AvocodoGenerator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Avocodo generator module.</p>
<p>Initialize AvocodoGenerator module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<em>int</em>) – Number of input channels.</p></li>
<li><p><strong>out_channels</strong> (<em>int</em>) – Number of output channels.</p></li>
<li><p><strong>channels</strong> (<em>int</em>) – Number of hidden representation channels.</p></li>
<li><p><strong>global_channels</strong> (<em>int</em>) – Number of global conditioning channels.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – Kernel size of initial and final conv layer.</p></li>
<li><p><strong>upsample_scales</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of upsampling scales.</p></li>
<li><p><strong>upsample_kernel_sizes</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of kernel sizes for upsample layers.</p></li>
<li><p><strong>resblock_kernel_sizes</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of kernel sizes for residual blocks.</p></li>
<li><p><strong>resblock_dilations</strong> (<em>List</em><em>[</em><em>List</em><em>[</em><em>int</em><em>]</em><em>]</em>) – List of list of dilations for residual
blocks.</p></li>
<li><p><strong>use_additional_convs</strong> (<em>bool</em>) – Whether to use additional conv layers in
residual blocks.</p></li>
<li><p><strong>bias</strong> (<em>bool</em>) – Whether to add bias parameter in convolution layers.</p></li>
<li><p><strong>nonlinear_activation</strong> (<em>str</em>) – Activation function module name.</p></li>
<li><p><strong>nonlinear_activation_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Hyperparameters for activation
function.</p></li>
<li><p><strong>use_weight_norm</strong> (<em>bool</em>) – Whether to use weight norm. If set to true, it will
be applied to all of the conv layers.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_svs.avocodo.__init__.AvocodoGenerator.apply_weight_norm">
<code class="sig-name descname">apply_weight_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/avocodo/avocodo.html#AvocodoGenerator.apply_weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.avocodo.__init__.AvocodoGenerator.apply_weight_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply weight normalization module from all of the layers.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_svs.avocodo.__init__.AvocodoGenerator.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">c: torch.Tensor</em>, <em class="sig-param">g: Optional[torch.Tensor] = None</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_svs/avocodo/avocodo.html#AvocodoGenerator.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.avocodo.__init__.AvocodoGenerator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>c</strong> (<em>Tensor</em>) – Input tensor (B, in_channels, T).</p></li>
<li><p><strong>g</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Global conditioning tensor (B, global_channels, 1).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>List of output tensors (B, out_channels, T).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>List[Tensor]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_svs.avocodo.__init__.AvocodoGenerator.remove_weight_norm">
<code class="sig-name descname">remove_weight_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/avocodo/avocodo.html#AvocodoGenerator.remove_weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.avocodo.__init__.AvocodoGenerator.remove_weight_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Remove weight normalization module from all of the layers.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_svs.avocodo.__init__.AvocodoGenerator.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/avocodo/avocodo.html#AvocodoGenerator.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.avocodo.__init__.AvocodoGenerator.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Reset parameters.</p>
<p>This initialization follows the official implementation manner.
<a class="reference external" href="https://github.com/jik876/hifi-gan/blob/master/models.py">https://github.com/jik876/hifi-gan/blob/master/models.py</a></p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_svs.avocodo.__init__.CoMBD">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_svs.avocodo.__init__.</code><code class="sig-name descname">CoMBD</code><span class="sig-paren">(</span><em class="sig-param">h</em>, <em class="sig-param">pqmf_list=None</em>, <em class="sig-param">use_spectral_norm=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/avocodo/avocodo.html#CoMBD"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.avocodo.__init__.CoMBD" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>CoMBD (Collaborative Multi-band Discriminator) module
from from <a class="reference external" href="https://arxiv.org/abs/2206.13404">https://arxiv.org/abs/2206.13404</a></p>
<dl class="method">
<dt id="espnet2.gan_svs.avocodo.__init__.CoMBD.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">ys</em>, <em class="sig-param">ys_hat</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/avocodo/avocodo.html#CoMBD.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.avocodo.__init__.CoMBD.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ys</strong> (<em>List</em><em>[</em><em>Tensor</em><em>]</em>) – List of ground truth signals of shape (B, 1, T).</p></li>
<li><p><strong>ys_hat</strong> (<em>List</em><em>[</em><em>Tensor</em><em>]</em>) – List of predicted signals of shape (B, 1, T).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Tuple containing the list of output tensors of shape (B, C_out, T_out)
for real and fake, respectively, and the list of feature maps of shape
(B, C, T) at each Conv1d layer for real and fake, respectively.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple[List[Tensor], List[Tensor], List[List[Tensor]], List[List[Tensor]]]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_svs.avocodo.__init__.CoMBDBlock">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_svs.avocodo.__init__.</code><code class="sig-name descname">CoMBDBlock</code><span class="sig-paren">(</span><em class="sig-param">h_u: List[int], d_k: List[int], d_s: List[int], d_d: List[int], d_g: List[int], d_p: List[int], op_f: int, op_k: int, op_g: int, use_spectral_norm=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/avocodo/avocodo.html#CoMBDBlock"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.avocodo.__init__.CoMBDBlock" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>CoMBD (Collaborative Multi-band Discriminator) block module</p>
<dl class="method">
<dt id="espnet2.gan_svs.avocodo.__init__.CoMBDBlock.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/avocodo/avocodo.html#CoMBDBlock.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.avocodo.__init__.CoMBDBlock.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward pass through the CoMBD block.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>) – Input tensor of shape (B, C_in, T_in).</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>Tuple containing the output tensor of</dt><dd><p>shape (B, C_out, T_out)</p>
</dd>
</dl>
<p>and a list of feature maps of shape (B, C, T) at each Conv1d layer.</p>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple[Tensor, List[Tensor]]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_svs.avocodo.__init__.SBDBlock">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_svs.avocodo.__init__.</code><code class="sig-name descname">SBDBlock</code><span class="sig-paren">(</span><em class="sig-param">segment_dim</em>, <em class="sig-param">strides</em>, <em class="sig-param">filters</em>, <em class="sig-param">kernel_size</em>, <em class="sig-param">dilations</em>, <em class="sig-param">use_spectral_norm=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/avocodo/avocodo.html#SBDBlock"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.avocodo.__init__.SBDBlock" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>SBD (Sub-band Discriminator) Block</p>
<dl class="method">
<dt id="espnet2.gan_svs.avocodo.__init__.SBDBlock.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/avocodo/avocodo.html#SBDBlock.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.avocodo.__init__.SBDBlock.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</aside>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-gan-svs-uhifigan-sine-generator-1">
<span id="espnet2-gan-svs-uhifigan-sine-generator"></span><h2>espnet2.gan_svs.uhifigan.sine_generator<a class="headerlink" href="#espnet2-gan-svs-uhifigan-sine-generator-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_svs.uhifigan.sine_generator"></span><dl class="class">
<dt id="espnet2.gan_svs.uhifigan.sine_generator.SineGen">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_svs.uhifigan.sine_generator.</code><code class="sig-name descname">SineGen</code><span class="sig-paren">(</span><em class="sig-param">sample_rate</em>, <em class="sig-param">harmonic_num=0</em>, <em class="sig-param">sine_amp=0.1</em>, <em class="sig-param">noise_std=0.003</em>, <em class="sig-param">voiced_threshold=0</em>, <em class="sig-param">flag_for_pulse=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/uhifigan/sine_generator.html#SineGen"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.uhifigan.sine_generator.SineGen" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Definition of sine generator
SineGen(samp_rate, harmonic_num = 0,</p>
<blockquote>
<div><p>sine_amp = 0.1, noise_std = 0.003,
voiced_threshold = 0,
flag_for_pulse=False)</p>
</div></blockquote>
<p>sample_rate: sampling rate in Hz
harmonic_num: number of harmonic overtones (default 0)
sine_amp: amplitude of sine-wavefrom (default 0.1)
noise_std: std of Gaussian noise (default 0.003)
voiced_thoreshold: F0 threshold for U/V classification (default 0)
flag_for_pulse: this SinGen is used inside PulseGen (default False)</p>
<dl class="simple">
<dt>Note: when flag_for_pulse is True, the first time step of a voiced</dt><dd><p>segment is always sin(np.pi) or cos(0)</p>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_svs.uhifigan.sine_generator.SineGen.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">f0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/uhifigan/sine_generator.html#SineGen.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.uhifigan.sine_generator.SineGen.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>sine_tensor, uv = forward(f0)
input F0: tensor(batchsize=1, length, dim=1)</p>
<blockquote>
<div><p>f0 for unvoiced steps should be 0</p>
</div></blockquote>
<p>output sine_tensor: tensor(batchsize=1, length, dim)
output uv: tensor(batchsize=1, length, 1)</p>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-gan-svs-uhifigan-init-1">
<span id="espnet2-gan-svs-uhifigan-init"></span><h2>espnet2.gan_svs.uhifigan.__init__<a class="headerlink" href="#espnet2-gan-svs-uhifigan-init-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_svs.uhifigan.__init__"></span><dl class="class">
<dt id="espnet2.gan_svs.uhifigan.__init__.UHiFiGANGenerator">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_svs.uhifigan.__init__.</code><code class="sig-name descname">UHiFiGANGenerator</code><span class="sig-paren">(</span><em class="sig-param">in_channels=80, out_channels=1, channels=512, global_channels: int = -1, kernel_size=7, downsample_scales=(2, 2, 8, 8), downsample_kernel_sizes=(4, 4, 16, 16), upsample_scales=(8, 8, 2, 2), upsample_kernel_sizes=(16, 16, 4, 4), resblock_kernel_sizes=(3, 7, 11), resblock_dilations=[(1, 3, 5), (1, 3, 5), (1, 3, 5)], projection_filters: List[int] = [0, 1, 1, 1], projection_kernels: List[int] = [0, 5, 7, 11], dropout=0.3, use_additional_convs=True, bias=True, nonlinear_activation='LeakyReLU', nonlinear_activation_params={'negative_slope': 0.1}, use_causal_conv=False, use_weight_norm=True, use_avocodo=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/uhifigan/uhifigan.html#UHiFiGANGenerator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.uhifigan.__init__.UHiFiGANGenerator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>UHiFiGAN generator module.</p>
<p>Initialize Unet-based HiFiGANGenerator module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<em>int</em>) – Number of input channels.</p></li>
<li><p><strong>out_channels</strong> (<em>int</em>) – Number of output channels.</p></li>
<li><p><strong>channels</strong> (<em>int</em>) – Number of hidden representation channels.</p></li>
<li><p><strong>global_channels</strong> (<em>int</em>) – Number of global conditioning channels.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – Kernel size of initial and final conv layer.</p></li>
<li><p><strong>upsample_scales</strong> (<em>list</em>) – List of upsampling scales.</p></li>
<li><p><strong>upsample_kernel_sizes</strong> (<em>list</em>) – List of kernel sizes for upsampling layers.</p></li>
<li><p><strong>resblock_kernel_sizes</strong> (<em>list</em>) – List of kernel sizes for residual blocks.</p></li>
<li><p><strong>resblock_dilations</strong> (<em>list</em>) – List of dilation list for residual blocks.</p></li>
<li><p><strong>use_additional_convs</strong> (<em>bool</em>) – Whether to use additional conv layers
in residual blocks.</p></li>
<li><p><strong>bias</strong> (<em>bool</em>) – Whether to add bias parameter in convolution layers.</p></li>
<li><p><strong>nonlinear_activation</strong> (<em>str</em>) – Activation function module name.</p></li>
<li><p><strong>nonlinear_activation_params</strong> (<em>dict</em>) – Hyperparameters for activation function.</p></li>
<li><p><strong>use_causal_conv</strong> (<em>bool</em>) – Whether to use causal structure.</p></li>
<li><p><strong>use_weight_norm</strong> (<em>bool</em>) – Whether to use weight norm.
If set to true, it will be applied to all of the conv layers.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_svs.uhifigan.__init__.UHiFiGANGenerator.apply_weight_norm">
<code class="sig-name descname">apply_weight_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/uhifigan/uhifigan.html#UHiFiGANGenerator.apply_weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.uhifigan.__init__.UHiFiGANGenerator.apply_weight_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply weight normalization module from all of the layers.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_svs.uhifigan.__init__.UHiFiGANGenerator.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">c=None</em>, <em class="sig-param">f0=None</em>, <em class="sig-param">excitation=None</em>, <em class="sig-param">g: Optional[torch.Tensor] = None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/uhifigan/uhifigan.html#UHiFiGANGenerator.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.uhifigan.__init__.UHiFiGANGenerator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>c</strong> (<em>Tensor</em>) – Input tensor (B, in_channels, T).</p></li>
<li><p><strong>f0</strong> (<em>Tensor</em>) – Input tensor (B, 1, T).</p></li>
<li><p><strong>excitation</strong> (<em>Tensor</em>) – Input tensor (B, frame_len, T).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Output tensor (B, out_channels, T).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_svs.uhifigan.__init__.UHiFiGANGenerator.inference">
<code class="sig-name descname">inference</code><span class="sig-paren">(</span><em class="sig-param">excitation=None</em>, <em class="sig-param">f0=None</em>, <em class="sig-param">c=None</em>, <em class="sig-param">normalize_before=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/uhifigan/uhifigan.html#UHiFiGANGenerator.inference"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.uhifigan.__init__.UHiFiGANGenerator.inference" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform inference.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>c</strong> (<em>Union</em><em>[</em><em>Tensor</em><em>, </em><em>ndarray</em><em>]</em>) – Input tensor (T, in_channels).</p></li>
<li><p><strong>normalize_before</strong> (<em>bool</em>) – Whether to perform normalization.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Output tensor (T ** prod(upsample_scales), out_channels).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_svs.uhifigan.__init__.UHiFiGANGenerator.register_stats">
<code class="sig-name descname">register_stats</code><span class="sig-paren">(</span><em class="sig-param">stats</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/uhifigan/uhifigan.html#UHiFiGANGenerator.register_stats"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.uhifigan.__init__.UHiFiGANGenerator.register_stats" title="Permalink to this definition">¶</a></dt>
<dd><p>Register stats for de-normalization as buffer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>stats</strong> (<em>str</em>) – Path of statistics file (“.npy” or “.h5”).</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_svs.uhifigan.__init__.UHiFiGANGenerator.remove_weight_norm">
<code class="sig-name descname">remove_weight_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/uhifigan/uhifigan.html#UHiFiGANGenerator.remove_weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.uhifigan.__init__.UHiFiGANGenerator.remove_weight_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Remove weight normalization module from all of the layers.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_svs.uhifigan.__init__.UHiFiGANGenerator.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/uhifigan/uhifigan.html#UHiFiGANGenerator.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.uhifigan.__init__.UHiFiGANGenerator.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Reset parameters.</p>
<p>This initialization follows the official implementation manner.
<a class="reference external" href="https://github.com/jik876/hifi-gan/blob/master/models.py">https://github.com/jik876/hifi-gan/blob/master/models.py</a></p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_svs.uhifigan.__init__.SineGen">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_svs.uhifigan.__init__.</code><code class="sig-name descname">SineGen</code><span class="sig-paren">(</span><em class="sig-param">sample_rate</em>, <em class="sig-param">harmonic_num=0</em>, <em class="sig-param">sine_amp=0.1</em>, <em class="sig-param">noise_std=0.003</em>, <em class="sig-param">voiced_threshold=0</em>, <em class="sig-param">flag_for_pulse=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/uhifigan/sine_generator.html#SineGen"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.uhifigan.__init__.SineGen" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Definition of sine generator
SineGen(samp_rate, harmonic_num = 0,</p>
<blockquote>
<div><p>sine_amp = 0.1, noise_std = 0.003,
voiced_threshold = 0,
flag_for_pulse=False)</p>
</div></blockquote>
<p>sample_rate: sampling rate in Hz
harmonic_num: number of harmonic overtones (default 0)
sine_amp: amplitude of sine-wavefrom (default 0.1)
noise_std: std of Gaussian noise (default 0.003)
voiced_thoreshold: F0 threshold for U/V classification (default 0)
flag_for_pulse: this SinGen is used inside PulseGen (default False)</p>
<dl class="simple">
<dt>Note: when flag_for_pulse is True, the first time step of a voiced</dt><dd><p>segment is always sin(np.pi) or cos(0)</p>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_svs.uhifigan.__init__.SineGen.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">f0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/uhifigan/sine_generator.html#SineGen.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.uhifigan.__init__.SineGen.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>sine_tensor, uv = forward(f0)
input F0: tensor(batchsize=1, length, dim=1)</p>
<blockquote>
<div><p>f0 for unvoiced steps should be 0</p>
</div></blockquote>
<p>output sine_tensor: tensor(batchsize=1, length, dim)
output uv: tensor(batchsize=1, length, 1)</p>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-gan-svs-uhifigan-uhifigan-1">
<span id="espnet2-gan-svs-uhifigan-uhifigan"></span><h2>espnet2.gan_svs.uhifigan.uhifigan<a class="headerlink" href="#espnet2-gan-svs-uhifigan-uhifigan-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_svs.uhifigan.uhifigan"></span><p>Unet-baed HiFi-GAN Modules.</p>
<p>This code is based on <a class="reference external" href="https://github.com/jik876/hifi-gan">https://github.com/jik876/hifi-gan</a>
and <a class="reference external" href="https://github.com/kan-bayashi/ParallelWaveGAN">https://github.com/kan-bayashi/ParallelWaveGAN</a>.</p>
<dl class="class">
<dt id="espnet2.gan_svs.uhifigan.uhifigan.UHiFiGANGenerator">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_svs.uhifigan.uhifigan.</code><code class="sig-name descname">UHiFiGANGenerator</code><span class="sig-paren">(</span><em class="sig-param">in_channels=80, out_channels=1, channels=512, global_channels: int = -1, kernel_size=7, downsample_scales=(2, 2, 8, 8), downsample_kernel_sizes=(4, 4, 16, 16), upsample_scales=(8, 8, 2, 2), upsample_kernel_sizes=(16, 16, 4, 4), resblock_kernel_sizes=(3, 7, 11), resblock_dilations=[(1, 3, 5), (1, 3, 5), (1, 3, 5)], projection_filters: List[int] = [0, 1, 1, 1], projection_kernels: List[int] = [0, 5, 7, 11], dropout=0.3, use_additional_convs=True, bias=True, nonlinear_activation='LeakyReLU', nonlinear_activation_params={'negative_slope': 0.1}, use_causal_conv=False, use_weight_norm=True, use_avocodo=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/uhifigan/uhifigan.html#UHiFiGANGenerator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.uhifigan.uhifigan.UHiFiGANGenerator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>UHiFiGAN generator module.</p>
<p>Initialize Unet-based HiFiGANGenerator module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<em>int</em>) – Number of input channels.</p></li>
<li><p><strong>out_channels</strong> (<em>int</em>) – Number of output channels.</p></li>
<li><p><strong>channels</strong> (<em>int</em>) – Number of hidden representation channels.</p></li>
<li><p><strong>global_channels</strong> (<em>int</em>) – Number of global conditioning channels.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – Kernel size of initial and final conv layer.</p></li>
<li><p><strong>upsample_scales</strong> (<em>list</em>) – List of upsampling scales.</p></li>
<li><p><strong>upsample_kernel_sizes</strong> (<em>list</em>) – List of kernel sizes for upsampling layers.</p></li>
<li><p><strong>resblock_kernel_sizes</strong> (<em>list</em>) – List of kernel sizes for residual blocks.</p></li>
<li><p><strong>resblock_dilations</strong> (<em>list</em>) – List of dilation list for residual blocks.</p></li>
<li><p><strong>use_additional_convs</strong> (<em>bool</em>) – Whether to use additional conv layers
in residual blocks.</p></li>
<li><p><strong>bias</strong> (<em>bool</em>) – Whether to add bias parameter in convolution layers.</p></li>
<li><p><strong>nonlinear_activation</strong> (<em>str</em>) – Activation function module name.</p></li>
<li><p><strong>nonlinear_activation_params</strong> (<em>dict</em>) – Hyperparameters for activation function.</p></li>
<li><p><strong>use_causal_conv</strong> (<em>bool</em>) – Whether to use causal structure.</p></li>
<li><p><strong>use_weight_norm</strong> (<em>bool</em>) – Whether to use weight norm.
If set to true, it will be applied to all of the conv layers.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_svs.uhifigan.uhifigan.UHiFiGANGenerator.apply_weight_norm">
<code class="sig-name descname">apply_weight_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/uhifigan/uhifigan.html#UHiFiGANGenerator.apply_weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.uhifigan.uhifigan.UHiFiGANGenerator.apply_weight_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply weight normalization module from all of the layers.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_svs.uhifigan.uhifigan.UHiFiGANGenerator.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">c=None</em>, <em class="sig-param">f0=None</em>, <em class="sig-param">excitation=None</em>, <em class="sig-param">g: Optional[torch.Tensor] = None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/uhifigan/uhifigan.html#UHiFiGANGenerator.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.uhifigan.uhifigan.UHiFiGANGenerator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>c</strong> (<em>Tensor</em>) – Input tensor (B, in_channels, T).</p></li>
<li><p><strong>f0</strong> (<em>Tensor</em>) – Input tensor (B, 1, T).</p></li>
<li><p><strong>excitation</strong> (<em>Tensor</em>) – Input tensor (B, frame_len, T).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Output tensor (B, out_channels, T).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_svs.uhifigan.uhifigan.UHiFiGANGenerator.inference">
<code class="sig-name descname">inference</code><span class="sig-paren">(</span><em class="sig-param">excitation=None</em>, <em class="sig-param">f0=None</em>, <em class="sig-param">c=None</em>, <em class="sig-param">normalize_before=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/uhifigan/uhifigan.html#UHiFiGANGenerator.inference"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.uhifigan.uhifigan.UHiFiGANGenerator.inference" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform inference.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>c</strong> (<em>Union</em><em>[</em><em>Tensor</em><em>, </em><em>ndarray</em><em>]</em>) – Input tensor (T, in_channels).</p></li>
<li><p><strong>normalize_before</strong> (<em>bool</em>) – Whether to perform normalization.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Output tensor (T ** prod(upsample_scales), out_channels).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_svs.uhifigan.uhifigan.UHiFiGANGenerator.register_stats">
<code class="sig-name descname">register_stats</code><span class="sig-paren">(</span><em class="sig-param">stats</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/uhifigan/uhifigan.html#UHiFiGANGenerator.register_stats"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.uhifigan.uhifigan.UHiFiGANGenerator.register_stats" title="Permalink to this definition">¶</a></dt>
<dd><p>Register stats for de-normalization as buffer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>stats</strong> (<em>str</em>) – Path of statistics file (“.npy” or “.h5”).</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_svs.uhifigan.uhifigan.UHiFiGANGenerator.remove_weight_norm">
<code class="sig-name descname">remove_weight_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/uhifigan/uhifigan.html#UHiFiGANGenerator.remove_weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.uhifigan.uhifigan.UHiFiGANGenerator.remove_weight_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Remove weight normalization module from all of the layers.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_svs.uhifigan.uhifigan.UHiFiGANGenerator.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/uhifigan/uhifigan.html#UHiFiGANGenerator.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.uhifigan.uhifigan.UHiFiGANGenerator.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Reset parameters.</p>
<p>This initialization follows the official implementation manner.
<a class="reference external" href="https://github.com/jik876/hifi-gan/blob/master/models.py">https://github.com/jik876/hifi-gan/blob/master/models.py</a></p>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-gan-svs-utils-expand-f0-1">
<span id="espnet2-gan-svs-utils-expand-f0"></span><h2>espnet2.gan_svs.utils.expand_f0<a class="headerlink" href="#espnet2-gan-svs-utils-expand-f0-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_svs.utils.expand_f0"></span><p>Function to get random segments.</p>
<dl class="function">
<dt id="espnet2.gan_svs.utils.expand_f0.expand_f0">
<code class="sig-prename descclassname">espnet2.gan_svs.utils.expand_f0.</code><code class="sig-name descname">expand_f0</code><span class="sig-paren">(</span><em class="sig-param">f0_frame</em>, <em class="sig-param">hop_length</em>, <em class="sig-param">method='interpolation'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/utils/expand_f0.html#expand_f0"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.utils.expand_f0.expand_f0" title="Permalink to this definition">¶</a></dt>
<dd><p>Expand f0 to output wave length.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>f0_frame</strong> (<em>Tensor</em>) – Input tensor (B, 1, frame_len).</p></li>
<li><p><strong>hop_length</strong> (<em>Tensor</em>) – Hop length.</p></li>
<li><p><strong>method</strong> (<em>str</em>) – Method to expand f0. Choose either ‘interpolation’ or ‘repeat’.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Output tensor (B, 1, wav_len).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="espnet2-gan-svs-utils-init-1">
<span id="espnet2-gan-svs-utils-init"></span><h2>espnet2.gan_svs.utils.__init__<a class="headerlink" href="#espnet2-gan-svs-utils-init-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_svs.utils.__init__"></span></section>
<section id="espnet2-gan-svs-visinger2-ddsp-1">
<span id="espnet2-gan-svs-visinger2-ddsp"></span><h2>espnet2.gan_svs.visinger2.ddsp<a class="headerlink" href="#espnet2-gan-svs-visinger2-ddsp-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_svs.visinger2.ddsp"></span><dl class="function">
<dt id="espnet2.gan_svs.visinger2.ddsp.amp_to_impulse_response">
<code class="sig-prename descclassname">espnet2.gan_svs.visinger2.ddsp.</code><code class="sig-name descname">amp_to_impulse_response</code><span class="sig-paren">(</span><em class="sig-param">amp</em>, <em class="sig-param">target_size</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/visinger2/ddsp.html#amp_to_impulse_response"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.visinger2.ddsp.amp_to_impulse_response" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="espnet2.gan_svs.visinger2.ddsp.extract_loudness">
<code class="sig-prename descclassname">espnet2.gan_svs.visinger2.ddsp.</code><code class="sig-name descname">extract_loudness</code><span class="sig-paren">(</span><em class="sig-param">signal</em>, <em class="sig-param">sampling_rate</em>, <em class="sig-param">block_size</em>, <em class="sig-param">n_fft=2048</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/visinger2/ddsp.html#extract_loudness"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.visinger2.ddsp.extract_loudness" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="espnet2.gan_svs.visinger2.ddsp.extract_pitch">
<code class="sig-prename descclassname">espnet2.gan_svs.visinger2.ddsp.</code><code class="sig-name descname">extract_pitch</code><span class="sig-paren">(</span><em class="sig-param">signal</em>, <em class="sig-param">sampling_rate</em>, <em class="sig-param">block_size</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/visinger2/ddsp.html#extract_pitch"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.visinger2.ddsp.extract_pitch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="espnet2.gan_svs.visinger2.ddsp.fft_convolve">
<code class="sig-prename descclassname">espnet2.gan_svs.visinger2.ddsp.</code><code class="sig-name descname">fft_convolve</code><span class="sig-paren">(</span><em class="sig-param">signal</em>, <em class="sig-param">kernel</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/visinger2/ddsp.html#fft_convolve"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.visinger2.ddsp.fft_convolve" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="espnet2.gan_svs.visinger2.ddsp.gru">
<code class="sig-prename descclassname">espnet2.gan_svs.visinger2.ddsp.</code><code class="sig-name descname">gru</code><span class="sig-paren">(</span><em class="sig-param">n_input</em>, <em class="sig-param">hidden_size</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/visinger2/ddsp.html#gru"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.visinger2.ddsp.gru" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="espnet2.gan_svs.visinger2.ddsp.harmonic_synth">
<code class="sig-prename descclassname">espnet2.gan_svs.visinger2.ddsp.</code><code class="sig-name descname">harmonic_synth</code><span class="sig-paren">(</span><em class="sig-param">pitch</em>, <em class="sig-param">amplitudes</em>, <em class="sig-param">sampling_rate</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/visinger2/ddsp.html#harmonic_synth"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.visinger2.ddsp.harmonic_synth" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="espnet2.gan_svs.visinger2.ddsp.init_kernels">
<code class="sig-prename descclassname">espnet2.gan_svs.visinger2.ddsp.</code><code class="sig-name descname">init_kernels</code><span class="sig-paren">(</span><em class="sig-param">win_len</em>, <em class="sig-param">win_inc</em>, <em class="sig-param">fft_len</em>, <em class="sig-param">win_type=None</em>, <em class="sig-param">invers=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/visinger2/ddsp.html#init_kernels"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.visinger2.ddsp.init_kernels" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="espnet2.gan_svs.visinger2.ddsp.mean_std_loudness">
<code class="sig-prename descclassname">espnet2.gan_svs.visinger2.ddsp.</code><code class="sig-name descname">mean_std_loudness</code><span class="sig-paren">(</span><em class="sig-param">dataset</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/visinger2/ddsp.html#mean_std_loudness"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.visinger2.ddsp.mean_std_loudness" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="espnet2.gan_svs.visinger2.ddsp.mlp">
<code class="sig-prename descclassname">espnet2.gan_svs.visinger2.ddsp.</code><code class="sig-name descname">mlp</code><span class="sig-paren">(</span><em class="sig-param">in_size</em>, <em class="sig-param">hidden_size</em>, <em class="sig-param">n_layers</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/visinger2/ddsp.html#mlp"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.visinger2.ddsp.mlp" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="espnet2.gan_svs.visinger2.ddsp.multiscale_fft">
<code class="sig-prename descclassname">espnet2.gan_svs.visinger2.ddsp.</code><code class="sig-name descname">multiscale_fft</code><span class="sig-paren">(</span><em class="sig-param">signal</em>, <em class="sig-param">scales</em>, <em class="sig-param">overlap</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/visinger2/ddsp.html#multiscale_fft"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.visinger2.ddsp.multiscale_fft" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="espnet2.gan_svs.visinger2.ddsp.remove_above_nyquist">
<code class="sig-prename descclassname">espnet2.gan_svs.visinger2.ddsp.</code><code class="sig-name descname">remove_above_nyquist</code><span class="sig-paren">(</span><em class="sig-param">amplitudes</em>, <em class="sig-param">pitch</em>, <em class="sig-param">sampling_rate</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/visinger2/ddsp.html#remove_above_nyquist"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.visinger2.ddsp.remove_above_nyquist" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="espnet2.gan_svs.visinger2.ddsp.resample">
<code class="sig-prename descclassname">espnet2.gan_svs.visinger2.ddsp.</code><code class="sig-name descname">resample</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">factor: int</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/visinger2/ddsp.html#resample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.visinger2.ddsp.resample" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="espnet2.gan_svs.visinger2.ddsp.safe_log">
<code class="sig-prename descclassname">espnet2.gan_svs.visinger2.ddsp.</code><code class="sig-name descname">safe_log</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/visinger2/ddsp.html#safe_log"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.visinger2.ddsp.safe_log" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="espnet2.gan_svs.visinger2.ddsp.scale_function">
<code class="sig-prename descclassname">espnet2.gan_svs.visinger2.ddsp.</code><code class="sig-name descname">scale_function</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/visinger2/ddsp.html#scale_function"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.visinger2.ddsp.scale_function" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="espnet2.gan_svs.visinger2.ddsp.upsample">
<code class="sig-prename descclassname">espnet2.gan_svs.visinger2.ddsp.</code><code class="sig-name descname">upsample</code><span class="sig-paren">(</span><em class="sig-param">signal</em>, <em class="sig-param">factor</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/visinger2/ddsp.html#upsample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.visinger2.ddsp.upsample" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</section>
<section id="espnet2-gan-svs-visinger2-init-1">
<span id="espnet2-gan-svs-visinger2-init"></span><h2>espnet2.gan_svs.visinger2.__init__<a class="headerlink" href="#espnet2-gan-svs-visinger2-init-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_svs.visinger2.__init__"></span><dl class="class">
<dt id="espnet2.gan_svs.visinger2.__init__.Generator_Harm">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_svs.visinger2.__init__.</code><code class="sig-name descname">Generator_Harm</code><span class="sig-paren">(</span><em class="sig-param">hidden_channels: int = 192</em>, <em class="sig-param">n_harmonic: int = 64</em>, <em class="sig-param">kernel_size: int = 3</em>, <em class="sig-param">padding: int = 1</em>, <em class="sig-param">dropout_rate: float = 0.1</em>, <em class="sig-param">sample_rate: int = 22050</em>, <em class="sig-param">hop_size: int = 256</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/visinger2/visinger2_vocoder.html#Generator_Harm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.visinger2.__init__.Generator_Harm" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Initialize harmonic generator module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hidden_channels</strong> (<em>int</em>) – Number of channels in the input and hidden layers.</p></li>
<li><p><strong>n_harmonic</strong> (<em>int</em>) – Number of harmonic channels.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – Size of the convolutional kernel.</p></li>
<li><p><strong>padding</strong> (<em>int</em>) – Amount of padding added to the input.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>) – Dropout rate.</p></li>
<li><p><strong>sample_rate</strong> (<em>int</em>) – Sampling rate of the input audio.</p></li>
<li><p><strong>hop_size</strong> (<em>int</em>) – Hop size used in the analysis of the input audio.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_svs.visinger2.__init__.Generator_Harm.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">f0</em>, <em class="sig-param">harm</em>, <em class="sig-param">mask</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/visinger2/visinger2_vocoder.html#Generator_Harm.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.visinger2.__init__.Generator_Harm.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate harmonics from F0 and harmonic data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>f0</strong> (<em>Tensor</em>) – Pitch (F0) tensor (B, 1, T).</p></li>
<li><p><strong>harm</strong> (<em>Tensor</em>) – Harmonic data tensor (B, hidden_channels, T).</p></li>
<li><p><strong>mask</strong> (<em>Tensor</em>) – Mask tensor for harmonic data (B, 1, T).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Harmonic signal tensor (B, n_harmonic, T * hop_length).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_svs.visinger2.__init__.Generator_Noise">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_svs.visinger2.__init__.</code><code class="sig-name descname">Generator_Noise</code><span class="sig-paren">(</span><em class="sig-param">win_length: int = 1024</em>, <em class="sig-param">hop_length: int = 256</em>, <em class="sig-param">n_fft: int = 1024</em>, <em class="sig-param">hidden_channels: int = 192</em>, <em class="sig-param">kernel_size: int = 3</em>, <em class="sig-param">padding: int = 1</em>, <em class="sig-param">dropout_rate: float = 0.1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/visinger2/visinger2_vocoder.html#Generator_Noise"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.visinger2.__init__.Generator_Noise" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Initialize the Generator_Noise module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>win_length</strong> (<em>int</em><em>, </em><em>optional</em>) – Window length. If None, set to <cite>n_fft</cite>.</p></li>
<li><p><strong>hop_length</strong> (<em>int</em>) – Hop length.</p></li>
<li><p><strong>n_fft</strong> (<em>int</em>) – FFT size.</p></li>
<li><p><strong>hidden_channels</strong> (<em>int</em>) – Number of hidden representation channels.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – Size of the convolutional kernel.</p></li>
<li><p><strong>padding</strong> (<em>int</em>) – Size of the padding applied to the input.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>) – Dropout rate.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_svs.visinger2.__init__.Generator_Noise.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">mask</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/visinger2/visinger2_vocoder.html#Generator_Noise.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.visinger2.__init__.Generator_Noise.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – Input tensor (B, hidden_channels, T).</p></li>
<li><p><strong>mask</strong> (<em>Tensor</em>) – Mask tensor (B, 1, T).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Output tensor (B, 1, T * hop_size).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_svs.visinger2.__init__.VISinger2Discriminator">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_svs.visinger2.__init__.</code><code class="sig-name descname">VISinger2Discriminator</code><span class="sig-paren">(</span><em class="sig-param">scales: int = 1, scale_downsample_pooling: str = 'AvgPool1d', scale_downsample_pooling_params: Dict[str, Any] = {'kernel_size': 4, 'padding': 2, 'stride': 2}, scale_discriminator_params: Dict[str, Any] = {'bias': True, 'channels': 128, 'downsample_scales': [2, 2, 4, 4, 1], 'in_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'max_downsample_channels': 1024, 'max_groups': 16, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'out_channels': 1}, follow_official_norm: bool = True, periods: List[int] = [2, 3, 5, 7, 11], period_discriminator_params: Dict[str, Any] = {'bias': True, 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'in_channels': 1, 'kernel_sizes': [5, 3], 'max_downsample_channels': 1024, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'out_channels': 1, 'use_spectral_norm': False, 'use_weight_norm': True}, multi_freq_disc_params: Dict[str, Any] = {'divisors': [32, 16, 8, 4, 2, 1, 1], 'domain': 'double', 'hidden_channels': [256, 512, 512], 'hop_length_factors': [4, 8, 16], 'mel_scale': True, 'sample_rate': 22050, 'strides': [1, 2, 1, 2, 1, 2, 1]}</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/visinger2/visinger2_vocoder.html#VISinger2Discriminator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.visinger2.__init__.VISinger2Discriminator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Discriminator module for VISinger2, including MSD, MPD, and MFD.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>scales</strong> (<em>int</em>) – Number of scales to be used in the multi-scale discriminator.</p></li>
<li><p><strong>scale_downsample_pooling</strong> (<em>str</em>) – Type of pooling used for downsampling.</p></li>
<li><p><strong>scale_downsample_pooling_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Parameters for the
downsampling pooling
layer.</p></li>
<li><p><strong>scale_discriminator_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Parameters for the scale
discriminator.</p></li>
<li><p><strong>follow_official_norm</strong> (<em>bool</em>) – Whether to follow the official normalization.</p></li>
<li><p><strong>periods</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of periods to be used in the multi-period
discriminator.</p></li>
<li><p><strong>period_discriminator_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Parameters for the period
discriminator.</p></li>
<li><p><strong>multi_freq_disc_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Parameters for the
multi-frequency discriminator.</p></li>
<li><p><strong>use_spectral_norm</strong> (<em>bool</em>) – Whether to use spectral normalization or not.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_svs.visinger2.__init__.VISinger2Discriminator.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/visinger2/visinger2_vocoder.html#VISinger2Discriminator.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.visinger2.__init__.VISinger2Discriminator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</aside>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_svs.visinger2.__init__.VISinger2VocoderGenerator">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_svs.visinger2.__init__.</code><code class="sig-name descname">VISinger2VocoderGenerator</code><span class="sig-paren">(</span><em class="sig-param">in_channels: int = 80, out_channels: int = 1, channels: int = 512, global_channels: int = -1, kernel_size: int = 7, upsample_scales: List[int] = [8, 8, 2, 2], upsample_kernel_sizes: List[int] = [16, 16, 4, 4], resblock_kernel_sizes: List[int] = [3, 7, 11], resblock_dilations: List[List[int]] = [[1, 3, 5], [1, 3, 5], [1, 3, 5]], n_harmonic: int = 64, use_additional_convs: bool = True, bias: bool = True, nonlinear_activation: str = 'LeakyReLU', nonlinear_activation_params: Dict[str, Any] = {'negative_slope': 0.1}, use_weight_norm: bool = True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/visinger2/visinger2_vocoder.html#VISinger2VocoderGenerator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.visinger2.__init__.VISinger2VocoderGenerator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Initialize HiFiGANGenerator module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<em>int</em>) – Number of input channels.</p></li>
<li><p><strong>out_channels</strong> (<em>int</em>) – Number of output channels.</p></li>
<li><p><strong>channels</strong> (<em>int</em>) – Number of hidden representation channels.</p></li>
<li><p><strong>global_channels</strong> (<em>int</em>) – Number of global conditioning channels.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – Kernel size of initial and final conv layer.</p></li>
<li><p><strong>upsample_scales</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of upsampling scales.</p></li>
<li><p><strong>upsample_kernel_sizes</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of kernel sizes for upsample layers.</p></li>
<li><p><strong>resblock_kernel_sizes</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of kernel sizes for residual blocks.</p></li>
<li><p><strong>resblock_dilations</strong> (<em>List</em><em>[</em><em>List</em><em>[</em><em>int</em><em>]</em><em>]</em>) – List of list of dilations for residual
blocks.</p></li>
<li><p><strong>n_harmonic</strong> (<em>int</em>) – Number of harmonics used to synthesize a sound signal.</p></li>
<li><p><strong>use_additional_convs</strong> (<em>bool</em>) – Whether to use additional conv layers in
residual blocks.</p></li>
<li><p><strong>bias</strong> (<em>bool</em>) – Whether to add bias parameter in convolution layers.</p></li>
<li><p><strong>nonlinear_activation</strong> (<em>str</em>) – Activation function module name.</p></li>
<li><p><strong>nonlinear_activation_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Hyperparameters for activation
function.</p></li>
<li><p><strong>use_weight_norm</strong> (<em>bool</em>) – Whether to use weight norm. If set to true, it will
be applied to all of the conv layers.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_svs.visinger2.__init__.VISinger2VocoderGenerator.apply_weight_norm">
<code class="sig-name descname">apply_weight_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/visinger2/visinger2_vocoder.html#VISinger2VocoderGenerator.apply_weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.visinger2.__init__.VISinger2VocoderGenerator.apply_weight_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply weight normalization module from all of the layers.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_svs.visinger2.__init__.VISinger2VocoderGenerator.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">c</em>, <em class="sig-param">ddsp</em>, <em class="sig-param">g: Optional[torch.Tensor] = None</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_svs/visinger2/visinger2_vocoder.html#VISinger2VocoderGenerator.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.visinger2.__init__.VISinger2VocoderGenerator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>c</strong> (<em>Tensor</em>) – Input tensor (B, in_channels, T).</p></li>
<li><p><strong>ddsp</strong> (<em>Tensor</em>) – Input tensor (B, n_harmonic + 2, T * hop_length).</p></li>
<li><p><strong>g</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Global conditioning tensor (B, global_channels, 1).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Output tensor (B, out_channels, T).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_svs.visinger2.__init__.VISinger2VocoderGenerator.remove_weight_norm">
<code class="sig-name descname">remove_weight_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/visinger2/visinger2_vocoder.html#VISinger2VocoderGenerator.remove_weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.visinger2.__init__.VISinger2VocoderGenerator.remove_weight_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Remove weight normalization module from all of the layers.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_svs.visinger2.__init__.VISinger2VocoderGenerator.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/visinger2/visinger2_vocoder.html#VISinger2VocoderGenerator.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.visinger2.__init__.VISinger2VocoderGenerator.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Reset parameters.</p>
<p>This initialization follows the official implementation manner.
<a class="reference external" href="https://github.com/jik876/hifi-gan/blob/master/models.py">https://github.com/jik876/hifi-gan/blob/master/models.py</a></p>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-gan-svs-visinger2-visinger2-vocoder-1">
<span id="espnet2-gan-svs-visinger2-visinger2-vocoder"></span><h2>espnet2.gan_svs.visinger2.visinger2_vocoder<a class="headerlink" href="#espnet2-gan-svs-visinger2-visinger2-vocoder-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_svs.visinger2.visinger2_vocoder"></span><p>VISinger2 HiFi-GAN Modules.</p>
<p>This code is based on <a class="reference external" href="https://github.com/zhangyongmao/VISinger2">https://github.com/zhangyongmao/VISinger2</a></p>
<dl class="class">
<dt id="espnet2.gan_svs.visinger2.visinger2_vocoder.BaseFrequenceDiscriminator">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_svs.visinger2.visinger2_vocoder.</code><code class="sig-name descname">BaseFrequenceDiscriminator</code><span class="sig-paren">(</span><em class="sig-param">in_channels, hidden_channels=512, divisors=[32, 16, 8, 4, 2, 1, 1], strides=[1, 2, 1, 2, 1, 2, 1]</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/visinger2/visinger2_vocoder.html#BaseFrequenceDiscriminator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.visinger2.visinger2_vocoder.BaseFrequenceDiscriminator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<em>int</em>) – Number of input channels.</p></li>
<li><p><strong>hidden_channels</strong> (<em>int</em><em>, </em><em>optional</em>) – Number of channels in hidden layers.
Defaults to 512.</p></li>
<li><p><strong>divisors</strong> (<em>List</em><em>[</em><em>int</em><em>]</em><em>, </em><em>optional</em>) – List of divisors for the number of channels
in each layer. The length of the list
determines the number of layers. Defaults
to [32, 16, 8, 4, 2, 1, 1].</p></li>
<li><p><strong>strides</strong> (<em>List</em><em>[</em><em>int</em><em>]</em><em>, </em><em>optional</em>) – List of stride values for each layer. The
length of the list determines the number
of layers.Defaults to [1, 2, 1, 2, 1, 2, 1].</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_svs.visinger2.visinger2_vocoder.BaseFrequenceDiscriminator.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/visinger2/visinger2_vocoder.html#BaseFrequenceDiscriminator.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.visinger2.visinger2_vocoder.BaseFrequenceDiscriminator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform forward pass through the base frequency discriminator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.Tensor</em>) – Input tensor of shape
(B, in_channels, freq_bins, time_steps).</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>List of output tensors from each layer of the</dt><dd><p>discriminator, where the first tensor corresponds to
the output of the first layer, and so on.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>List[torch.Tensor]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_svs.visinger2.visinger2_vocoder.ConvReluNorm">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_svs.visinger2.visinger2_vocoder.</code><code class="sig-name descname">ConvReluNorm</code><span class="sig-paren">(</span><em class="sig-param">in_channels</em>, <em class="sig-param">hidden_channels</em>, <em class="sig-param">out_channels</em>, <em class="sig-param">kernel_size</em>, <em class="sig-param">n_layers</em>, <em class="sig-param">dropout_rate</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/visinger2/visinger2_vocoder.html#ConvReluNorm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.visinger2.visinger2_vocoder.ConvReluNorm" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="method">
<dt id="espnet2.gan_svs.visinger2.visinger2_vocoder.ConvReluNorm.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/visinger2/visinger2_vocoder.html#ConvReluNorm.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.visinger2.visinger2_vocoder.ConvReluNorm.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</aside>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_svs.visinger2.visinger2_vocoder.Generator_Harm">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_svs.visinger2.visinger2_vocoder.</code><code class="sig-name descname">Generator_Harm</code><span class="sig-paren">(</span><em class="sig-param">hidden_channels: int = 192</em>, <em class="sig-param">n_harmonic: int = 64</em>, <em class="sig-param">kernel_size: int = 3</em>, <em class="sig-param">padding: int = 1</em>, <em class="sig-param">dropout_rate: float = 0.1</em>, <em class="sig-param">sample_rate: int = 22050</em>, <em class="sig-param">hop_size: int = 256</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/visinger2/visinger2_vocoder.html#Generator_Harm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.visinger2.visinger2_vocoder.Generator_Harm" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Initialize harmonic generator module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hidden_channels</strong> (<em>int</em>) – Number of channels in the input and hidden layers.</p></li>
<li><p><strong>n_harmonic</strong> (<em>int</em>) – Number of harmonic channels.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – Size of the convolutional kernel.</p></li>
<li><p><strong>padding</strong> (<em>int</em>) – Amount of padding added to the input.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>) – Dropout rate.</p></li>
<li><p><strong>sample_rate</strong> (<em>int</em>) – Sampling rate of the input audio.</p></li>
<li><p><strong>hop_size</strong> (<em>int</em>) – Hop size used in the analysis of the input audio.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_svs.visinger2.visinger2_vocoder.Generator_Harm.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">f0</em>, <em class="sig-param">harm</em>, <em class="sig-param">mask</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/visinger2/visinger2_vocoder.html#Generator_Harm.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.visinger2.visinger2_vocoder.Generator_Harm.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate harmonics from F0 and harmonic data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>f0</strong> (<em>Tensor</em>) – Pitch (F0) tensor (B, 1, T).</p></li>
<li><p><strong>harm</strong> (<em>Tensor</em>) – Harmonic data tensor (B, hidden_channels, T).</p></li>
<li><p><strong>mask</strong> (<em>Tensor</em>) – Mask tensor for harmonic data (B, 1, T).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Harmonic signal tensor (B, n_harmonic, T * hop_length).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_svs.visinger2.visinger2_vocoder.Generator_Noise">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_svs.visinger2.visinger2_vocoder.</code><code class="sig-name descname">Generator_Noise</code><span class="sig-paren">(</span><em class="sig-param">win_length: int = 1024</em>, <em class="sig-param">hop_length: int = 256</em>, <em class="sig-param">n_fft: int = 1024</em>, <em class="sig-param">hidden_channels: int = 192</em>, <em class="sig-param">kernel_size: int = 3</em>, <em class="sig-param">padding: int = 1</em>, <em class="sig-param">dropout_rate: float = 0.1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/visinger2/visinger2_vocoder.html#Generator_Noise"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.visinger2.visinger2_vocoder.Generator_Noise" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Initialize the Generator_Noise module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>win_length</strong> (<em>int</em><em>, </em><em>optional</em>) – Window length. If None, set to <cite>n_fft</cite>.</p></li>
<li><p><strong>hop_length</strong> (<em>int</em>) – Hop length.</p></li>
<li><p><strong>n_fft</strong> (<em>int</em>) – FFT size.</p></li>
<li><p><strong>hidden_channels</strong> (<em>int</em>) – Number of hidden representation channels.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – Size of the convolutional kernel.</p></li>
<li><p><strong>padding</strong> (<em>int</em>) – Size of the padding applied to the input.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>) – Dropout rate.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_svs.visinger2.visinger2_vocoder.Generator_Noise.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">mask</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/visinger2/visinger2_vocoder.html#Generator_Noise.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.visinger2.visinger2_vocoder.Generator_Noise.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – Input tensor (B, hidden_channels, T).</p></li>
<li><p><strong>mask</strong> (<em>Tensor</em>) – Mask tensor (B, 1, T).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Output tensor (B, 1, T * hop_size).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_svs.visinger2.visinger2_vocoder.LayerNorm">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_svs.visinger2.visinger2_vocoder.</code><code class="sig-name descname">LayerNorm</code><span class="sig-paren">(</span><em class="sig-param">channels</em>, <em class="sig-param">eps=1e-05</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/visinger2/visinger2_vocoder.html#LayerNorm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.visinger2.visinger2_vocoder.LayerNorm" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="method">
<dt id="espnet2.gan_svs.visinger2.visinger2_vocoder.LayerNorm.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/visinger2/visinger2_vocoder.html#LayerNorm.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.visinger2.visinger2_vocoder.LayerNorm.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</aside>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_svs.visinger2.visinger2_vocoder.MelScale">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_svs.visinger2.visinger2_vocoder.</code><code class="sig-name descname">MelScale</code><span class="sig-paren">(</span><em class="sig-param">n_mels: int = 128</em>, <em class="sig-param">sample_rate: int = 24000</em>, <em class="sig-param">f_min: float = 0.0</em>, <em class="sig-param">f_max: Optional[float] = None</em>, <em class="sig-param">n_stft: Optional[int] = None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/visinger2/visinger2_vocoder.html#MelScale"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.visinger2.visinger2_vocoder.MelScale" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Turn a normal STFT into a mel frequency STFT, using a conversion
matrix.  This uses triangular filter banks.
User can control which device the filter bank (fb) is (e.g. fb.to(spec_f.device)).
:param n_mels: Number of mel filterbanks. (Default: 128)
:type n_mels: int, optional
:param sample_rate: Sample rate of audio signal. (Default: 16000)
:type sample_rate: int, optional
:param f_min: Minimum frequency. (Default: 0.)
:type f_min: float, optional
:param f_max: Maximum frequency.</p>
<blockquote>
<div><p>(Default: sample_rate // 2)</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>n_stft</strong> (<em>int</em><em>, </em><em>optional</em>) – Number of bins in STFT. Calculated from first input
if None is given.  See n_fft in :class:Spectrogram.
(Default: None)</p>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_svs.visinger2.visinger2_vocoder.MelScale.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">specgram: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_svs/visinger2/visinger2_vocoder.html#MelScale.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.visinger2.visinger2_vocoder.MelScale.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>specgram</strong> (<em>Tensor</em>) – A spectrogram STFT of dimension (…, freq, time).</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Mel frequency spectrogram of size (…, n_mels, time).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_svs.visinger2.visinger2_vocoder.MultiFrequencyDiscriminator">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_svs.visinger2.visinger2_vocoder.</code><code class="sig-name descname">MultiFrequencyDiscriminator</code><span class="sig-paren">(</span><em class="sig-param">sample_rate: int = 22050, hop_lengths=[128, 256, 512], hidden_channels=[256, 512, 512], domain='double', mel_scale=True, divisors=[32, 16, 8, 4, 2, 1, 1], strides=[1, 2, 1, 2, 1, 2, 1]</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/visinger2/visinger2_vocoder.html#MultiFrequencyDiscriminator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.visinger2.visinger2_vocoder.MultiFrequencyDiscriminator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Multi-Frequency Discriminator module in UnivNet.</p>
<p>Initialize Multi-Frequency Discriminator module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hop_lengths</strong> (<em>list</em>) – List of hop lengths.</p></li>
<li><p><strong>hidden_channels</strong> (<em>list</em>) – List of number of channels in hidden layers.</p></li>
<li><p><strong>domain</strong> (<em>str</em>) – Domain of input signal. Default is “double”.</p></li>
<li><p><strong>mel_scale</strong> (<em>bool</em>) – Whether to use mel-scale frequency. Default is True.</p></li>
<li><p><strong>divisors</strong> (<em>list</em>) – List of divisors for each layer in the discriminator.
Default is [32, 16, 8, 4, 2, 1, 1].</p></li>
<li><p><strong>strides</strong> (<em>list</em>) – List of strides for each layer in the discriminator.
Default is [1, 2, 1, 2, 1, 2, 1].</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_svs.visinger2.visinger2_vocoder.MultiFrequencyDiscriminator.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/visinger2/visinger2_vocoder.html#MultiFrequencyDiscriminator.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.visinger2.visinger2_vocoder.MultiFrequencyDiscriminator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward pass of Multi-Frequency Discriminator module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>) – Input tensor (B, 1, T * hop_size).</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>List of feature maps.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>List[Tensor]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_svs.visinger2.visinger2_vocoder.TorchSTFT">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_svs.visinger2.visinger2_vocoder.</code><code class="sig-name descname">TorchSTFT</code><span class="sig-paren">(</span><em class="sig-param">sample_rate</em>, <em class="sig-param">fft_size</em>, <em class="sig-param">hop_size</em>, <em class="sig-param">win_size</em>, <em class="sig-param">normalized=False</em>, <em class="sig-param">domain='linear'</em>, <em class="sig-param">mel_scale=False</em>, <em class="sig-param">ref_level_db=20</em>, <em class="sig-param">min_level_db=-100</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/visinger2/visinger2_vocoder.html#TorchSTFT"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.visinger2.visinger2_vocoder.TorchSTFT" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="method">
<dt id="espnet2.gan_svs.visinger2.visinger2_vocoder.TorchSTFT.complex">
<code class="sig-name descname">complex</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/visinger2/visinger2_vocoder.html#TorchSTFT.complex"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.visinger2.visinger2_vocoder.TorchSTFT.complex" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="espnet2.gan_svs.visinger2.visinger2_vocoder.TorchSTFT.transform">
<code class="sig-name descname">transform</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/visinger2/visinger2_vocoder.html#TorchSTFT.transform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.visinger2.visinger2_vocoder.TorchSTFT.transform" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_svs.visinger2.visinger2_vocoder.VISinger2Discriminator">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_svs.visinger2.visinger2_vocoder.</code><code class="sig-name descname">VISinger2Discriminator</code><span class="sig-paren">(</span><em class="sig-param">scales: int = 1, scale_downsample_pooling: str = 'AvgPool1d', scale_downsample_pooling_params: Dict[str, Any] = {'kernel_size': 4, 'padding': 2, 'stride': 2}, scale_discriminator_params: Dict[str, Any] = {'bias': True, 'channels': 128, 'downsample_scales': [2, 2, 4, 4, 1], 'in_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'max_downsample_channels': 1024, 'max_groups': 16, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'out_channels': 1}, follow_official_norm: bool = True, periods: List[int] = [2, 3, 5, 7, 11], period_discriminator_params: Dict[str, Any] = {'bias': True, 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'in_channels': 1, 'kernel_sizes': [5, 3], 'max_downsample_channels': 1024, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'out_channels': 1, 'use_spectral_norm': False, 'use_weight_norm': True}, multi_freq_disc_params: Dict[str, Any] = {'divisors': [32, 16, 8, 4, 2, 1, 1], 'domain': 'double', 'hidden_channels': [256, 512, 512], 'hop_length_factors': [4, 8, 16], 'mel_scale': True, 'sample_rate': 22050, 'strides': [1, 2, 1, 2, 1, 2, 1]}</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/visinger2/visinger2_vocoder.html#VISinger2Discriminator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.visinger2.visinger2_vocoder.VISinger2Discriminator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Discriminator module for VISinger2, including MSD, MPD, and MFD.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>scales</strong> (<em>int</em>) – Number of scales to be used in the multi-scale discriminator.</p></li>
<li><p><strong>scale_downsample_pooling</strong> (<em>str</em>) – Type of pooling used for downsampling.</p></li>
<li><p><strong>scale_downsample_pooling_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Parameters for the
downsampling pooling
layer.</p></li>
<li><p><strong>scale_discriminator_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Parameters for the scale
discriminator.</p></li>
<li><p><strong>follow_official_norm</strong> (<em>bool</em>) – Whether to follow the official normalization.</p></li>
<li><p><strong>periods</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of periods to be used in the multi-period
discriminator.</p></li>
<li><p><strong>period_discriminator_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Parameters for the period
discriminator.</p></li>
<li><p><strong>multi_freq_disc_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Parameters for the
multi-frequency discriminator.</p></li>
<li><p><strong>use_spectral_norm</strong> (<em>bool</em>) – Whether to use spectral normalization or not.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_svs.visinger2.visinger2_vocoder.VISinger2Discriminator.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/visinger2/visinger2_vocoder.html#VISinger2Discriminator.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.visinger2.visinger2_vocoder.VISinger2Discriminator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</aside>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_svs.visinger2.visinger2_vocoder.VISinger2VocoderGenerator">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_svs.visinger2.visinger2_vocoder.</code><code class="sig-name descname">VISinger2VocoderGenerator</code><span class="sig-paren">(</span><em class="sig-param">in_channels: int = 80, out_channels: int = 1, channels: int = 512, global_channels: int = -1, kernel_size: int = 7, upsample_scales: List[int] = [8, 8, 2, 2], upsample_kernel_sizes: List[int] = [16, 16, 4, 4], resblock_kernel_sizes: List[int] = [3, 7, 11], resblock_dilations: List[List[int]] = [[1, 3, 5], [1, 3, 5], [1, 3, 5]], n_harmonic: int = 64, use_additional_convs: bool = True, bias: bool = True, nonlinear_activation: str = 'LeakyReLU', nonlinear_activation_params: Dict[str, Any] = {'negative_slope': 0.1}, use_weight_norm: bool = True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/visinger2/visinger2_vocoder.html#VISinger2VocoderGenerator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.visinger2.visinger2_vocoder.VISinger2VocoderGenerator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Initialize HiFiGANGenerator module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<em>int</em>) – Number of input channels.</p></li>
<li><p><strong>out_channels</strong> (<em>int</em>) – Number of output channels.</p></li>
<li><p><strong>channels</strong> (<em>int</em>) – Number of hidden representation channels.</p></li>
<li><p><strong>global_channels</strong> (<em>int</em>) – Number of global conditioning channels.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – Kernel size of initial and final conv layer.</p></li>
<li><p><strong>upsample_scales</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of upsampling scales.</p></li>
<li><p><strong>upsample_kernel_sizes</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of kernel sizes for upsample layers.</p></li>
<li><p><strong>resblock_kernel_sizes</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of kernel sizes for residual blocks.</p></li>
<li><p><strong>resblock_dilations</strong> (<em>List</em><em>[</em><em>List</em><em>[</em><em>int</em><em>]</em><em>]</em>) – List of list of dilations for residual
blocks.</p></li>
<li><p><strong>n_harmonic</strong> (<em>int</em>) – Number of harmonics used to synthesize a sound signal.</p></li>
<li><p><strong>use_additional_convs</strong> (<em>bool</em>) – Whether to use additional conv layers in
residual blocks.</p></li>
<li><p><strong>bias</strong> (<em>bool</em>) – Whether to add bias parameter in convolution layers.</p></li>
<li><p><strong>nonlinear_activation</strong> (<em>str</em>) – Activation function module name.</p></li>
<li><p><strong>nonlinear_activation_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Hyperparameters for activation
function.</p></li>
<li><p><strong>use_weight_norm</strong> (<em>bool</em>) – Whether to use weight norm. If set to true, it will
be applied to all of the conv layers.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_svs.visinger2.visinger2_vocoder.VISinger2VocoderGenerator.apply_weight_norm">
<code class="sig-name descname">apply_weight_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/visinger2/visinger2_vocoder.html#VISinger2VocoderGenerator.apply_weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.visinger2.visinger2_vocoder.VISinger2VocoderGenerator.apply_weight_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply weight normalization module from all of the layers.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_svs.visinger2.visinger2_vocoder.VISinger2VocoderGenerator.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">c</em>, <em class="sig-param">ddsp</em>, <em class="sig-param">g: Optional[torch.Tensor] = None</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_svs/visinger2/visinger2_vocoder.html#VISinger2VocoderGenerator.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.visinger2.visinger2_vocoder.VISinger2VocoderGenerator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>c</strong> (<em>Tensor</em>) – Input tensor (B, in_channels, T).</p></li>
<li><p><strong>ddsp</strong> (<em>Tensor</em>) – Input tensor (B, n_harmonic + 2, T * hop_length).</p></li>
<li><p><strong>g</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Global conditioning tensor (B, global_channels, 1).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Output tensor (B, out_channels, T).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_svs.visinger2.visinger2_vocoder.VISinger2VocoderGenerator.remove_weight_norm">
<code class="sig-name descname">remove_weight_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/visinger2/visinger2_vocoder.html#VISinger2VocoderGenerator.remove_weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.visinger2.visinger2_vocoder.VISinger2VocoderGenerator.remove_weight_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Remove weight normalization module from all of the layers.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_svs.visinger2.visinger2_vocoder.VISinger2VocoderGenerator.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/visinger2/visinger2_vocoder.html#VISinger2VocoderGenerator.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.visinger2.visinger2_vocoder.VISinger2VocoderGenerator.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Reset parameters.</p>
<p>This initialization follows the official implementation manner.
<a class="reference external" href="https://github.com/jik876/hifi-gan/blob/master/models.py">https://github.com/jik876/hifi-gan/blob/master/models.py</a></p>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="espnet2.gan_svs.visinger2.visinger2_vocoder.create_fb_matrix">
<code class="sig-prename descclassname">espnet2.gan_svs.visinger2.visinger2_vocoder.</code><code class="sig-name descname">create_fb_matrix</code><span class="sig-paren">(</span><em class="sig-param">n_freqs: int</em>, <em class="sig-param">f_min: float</em>, <em class="sig-param">f_max: float</em>, <em class="sig-param">n_mels: int</em>, <em class="sig-param">sample_rate: int</em>, <em class="sig-param">norm: Optional[str] = None</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_svs/visinger2/visinger2_vocoder.html#create_fb_matrix"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.visinger2.visinger2_vocoder.create_fb_matrix" title="Permalink to this definition">¶</a></dt>
<dd><p>Create a frequency bin conversion matrix.
:param n_freqs: Number of frequencies to highlight/apply
:type n_freqs: int
:param f_min: Minimum frequency (Hz)
:type f_min: float
:param f_max: Maximum frequency (Hz)
:type f_max: float
:param n_mels: Number of mel filterbanks
:type n_mels: int
:param sample_rate: Sample rate of the audio waveform
:type sample_rate: int
:param norm: If ‘slaney’,
:type norm: Optional[str]
:param divide the triangular mel weights by the width of the mel band:
:param (area normalization). (Default: None)</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Triangular filter banks (fb matrix) of size (n_freqs, n_mels)
meaning number of frequencies to highlight/apply to x the number of filterbanks.
Each column is a filterbank so that assuming there is a matrix A of
size (…, n_freqs), the applied result would be
A * create_fb_matrix(A.size(-1), …).</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="espnet2-gan-svs-joint-init-1">
<span id="espnet2-gan-svs-joint-init"></span><h2>espnet2.gan_svs.joint.__init__<a class="headerlink" href="#espnet2-gan-svs-joint-init-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_svs.joint.__init__"></span></section>
<section id="espnet2-gan-svs-joint-joint-score2wav-1">
<span id="espnet2-gan-svs-joint-joint-score2wav"></span><h2>espnet2.gan_svs.joint.joint_score2wav<a class="headerlink" href="#espnet2-gan-svs-joint-joint-score2wav-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_svs.joint.joint_score2wav"></span><p>Joint text-to-wav module for end-to-end training.</p>
<dl class="class">
<dt id="espnet2.gan_svs.joint.joint_score2wav.JointScore2Wav">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_svs.joint.joint_score2wav.</code><code class="sig-name descname">JointScore2Wav</code><span class="sig-paren">(</span><em class="sig-param">idim: int, odim: int, segment_size: int = 32, sampling_rate: int = 22050, score2mel_type: str = 'xiaoice', score2mel_params: Dict[str, Any] = {'adim': 384, 'aheads': 4, 'conformer_activation_type': 'swish', 'conformer_dec_kernel_size': 31, 'conformer_enc_kernel_size': 7, 'conformer_pos_enc_layer_type': 'rel_pos', 'conformer_rel_pos_type': 'latest', 'conformer_self_attn_layer_type': 'rel_selfattn', 'decoder_concat_after': False, 'decoder_normalize_before': True, 'decoder_type': 'transformer', 'dlayers': 6, 'dunits': 1536, 'duration_predictor_chans': 384, 'duration_predictor_dropout_rate': 0.1, 'duration_predictor_kernel_size': 3, 'duration_predictor_layers': 2, 'elayers': 6, 'embed_dim': 512, 'encoder_concat_after': False, 'encoder_normalize_before': True, 'encoder_type': 'transformer', 'eunits': 1536, 'init_dec_alpha': 1.0, 'init_enc_alpha': 1.0, 'init_type': 'xavier_uniform', 'langs': None, 'loss_type': 'L1', 'midi_dim': 129, 'positionwise_conv_kernel_size': 1, 'positionwise_layer_type': 'conv1d', 'postnet_chans': 512, 'postnet_dropout_rate': 0.5, 'postnet_filts': 5, 'postnet_layers': 5, 'reduction_factor': 1, 'spk_embed_dim': None, 'spk_embed_integration_type': 'add', 'spks': None, 'tempo_dim': 500, 'transformer_dec_attn_dropout_rate': 0.1, 'transformer_dec_dropout_rate': 0.1, 'transformer_dec_positional_dropout_rate': 0.1, 'transformer_enc_attn_dropout_rate': 0.1, 'transformer_enc_dropout_rate': 0.1, 'transformer_enc_positional_dropout_rate': 0.1, 'use_batch_norm': True, 'use_cnn_in_conformer': True, 'use_macaron_style_in_conformer': True, 'use_masking': False, 'use_scaled_pos_enc': True, 'use_weighted_masking': False, 'zero_triu': False}, vocoder_type: str = 'hifigan_generator', vocoder_params: Dict[str, Any] = {'bias': True, 'channels': 512, 'global_channels': -1, 'kernel_size': 7, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'out_channels': 1, 'resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'resblock_kernel_sizes': [3, 7, 11], 'upsample_kernel_sizes': [16, 16, 4, 4], 'upsample_scales': [8, 8, 2, 2], 'use_additional_convs': True, 'use_weight_norm': True}, use_pqmf: bool = False, pqmf_params: Dict[str, Any] = {'beta': 9.0, 'cutoff_ratio': 0.142, 'subbands': 4, 'taps': 62}, discriminator_type: str = 'hifigan_multi_scale_multi_period_discriminator', discriminator_params: Dict[str, Any] = {'follow_official_norm': False, 'period_discriminator_params': {'bias': True, 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'in_channels': 1, 'kernel_sizes': [5, 3], 'max_downsample_channels': 1024, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'out_channels': 1, 'use_spectral_norm': False, 'use_weight_norm': True}, 'periods': [2, 3, 5, 7, 11], 'scale_discriminator_params': {'bias': True, 'channels': 128, 'downsample_scales': [2, 2, 4, 4, 1], 'in_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'max_downsample_channels': 1024, 'max_groups': 16, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'out_channels': 1, 'use_spectral_norm': False, 'use_weight_norm': True}, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'padding': 2, 'stride': 2}, 'scales': 1}, generator_adv_loss_params: Dict[str, Any] = {'average_by_discriminators': False, 'loss_type': 'mse'}, discriminator_adv_loss_params: Dict[str, Any] = {'average_by_discriminators': False, 'loss_type': 'mse'}, use_feat_match_loss: bool = True, feat_match_loss_params: Dict[str, Any] = {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, use_mel_loss: bool = True, mel_loss_params: Dict[str, Any] = {'fmax': None, 'fmin': 0, 'fs': 22050, 'hop_length': 256, 'log_base': None, 'n_fft': 1024, 'n_mels': 80, 'win_length': None, 'window': 'hann'}, lambda_score2mel: float = 1.0, lambda_adv: float = 1.0, lambda_feat_match: float = 2.0, lambda_mel: float = 45.0, cache_generator_outputs: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_svs/joint/joint_score2wav.html#JointScore2Wav"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.joint.joint_score2wav.JointScore2Wav" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.gan_svs.abs_gan_svs.AbsGANSVS" title="espnet2.gan_svs.abs_gan_svs.AbsGANSVS"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.gan_svs.abs_gan_svs.AbsGANSVS</span></code></a></p>
<p>General class to jointly train score2mel and vocoder parts.</p>
<p>Initialize JointScore2Wav module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> (<em>int</em>) – Input vocabrary size.</p></li>
<li><p><strong>odim</strong> (<em>int</em>) – Acoustic feature dimension. The actual output channels will
be 1 since the model is the end-to-end text-to-wave model but for the
compatibility odim is used to indicate the acoustic feature dimension.</p></li>
<li><p><strong>segment_size</strong> (<em>int</em>) – Segment size for random windowed inputs.</p></li>
<li><p><strong>sampling_rate</strong> (<em>int</em>) – Sampling rate, not used for the training but it will
be referred in saving waveform during the inference.</p></li>
<li><p><strong>text2mel_type</strong> (<em>str</em>) – The text2mel model type.</p></li>
<li><p><strong>text2mel_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Parameter dict for text2mel model.</p></li>
<li><p><strong>use_pqmf</strong> (<em>bool</em>) – Whether to use PQMF for multi-band vocoder.</p></li>
<li><p><strong>pqmf_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Parameter dict for PQMF module.</p></li>
<li><p><strong>vocoder_type</strong> (<em>str</em>) – The vocoder model type.</p></li>
<li><p><strong>vocoder_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Parameter dict for vocoder model.</p></li>
<li><p><strong>discriminator_type</strong> (<em>str</em>) – Discriminator type.</p></li>
<li><p><strong>discriminator_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Parameter dict for discriminator.</p></li>
<li><p><strong>generator_adv_loss_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Parameter dict for generator
adversarial loss.</p></li>
<li><p><strong>discriminator_adv_loss_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Parameter dict for
discriminator adversarial loss.</p></li>
<li><p><strong>use_feat_match_loss</strong> (<em>bool</em>) – Whether to use feat match loss.</p></li>
<li><p><strong>feat_match_loss_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Parameter dict for feat match loss.</p></li>
<li><p><strong>use_mel_loss</strong> (<em>bool</em>) – Whether to use mel loss.</p></li>
<li><p><strong>mel_loss_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Parameter dict for mel loss.</p></li>
<li><p><strong>lambda_text2mel</strong> (<em>float</em>) – Loss scaling coefficient for text2mel model loss.</p></li>
<li><p><strong>lambda_adv</strong> (<em>float</em>) – Loss scaling coefficient for adversarial loss.</p></li>
<li><p><strong>lambda_feat_match</strong> (<em>float</em>) – Loss scaling coefficient for feat match loss.</p></li>
<li><p><strong>lambda_mel</strong> (<em>float</em>) – Loss scaling coefficient for mel loss.</p></li>
<li><p><strong>cache_generator_outputs</strong> (<em>bool</em>) – Whether to cache generator outputs.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_svs.joint.joint_score2wav.JointScore2Wav.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">text: torch.Tensor</em>, <em class="sig-param">text_lengths: torch.Tensor</em>, <em class="sig-param">feats: torch.Tensor</em>, <em class="sig-param">feats_lengths: torch.Tensor</em>, <em class="sig-param">singing: torch.Tensor</em>, <em class="sig-param">singing_lengths: torch.Tensor</em>, <em class="sig-param">label: Optional[Dict[str</em>, <em class="sig-param">torch.Tensor]] = None</em>, <em class="sig-param">label_lengths: Optional[Dict[str</em>, <em class="sig-param">torch.Tensor]] = None</em>, <em class="sig-param">melody: Optional[Dict[str</em>, <em class="sig-param">torch.Tensor]] = None</em>, <em class="sig-param">melody_lengths: Optional[Dict[str</em>, <em class="sig-param">torch.Tensor]] = None</em>, <em class="sig-param">pitch: torch.LongTensor = None</em>, <em class="sig-param">pitch_lengths: torch.Tensor = None</em>, <em class="sig-param">duration: Optional[Dict[str</em>, <em class="sig-param">torch.Tensor]] = None</em>, <em class="sig-param">duration_lengths: Optional[Dict[str</em>, <em class="sig-param">torch.Tensor]] = None</em>, <em class="sig-param">spembs: Optional[torch.Tensor] = None</em>, <em class="sig-param">sids: Optional[torch.Tensor] = None</em>, <em class="sig-param">lids: Optional[torch.Tensor] = None</em>, <em class="sig-param">forward_generator: bool = True</em><span class="sig-paren">)</span> &#x2192; Dict[str, Any]<a class="reference internal" href="../_modules/espnet2/gan_svs/joint/joint_score2wav.html#JointScore2Wav.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.joint.joint_score2wav.JointScore2Wav.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform generator forward.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>LongTensor</em>) – Batch of padded character ids (B, Tmax).</p></li>
<li><p><strong>text_lengths</strong> (<em>LongTensor</em>) – Batch of lengths of each input batch (B,).</p></li>
<li><p><strong>feats</strong> (<em>Tensor</em>) – Batch of padded target features (B, Lmax, odim).</p></li>
<li><p><strong>feats_lengths</strong> (<em>LongTensor</em>) – Batch of the lengths of each target (B,).</p></li>
<li><p><strong>singing</strong> (<em>Tensor</em>) – Singing waveform tensor (B, T_wav).</p></li>
<li><p><strong>singing_lengths</strong> (<em>Tensor</em>) – Singing length tensor (B,).</p></li>
<li><p><strong>label</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>]</em>) – key is “lab” or “score”;
value (LongTensor): Batch of padded label ids (B, Tmax).</p></li>
<li><p><strong>label_lengths</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>]</em>) – key is “lab” or “score”;
value (LongTensor): Batch of the lengths of padded label ids (B, ).</p></li>
<li><p><strong>melody</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>]</em>) – key is “lab” or “score”;
value (LongTensor): Batch of padded melody (B, Tmax).</p></li>
<li><p><strong>melody_lengths</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>]</em>) – key is “lab” or “score”;
value (LongTensor): Batch of the lengths of padded melody (B, ).</p></li>
<li><p><strong>pitch</strong> (<em>FloatTensor</em>) – Batch of padded f0 (B, Tmax).</p></li>
<li><p><strong>pitch_lengths</strong> (<em>LongTensor</em>) – Batch of the lengths of padded f0 (B, ).</p></li>
<li><p><strong>duration</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>]</em>) – key is “lab”, “score_phn” or “score_syb”;
value (LongTensor): Batch of padded duration (B, Tmax).</p></li>
<li><p><strong>duration_length</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>]</em>) – key is “lab”, “score_phn” or “score_syb”;
value (LongTensor): Batch of the lengths of padded duration (B, ).</p></li>
<li><p><strong>slur</strong> (<em>FloatTensor</em>) – Batch of padded slur (B, Tmax).</p></li>
<li><p><strong>slur_lengths</strong> (<em>LongTensor</em>) – Batch of the lengths of padded slur (B, ).</p></li>
<li><p><strong>spembs</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Batch of speaker embeddings (B, spk_embed_dim).</p></li>
<li><p><strong>sids</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Batch of speaker IDs (B, 1).</p></li>
<li><p><strong>lids</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Batch of language IDs (B, 1).</p></li>
<li><p><strong>forward_generator</strong> (<em>bool</em>) – Whether to forward generator.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p>loss (Tensor): Loss scalar tensor.</p></li>
<li><p>stats (Dict[str, float]): Statistics to be monitored.</p></li>
<li><p>weight (Tensor): Weight tensor to summarize losses.</p></li>
<li><p>optim_idx (int): Optimizer index (0 for G and 1 for D).</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Dict[str, Any]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_svs.joint.joint_score2wav.JointScore2Wav.inference">
<code class="sig-name descname">inference</code><span class="sig-paren">(</span><em class="sig-param">text: torch.Tensor</em>, <em class="sig-param">feats: Optional[torch.Tensor] = None</em>, <em class="sig-param">label: Optional[Dict[str</em>, <em class="sig-param">torch.Tensor]] = None</em>, <em class="sig-param">melody: Optional[Dict[str</em>, <em class="sig-param">torch.Tensor]] = None</em>, <em class="sig-param">pitch: Optional[torch.Tensor] = None</em>, <em class="sig-param">duration: Optional[Dict[str</em>, <em class="sig-param">torch.Tensor]] = None</em>, <em class="sig-param">slur: Optional[Dict[str</em>, <em class="sig-param">torch.Tensor]] = None</em>, <em class="sig-param">spembs: Optional[torch.Tensor] = None</em>, <em class="sig-param">sids: Optional[torch.Tensor] = None</em>, <em class="sig-param">lids: Optional[torch.Tensor] = None</em>, <em class="sig-param">noise_scale: float = 0.667</em>, <em class="sig-param">noise_scale_dur: float = 0.8</em>, <em class="sig-param">alpha: float = 1.0</em>, <em class="sig-param">max_len: Optional[int] = None</em>, <em class="sig-param">use_teacher_forcing: bool = False</em><span class="sig-paren">)</span> &#x2192; Dict[str, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/gan_svs/joint/joint_score2wav.html#JointScore2Wav.inference"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_svs.joint.joint_score2wav.JointScore2Wav.inference" title="Permalink to this definition">¶</a></dt>
<dd><p>Run inference.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>Tensor</em>) – Input text index tensor (T_text,).</p></li>
<li><p><strong>feats</strong> (<em>Tensor</em>) – Feature tensor (T_feats, aux_channels).</p></li>
<li><p><strong>label</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>]</em>) – key is “lab” or “score”;
value (LongTensor): Batch of padded label ids (B, Tmax).</p></li>
<li><p><strong>melody</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>]</em>) – key is “lab” or “score”;
value (LongTensor): Batch of padded melody (B, Tmax).</p></li>
<li><p><strong>tempo</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>]</em>) – key is “lab” or “score”;
value (LongTensor): Batch of padded tempo (B, Tmax).</p></li>
<li><p><strong>beat</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>]</em>) – key is “lab”, “score_phn” or “score_syb”;
value (LongTensor): Batch of padded beat (B, Tmax).</p></li>
<li><p><strong>pitch</strong> (<em>FloatTensor</em>) – Batch of padded f0 (B, Tmax).</p></li>
<li><p><strong>duration</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>]</em>) – key is “phn”, “syb”;
value (LongTensor): Batch of padded beat (B, Tmax).</p></li>
<li><p><strong>slur</strong> (<em>LongTensor</em>) – Batch of padded slur (B, Tmax).</p></li>
<li><p><strong>sids</strong> (<em>Tensor</em>) – Speaker index tensor (1,).</p></li>
<li><p><strong>spembs</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Speaker embedding tensor (spk_embed_dim,).</p></li>
<li><p><strong>lids</strong> (<em>Tensor</em>) – Language index tensor (1,).</p></li>
<li><p><strong>noise_scale</strong> (<em>float</em>) – Noise scale value for flow.</p></li>
<li><p><strong>noise_scale_dur</strong> (<em>float</em>) – Noise scale value for duration predictor.</p></li>
<li><p><strong>alpha</strong> (<em>float</em>) – Alpha parameter to control the speed of generated singing.</p></li>
<li><p><strong>max_len</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – Maximum length.</p></li>
<li><p><strong>use_teacher_forcing</strong> (<em>bool</em>) – Whether to use teacher forcing.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p>wav (Tensor): Generated waveform tensor (T_wav,).</p></li>
<li><p>feat_gan (Tensor): Generated feature tensor (T_text, C).</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Dict[str, Tensor]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_svs.joint.joint_score2wav.JointScore2Wav.require_raw_singing">
<em class="property">property </em><code class="sig-name descname">require_raw_singing</code><a class="headerlink" href="#espnet2.gan_svs.joint.joint_score2wav.JointScore2Wav.require_raw_singing" title="Permalink to this definition">¶</a></dt>
<dd><p>Return whether or not singing is required.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_svs.joint.joint_score2wav.JointScore2Wav.require_vocoder">
<em class="property">property </em><code class="sig-name descname">require_vocoder</code><a class="headerlink" href="#espnet2.gan_svs.joint.joint_score2wav.JointScore2Wav.require_vocoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Return whether or not vocoder is required.</p>
</dd></dl>

</dd></dl>

</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="espnet2.spk.html" class="btn btn-neutral float-left" title="espnet2.spk package" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="espnet2.asr_transducer.html" class="btn btn-neutral float-right" title="espnet2.asr_transducer package" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2017, Shinji Watanabe.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>