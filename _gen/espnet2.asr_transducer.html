<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>espnet2.asr_transducer package &mdash; ESPnet 202211 documentation</title><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/language_data.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "tex2jax_ignore|mathjax_ignore|document", "processClass": "tex2jax_process|mathjax_process|math|output_area"}})</script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="core tools" href="../apis/espnet_bin.html" />
    <link rel="prev" title="espnet2.enh package" href="espnet2.enh.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> ESPnet
          </a>
              <div class="version">
                202211
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p><span class="caption-text">Tutorial:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorial.html">Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallelization.html">Using Job scheduling system</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">FAQ</a></li>
<li class="toctree-l1"><a class="reference internal" href="../docker.html">Docker</a></li>
</ul>
<p><span class="caption-text">ESPnet2:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../espnet2_tutorial.html">ESPnet2</a></li>
<li class="toctree-l1"><a class="reference internal" href="../espnet2_tutorial.html#instruction-for-run-sh">Instruction for run.sh</a></li>
<li class="toctree-l1"><a class="reference internal" href="../espnet2_training_option.html">Change the configuration for training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../espnet2_task.html">Task class and data input system for training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../espnet2_distributed.html">Distributed training</a></li>
</ul>
<p><span class="caption-text">Notebook:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../notebook/asr_cli.html">Speech Recognition (Recipe)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/asr_library.html">Speech Recognition (Library)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_2pass_slu_demo.html">ESPNET 2 pass SLU Demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_asr_realtime_demo.html">ESPnet2-ASR realtime demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_asr_transfer_learning_demo.html"><strong>Use transfer learning for ASR in ESPnet2</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_asr_transfer_learning_demo.html#Abstract">Abstract</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_asr_transfer_learning_demo.html#ESPnet-installation-(about-10-minutes-in-total)">ESPnet installation (about 10 minutes in total)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_asr_transfer_learning_demo.html#mini_an4-recipe-as-a-transfer-learning-example">mini_an4 recipe as a transfer learning example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_new_task_tutorial_CMU_11751_18781_Fall2022.html">CMU 11751/18781 Fall 2022: ESPnet Tutorial2 (New task)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_new_task_tutorial_CMU_11751_18781_Fall2022.html#Install-ESPnet-(Almost-same-procedure-as-your-first-tutorial)">Install ESPnet (Almost same procedure as your first tutorial)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_new_task_tutorial_CMU_11751_18781_Fall2022.html#What-we-provide-you-and-what-you-need-to-proceed">What we provide you and what you need to proceed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_recipe_tutorial_CMU_11751_18781_Fall2022.html">CMU 11751/18781 Fall 2022: ESPnet Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_recipe_tutorial_CMU_11751_18781_Fall2022.html#Install-ESPnet">Install ESPnet</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_recipe_tutorial_CMU_11751_18781_Fall2022.html#Run-an-existing-recipe">Run an existing recipe</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_recipe_tutorial_CMU_11751_18781_Fall2022.html#Make-a-new-recipe">Make a new recipe</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_recipe_tutorial_CMU_11751_18781_Fall2022.html#Additional-resources">Additional resources</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_streaming_asr_demo.html">ESPnet2 real streaming Transformer demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_tts_realtime_demo.html">ESPnet2-TTS realtime demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_tutorial_2021_CMU_11751_18781.html">CMU 11751/18781 2021: ESPnet Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_tutorial_2021_CMU_11751_18781.html#Run-an-inference-example">Run an inference example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_tutorial_2021_CMU_11751_18781.html#Full-installation">Full installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_tutorial_2021_CMU_11751_18781.html#Run-a-recipe-example">Run a recipe example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet_se_demonstration_for_waspaa_2021.html">ESPnet Speech Enhancement Demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet_se_demonstration_for_waspaa_2021.html#Contents">Contents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet_se_demonstration_for_waspaa_2021.html#(1)-Tutorials-on-the-Basic-Usage">(1) Tutorials on the Basic Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet_se_demonstration_for_waspaa_2021.html#(2)-Tutorials-on-Contributing-to-ESPNet-SE-Project">(2) Tutorials on Contributing to ESPNet-SE Project</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/onnx_conversion_demo.html">espnet_onnx demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/onnx_conversion_demo.html#Install-Dependency">Install Dependency</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/onnx_conversion_demo.html#Export-your-model">Export your model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/onnx_conversion_demo.html#Inference-with-onnx">Inference with onnx</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/onnx_conversion_demo.html#Using-streaming-model">Using streaming model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/pretrained.html">Pretrained Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/se_demo.html">ESPnet Speech Enhancement Demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/st_demo.html">ESPnet Speech Translation Demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/tts_cli.html">Text-to-Speech (Recipe)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/tts_realtime_demo.html">ESPnet real time E2E-TTS demonstration</a></li>
</ul>
<p><span class="caption-text">Package Reference:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="espnet.asr.html">espnet.asr package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.scheduler.html">espnet.scheduler package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.optimizer.html">espnet.optimizer package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.transform.html">espnet.transform package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.tts.html">espnet.tts package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.utils.html">espnet.utils package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.lm.html">espnet.lm package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.vc.html">espnet.vc package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.bin.html">espnet.bin package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.st.html">espnet.st package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.mt.html">espnet.mt package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.distributed.html">espnet.distributed package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.nets.html">espnet.nets package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.asr.html">espnet2.asr package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.torch_utils.html">espnet2.torch_utils package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.main_funcs.html">espnet2.main_funcs package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.diar.html">espnet2.diar package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.tts.html">espnet2.tts package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.fileio.html">espnet2.fileio package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.hubert.html">espnet2.hubert package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.train.html">espnet2.train package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.text.html">espnet2.text package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.fst.html">espnet2.fst package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.optimizers.html">espnet2.optimizers package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.tasks.html">espnet2.tasks package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.iterators.html">espnet2.iterators package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.slu.html">espnet2.slu package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.schedulers.html">espnet2.schedulers package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.utils.html">espnet2.utils package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.uasr.html">espnet2.uasr package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.lm.html">espnet2.lm package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.layers.html">espnet2.layers package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.gan_svs.html">espnet2.gan_svs package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.bin.html">espnet2.bin package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.samplers.html">espnet2.samplers package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.st.html">espnet2.st package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.mt.html">espnet2.mt package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.gan_tts.html">espnet2.gan_tts package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.svs.html">espnet2.svs package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.enh.html">espnet2.enh package</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">espnet2.asr_transducer package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-beam-search-transducer">espnet2.asr_transducer.beam_search_transducer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-activation">espnet2.asr_transducer.activation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-error-calculator">espnet2.asr_transducer.error_calculator</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-utils">espnet2.asr_transducer.utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-init">espnet2.asr_transducer.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-joint-network">espnet2.asr_transducer.joint_network</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-espnet-transducer-model">espnet2.asr_transducer.espnet_transducer_model</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-encoder-validation">espnet2.asr_transducer.encoder.validation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-encoder-building">espnet2.asr_transducer.encoder.building</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-encoder-init">espnet2.asr_transducer.encoder.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-encoder-encoder">espnet2.asr_transducer.encoder.encoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-encoder-modules-multi-blocks">espnet2.asr_transducer.encoder.modules.multi_blocks</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-encoder-modules-attention">espnet2.asr_transducer.encoder.modules.attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-encoder-modules-positional-encoding">espnet2.asr_transducer.encoder.modules.positional_encoding</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-encoder-modules-normalization">espnet2.asr_transducer.encoder.modules.normalization</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-encoder-modules-convolution">espnet2.asr_transducer.encoder.modules.convolution</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-encoder-modules-init">espnet2.asr_transducer.encoder.modules.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-encoder-blocks-conv-input">espnet2.asr_transducer.encoder.blocks.conv_input</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-encoder-blocks-branchformer">espnet2.asr_transducer.encoder.blocks.branchformer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-encoder-blocks-conformer">espnet2.asr_transducer.encoder.blocks.conformer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-encoder-blocks-init">espnet2.asr_transducer.encoder.blocks.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-encoder-blocks-conv1d">espnet2.asr_transducer.encoder.blocks.conv1d</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-decoder-rnn-decoder">espnet2.asr_transducer.decoder.rnn_decoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-decoder-stateless-decoder">espnet2.asr_transducer.decoder.stateless_decoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-decoder-init">espnet2.asr_transducer.decoder.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-decoder-abs-decoder">espnet2.asr_transducer.decoder.abs_decoder</a></li>
</ul>
</li>
</ul>
<p><span class="caption-text">Tool Reference:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../apis/espnet_bin.html">core tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../apis/espnet2_bin.html">core tools (espnet2)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../apis/utils_py.html">python utility tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../apis/utils_sh.html">bash utility tools</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">ESPnet</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a></li>
      <li class="breadcrumb-item active">espnet2.asr_transducer package</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/_gen/espnet2.asr_transducer.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="espnet2-asr-transducer-package">
<h1>espnet2.asr_transducer package<a class="headerlink" href="#espnet2-asr-transducer-package" title="Permalink to this headline">¶</a></h1>
<section id="espnet2-asr-transducer-beam-search-transducer">
<span id="id1"></span><h2>espnet2.asr_transducer.beam_search_transducer<a class="headerlink" href="#espnet2-asr-transducer-beam-search-transducer" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.beam_search_transducer"></span><p>Search algorithms for Transducer models.</p>
<dl class="class">
<dt id="espnet2.asr_transducer.beam_search_transducer.BeamSearchTransducer">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr_transducer.beam_search_transducer.</code><code class="sig-name descname">BeamSearchTransducer</code><span class="sig-paren">(</span><em class="sig-param">decoder: espnet2.asr_transducer.decoder.abs_decoder.AbsDecoder</em>, <em class="sig-param">joint_network: espnet2.asr_transducer.joint_network.JointNetwork</em>, <em class="sig-param">beam_size: int</em>, <em class="sig-param">lm: Optional[torch.nn.modules.module.Module] = None</em>, <em class="sig-param">lm_weight: float = 0.1</em>, <em class="sig-param">search_type: str = 'default'</em>, <em class="sig-param">max_sym_exp: int = 3</em>, <em class="sig-param">u_max: int = 50</em>, <em class="sig-param">nstep: int = 2</em>, <em class="sig-param">expansion_gamma: float = 2.3</em>, <em class="sig-param">expansion_beta: int = 2</em>, <em class="sig-param">score_norm: bool = False</em>, <em class="sig-param">nbest: int = 1</em>, <em class="sig-param">streaming: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr_transducer/beam_search_transducer.html#BeamSearchTransducer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.beam_search_transducer.BeamSearchTransducer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Beam search implementation for Transducer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>decoder</strong> – Decoder module.</p></li>
<li><p><strong>joint_network</strong> – Joint network module.</p></li>
<li><p><strong>beam_size</strong> – Size of the beam.</p></li>
<li><p><strong>lm</strong> – LM class.</p></li>
<li><p><strong>lm_weight</strong> – LM weight for soft fusion.</p></li>
<li><p><strong>search_type</strong> – Search algorithm to use during inference.</p></li>
<li><p><strong>max_sym_exp</strong> – Number of maximum symbol expansions at each time step. (TSD)</p></li>
<li><p><strong>u_max</strong> – Maximum expected target sequence length. (ALSD)</p></li>
<li><p><strong>nstep</strong> – Number of maximum expansion steps at each time step. (mAES)</p></li>
<li><p><strong>expansion_gamma</strong> – Allowed logp difference for prune-by-value method. (mAES)</p></li>
<li><p><strong>expansion_beta</strong> – Number of additional candidates for expanded hypotheses selection. (mAES)</p></li>
<li><p><strong>score_norm</strong> – Normalize final scores by length.</p></li>
<li><p><strong>nbest</strong> – Number of final hypothesis.</p></li>
<li><p><strong>streaming</strong> – Whether to perform chunk-by-chunk beam search.</p></li>
</ul>
</dd>
</dl>
<p>Construct a BeamSearchTransducer object.</p>
<dl class="method">
<dt id="espnet2.asr_transducer.beam_search_transducer.BeamSearchTransducer.align_length_sync_decoding">
<code class="sig-name descname">align_length_sync_decoding</code><span class="sig-paren">(</span><em class="sig-param">enc_out: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; List[espnet2.asr_transducer.beam_search_transducer.Hypothesis]<a class="reference internal" href="../_modules/espnet2/asr_transducer/beam_search_transducer.html#BeamSearchTransducer.align_length_sync_decoding"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.beam_search_transducer.BeamSearchTransducer.align_length_sync_decoding" title="Permalink to this definition">¶</a></dt>
<dd><p>Alignment-length synchronous beam search implementation.</p>
<p>Based on <a class="reference external" href="https://ieeexplore.ieee.org/document/9053040">https://ieeexplore.ieee.org/document/9053040</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>h</strong> – Encoder output sequences. (T, D)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>N-best hypothesis.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>nbest_hyps</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.beam_search_transducer.BeamSearchTransducer.create_lm_batch_inputs">
<code class="sig-name descname">create_lm_batch_inputs</code><span class="sig-paren">(</span><em class="sig-param">hyps_seq: List[List[int]]</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr_transducer/beam_search_transducer.html#BeamSearchTransducer.create_lm_batch_inputs"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.beam_search_transducer.BeamSearchTransducer.create_lm_batch_inputs" title="Permalink to this definition">¶</a></dt>
<dd><p>Make batch of inputs with left padding for LM scoring.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>hyps_seq</strong> – Hypothesis sequences.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Padded batch of sequences.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.beam_search_transducer.BeamSearchTransducer.default_beam_search">
<code class="sig-name descname">default_beam_search</code><span class="sig-paren">(</span><em class="sig-param">enc_out: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; List[espnet2.asr_transducer.beam_search_transducer.Hypothesis]<a class="reference internal" href="../_modules/espnet2/asr_transducer/beam_search_transducer.html#BeamSearchTransducer.default_beam_search"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.beam_search_transducer.BeamSearchTransducer.default_beam_search" title="Permalink to this definition">¶</a></dt>
<dd><p>Beam search implementation without prefix search.</p>
<p>Modified from <a class="reference external" href="https://arxiv.org/pdf/1211.3711.pdf">https://arxiv.org/pdf/1211.3711.pdf</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>enc_out</strong> – Encoder output sequence. (T, D)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>N-best hypothesis.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>nbest_hyps</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.beam_search_transducer.BeamSearchTransducer.modified_adaptive_expansion_search">
<code class="sig-name descname">modified_adaptive_expansion_search</code><span class="sig-paren">(</span><em class="sig-param">enc_out: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; List[espnet2.asr_transducer.beam_search_transducer.ExtendedHypothesis]<a class="reference internal" href="../_modules/espnet2/asr_transducer/beam_search_transducer.html#BeamSearchTransducer.modified_adaptive_expansion_search"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.beam_search_transducer.BeamSearchTransducer.modified_adaptive_expansion_search" title="Permalink to this definition">¶</a></dt>
<dd><p>Modified version of Adaptive Expansion Search (mAES).</p>
<dl class="simple">
<dt>Based on AES (<a class="reference external" href="https://ieeexplore.ieee.org/document/9250505">https://ieeexplore.ieee.org/document/9250505</a>) and</dt><dd><p>NSC (<a class="reference external" href="https://arxiv.org/abs/2201.05420">https://arxiv.org/abs/2201.05420</a>).</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>enc_out</strong> – Encoder output sequence. (T, D_enc)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>N-best hypothesis.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>nbest_hyps</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.beam_search_transducer.BeamSearchTransducer.recombine_hyps">
<code class="sig-name descname">recombine_hyps</code><span class="sig-paren">(</span><em class="sig-param">hyps: List[espnet2.asr_transducer.beam_search_transducer.Hypothesis]</em><span class="sig-paren">)</span> &#x2192; List[espnet2.asr_transducer.beam_search_transducer.Hypothesis]<a class="reference internal" href="../_modules/espnet2/asr_transducer/beam_search_transducer.html#BeamSearchTransducer.recombine_hyps"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.beam_search_transducer.BeamSearchTransducer.recombine_hyps" title="Permalink to this definition">¶</a></dt>
<dd><p>Recombine hypotheses with same label ID sequence.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>hyps</strong> – Hypotheses.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Recombined hypotheses.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>final</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.beam_search_transducer.BeamSearchTransducer.reset_inference_cache">
<code class="sig-name descname">reset_inference_cache</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../_modules/espnet2/asr_transducer/beam_search_transducer.html#BeamSearchTransducer.reset_inference_cache"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.beam_search_transducer.BeamSearchTransducer.reset_inference_cache" title="Permalink to this definition">¶</a></dt>
<dd><p>Reset cache for decoder scoring and streaming.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.beam_search_transducer.BeamSearchTransducer.select_k_expansions">
<code class="sig-name descname">select_k_expansions</code><span class="sig-paren">(</span><em class="sig-param">hyps: List[espnet2.asr_transducer.beam_search_transducer.ExtendedHypothesis], topk_idx: torch.Tensor, topk_logp: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; List[espnet2.asr_transducer.beam_search_transducer.ExtendedHypothesis]<a class="reference internal" href="../_modules/espnet2/asr_transducer/beam_search_transducer.html#BeamSearchTransducer.select_k_expansions"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.beam_search_transducer.BeamSearchTransducer.select_k_expansions" title="Permalink to this definition">¶</a></dt>
<dd><p>Return K hypotheses candidates for expansion from a list of hypothesis.</p>
<p>K candidates are selected according to the extended hypotheses probabilities
and a prune-by-value method. Where K is equal to beam_size + beta.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hyps</strong> – Hypotheses.</p></li>
<li><p><strong>topk_idx</strong> – Indices of candidates hypothesis.</p></li>
<li><p><strong>topk_logp</strong> – Log-probabilities of candidates hypothesis.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Best K expansion hypotheses candidates.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>k_expansions</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.beam_search_transducer.BeamSearchTransducer.sort_nbest">
<code class="sig-name descname">sort_nbest</code><span class="sig-paren">(</span><em class="sig-param">hyps: List[espnet2.asr_transducer.beam_search_transducer.Hypothesis]</em><span class="sig-paren">)</span> &#x2192; List[espnet2.asr_transducer.beam_search_transducer.Hypothesis]<a class="reference internal" href="../_modules/espnet2/asr_transducer/beam_search_transducer.html#BeamSearchTransducer.sort_nbest"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.beam_search_transducer.BeamSearchTransducer.sort_nbest" title="Permalink to this definition">¶</a></dt>
<dd><p>Sort in-place hypotheses by score or score given sequence length.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>hyps</strong> – Hypothesis.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Sorted hypothesis.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>hyps</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.beam_search_transducer.BeamSearchTransducer.time_sync_decoding">
<code class="sig-name descname">time_sync_decoding</code><span class="sig-paren">(</span><em class="sig-param">enc_out: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; List[espnet2.asr_transducer.beam_search_transducer.Hypothesis]<a class="reference internal" href="../_modules/espnet2/asr_transducer/beam_search_transducer.html#BeamSearchTransducer.time_sync_decoding"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.beam_search_transducer.BeamSearchTransducer.time_sync_decoding" title="Permalink to this definition">¶</a></dt>
<dd><p>Time synchronous beam search implementation.</p>
<p>Based on <a class="reference external" href="https://ieeexplore.ieee.org/document/9053040">https://ieeexplore.ieee.org/document/9053040</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>enc_out</strong> – Encoder output sequence. (T, D)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>N-best hypothesis.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>nbest_hyps</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.asr_transducer.beam_search_transducer.ExtendedHypothesis">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr_transducer.beam_search_transducer.</code><code class="sig-name descname">ExtendedHypothesis</code><span class="sig-paren">(</span><em class="sig-param">score: float, yseq: List[int], dec_state: Optional[Tuple[torch.Tensor, Optional[torch.Tensor]]] = None, lm_state: Union[Dict[str, Any], List[Any], None] = None, dec_out: torch.Tensor = None, lm_score: torch.Tensor = None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr_transducer/beam_search_transducer.html#ExtendedHypothesis"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.beam_search_transducer.ExtendedHypothesis" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr_transducer.beam_search_transducer.Hypothesis" title="espnet2.asr_transducer.beam_search_transducer.Hypothesis"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr_transducer.beam_search_transducer.Hypothesis</span></code></a></p>
<p>Extended hypothesis definition for NSC beam search and mAES.</p>
<p>:param : Hypothesis dataclass arguments.
:param dec_out: Decoder output sequence. (B, D_dec)
:param lm_score: Log-probabilities of the LM for given label. (vocab_size)</p>
<dl class="attribute">
<dt id="espnet2.asr_transducer.beam_search_transducer.ExtendedHypothesis.dec_out">
<code class="sig-name descname">dec_out</code><em class="property"> = None</em><a class="headerlink" href="#espnet2.asr_transducer.beam_search_transducer.ExtendedHypothesis.dec_out" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="espnet2.asr_transducer.beam_search_transducer.ExtendedHypothesis.lm_score">
<code class="sig-name descname">lm_score</code><em class="property"> = None</em><a class="headerlink" href="#espnet2.asr_transducer.beam_search_transducer.ExtendedHypothesis.lm_score" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.asr_transducer.beam_search_transducer.Hypothesis">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr_transducer.beam_search_transducer.</code><code class="sig-name descname">Hypothesis</code><span class="sig-paren">(</span><em class="sig-param">score: float, yseq: List[int], dec_state: Optional[Tuple[torch.Tensor, Optional[torch.Tensor]]] = None, lm_state: Union[Dict[str, Any], List[Any], None] = None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr_transducer/beam_search_transducer.html#Hypothesis"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.beam_search_transducer.Hypothesis" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Default hypothesis definition for Transducer search algorithms.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>score</strong> – Total log-probability.</p></li>
<li><p><strong>yseq</strong> – Label sequence as integer ID sequence.</p></li>
<li><p><strong>dec_state</strong> – RNNDecoder or StatelessDecoder state.
((N, 1, D_dec), (N, 1, D_dec) or None) or None</p></li>
<li><p><strong>lm_state</strong> – RNNLM state. ((N, D_lm), (N, D_lm)) or None</p></li>
</ul>
</dd>
</dl>
<dl class="attribute">
<dt id="espnet2.asr_transducer.beam_search_transducer.Hypothesis.dec_state">
<code class="sig-name descname">dec_state</code><em class="property"> = None</em><a class="headerlink" href="#espnet2.asr_transducer.beam_search_transducer.Hypothesis.dec_state" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="espnet2.asr_transducer.beam_search_transducer.Hypothesis.lm_state">
<code class="sig-name descname">lm_state</code><em class="property"> = None</em><a class="headerlink" href="#espnet2.asr_transducer.beam_search_transducer.Hypothesis.lm_state" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-transducer-activation">
<span id="id2"></span><h2>espnet2.asr_transducer.activation<a class="headerlink" href="#espnet2-asr-transducer-activation" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.activation"></span><p>Activation functions for Transducer.</p>
<dl class="class">
<dt id="espnet2.asr_transducer.activation.FTSwish">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr_transducer.activation.</code><code class="sig-name descname">FTSwish</code><span class="sig-paren">(</span><em class="sig-param">threshold: float = -0.2</em>, <em class="sig-param">mean_shift: float = 0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr_transducer/activation.html#FTSwish"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.activation.FTSwish" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Flatten-T Swish activation definition.</p>
<dl class="simple">
<dt>FTSwish(x) = x * sigmoid(x) + threshold</dt><dd><p>where FTSwish(x) &lt; 0 = threshold</p>
</dd>
</dl>
<p>Reference: <a class="reference external" href="https://arxiv.org/abs/1812.06247">https://arxiv.org/abs/1812.06247</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>threshold</strong> – Threshold value for FTSwish activation formulation. (threshold &lt; 0)</p></li>
<li><p><strong>mean_shift</strong> – Mean shifting value for FTSwish activation formulation.
(applied only if != 0, disabled by default)</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.asr_transducer.activation.FTSwish.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr_transducer/activation.html#FTSwish.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.activation.FTSwish.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward computation.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.asr_transducer.activation.Mish">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr_transducer.activation.</code><code class="sig-name descname">Mish</code><span class="sig-paren">(</span><em class="sig-param">softplus_beta: float = 1.0</em>, <em class="sig-param">softplus_threshold: int = 20</em>, <em class="sig-param">use_builtin: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr_transducer/activation.html#Mish"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.activation.Mish" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Mish activation definition.</p>
<p>Mish(x) = x * tanh(softplus(x))</p>
<p>Reference: <a class="reference external" href="https://arxiv.org/abs/1908.08681">https://arxiv.org/abs/1908.08681</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>softplus_beta</strong> – Beta value for softplus activation formulation.
(Usually 0 &gt; softplus_beta &gt;= 2)</p></li>
<li><p><strong>softplus_threshold</strong> – Values above this revert to a linear function.
(Usually 10 &gt; softplus_threshold &gt;= 20)</p></li>
<li><p><strong>use_builtin</strong> – Whether to use PyTorch activation function if available.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.asr_transducer.activation.Mish.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr_transducer/activation.html#Mish.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.activation.Mish.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward computation.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.asr_transducer.activation.Smish">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr_transducer.activation.</code><code class="sig-name descname">Smish</code><span class="sig-paren">(</span><em class="sig-param">alpha: float = 1.0</em>, <em class="sig-param">beta: float = 1.0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr_transducer/activation.html#Smish"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.activation.Smish" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Smish activation definition.</p>
<dl class="simple">
<dt>Smish(x) = (alpha * x) * tanh(log(1 + sigmoid(beta * x)))</dt><dd><p>where alpha &gt; 0 and beta &gt; 0</p>
</dd>
</dl>
<p>Reference: <a class="reference external" href="https://www.mdpi.com/2079-9292/11/4/540/htm">https://www.mdpi.com/2079-9292/11/4/540/htm</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>alpha</strong> – Alpha value for Smish activation fomulation.
(Usually, alpha = 1. If alpha &lt;= 0, set value to 1).</p></li>
<li><p><strong>beta</strong> – Beta value for Smish activation formulation.
(Usually, beta = 1. If beta &lt;= 0, set value to 1).</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.asr_transducer.activation.Smish.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr_transducer/activation.html#Smish.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.activation.Smish.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward computation.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.asr_transducer.activation.Swish">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr_transducer.activation.</code><code class="sig-name descname">Swish</code><span class="sig-paren">(</span><em class="sig-param">beta: float = 1.0</em>, <em class="sig-param">use_builtin: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr_transducer/activation.html#Swish"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.activation.Swish" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Swish activation definition.</p>
<dl class="simple">
<dt>Swish(x) = (beta * x) * sigmoid(x)</dt><dd><p>where beta = 1 defines standard Swish activation.</p>
</dd>
</dl>
<p class="rubric">References</p>
<p><a class="reference external" href="https://arxiv.org/abs/2108.12943">https://arxiv.org/abs/2108.12943</a> / <a class="reference external" href="https://arxiv.org/abs/1710.05941v1">https://arxiv.org/abs/1710.05941v1</a>.
E-swish variant: <a class="reference external" href="https://arxiv.org/abs/1801.07145">https://arxiv.org/abs/1801.07145</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>beta</strong> – Beta parameter for E-Swish.
(beta &gt;= 1. If beta &lt; 1, use standard Swish).</p></li>
<li><p><strong>use_builtin</strong> – Whether to use PyTorch function if available.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.asr_transducer.activation.Swish.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr_transducer/activation.html#Swish.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.activation.Swish.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward computation.</p>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="espnet2.asr_transducer.activation.get_activation">
<code class="sig-prename descclassname">espnet2.asr_transducer.activation.</code><code class="sig-name descname">get_activation</code><span class="sig-paren">(</span><em class="sig-param">activation_type: str</em>, <em class="sig-param">ftswish_threshold: float = -0.2</em>, <em class="sig-param">ftswish_mean_shift: float = 0.0</em>, <em class="sig-param">hardtanh_min_val: int = -1.0</em>, <em class="sig-param">hardtanh_max_val: int = 1.0</em>, <em class="sig-param">leakyrelu_neg_slope: float = 0.01</em>, <em class="sig-param">smish_alpha: float = 1.0</em>, <em class="sig-param">smish_beta: float = 1.0</em>, <em class="sig-param">softplus_beta: float = 1.0</em>, <em class="sig-param">softplus_threshold: int = 20</em>, <em class="sig-param">swish_beta: float = 1.0</em><span class="sig-paren">)</span> &#x2192; torch.nn.modules.module.Module<a class="reference internal" href="../_modules/espnet2/asr_transducer/activation.html#get_activation"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.activation.get_activation" title="Permalink to this definition">¶</a></dt>
<dd><p>Return activation function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>activation_type</strong> – Activation function type.</p></li>
<li><p><strong>ftswish_threshold</strong> – Threshold value for FTSwish activation formulation.</p></li>
<li><p><strong>ftswish_mean_shift</strong> – Mean shifting value for FTSwish activation formulation.</p></li>
<li><p><strong>hardtanh_min_val</strong> – Minimum value of the linear region range for HardTanh.</p></li>
<li><p><strong>hardtanh_max_val</strong> – Maximum value of the linear region range for HardTanh.</p></li>
<li><p><strong>leakyrelu_neg_slope</strong> – Negative slope value for LeakyReLU activation formulation.</p></li>
<li><p><strong>smish_alpha</strong> – Alpha value for Smish activation fomulation.</p></li>
<li><p><strong>smish_beta</strong> – Beta value for Smish activation formulation.</p></li>
<li><p><strong>softplus_beta</strong> – Beta value for softplus activation formulation in Mish.</p></li>
<li><p><strong>softplus_threshold</strong> – Values above this revert to a linear function in Mish.</p></li>
<li><p><strong>swish_beta</strong> – Beta value for Swish variant formulation.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Activation function.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="espnet2-asr-transducer-error-calculator">
<span id="id3"></span><h2>espnet2.asr_transducer.error_calculator<a class="headerlink" href="#espnet2-asr-transducer-error-calculator" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.error_calculator"></span><p>Error Calculator module for Transducer.</p>
<dl class="class">
<dt id="espnet2.asr_transducer.error_calculator.ErrorCalculator">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr_transducer.error_calculator.</code><code class="sig-name descname">ErrorCalculator</code><span class="sig-paren">(</span><em class="sig-param">decoder: espnet2.asr_transducer.decoder.abs_decoder.AbsDecoder, joint_network: espnet2.asr_transducer.joint_network.JointNetwork, token_list: List[int], sym_space: str, sym_blank: str, report_cer: bool = False, report_wer: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr_transducer/error_calculator.html#ErrorCalculator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.error_calculator.ErrorCalculator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Calculate CER and WER for transducer models.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>decoder</strong> – Decoder module.</p></li>
<li><p><strong>joint_network</strong> – Joint Network module.</p></li>
<li><p><strong>token_list</strong> – List of token units.</p></li>
<li><p><strong>sym_space</strong> – Space symbol.</p></li>
<li><p><strong>sym_blank</strong> – Blank symbol.</p></li>
<li><p><strong>report_cer</strong> – Whether to compute CER.</p></li>
<li><p><strong>report_wer</strong> – Whether to compute WER.</p></li>
</ul>
</dd>
</dl>
<p>Construct an ErrorCalculatorTransducer object.</p>
<dl class="method">
<dt id="espnet2.asr_transducer.error_calculator.ErrorCalculator.calculate_cer">
<code class="sig-name descname">calculate_cer</code><span class="sig-paren">(</span><em class="sig-param">char_pred: torch.Tensor</em>, <em class="sig-param">char_target: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; float<a class="reference internal" href="../_modules/espnet2/asr_transducer/error_calculator.html#ErrorCalculator.calculate_cer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.error_calculator.ErrorCalculator.calculate_cer" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate sentence-level CER score.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>char_pred</strong> – Prediction character sequences. (B, ?)</p></li>
<li><p><strong>char_target</strong> – Target character sequences. (B, ?)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Average sentence-level CER score.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.error_calculator.ErrorCalculator.calculate_wer">
<code class="sig-name descname">calculate_wer</code><span class="sig-paren">(</span><em class="sig-param">char_pred: torch.Tensor</em>, <em class="sig-param">char_target: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; float<a class="reference internal" href="../_modules/espnet2/asr_transducer/error_calculator.html#ErrorCalculator.calculate_wer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.error_calculator.ErrorCalculator.calculate_wer" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate sentence-level WER score.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>char_pred</strong> – Prediction character sequences. (B, ?)</p></li>
<li><p><strong>char_target</strong> – Target character sequences. (B, ?)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Average sentence-level WER score</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.error_calculator.ErrorCalculator.convert_to_char">
<code class="sig-name descname">convert_to_char</code><span class="sig-paren">(</span><em class="sig-param">pred: torch.Tensor</em>, <em class="sig-param">target: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Tuple[List, List]<a class="reference internal" href="../_modules/espnet2/asr_transducer/error_calculator.html#ErrorCalculator.convert_to_char"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.error_calculator.ErrorCalculator.convert_to_char" title="Permalink to this definition">¶</a></dt>
<dd><p>Convert label ID sequences to character sequences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pred</strong> – Prediction label ID sequences. (B, U)</p></li>
<li><p><strong>target</strong> – Target label ID sequences. (B, L)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Prediction character sequences. (B, ?)
char_target: Target character sequences. (B, ?)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>char_pred</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-transducer-utils">
<span id="id4"></span><h2>espnet2.asr_transducer.utils<a class="headerlink" href="#espnet2-asr-transducer-utils" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.utils"></span><p>Utility functions for Transducer models.</p>
<dl class="exception">
<dt id="espnet2.asr_transducer.utils.TooShortUttError">
<em class="property">exception </em><code class="sig-prename descclassname">espnet2.asr_transducer.utils.</code><code class="sig-name descname">TooShortUttError</code><span class="sig-paren">(</span><em class="sig-param">message: str</em>, <em class="sig-param">actual_size: int</em>, <em class="sig-param">limit: int</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr_transducer/utils.html#TooShortUttError"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.utils.TooShortUttError" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Exception</span></code></p>
<p>Raised when the utt is too short for subsampling.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>message</strong> – Error message to display.</p></li>
<li><p><strong>actual_size</strong> – The size that cannot pass the subsampling.</p></li>
<li><p><strong>limit</strong> – The size limit for subsampling.</p></li>
</ul>
</dd>
</dl>
<p>Construct a TooShortUttError module.</p>
</dd></dl>

<dl class="function">
<dt id="espnet2.asr_transducer.utils.check_short_utt">
<code class="sig-prename descclassname">espnet2.asr_transducer.utils.</code><code class="sig-name descname">check_short_utt</code><span class="sig-paren">(</span><em class="sig-param">sub_factor: int</em>, <em class="sig-param">size: int</em><span class="sig-paren">)</span> &#x2192; Tuple[bool, int]<a class="reference internal" href="../_modules/espnet2/asr_transducer/utils.html#check_short_utt"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.utils.check_short_utt" title="Permalink to this definition">¶</a></dt>
<dd><p>Check if the input is too short for subsampling.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sub_factor</strong> – Subsampling factor for Conv2DSubsampling.</p></li>
<li><p><strong>size</strong> – Input size.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Whether an error should be sent.
: Size limit for specified subsampling factor.</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet2.asr_transducer.utils.get_transducer_task_io">
<code class="sig-prename descclassname">espnet2.asr_transducer.utils.</code><code class="sig-name descname">get_transducer_task_io</code><span class="sig-paren">(</span><em class="sig-param">labels: torch.Tensor</em>, <em class="sig-param">encoder_out_lens: torch.Tensor</em>, <em class="sig-param">ignore_id: int = -1</em>, <em class="sig-param">blank_id: int = 0</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr_transducer/utils.html#get_transducer_task_io"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.utils.get_transducer_task_io" title="Permalink to this definition">¶</a></dt>
<dd><p>Get Transducer loss I/O.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>labels</strong> – Label ID sequences. (B, L)</p></li>
<li><p><strong>encoder_out_lens</strong> – Encoder output lengths. (B,)</p></li>
<li><p><strong>ignore_id</strong> – Padding symbol ID.</p></li>
<li><p><strong>blank_id</strong> – Blank symbol ID.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Decoder inputs. (B, U)
target: Target label ID sequences. (B, U)
t_len: Time lengths. (B,)
u_len: Label lengths. (B,)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>decoder_in</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet2.asr_transducer.utils.make_chunk_mask">
<code class="sig-prename descclassname">espnet2.asr_transducer.utils.</code><code class="sig-name descname">make_chunk_mask</code><span class="sig-paren">(</span><em class="sig-param">size: int</em>, <em class="sig-param">chunk_size: int</em>, <em class="sig-param">left_chunk_size: int = 0</em>, <em class="sig-param">device: torch.device = None</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr_transducer/utils.html#make_chunk_mask"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.utils.make_chunk_mask" title="Permalink to this definition">¶</a></dt>
<dd><p>Create chunk mask for the subsequent steps (size, size).</p>
<p>Reference: <a class="reference external" href="https://github.com/k2-fsa/icefall/blob/master/icefall/utils.py">https://github.com/k2-fsa/icefall/blob/master/icefall/utils.py</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>size</strong> – Size of the source mask.</p></li>
<li><p><strong>chunk_size</strong> – Number of frames in chunk.</p></li>
<li><p><strong>left_chunk_size</strong> – Size of the left context in chunks (0 means full context).</p></li>
<li><p><strong>device</strong> – Device for the mask tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Chunk mask. (size, size)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>mask</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet2.asr_transducer.utils.make_source_mask">
<code class="sig-prename descclassname">espnet2.asr_transducer.utils.</code><code class="sig-name descname">make_source_mask</code><span class="sig-paren">(</span><em class="sig-param">lengths: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr_transducer/utils.html#make_source_mask"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.utils.make_source_mask" title="Permalink to this definition">¶</a></dt>
<dd><p>Create source mask for given lengths.</p>
<p>Reference: <a class="reference external" href="https://github.com/k2-fsa/icefall/blob/master/icefall/utils.py">https://github.com/k2-fsa/icefall/blob/master/icefall/utils.py</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>lengths</strong> – Sequence lengths. (B,)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Mask for the sequence lengths. (B, max_len)</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet2.asr_transducer.utils.sub_factor_to_params">
<code class="sig-prename descclassname">espnet2.asr_transducer.utils.</code><code class="sig-name descname">sub_factor_to_params</code><span class="sig-paren">(</span><em class="sig-param">sub_factor: int</em>, <em class="sig-param">input_size: int</em><span class="sig-paren">)</span> &#x2192; Tuple[int, int, int]<a class="reference internal" href="../_modules/espnet2/asr_transducer/utils.html#sub_factor_to_params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.utils.sub_factor_to_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get conv2D second layer parameters for given subsampling factor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sub_factor</strong> – Subsampling factor (1/X).</p></li>
<li><p><strong>input_size</strong> – Input size.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Kernel size for second convolution.
: Stride for second convolution.
: Conv2DSubsampling output size.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="espnet2-asr-transducer-init">
<span id="id5"></span><h2>espnet2.asr_transducer.__init__<a class="headerlink" href="#espnet2-asr-transducer-init" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.__init__"></span></section>
<section id="espnet2-asr-transducer-joint-network">
<span id="id6"></span><h2>espnet2.asr_transducer.joint_network<a class="headerlink" href="#espnet2-asr-transducer-joint-network" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.joint_network"></span><p>Transducer joint network implementation.</p>
<dl class="class">
<dt id="espnet2.asr_transducer.joint_network.JointNetwork">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr_transducer.joint_network.</code><code class="sig-name descname">JointNetwork</code><span class="sig-paren">(</span><em class="sig-param">output_size: int</em>, <em class="sig-param">encoder_size: int</em>, <em class="sig-param">decoder_size: int</em>, <em class="sig-param">joint_space_size: int = 256</em>, <em class="sig-param">joint_activation_type: str = 'tanh'</em>, <em class="sig-param">**activation_parameters</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr_transducer/joint_network.html#JointNetwork"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.joint_network.JointNetwork" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Transducer joint network module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>output_size</strong> – Output size.</p></li>
<li><p><strong>encoder_size</strong> – Encoder output size.</p></li>
<li><p><strong>decoder_size</strong> – Decoder output size..</p></li>
<li><p><strong>joint_space_size</strong> – Joint space size.</p></li>
<li><p><strong>joint_act_type</strong> – Type of activation for joint network.</p></li>
<li><p><strong>**activation_parameters</strong> – Parameters for the activation function.</p></li>
</ul>
</dd>
</dl>
<p>Construct a JointNetwork object.</p>
<dl class="method">
<dt id="espnet2.asr_transducer.joint_network.JointNetwork.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">enc_out: torch.Tensor</em>, <em class="sig-param">dec_out: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr_transducer/joint_network.html#JointNetwork.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.joint_network.JointNetwork.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Joint computation of encoder and decoder hidden state sequences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>enc_out</strong> – Expanded encoder output state sequences (B, T, 1, D_enc)</p></li>
<li><p><strong>dec_out</strong> – Expanded decoder output state sequences (B, 1, U, D_dec)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Joint output state sequences. (B, T, U, D_out)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>joint_out</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-transducer-espnet-transducer-model">
<span id="id7"></span><h2>espnet2.asr_transducer.espnet_transducer_model<a class="headerlink" href="#espnet2-asr-transducer-espnet-transducer-model" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.espnet_transducer_model"></span><p>ESPnet2 ASR Transducer model.</p>
<dl class="class">
<dt id="espnet2.asr_transducer.espnet_transducer_model.ESPnetASRTransducerModel">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr_transducer.espnet_transducer_model.</code><code class="sig-name descname">ESPnetASRTransducerModel</code><span class="sig-paren">(</span><em class="sig-param">vocab_size: int, token_list: Union[Tuple[str, ...], List[str]], frontend: Optional[espnet2.asr.frontend.abs_frontend.AbsFrontend], specaug: Optional[espnet2.asr.specaug.abs_specaug.AbsSpecAug], normalize: Optional[espnet2.layers.abs_normalize.AbsNormalize], encoder: espnet2.asr_transducer.encoder.encoder.Encoder, decoder: espnet2.asr_transducer.decoder.abs_decoder.AbsDecoder, joint_network: espnet2.asr_transducer.joint_network.JointNetwork, transducer_weight: float = 1.0, fastemit_lambda: float = 0.0, auxiliary_ctc_weight: float = 0.0, auxiliary_ctc_dropout_rate: float = 0.0, auxiliary_lm_loss_weight: float = 0.0, auxiliary_lm_loss_smoothing: float = 0.05, ignore_id: int = -1, sym_space: str = '&lt;space&gt;', sym_blank: str = '&lt;blank&gt;', report_cer: bool = False, report_wer: bool = False, extract_feats_in_collect_stats: bool = True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr_transducer/espnet_transducer_model.html#ESPnetASRTransducerModel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.espnet_transducer_model.ESPnetASRTransducerModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="espnet2.train.html#espnet2.train.abs_espnet_model.AbsESPnetModel" title="espnet2.train.abs_espnet_model.AbsESPnetModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.train.abs_espnet_model.AbsESPnetModel</span></code></a></p>
<p>ESPnet2ASRTransducerModel module definition.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>vocab_size</strong> – Size of complete vocabulary (w/ SOS/EOS and blank included).</p></li>
<li><p><strong>token_list</strong> – List of tokens in vocabulary (minus reserved tokens).</p></li>
<li><p><strong>frontend</strong> – Frontend module.</p></li>
<li><p><strong>specaug</strong> – SpecAugment module.</p></li>
<li><p><strong>normalize</strong> – Normalization module.</p></li>
<li><p><strong>encoder</strong> – Encoder module.</p></li>
<li><p><strong>decoder</strong> – Decoder module.</p></li>
<li><p><strong>joint_network</strong> – Joint Network module.</p></li>
<li><p><strong>transducer_weight</strong> – Weight of the Transducer loss.</p></li>
<li><p><strong>fastemit_lambda</strong> – FastEmit lambda value.</p></li>
<li><p><strong>auxiliary_ctc_weight</strong> – Weight of auxiliary CTC loss.</p></li>
<li><p><strong>auxiliary_ctc_dropout_rate</strong> – Dropout rate for auxiliary CTC loss inputs.</p></li>
<li><p><strong>auxiliary_lm_loss_weight</strong> – Weight of auxiliary LM loss.</p></li>
<li><p><strong>auxiliary_lm_loss_smoothing</strong> – Smoothing rate for LM loss’ label smoothing.</p></li>
<li><p><strong>ignore_id</strong> – Initial padding ID.</p></li>
<li><p><strong>sym_space</strong> – Space symbol.</p></li>
<li><p><strong>sym_blank</strong> – Blank Symbol.</p></li>
<li><p><strong>report_cer</strong> – Whether to report Character Error Rate during validation.</p></li>
<li><p><strong>report_wer</strong> – Whether to report Word Error Rate during validation.</p></li>
<li><p><strong>extract_feats_in_collect_stats</strong> – Whether to use extract_feats stats collection.</p></li>
</ul>
</dd>
</dl>
<p>Construct an ESPnetASRTransducerModel object.</p>
<dl class="method">
<dt id="espnet2.asr_transducer.espnet_transducer_model.ESPnetASRTransducerModel.collect_feats">
<code class="sig-name descname">collect_feats</code><span class="sig-paren">(</span><em class="sig-param">speech: torch.Tensor</em>, <em class="sig-param">speech_lengths: torch.Tensor</em>, <em class="sig-param">text: torch.Tensor</em>, <em class="sig-param">text_lengths: torch.Tensor</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span> &#x2192; Dict[str, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr_transducer/espnet_transducer_model.html#ESPnetASRTransducerModel.collect_feats"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.espnet_transducer_model.ESPnetASRTransducerModel.collect_feats" title="Permalink to this definition">¶</a></dt>
<dd><p>Collect features sequences and features lengths sequences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>speech</strong> – Speech sequences. (B, S)</p></li>
<li><p><strong>speech_lengths</strong> – Speech sequences lengths. (B,)</p></li>
<li><p><strong>text</strong> – Label ID sequences. (B, L)</p></li>
<li><p><strong>text_lengths</strong> – Label ID sequences lengths. (B,)</p></li>
<li><p><strong>kwargs</strong> – Contains “utts_id”.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>“feats”: Features sequences. (B, T, D_feats),</dt><dd><p>”feats_lengths”: Features sequences lengths. (B,)</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>{}</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.espnet_transducer_model.ESPnetASRTransducerModel.encode">
<code class="sig-name descname">encode</code><span class="sig-paren">(</span><em class="sig-param">speech: torch.Tensor</em>, <em class="sig-param">speech_lengths: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr_transducer/espnet_transducer_model.html#ESPnetASRTransducerModel.encode"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.espnet_transducer_model.ESPnetASRTransducerModel.encode" title="Permalink to this definition">¶</a></dt>
<dd><p>Encoder speech sequences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>speech</strong> – Speech sequences. (B, S)</p></li>
<li><p><strong>speech_lengths</strong> – Speech sequences lengths. (B,)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Encoder outputs. (B, T, D_enc)
encoder_out_lens: Encoder outputs lengths. (B,)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>encoder_out</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.espnet_transducer_model.ESPnetASRTransducerModel.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">speech: torch.Tensor</em>, <em class="sig-param">speech_lengths: torch.Tensor</em>, <em class="sig-param">text: torch.Tensor</em>, <em class="sig-param">text_lengths: torch.Tensor</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, Dict[str, torch.Tensor], torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr_transducer/espnet_transducer_model.html#ESPnetASRTransducerModel.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.espnet_transducer_model.ESPnetASRTransducerModel.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward architecture and compute loss(es).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>speech</strong> – Speech sequences. (B, S)</p></li>
<li><p><strong>speech_lengths</strong> – Speech sequences lengths. (B,)</p></li>
<li><p><strong>text</strong> – Label ID sequences. (B, L)</p></li>
<li><p><strong>text_lengths</strong> – Label ID sequences lengths. (B,)</p></li>
<li><p><strong>kwargs</strong> – Contains “utts_id”.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Main loss value.
stats: Task statistics.
weight: Task weights.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>loss</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-transducer-encoder-validation">
<span id="id8"></span><h2>espnet2.asr_transducer.encoder.validation<a class="headerlink" href="#espnet2-asr-transducer-encoder-validation" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.encoder.validation"></span><p>Set of methods to validate encoder architecture.</p>
<dl class="function">
<dt id="espnet2.asr_transducer.encoder.validation.validate_architecture">
<code class="sig-prename descclassname">espnet2.asr_transducer.encoder.validation.</code><code class="sig-name descname">validate_architecture</code><span class="sig-paren">(</span><em class="sig-param">input_conf: Dict[str, Any], body_conf: List[Dict[str, Any]], input_size: int</em><span class="sig-paren">)</span> &#x2192; Tuple[int, int]<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/validation.html#validate_architecture"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.validation.validate_architecture" title="Permalink to this definition">¶</a></dt>
<dd><p>Validate specified architecture is valid.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_conf</strong> – Encoder input block configuration.</p></li>
<li><p><strong>body_conf</strong> – Encoder body blocks configuration.</p></li>
<li><p><strong>input_size</strong> – Encoder input size.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Encoder input block output size.
: Encoder body block output size.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>input_block_osize</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet2.asr_transducer.encoder.validation.validate_block_arguments">
<code class="sig-prename descclassname">espnet2.asr_transducer.encoder.validation.</code><code class="sig-name descname">validate_block_arguments</code><span class="sig-paren">(</span><em class="sig-param">configuration: Dict[str, Any], block_id: int, previous_block_output: int</em><span class="sig-paren">)</span> &#x2192; Tuple[int, int]<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/validation.html#validate_block_arguments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.validation.validate_block_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>Validate block arguments.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>configuration</strong> – Architecture configuration.</p></li>
<li><p><strong>block_id</strong> – Block ID.</p></li>
<li><p><strong>previous_block_output</strong> – Previous block output size.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Block input size.
output_size: Block output size.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>input_size</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet2.asr_transducer.encoder.validation.validate_input_block">
<code class="sig-prename descclassname">espnet2.asr_transducer.encoder.validation.</code><code class="sig-name descname">validate_input_block</code><span class="sig-paren">(</span><em class="sig-param">configuration: Dict[str, Any], body_first_conf: Dict[str, Any], input_size: int</em><span class="sig-paren">)</span> &#x2192; int<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/validation.html#validate_input_block"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.validation.validate_input_block" title="Permalink to this definition">¶</a></dt>
<dd><p>Validate input block.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>configuration</strong> – Encoder input block configuration.</p></li>
<li><p><strong>body_first_conf</strong> – Encoder first body block configuration.</p></li>
<li><p><strong>input_size</strong> – Encoder input block input size.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Encoder input block output size.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>output_size</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="espnet2-asr-transducer-encoder-building">
<span id="id9"></span><h2>espnet2.asr_transducer.encoder.building<a class="headerlink" href="#espnet2-asr-transducer-encoder-building" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.encoder.building"></span><p>Set of methods to build Transducer encoder architecture.</p>
<dl class="function">
<dt id="espnet2.asr_transducer.encoder.building.build_body_blocks">
<code class="sig-prename descclassname">espnet2.asr_transducer.encoder.building.</code><code class="sig-name descname">build_body_blocks</code><span class="sig-paren">(</span><em class="sig-param">configuration: List[Dict[str, Any]], main_params: Dict[str, Any], output_size: int</em><span class="sig-paren">)</span> &#x2192; espnet2.asr_transducer.encoder.modules.multi_blocks.MultiBlocks<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/building.html#build_body_blocks"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.building.build_body_blocks" title="Permalink to this definition">¶</a></dt>
<dd><p>Build encoder body blocks.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>configuration</strong> – Body blocks configuration.</p></li>
<li><p><strong>main_params</strong> – Encoder main parameters.</p></li>
<li><p><strong>output_size</strong> – Architecture output size.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>MultiBlocks function encapsulation all encoder blocks.</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet2.asr_transducer.encoder.building.build_branchformer_block">
<code class="sig-prename descclassname">espnet2.asr_transducer.encoder.building.</code><code class="sig-name descname">build_branchformer_block</code><span class="sig-paren">(</span><em class="sig-param">configuration: List[Dict[str, Any]], main_params: Dict[str, Any]</em><span class="sig-paren">)</span> &#x2192; espnet2.asr_transducer.encoder.blocks.conformer.Conformer<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/building.html#build_branchformer_block"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.building.build_branchformer_block" title="Permalink to this definition">¶</a></dt>
<dd><p>Build Branchformer block.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>configuration</strong> – Branchformer block configuration.</p></li>
<li><p><strong>main_params</strong> – Encoder main parameters.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Branchformer block function.</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet2.asr_transducer.encoder.building.build_conformer_block">
<code class="sig-prename descclassname">espnet2.asr_transducer.encoder.building.</code><code class="sig-name descname">build_conformer_block</code><span class="sig-paren">(</span><em class="sig-param">configuration: List[Dict[str, Any]], main_params: Dict[str, Any]</em><span class="sig-paren">)</span> &#x2192; espnet2.asr_transducer.encoder.blocks.conformer.Conformer<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/building.html#build_conformer_block"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.building.build_conformer_block" title="Permalink to this definition">¶</a></dt>
<dd><p>Build Conformer block.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>configuration</strong> – Conformer block configuration.</p></li>
<li><p><strong>main_params</strong> – Encoder main parameters.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Conformer block function.</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet2.asr_transducer.encoder.building.build_conv1d_block">
<code class="sig-prename descclassname">espnet2.asr_transducer.encoder.building.</code><code class="sig-name descname">build_conv1d_block</code><span class="sig-paren">(</span><em class="sig-param">configuration: List[Dict[str, Any]], causal: bool</em><span class="sig-paren">)</span> &#x2192; espnet2.asr_transducer.encoder.blocks.conv1d.Conv1d<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/building.html#build_conv1d_block"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.building.build_conv1d_block" title="Permalink to this definition">¶</a></dt>
<dd><p>Build Conv1d block.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>configuration</strong> – Conv1d block configuration.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Conv1d block function.</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet2.asr_transducer.encoder.building.build_input_block">
<code class="sig-prename descclassname">espnet2.asr_transducer.encoder.building.</code><code class="sig-name descname">build_input_block</code><span class="sig-paren">(</span><em class="sig-param">input_size: int, configuration: Dict[str, Union[str, int]]</em><span class="sig-paren">)</span> &#x2192; espnet2.asr_transducer.encoder.blocks.conv_input.ConvInput<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/building.html#build_input_block"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.building.build_input_block" title="Permalink to this definition">¶</a></dt>
<dd><p>Build encoder input block.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> – Input size.</p></li>
<li><p><strong>configuration</strong> – Input block configuration.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>ConvInput block function.</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet2.asr_transducer.encoder.building.build_main_parameters">
<code class="sig-prename descclassname">espnet2.asr_transducer.encoder.building.</code><code class="sig-name descname">build_main_parameters</code><span class="sig-paren">(</span><em class="sig-param">pos_wise_act_type: str = 'swish'</em>, <em class="sig-param">conv_mod_act_type: str = 'swish'</em>, <em class="sig-param">pos_enc_dropout_rate: float = 0.0</em>, <em class="sig-param">pos_enc_max_len: int = 5000</em>, <em class="sig-param">simplified_att_score: bool = False</em>, <em class="sig-param">norm_type: str = 'layer_norm'</em>, <em class="sig-param">conv_mod_norm_type: str = 'layer_norm'</em>, <em class="sig-param">after_norm_eps: Optional[float] = None</em>, <em class="sig-param">after_norm_partial: Optional[float] = None</em>, <em class="sig-param">dynamic_chunk_training: bool = False</em>, <em class="sig-param">short_chunk_threshold: float = 0.75</em>, <em class="sig-param">short_chunk_size: int = 25</em>, <em class="sig-param">left_chunk_size: int = 0</em>, <em class="sig-param">**activation_parameters</em><span class="sig-paren">)</span> &#x2192; Dict[str, Any]<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/building.html#build_main_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.building.build_main_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Build encoder main parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pos_wise_act_type</strong> – Conformer position-wise feed-forward activation type.</p></li>
<li><p><strong>conv_mod_act_type</strong> – Conformer convolution module activation type.</p></li>
<li><p><strong>pos_enc_dropout_rate</strong> – Positional encoding dropout rate.</p></li>
<li><p><strong>pos_enc_max_len</strong> – Positional encoding maximum length.</p></li>
<li><p><strong>simplified_att_score</strong> – Whether to use simplified attention score computation.</p></li>
<li><p><strong>norm_type</strong> – X-former normalization module type.</p></li>
<li><p><strong>conv_mod_norm_type</strong> – Conformer convolution module normalization type.</p></li>
<li><p><strong>after_norm_eps</strong> – Epsilon value for the final normalization.</p></li>
<li><p><strong>after_norm_partial</strong> – Value for the final normalization with RMSNorm.</p></li>
<li><p><strong>dynamic_chunk_training</strong> – Whether to use dynamic chunk training.</p></li>
<li><p><strong>short_chunk_threshold</strong> – Threshold for dynamic chunk selection.</p></li>
<li><p><strong>short_chunk_size</strong> – Minimum number of frames during dynamic chunk training.</p></li>
<li><p><strong>left_chunk_size</strong> – Number of frames in left context.</p></li>
<li><p><strong>**activations_parameters</strong> – Parameters of the activation functions.
(See espnet2/asr_transducer/activation.py)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Main encoder parameters</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet2.asr_transducer.encoder.building.build_positional_encoding">
<code class="sig-prename descclassname">espnet2.asr_transducer.encoder.building.</code><code class="sig-name descname">build_positional_encoding</code><span class="sig-paren">(</span><em class="sig-param">block_size: int, configuration: Dict[str, Any]</em><span class="sig-paren">)</span> &#x2192; espnet2.asr_transducer.encoder.modules.positional_encoding.RelPositionalEncoding<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/building.html#build_positional_encoding"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.building.build_positional_encoding" title="Permalink to this definition">¶</a></dt>
<dd><p>Build positional encoding block.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>block_size</strong> – Input/output size.</p></li>
<li><p><strong>configuration</strong> – Positional encoding configuration.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Positional encoding module.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="espnet2-asr-transducer-encoder-init">
<span id="id10"></span><h2>espnet2.asr_transducer.encoder.__init__<a class="headerlink" href="#espnet2-asr-transducer-encoder-init" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.encoder.__init__"></span></section>
<section id="espnet2-asr-transducer-encoder-encoder">
<span id="id11"></span><h2>espnet2.asr_transducer.encoder.encoder<a class="headerlink" href="#espnet2-asr-transducer-encoder-encoder" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.encoder.encoder"></span><p>Encoder for Transducer model.</p>
<dl class="class">
<dt id="espnet2.asr_transducer.encoder.encoder.Encoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr_transducer.encoder.encoder.</code><code class="sig-name descname">Encoder</code><span class="sig-paren">(</span><em class="sig-param">input_size: int, body_conf: List[Dict[str, Any]], input_conf: Dict[str, Any] = {}, main_conf: Dict[str, Any] = {}</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/encoder.html#Encoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.encoder.Encoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Encoder module definition.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> – Input size.</p></li>
<li><p><strong>body_conf</strong> – Encoder body configuration.</p></li>
<li><p><strong>input_conf</strong> – Encoder input configuration.</p></li>
<li><p><strong>main_conf</strong> – Encoder main configuration.</p></li>
</ul>
</dd>
</dl>
<p>Construct an Encoder object.</p>
<dl class="method">
<dt id="espnet2.asr_transducer.encoder.encoder.Encoder.chunk_forward">
<code class="sig-name descname">chunk_forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">x_len: torch.Tensor</em>, <em class="sig-param">processed_frames: torch._VariableFunctionsClass.tensor</em>, <em class="sig-param">left_context: int = 32</em>, <em class="sig-param">right_context: int = 0</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/encoder.html#Encoder.chunk_forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.encoder.Encoder.chunk_forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Encode input sequences as chunks.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Encoder input features. (1, T_in, F)</p></li>
<li><p><strong>x_len</strong> – Encoder input features lengths. (1,)</p></li>
<li><p><strong>processed_frames</strong> – Number of frames already seen.</p></li>
<li><p><strong>left_context</strong> – Number of frames in left context.</p></li>
<li><p><strong>right_context</strong> – Number of frames in right context.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Encoder outputs. (B, T_out, D_enc)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>x</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.encoder.encoder.Encoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">x_len: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/encoder.html#Encoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.encoder.Encoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Encode input sequences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Encoder input features. (B, T_in, F)</p></li>
<li><p><strong>x_len</strong> – Encoder input features lengths. (B,)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Encoder outputs. (B, T_out, D_enc)
x_len: Encoder outputs lenghts. (B,)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>x</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.encoder.encoder.Encoder.get_encoder_input_raw_size">
<code class="sig-name descname">get_encoder_input_raw_size</code><span class="sig-paren">(</span><em class="sig-param">size: int</em>, <em class="sig-param">hop_length: int</em><span class="sig-paren">)</span> &#x2192; int<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/encoder.html#Encoder.get_encoder_input_raw_size"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.encoder.Encoder.get_encoder_input_raw_size" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the corresponding number of sample for a given chunk size, in frames.</p>
<p>Where size is the number of features frames after applying subsampling.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>size</strong> – Number of frames after subsampling.</p></li>
<li><p><strong>hop_length</strong> – Frontend’s hop length</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Number of raw samples</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.encoder.encoder.Encoder.reset_streaming_cache">
<code class="sig-name descname">reset_streaming_cache</code><span class="sig-paren">(</span><em class="sig-param">left_context: int</em>, <em class="sig-param">device: torch.device</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/encoder.html#Encoder.reset_streaming_cache"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.encoder.Encoder.reset_streaming_cache" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize/Reset encoder streaming cache.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>left_context</strong> – Number of frames in left context.</p></li>
<li><p><strong>device</strong> – Device ID.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-transducer-encoder-modules-multi-blocks">
<span id="id12"></span><h2>espnet2.asr_transducer.encoder.modules.multi_blocks<a class="headerlink" href="#espnet2-asr-transducer-encoder-modules-multi-blocks" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.encoder.modules.multi_blocks"></span><p>MultiBlocks for encoder architecture.</p>
<dl class="class">
<dt id="espnet2.asr_transducer.encoder.modules.multi_blocks.MultiBlocks">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr_transducer.encoder.modules.multi_blocks.</code><code class="sig-name descname">MultiBlocks</code><span class="sig-paren">(</span><em class="sig-param">block_list: List[torch.nn.modules.module.Module], output_size: int, norm_class: torch.nn.modules.module.Module = &lt;class 'torch.nn.modules.normalization.LayerNorm'&gt;, norm_args: Optional[Dict] = None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/modules/multi_blocks.html#MultiBlocks"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.modules.multi_blocks.MultiBlocks" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>MultiBlocks definition.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>block_list</strong> – Individual blocks of the encoder architecture.</p></li>
<li><p><strong>output_size</strong> – Architecture output size.</p></li>
<li><p><strong>norm_class</strong> – Normalization module class.</p></li>
<li><p><strong>norm_args</strong> – Normalization module arguments.</p></li>
</ul>
</dd>
</dl>
<p>Construct a MultiBlocks object.</p>
<dl class="method">
<dt id="espnet2.asr_transducer.encoder.modules.multi_blocks.MultiBlocks.chunk_forward">
<code class="sig-name descname">chunk_forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">pos_enc: torch.Tensor</em>, <em class="sig-param">mask: torch.Tensor</em>, <em class="sig-param">left_context: int = 0</em>, <em class="sig-param">right_context: int = 0</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/modules/multi_blocks.html#MultiBlocks.chunk_forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.modules.multi_blocks.MultiBlocks.chunk_forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward each block of the encoder architecture.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – MultiBlocks input sequences. (B, T, D_block_1)</p></li>
<li><p><strong>pos_enc</strong> – Positional embedding sequences. (B, 2 * (T - 1), D_att)</p></li>
<li><p><strong>mask</strong> – Source mask. (B, T_2)</p></li>
<li><p><strong>left_context</strong> – Number of frames in left context.</p></li>
<li><p><strong>right_context</strong> – Number of frames in right context.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>MultiBlocks output sequences. (B, T, D_block_N)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>x</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.encoder.modules.multi_blocks.MultiBlocks.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">pos_enc: torch.Tensor</em>, <em class="sig-param">mask: torch.Tensor</em>, <em class="sig-param">chunk_mask: Optional[torch.Tensor] = None</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/modules/multi_blocks.html#MultiBlocks.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.modules.multi_blocks.MultiBlocks.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward each block of the encoder architecture.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – MultiBlocks input sequences. (B, T, D_block_1)</p></li>
<li><p><strong>pos_enc</strong> – Positional embedding sequences.</p></li>
<li><p><strong>mask</strong> – Source mask. (B, T)</p></li>
<li><p><strong>chunk_mask</strong> – Chunk mask. (T_2, T_2)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output sequences. (B, T, D_block_N)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>x</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.encoder.modules.multi_blocks.MultiBlocks.reset_streaming_cache">
<code class="sig-name descname">reset_streaming_cache</code><span class="sig-paren">(</span><em class="sig-param">left_context: int</em>, <em class="sig-param">device: torch.device</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/modules/multi_blocks.html#MultiBlocks.reset_streaming_cache"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.modules.multi_blocks.MultiBlocks.reset_streaming_cache" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize/Reset encoder streaming cache.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>left_context</strong> – Number of left frames during chunk-by-chunk inference.</p></li>
<li><p><strong>device</strong> – Device to use for cache tensor.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-transducer-encoder-modules-attention">
<span id="id13"></span><h2>espnet2.asr_transducer.encoder.modules.attention<a class="headerlink" href="#espnet2-asr-transducer-encoder-modules-attention" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.encoder.modules.attention"></span><p>Multi-Head attention layers with relative positional encoding.</p>
<dl class="class">
<dt id="espnet2.asr_transducer.encoder.modules.attention.RelPositionMultiHeadedAttention">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr_transducer.encoder.modules.attention.</code><code class="sig-name descname">RelPositionMultiHeadedAttention</code><span class="sig-paren">(</span><em class="sig-param">num_heads: int</em>, <em class="sig-param">embed_size: int</em>, <em class="sig-param">dropout_rate: float = 0.0</em>, <em class="sig-param">simplified_attention_score: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/modules/attention.html#RelPositionMultiHeadedAttention"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.modules.attention.RelPositionMultiHeadedAttention" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>RelPositionMultiHeadedAttention definition.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_heads</strong> – Number of attention heads.</p></li>
<li><p><strong>embed_size</strong> – Embedding size.</p></li>
<li><p><strong>dropout_rate</strong> – Dropout rate.</p></li>
</ul>
</dd>
</dl>
<p>Construct an MultiHeadedAttention object.</p>
<dl class="method">
<dt id="espnet2.asr_transducer.encoder.modules.attention.RelPositionMultiHeadedAttention.compute_attention_score">
<code class="sig-name descname">compute_attention_score</code><span class="sig-paren">(</span><em class="sig-param">query: torch.Tensor</em>, <em class="sig-param">key: torch.Tensor</em>, <em class="sig-param">pos_enc: torch.Tensor</em>, <em class="sig-param">left_context: int = 0</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/modules/attention.html#RelPositionMultiHeadedAttention.compute_attention_score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.modules.attention.RelPositionMultiHeadedAttention.compute_attention_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Attention score computation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>query</strong> – Transformed query tensor. (B, H, T_1, d_k)</p></li>
<li><p><strong>key</strong> – Transformed key tensor. (B, H, T_2, d_k)</p></li>
<li><p><strong>pos_enc</strong> – Positional embedding tensor. (B, 2 * T_1 - 1, size)</p></li>
<li><p><strong>left_context</strong> – Number of frames in left context.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Attention score. (B, H, T_1, T_2)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.encoder.modules.attention.RelPositionMultiHeadedAttention.compute_simplified_attention_score">
<code class="sig-name descname">compute_simplified_attention_score</code><span class="sig-paren">(</span><em class="sig-param">query: torch.Tensor</em>, <em class="sig-param">key: torch.Tensor</em>, <em class="sig-param">pos_enc: torch.Tensor</em>, <em class="sig-param">left_context: int = 0</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/modules/attention.html#RelPositionMultiHeadedAttention.compute_simplified_attention_score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.modules.attention.RelPositionMultiHeadedAttention.compute_simplified_attention_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Simplified attention score computation.</p>
<p>Reference: <a class="reference external" href="https://github.com/k2-fsa/icefall/pull/458">https://github.com/k2-fsa/icefall/pull/458</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>query</strong> – Transformed query tensor. (B, H, T_1, d_k)</p></li>
<li><p><strong>key</strong> – Transformed key tensor. (B, H, T_2, d_k)</p></li>
<li><p><strong>pos_enc</strong> – Positional embedding tensor. (B, 2 * T_1 - 1, size)</p></li>
<li><p><strong>left_context</strong> – Number of frames in left context.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Attention score. (B, H, T_1, T_2)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.encoder.modules.attention.RelPositionMultiHeadedAttention.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">query: torch.Tensor</em>, <em class="sig-param">key: torch.Tensor</em>, <em class="sig-param">value: torch.Tensor</em>, <em class="sig-param">pos_enc: torch.Tensor</em>, <em class="sig-param">mask: torch.Tensor</em>, <em class="sig-param">chunk_mask: Optional[torch.Tensor] = None</em>, <em class="sig-param">left_context: int = 0</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/modules/attention.html#RelPositionMultiHeadedAttention.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.modules.attention.RelPositionMultiHeadedAttention.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute scaled dot product attention with rel. positional encoding.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>query</strong> – Query tensor. (B, T_1, size)</p></li>
<li><p><strong>key</strong> – Key tensor. (B, T_2, size)</p></li>
<li><p><strong>value</strong> – Value tensor. (B, T_2, size)</p></li>
<li><p><strong>pos_enc</strong> – Positional embedding tensor. (B, 2 * T_1 - 1, size)</p></li>
<li><p><strong>mask</strong> – Source mask. (B, T_2)</p></li>
<li><p><strong>chunk_mask</strong> – Chunk mask. (T_1, T_1)</p></li>
<li><p><strong>left_context</strong> – Number of frames in left context.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor. (B, T_1, H * d_k)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.encoder.modules.attention.RelPositionMultiHeadedAttention.forward_attention">
<code class="sig-name descname">forward_attention</code><span class="sig-paren">(</span><em class="sig-param">value: torch.Tensor</em>, <em class="sig-param">scores: torch.Tensor</em>, <em class="sig-param">mask: torch.Tensor</em>, <em class="sig-param">chunk_mask: Optional[torch.Tensor] = None</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/modules/attention.html#RelPositionMultiHeadedAttention.forward_attention"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.modules.attention.RelPositionMultiHeadedAttention.forward_attention" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute attention context vector.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>value</strong> – Transformed value. (B, H, T_2, d_k)</p></li>
<li><p><strong>scores</strong> – Attention score. (B, H, T_1, T_2)</p></li>
<li><p><strong>mask</strong> – Source mask. (B, T_2)</p></li>
<li><p><strong>chunk_mask</strong> – Chunk mask. (T_1, T_1)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Transformed value weighted by attention score. (B, T_1, H * d_k)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>attn_output</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.encoder.modules.attention.RelPositionMultiHeadedAttention.forward_qkv">
<code class="sig-name descname">forward_qkv</code><span class="sig-paren">(</span><em class="sig-param">query: torch.Tensor</em>, <em class="sig-param">key: torch.Tensor</em>, <em class="sig-param">value: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/modules/attention.html#RelPositionMultiHeadedAttention.forward_qkv"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.modules.attention.RelPositionMultiHeadedAttention.forward_qkv" title="Permalink to this definition">¶</a></dt>
<dd><p>Transform query, key and value.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>query</strong> – Query tensor. (B, T_1, size)</p></li>
<li><p><strong>key</strong> – Key tensor. (B, T_2, size)</p></li>
<li><p><strong>v</strong> – Value tensor. (B, T_2, size)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Transformed query tensor. (B, H, T_1, d_k)
k: Transformed key tensor. (B, H, T_2, d_k)
v: Transformed value tensor. (B, H, T_2, d_k)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>q</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.encoder.modules.attention.RelPositionMultiHeadedAttention.rel_shift">
<code class="sig-name descname">rel_shift</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">left_context: int = 0</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/modules/attention.html#RelPositionMultiHeadedAttention.rel_shift"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.modules.attention.RelPositionMultiHeadedAttention.rel_shift" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute relative positional encoding.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Input sequence. (B, H, T_1, 2 * T_1 - 1)</p></li>
<li><p><strong>left_context</strong> – Number of frames in left context.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output sequence. (B, H, T_1, T_2)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>x</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-transducer-encoder-modules-positional-encoding">
<span id="id14"></span><h2>espnet2.asr_transducer.encoder.modules.positional_encoding<a class="headerlink" href="#espnet2-asr-transducer-encoder-modules-positional-encoding" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.encoder.modules.positional_encoding"></span><p>Positional encoding modules.</p>
<dl class="class">
<dt id="espnet2.asr_transducer.encoder.modules.positional_encoding.RelPositionalEncoding">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr_transducer.encoder.modules.positional_encoding.</code><code class="sig-name descname">RelPositionalEncoding</code><span class="sig-paren">(</span><em class="sig-param">size: int</em>, <em class="sig-param">dropout_rate: float = 0.0</em>, <em class="sig-param">max_len: int = 5000</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/modules/positional_encoding.html#RelPositionalEncoding"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.modules.positional_encoding.RelPositionalEncoding" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Relative positional encoding.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>size</strong> – Module size.</p></li>
<li><p><strong>max_len</strong> – Maximum input length.</p></li>
<li><p><strong>dropout_rate</strong> – Dropout rate.</p></li>
</ul>
</dd>
</dl>
<p>Construct a RelativePositionalEncoding object.</p>
<dl class="method">
<dt id="espnet2.asr_transducer.encoder.modules.positional_encoding.RelPositionalEncoding.extend_pe">
<code class="sig-name descname">extend_pe</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">left_context: int = 0</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/modules/positional_encoding.html#RelPositionalEncoding.extend_pe"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.modules.positional_encoding.RelPositionalEncoding.extend_pe" title="Permalink to this definition">¶</a></dt>
<dd><p>Reset positional encoding.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Input sequences. (B, T, ?)</p></li>
<li><p><strong>left_context</strong> – Number of frames in left context.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.encoder.modules.positional_encoding.RelPositionalEncoding.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">left_context: int = 0</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/modules/positional_encoding.html#RelPositionalEncoding.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.modules.positional_encoding.RelPositionalEncoding.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute positional encoding.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Input sequences. (B, T, ?)</p></li>
<li><p><strong>left_context</strong> – Number of frames in left context.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Positional embedding sequences. (B, 2 * (T - 1), ?)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>pos_enc</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-transducer-encoder-modules-normalization">
<span id="id15"></span><h2>espnet2.asr_transducer.encoder.modules.normalization<a class="headerlink" href="#espnet2-asr-transducer-encoder-modules-normalization" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.encoder.modules.normalization"></span><p>Normalization modules for X-former blocks.</p>
<dl class="class">
<dt id="espnet2.asr_transducer.encoder.modules.normalization.BasicNorm">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr_transducer.encoder.modules.normalization.</code><code class="sig-name descname">BasicNorm</code><span class="sig-paren">(</span><em class="sig-param">normalized_shape: int</em>, <em class="sig-param">eps: float = 0.25</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/modules/normalization.html#BasicNorm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.modules.normalization.BasicNorm" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>BasicNorm module definition.</p>
<p>Reference: <a class="reference external" href="https://github.com/k2-fsa/icefall/pull/288">https://github.com/k2-fsa/icefall/pull/288</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>normalized_shape</strong> – Expected size.</p></li>
<li><p><strong>eps</strong> – Value added to the denominator for numerical stability.</p></li>
</ul>
</dd>
</dl>
<p>Construct a BasicNorm object.</p>
<dl class="method">
<dt id="espnet2.asr_transducer.encoder.modules.normalization.BasicNorm.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/modules/normalization.html#BasicNorm.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.modules.normalization.BasicNorm.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute basic normalization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> – Input sequences. (B, T, D_hidden)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output sequences. (B, T, D_hidden)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.asr_transducer.encoder.modules.normalization.RMSNorm">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr_transducer.encoder.modules.normalization.</code><code class="sig-name descname">RMSNorm</code><span class="sig-paren">(</span><em class="sig-param">normalized_shape: int</em>, <em class="sig-param">eps: float = 1e-05</em>, <em class="sig-param">partial: float = 0.0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/modules/normalization.html#RMSNorm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.modules.normalization.RMSNorm" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>RMSNorm module definition.</p>
<p>Reference: <a class="reference external" href="https://arxiv.org/pdf/1910.07467.pdf">https://arxiv.org/pdf/1910.07467.pdf</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>normalized_shape</strong> – Expected size.</p></li>
<li><p><strong>eps</strong> – Value added to the denominator for numerical stability.</p></li>
<li><p><strong>partial</strong> – Value defining the part of the input used for RMS stats.</p></li>
</ul>
</dd>
</dl>
<p>Construct a RMSNorm object.</p>
<dl class="method">
<dt id="espnet2.asr_transducer.encoder.modules.normalization.RMSNorm.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/modules/normalization.html#RMSNorm.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.modules.normalization.RMSNorm.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute RMS normalization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> – Input sequences. (B, T, D_hidden)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output sequences. (B, T, D_hidden)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>x</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.asr_transducer.encoder.modules.normalization.ScaleNorm">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr_transducer.encoder.modules.normalization.</code><code class="sig-name descname">ScaleNorm</code><span class="sig-paren">(</span><em class="sig-param">normalized_shape: int</em>, <em class="sig-param">eps: float = 1e-05</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/modules/normalization.html#ScaleNorm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.modules.normalization.ScaleNorm" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>ScaleNorm module definition.</p>
<p>Reference: <a class="reference external" href="https://arxiv.org/pdf/1910.05895.pdf">https://arxiv.org/pdf/1910.05895.pdf</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>normalized_shape</strong> – Expected size.</p></li>
<li><p><strong>eps</strong> – Value added to the denominator for numerical stability.</p></li>
</ul>
</dd>
</dl>
<p>Construct a ScaleNorm object.</p>
<dl class="method">
<dt id="espnet2.asr_transducer.encoder.modules.normalization.ScaleNorm.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/modules/normalization.html#ScaleNorm.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.modules.normalization.ScaleNorm.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute scale normalization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> – Input sequences. (B, T, D_hidden)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output sequences. (B, T, D_hidden)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="espnet2.asr_transducer.encoder.modules.normalization.get_normalization">
<code class="sig-prename descclassname">espnet2.asr_transducer.encoder.modules.normalization.</code><code class="sig-name descname">get_normalization</code><span class="sig-paren">(</span><em class="sig-param">normalization_type: str</em>, <em class="sig-param">eps: Optional[float] = None</em>, <em class="sig-param">partial: Optional[float] = None</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.nn.modules.module.Module, Dict]<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/modules/normalization.html#get_normalization"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.modules.normalization.get_normalization" title="Permalink to this definition">¶</a></dt>
<dd><p>Get normalization module and arguments given parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>normalization_type</strong> – Normalization module type.</p></li>
<li><p><strong>eps</strong> – Value added to the denominator.</p></li>
<li><p><strong>partial</strong> – Value defining the part of the input used for RMS stats (RMSNorm).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Normalization module class
: Normalization module arguments</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="espnet2-asr-transducer-encoder-modules-convolution">
<span id="id16"></span><h2>espnet2.asr_transducer.encoder.modules.convolution<a class="headerlink" href="#espnet2-asr-transducer-encoder-modules-convolution" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.encoder.modules.convolution"></span><p>Convolution modules for X-former blocks.</p>
<dl class="class">
<dt id="espnet2.asr_transducer.encoder.modules.convolution.ConformerConvolution">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr_transducer.encoder.modules.convolution.</code><code class="sig-name descname">ConformerConvolution</code><span class="sig-paren">(</span><em class="sig-param">channels: int</em>, <em class="sig-param">kernel_size: int</em>, <em class="sig-param">activation: torch.nn.modules.module.Module = ReLU()</em>, <em class="sig-param">norm_args: Dict = {}</em>, <em class="sig-param">causal: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/modules/convolution.html#ConformerConvolution"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.modules.convolution.ConformerConvolution" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>ConformerConvolution module definition.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>channels</strong> – The number of channels.</p></li>
<li><p><strong>kernel_size</strong> – Size of the convolving kernel.</p></li>
<li><p><strong>activation</strong> – Type of activation function.</p></li>
<li><p><strong>norm_args</strong> – Normalization module arguments.</p></li>
<li><p><strong>causal</strong> – Whether to use causal convolution (set to True if streaming).</p></li>
</ul>
</dd>
</dl>
<p>Construct an ConformerConvolution object.</p>
<dl class="method">
<dt id="espnet2.asr_transducer.encoder.modules.convolution.ConformerConvolution.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">cache: Optional[torch.Tensor] = None</em>, <em class="sig-param">mask: Optional[torch.Tensor] = None</em>, <em class="sig-param">right_context: int = 0</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/modules/convolution.html#ConformerConvolution.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.modules.convolution.ConformerConvolution.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute convolution module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – ConformerConvolution input sequences. (B, T, D_hidden)</p></li>
<li><p><strong>cache</strong> – ConformerConvolution input cache. (1, conv_kernel, D_hidden)</p></li>
<li><p><strong>right_context</strong> – Number of frames in right context.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>ConformerConvolution output sequences. (B, T, D_hidden)
cache: ConformerConvolution output cache. (1, conv_kernel, D_hidden)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>x</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.asr_transducer.encoder.modules.convolution.ConvolutionalSpatialGatingUnit">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr_transducer.encoder.modules.convolution.</code><code class="sig-name descname">ConvolutionalSpatialGatingUnit</code><span class="sig-paren">(</span><em class="sig-param">size: int</em>, <em class="sig-param">kernel_size: int</em>, <em class="sig-param">norm_class: torch.nn.modules.module.Module = &lt;class 'torch.nn.modules.normalization.LayerNorm'&gt;</em>, <em class="sig-param">norm_args: Dict = {}</em>, <em class="sig-param">dropout_rate: float = 0.0</em>, <em class="sig-param">causal: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/modules/convolution.html#ConvolutionalSpatialGatingUnit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.modules.convolution.ConvolutionalSpatialGatingUnit" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Convolutional Spatial Gating Unit module definition.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>size</strong> – Initial size to determine the number of channels.</p></li>
<li><p><strong>kernel_size</strong> – Size of the convolving kernel.</p></li>
<li><p><strong>norm_class</strong> – Normalization module class.</p></li>
<li><p><strong>norm_args</strong> – Normalization module arguments.</p></li>
<li><p><strong>dropout_rate</strong> – Dropout rate.</p></li>
<li><p><strong>causal</strong> – Whether to use causal convolution (set to True if streaming).</p></li>
</ul>
</dd>
</dl>
<p>Construct a ConvolutionalSpatialGatingUnit object.</p>
<dl class="method">
<dt id="espnet2.asr_transducer.encoder.modules.convolution.ConvolutionalSpatialGatingUnit.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">cache: Optional[torch.Tensor] = None</em>, <em class="sig-param">right_context: int = 0</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/modules/convolution.html#ConvolutionalSpatialGatingUnit.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.modules.convolution.ConvolutionalSpatialGatingUnit.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute convolution module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – ConvolutionalSpatialGatingUnit input sequences. (B, T, D_hidden)</p></li>
<li><p><strong>cache</strong> – ConvolutionalSpationGatingUnit input cache.
(1, conv_kernel, D_hidden)</p></li>
<li><p><strong>right_context</strong> – Number of frames in right context.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>ConvolutionalSpatialGatingUnit output sequences. (B, T, D_hidden // 2)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>x</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-transducer-encoder-modules-init">
<span id="id17"></span><h2>espnet2.asr_transducer.encoder.modules.__init__<a class="headerlink" href="#espnet2-asr-transducer-encoder-modules-init" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.encoder.modules.__init__"></span></section>
<section id="espnet2-asr-transducer-encoder-blocks-conv-input">
<span id="id18"></span><h2>espnet2.asr_transducer.encoder.blocks.conv_input<a class="headerlink" href="#espnet2-asr-transducer-encoder-blocks-conv-input" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.encoder.blocks.conv_input"></span><p>ConvInput block for Transducer encoder.</p>
<dl class="class">
<dt id="espnet2.asr_transducer.encoder.blocks.conv_input.ConvInput">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr_transducer.encoder.blocks.conv_input.</code><code class="sig-name descname">ConvInput</code><span class="sig-paren">(</span><em class="sig-param">input_size: int, conv_size: Union[int, Tuple], subsampling_factor: int = 4, vgg_like: bool = True, output_size: Optional[int] = None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/blocks/conv_input.html#ConvInput"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.blocks.conv_input.ConvInput" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>ConvInput module definition.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> – Input size.</p></li>
<li><p><strong>conv_size</strong> – Convolution size.</p></li>
<li><p><strong>subsampling_factor</strong> – Subsampling factor.</p></li>
<li><p><strong>vgg_like</strong> – Whether to use a VGG-like network.</p></li>
<li><p><strong>output_size</strong> – Block output dimension.</p></li>
</ul>
</dd>
</dl>
<p>Construct a ConvInput object.</p>
<dl class="method">
<dt id="espnet2.asr_transducer.encoder.blocks.conv_input.ConvInput.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor, mask: Optional[torch.Tensor]</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/blocks/conv_input.html#ConvInput.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.blocks.conv_input.ConvInput.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Encode input sequences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – ConvInput input sequences. (B, T, D_feats)</p></li>
<li><p><strong>mask</strong> – Mask of input sequences. (B, 1, T)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>ConvInput output sequences. (B, sub(T), D_out)
mask: Mask of output sequences. (B, 1, sub(T))</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>x</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.encoder.blocks.conv_input.ConvInput.get_size_before_subsampling">
<code class="sig-name descname">get_size_before_subsampling</code><span class="sig-paren">(</span><em class="sig-param">size: int</em><span class="sig-paren">)</span> &#x2192; int<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/blocks/conv_input.html#ConvInput.get_size_before_subsampling"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.blocks.conv_input.ConvInput.get_size_before_subsampling" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the original size before subsampling for a given size.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>size</strong> – Number of frames after subsampling.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Number of frames before subsampling.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-transducer-encoder-blocks-branchformer">
<span id="id19"></span><h2>espnet2.asr_transducer.encoder.blocks.branchformer<a class="headerlink" href="#espnet2-asr-transducer-encoder-blocks-branchformer" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.encoder.blocks.branchformer"></span><p>Branchformer block for Transducer encoder.</p>
<dl class="class">
<dt id="espnet2.asr_transducer.encoder.blocks.branchformer.Branchformer">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr_transducer.encoder.blocks.branchformer.</code><code class="sig-name descname">Branchformer</code><span class="sig-paren">(</span><em class="sig-param">block_size: int</em>, <em class="sig-param">linear_size: int</em>, <em class="sig-param">self_att: torch.nn.modules.module.Module</em>, <em class="sig-param">conv_mod: torch.nn.modules.module.Module</em>, <em class="sig-param">norm_class: torch.nn.modules.module.Module = &lt;class 'torch.nn.modules.normalization.LayerNorm'&gt;</em>, <em class="sig-param">norm_args: Dict = {}</em>, <em class="sig-param">dropout_rate: float = 0.0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/blocks/branchformer.html#Branchformer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.blocks.branchformer.Branchformer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Branchformer module definition.</p>
<p>Reference: <a class="reference external" href="https://arxiv.org/pdf/2207.02971.pdf">https://arxiv.org/pdf/2207.02971.pdf</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>block_size</strong> – Input/output size.</p></li>
<li><p><strong>linear_size</strong> – Linear layers’ hidden size.</p></li>
<li><p><strong>self_att</strong> – Self-attention module instance.</p></li>
<li><p><strong>conv_mod</strong> – Convolution module instance.</p></li>
<li><p><strong>norm_class</strong> – Normalization class.</p></li>
<li><p><strong>norm_args</strong> – Normalization module arguments.</p></li>
<li><p><strong>dropout_rate</strong> – Dropout rate.</p></li>
</ul>
</dd>
</dl>
<p>Construct a Branchformer object.</p>
<dl class="method">
<dt id="espnet2.asr_transducer.encoder.blocks.branchformer.Branchformer.chunk_forward">
<code class="sig-name descname">chunk_forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">pos_enc: torch.Tensor</em>, <em class="sig-param">mask: torch.Tensor</em>, <em class="sig-param">left_context: int = 0</em>, <em class="sig-param">right_context: int = 0</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/blocks/branchformer.html#Branchformer.chunk_forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.blocks.branchformer.Branchformer.chunk_forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Encode chunk of input sequence.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Branchformer input sequences. (B, T, D_block)</p></li>
<li><p><strong>pos_enc</strong> – Positional embedding sequences. (B, 2 * (T - 1), D_block)</p></li>
<li><p><strong>mask</strong> – Source mask. (B, T_2)</p></li>
<li><p><strong>left_context</strong> – Number of frames in left context.</p></li>
<li><p><strong>right_context</strong> – Number of frames in right context.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Branchformer output sequences. (B, T, D_block)
pos_enc: Positional embedding sequences. (B, 2 * (T - 1), D_block)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>x</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.encoder.blocks.branchformer.Branchformer.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">pos_enc: torch.Tensor</em>, <em class="sig-param">mask: torch.Tensor</em>, <em class="sig-param">chunk_mask: Optional[torch.Tensor] = None</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/blocks/branchformer.html#Branchformer.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.blocks.branchformer.Branchformer.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Encode input sequences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Branchformer input sequences. (B, T, D_block)</p></li>
<li><p><strong>pos_enc</strong> – Positional embedding sequences. (B, 2 * (T - 1), D_block)</p></li>
<li><p><strong>mask</strong> – Source mask. (B, T)</p></li>
<li><p><strong>chunk_mask</strong> – Chunk mask. (T_2, T_2)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Branchformer output sequences. (B, T, D_block)
mask: Source mask. (B, T)
pos_enc: Positional embedding sequences. (B, 2 * (T - 1), D_block)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>x</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.encoder.blocks.branchformer.Branchformer.reset_streaming_cache">
<code class="sig-name descname">reset_streaming_cache</code><span class="sig-paren">(</span><em class="sig-param">left_context: int</em>, <em class="sig-param">device: torch.device</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/blocks/branchformer.html#Branchformer.reset_streaming_cache"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.blocks.branchformer.Branchformer.reset_streaming_cache" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize/Reset self-attention and convolution modules cache for streaming.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>left_context</strong> – Number of left frames during chunk-by-chunk inference.</p></li>
<li><p><strong>device</strong> – Device to use for cache tensor.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-transducer-encoder-blocks-conformer">
<span id="id20"></span><h2>espnet2.asr_transducer.encoder.blocks.conformer<a class="headerlink" href="#espnet2-asr-transducer-encoder-blocks-conformer" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.encoder.blocks.conformer"></span><p>Conformer block for Transducer encoder.</p>
<dl class="class">
<dt id="espnet2.asr_transducer.encoder.blocks.conformer.Conformer">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr_transducer.encoder.blocks.conformer.</code><code class="sig-name descname">Conformer</code><span class="sig-paren">(</span><em class="sig-param">block_size: int</em>, <em class="sig-param">self_att: torch.nn.modules.module.Module</em>, <em class="sig-param">feed_forward: torch.nn.modules.module.Module</em>, <em class="sig-param">feed_forward_macaron: torch.nn.modules.module.Module</em>, <em class="sig-param">conv_mod: torch.nn.modules.module.Module</em>, <em class="sig-param">norm_class: torch.nn.modules.module.Module = &lt;class 'torch.nn.modules.normalization.LayerNorm'&gt;</em>, <em class="sig-param">norm_args: Dict = {}</em>, <em class="sig-param">dropout_rate: float = 0.0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/blocks/conformer.html#Conformer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.blocks.conformer.Conformer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Conformer module definition.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>block_size</strong> – Input/output size.</p></li>
<li><p><strong>self_att</strong> – Self-attention module instance.</p></li>
<li><p><strong>feed_forward</strong> – Feed-forward module instance.</p></li>
<li><p><strong>feed_forward_macaron</strong> – Feed-forward module instance for macaron network.</p></li>
<li><p><strong>conv_mod</strong> – Convolution module instance.</p></li>
<li><p><strong>norm_class</strong> – Normalization module class.</p></li>
<li><p><strong>norm_args</strong> – Normalization module arguments.</p></li>
<li><p><strong>dropout_rate</strong> – Dropout rate.</p></li>
</ul>
</dd>
</dl>
<p>Construct a Conformer object.</p>
<dl class="method">
<dt id="espnet2.asr_transducer.encoder.blocks.conformer.Conformer.chunk_forward">
<code class="sig-name descname">chunk_forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">pos_enc: torch.Tensor</em>, <em class="sig-param">mask: torch.Tensor</em>, <em class="sig-param">left_context: int = 0</em>, <em class="sig-param">right_context: int = 0</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/blocks/conformer.html#Conformer.chunk_forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.blocks.conformer.Conformer.chunk_forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Encode chunk of input sequence.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Conformer input sequences. (B, T, D_block)</p></li>
<li><p><strong>pos_enc</strong> – Positional embedding sequences. (B, 2 * (T - 1), D_block)</p></li>
<li><p><strong>mask</strong> – Source mask. (B, T_2)</p></li>
<li><p><strong>left_context</strong> – Number of frames in left context.</p></li>
<li><p><strong>right_context</strong> – Number of frames in right context.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Conformer output sequences. (B, T, D_block)
pos_enc: Positional embedding sequences. (B, 2 * (T - 1), D_block)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>x</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.encoder.blocks.conformer.Conformer.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">pos_enc: torch.Tensor</em>, <em class="sig-param">mask: torch.Tensor</em>, <em class="sig-param">chunk_mask: Optional[torch.Tensor] = None</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/blocks/conformer.html#Conformer.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.blocks.conformer.Conformer.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Encode input sequences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Conformer input sequences. (B, T, D_block)</p></li>
<li><p><strong>pos_enc</strong> – Positional embedding sequences. (B, 2 * (T - 1), D_block)</p></li>
<li><p><strong>mask</strong> – Source mask. (B, T)</p></li>
<li><p><strong>chunk_mask</strong> – Chunk mask. (T_2, T_2)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Conformer output sequences. (B, T, D_block)
mask: Source mask. (B, T)
pos_enc: Positional embedding sequences. (B, 2 * (T - 1), D_block)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>x</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.encoder.blocks.conformer.Conformer.reset_streaming_cache">
<code class="sig-name descname">reset_streaming_cache</code><span class="sig-paren">(</span><em class="sig-param">left_context: int</em>, <em class="sig-param">device: torch.device</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/blocks/conformer.html#Conformer.reset_streaming_cache"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.blocks.conformer.Conformer.reset_streaming_cache" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize/Reset self-attention and convolution modules cache for streaming.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>left_context</strong> – Number of left frames during chunk-by-chunk inference.</p></li>
<li><p><strong>device</strong> – Device to use for cache tensor.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-transducer-encoder-blocks-init">
<span id="id21"></span><h2>espnet2.asr_transducer.encoder.blocks.__init__<a class="headerlink" href="#espnet2-asr-transducer-encoder-blocks-init" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.encoder.blocks.__init__"></span></section>
<section id="espnet2-asr-transducer-encoder-blocks-conv1d">
<span id="id22"></span><h2>espnet2.asr_transducer.encoder.blocks.conv1d<a class="headerlink" href="#espnet2-asr-transducer-encoder-blocks-conv1d" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.encoder.blocks.conv1d"></span><p>Conv1d block for Transducer encoder.</p>
<dl class="class">
<dt id="espnet2.asr_transducer.encoder.blocks.conv1d.Conv1d">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr_transducer.encoder.blocks.conv1d.</code><code class="sig-name descname">Conv1d</code><span class="sig-paren">(</span><em class="sig-param">input_size: int, output_size: int, kernel_size: Union[int, Tuple], stride: Union[int, Tuple] = 1, dilation: Union[int, Tuple] = 1, groups: Union[int, Tuple] = 1, bias: bool = True, batch_norm: bool = False, relu: bool = True, causal: bool = False, dropout_rate: float = 0.0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/blocks/conv1d.html#Conv1d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.blocks.conv1d.Conv1d" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Conv1d module definition.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> – Input dimension.</p></li>
<li><p><strong>output_size</strong> – Output dimension.</p></li>
<li><p><strong>kernel_size</strong> – Size of the convolving kernel.</p></li>
<li><p><strong>stride</strong> – Stride of the convolution.</p></li>
<li><p><strong>dilation</strong> – Spacing between the kernel points.</p></li>
<li><p><strong>groups</strong> – Number of blocked connections from input channels to output channels.</p></li>
<li><p><strong>bias</strong> – Whether to add a learnable bias to the output.</p></li>
<li><p><strong>batch_norm</strong> – Whether to use batch normalization after convolution.</p></li>
<li><p><strong>relu</strong> – Whether to use a ReLU activation after convolution.</p></li>
<li><p><strong>causal</strong> – Whether to use causal convolution (set to True if streaming).</p></li>
<li><p><strong>dropout_rate</strong> – Dropout rate.</p></li>
</ul>
</dd>
</dl>
<p>Construct a Conv1d object.</p>
<dl class="method">
<dt id="espnet2.asr_transducer.encoder.blocks.conv1d.Conv1d.chunk_forward">
<code class="sig-name descname">chunk_forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">pos_enc: torch.Tensor</em>, <em class="sig-param">mask: torch.Tensor</em>, <em class="sig-param">left_context: int = 0</em>, <em class="sig-param">right_context: int = 0</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/blocks/conv1d.html#Conv1d.chunk_forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.blocks.conv1d.Conv1d.chunk_forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Encode chunk of input sequence.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Conv1d input sequences. (B, T, D_in)</p></li>
<li><p><strong>pos_enc</strong> – Positional embedding sequences. (B, 2 * (T - 1), D_in)</p></li>
<li><p><strong>mask</strong> – Source mask. (B, T)</p></li>
<li><p><strong>left_context</strong> – Number of frames in left context.</p></li>
<li><p><strong>right_context</strong> – Number of frames in right context.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Conv1d output sequences. (B, T, D_out)
pos_enc: Positional embedding sequences. (B, 2 * (T - 1), D_out)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>x</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.encoder.blocks.conv1d.Conv1d.create_new_mask">
<code class="sig-name descname">create_new_mask</code><span class="sig-paren">(</span><em class="sig-param">mask: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/blocks/conv1d.html#Conv1d.create_new_mask"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.blocks.conv1d.Conv1d.create_new_mask" title="Permalink to this definition">¶</a></dt>
<dd><p>Create new mask for output sequences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>mask</strong> – Mask of input sequences. (B, T)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Mask of output sequences. (B, sub(T))</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>mask</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.encoder.blocks.conv1d.Conv1d.create_new_pos_enc">
<code class="sig-name descname">create_new_pos_enc</code><span class="sig-paren">(</span><em class="sig-param">pos_enc: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/blocks/conv1d.html#Conv1d.create_new_pos_enc"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.blocks.conv1d.Conv1d.create_new_pos_enc" title="Permalink to this definition">¶</a></dt>
<dd><p>Create new positional embedding vector.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>pos_enc</strong> – Input sequences positional embedding.
(B, 2 * (T - 1), D_in)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>Output sequences positional embedding.</dt><dd><p>(B, 2 * (sub(T) - 1), D_in)</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>pos_enc</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.encoder.blocks.conv1d.Conv1d.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">pos_enc: torch.Tensor</em>, <em class="sig-param">mask: Optional[torch.Tensor] = None</em>, <em class="sig-param">chunk_mask: Optional[torch.Tensor] = None</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/blocks/conv1d.html#Conv1d.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.blocks.conv1d.Conv1d.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Encode input sequences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Conv1d input sequences. (B, T, D_in)</p></li>
<li><p><strong>pos_enc</strong> – Positional embedding sequences. (B, 2 * (T - 1), D_in)</p></li>
<li><p><strong>mask</strong> – Source mask. (B, T)</p></li>
<li><p><strong>chunk_mask</strong> – Chunk mask. (T_2, T_2)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>Conv1d output sequences. (B, sub(T), D_out)
mask: Source mask. (B, T) or (B, sub(T))
pos_enc: Positional embedding sequences.</p>
<blockquote>
<div><p>(B, 2 * (T - 1), D_att) or (B, 2 * (sub(T) - 1), D_out)</p>
</div></blockquote>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>x</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.encoder.blocks.conv1d.Conv1d.reset_streaming_cache">
<code class="sig-name descname">reset_streaming_cache</code><span class="sig-paren">(</span><em class="sig-param">left_context: int</em>, <em class="sig-param">device: torch.device</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/blocks/conv1d.html#Conv1d.reset_streaming_cache"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.blocks.conv1d.Conv1d.reset_streaming_cache" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize/Reset Conv1d cache for streaming.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>left_context</strong> – Number of left frames during chunk-by-chunk inference.</p></li>
<li><p><strong>device</strong> – Device to use for cache tensor.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-transducer-decoder-rnn-decoder">
<span id="id23"></span><h2>espnet2.asr_transducer.decoder.rnn_decoder<a class="headerlink" href="#espnet2-asr-transducer-decoder-rnn-decoder" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.decoder.rnn_decoder"></span><p>RNN decoder definition for Transducer models.</p>
<dl class="class">
<dt id="espnet2.asr_transducer.decoder.rnn_decoder.RNNDecoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr_transducer.decoder.rnn_decoder.</code><code class="sig-name descname">RNNDecoder</code><span class="sig-paren">(</span><em class="sig-param">vocab_size: int</em>, <em class="sig-param">embed_size: int = 256</em>, <em class="sig-param">hidden_size: int = 256</em>, <em class="sig-param">rnn_type: str = 'lstm'</em>, <em class="sig-param">num_layers: int = 1</em>, <em class="sig-param">dropout_rate: float = 0.0</em>, <em class="sig-param">embed_dropout_rate: float = 0.0</em>, <em class="sig-param">embed_pad: int = 0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/rnn_decoder.html#RNNDecoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.rnn_decoder.RNNDecoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr_transducer.decoder.abs_decoder.AbsDecoder" title="espnet2.asr_transducer.decoder.abs_decoder.AbsDecoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr_transducer.decoder.abs_decoder.AbsDecoder</span></code></a></p>
<p>RNN decoder module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>vocab_size</strong> – Vocabulary size.</p></li>
<li><p><strong>embed_size</strong> – Embedding size.</p></li>
<li><p><strong>hidden_size</strong> – Hidden size..</p></li>
<li><p><strong>rnn_type</strong> – Decoder layers type.</p></li>
<li><p><strong>num_layers</strong> – Number of decoder layers.</p></li>
<li><p><strong>dropout_rate</strong> – Dropout rate for decoder layers.</p></li>
<li><p><strong>embed_dropout_rate</strong> – Dropout rate for embedding layer.</p></li>
<li><p><strong>embed_pad</strong> – Embedding padding symbol ID.</p></li>
</ul>
</dd>
</dl>
<p>Construct a RNNDecoder object.</p>
<dl class="method">
<dt id="espnet2.asr_transducer.decoder.rnn_decoder.RNNDecoder.batch_score">
<code class="sig-name descname">batch_score</code><span class="sig-paren">(</span><em class="sig-param">hyps: List[espnet2.asr_transducer.beam_search_transducer.Hypothesis]</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, Tuple[torch.Tensor, Optional[torch.Tensor]]]<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/rnn_decoder.html#RNNDecoder.batch_score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.rnn_decoder.RNNDecoder.batch_score" title="Permalink to this definition">¶</a></dt>
<dd><p>One-step forward hypotheses.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>hyps</strong> – Hypotheses.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Decoder output sequences. (B, D_dec)
states: Decoder hidden states. ((N, B, D_dec), (N, B, D_dec) or None)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dec_out</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.rnn_decoder.RNNDecoder.create_batch_states">
<code class="sig-name descname">create_batch_states</code><span class="sig-paren">(</span><em class="sig-param">new_states: List[Tuple[torch.Tensor, Optional[torch.Tensor]]]</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, Optional[torch.Tensor]]<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/rnn_decoder.html#RNNDecoder.create_batch_states"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.rnn_decoder.RNNDecoder.create_batch_states" title="Permalink to this definition">¶</a></dt>
<dd><p>Create decoder hidden states.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>new_states</strong> – Decoder hidden states. [N x ((1, D_dec), (1, D_dec) or None)]</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Decoder hidden states. ((N, B, D_dec), (N, B, D_dec) or None)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>states</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.rnn_decoder.RNNDecoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">labels: torch.Tensor</em>, <em class="sig-param">states: Optional[Tuple[torch.Tensor</em>, <em class="sig-param">Optional[torch.Tensor]]] = None</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/rnn_decoder.html#RNNDecoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.rnn_decoder.RNNDecoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Encode source label sequences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>labels</strong> – Label ID sequences. (B, L)</p></li>
<li><p><strong>states</strong> – Decoder hidden states.
((N, B, D_dec), (N, B, D_dec) or None) or None</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Decoder output sequences. (B, U, D_dec)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dec_out</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.rnn_decoder.RNNDecoder.init_state">
<code class="sig-name descname">init_state</code><span class="sig-paren">(</span><em class="sig-param">batch_size: int</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, Optional[torch._VariableFunctionsClass.tensor]]<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/rnn_decoder.html#RNNDecoder.init_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.rnn_decoder.RNNDecoder.init_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize decoder states.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>batch_size</strong> – Batch size.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Initial decoder hidden states. ((N, B, D_dec), (N, B, D_dec) or None)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.rnn_decoder.RNNDecoder.rnn_forward">
<code class="sig-name descname">rnn_forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor, state: Tuple[torch.Tensor, Optional[torch.Tensor]]</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, Tuple[torch.Tensor, Optional[torch.Tensor]]]<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/rnn_decoder.html#RNNDecoder.rnn_forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.rnn_decoder.RNNDecoder.rnn_forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Encode source label sequences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – RNN input sequences. (B, D_emb)</p></li>
<li><p><strong>state</strong> – Decoder hidden states. ((N, B, D_dec), (N, B, D_dec) or None)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>RNN output sequences. (B, D_dec)
(h_next, c_next): Decoder hidden states.</p>
<blockquote>
<div><p>(N, B, D_dec), (N, B, D_dec) or None)</p>
</div></blockquote>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>x</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.rnn_decoder.RNNDecoder.score">
<code class="sig-name descname">score</code><span class="sig-paren">(</span><em class="sig-param">label: torch.Tensor, label_sequence: List[int], dec_state: Tuple[torch.Tensor, Optional[torch.Tensor]]</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, Tuple[torch.Tensor, Optional[torch.Tensor]]]<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/rnn_decoder.html#RNNDecoder.score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.rnn_decoder.RNNDecoder.score" title="Permalink to this definition">¶</a></dt>
<dd><p>One-step forward hypothesis.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>label</strong> – Previous label. (1, 1)</p></li>
<li><p><strong>label_sequence</strong> – Current label sequence.</p></li>
<li><p><strong>dec_state</strong> – Previous decoder hidden states.
((N, 1, D_dec), (N, 1, D_dec) or None)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>Decoder output sequence. (1, D_dec)
dec_state: Decoder hidden states.</p>
<blockquote>
<div><p>((N, 1, D_dec), (N, 1, D_dec) or None)</p>
</div></blockquote>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dec_out</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.rnn_decoder.RNNDecoder.select_state">
<code class="sig-name descname">select_state</code><span class="sig-paren">(</span><em class="sig-param">states: Tuple[torch.Tensor, Optional[torch.Tensor]], idx: int</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, Optional[torch.Tensor]]<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/rnn_decoder.html#RNNDecoder.select_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.rnn_decoder.RNNDecoder.select_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Get specified ID state from decoder hidden states.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>states</strong> – Decoder hidden states. ((N, B, D_dec), (N, B, D_dec) or None)</p></li>
<li><p><strong>idx</strong> – State ID to extract.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Decoder hidden state for given ID. ((N, 1, D_dec), (N, 1, D_dec) or None)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.rnn_decoder.RNNDecoder.set_device">
<code class="sig-name descname">set_device</code><span class="sig-paren">(</span><em class="sig-param">device: torch.device</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/rnn_decoder.html#RNNDecoder.set_device"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.rnn_decoder.RNNDecoder.set_device" title="Permalink to this definition">¶</a></dt>
<dd><p>Set GPU device to use.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>device</strong> – Device ID.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-transducer-decoder-stateless-decoder">
<span id="id24"></span><h2>espnet2.asr_transducer.decoder.stateless_decoder<a class="headerlink" href="#espnet2-asr-transducer-decoder-stateless-decoder" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.decoder.stateless_decoder"></span><p>Stateless decoder definition for Transducer models.</p>
<dl class="class">
<dt id="espnet2.asr_transducer.decoder.stateless_decoder.StatelessDecoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr_transducer.decoder.stateless_decoder.</code><code class="sig-name descname">StatelessDecoder</code><span class="sig-paren">(</span><em class="sig-param">vocab_size: int</em>, <em class="sig-param">embed_size: int = 256</em>, <em class="sig-param">embed_dropout_rate: float = 0.0</em>, <em class="sig-param">embed_pad: int = 0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/stateless_decoder.html#StatelessDecoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.stateless_decoder.StatelessDecoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr_transducer.decoder.abs_decoder.AbsDecoder" title="espnet2.asr_transducer.decoder.abs_decoder.AbsDecoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr_transducer.decoder.abs_decoder.AbsDecoder</span></code></a></p>
<p>Stateless Transducer decoder module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>vocab_size</strong> – Output size.</p></li>
<li><p><strong>embed_size</strong> – Embedding size.</p></li>
<li><p><strong>embed_dropout_rate</strong> – Dropout rate for embedding layer.</p></li>
<li><p><strong>embed_pad</strong> – Embed/Blank symbol ID.</p></li>
</ul>
</dd>
</dl>
<p>Construct a StatelessDecoder object.</p>
<dl class="method">
<dt id="espnet2.asr_transducer.decoder.stateless_decoder.StatelessDecoder.batch_score">
<code class="sig-name descname">batch_score</code><span class="sig-paren">(</span><em class="sig-param">hyps: List[espnet2.asr_transducer.beam_search_transducer.Hypothesis]</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, None]<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/stateless_decoder.html#StatelessDecoder.batch_score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.stateless_decoder.StatelessDecoder.batch_score" title="Permalink to this definition">¶</a></dt>
<dd><p>One-step forward hypotheses.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>hyps</strong> – Hypotheses.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Decoder output sequences. (B, D_dec)
states: Decoder hidden states. None</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dec_out</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.stateless_decoder.StatelessDecoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">labels: torch.Tensor</em>, <em class="sig-param">states: Optional[Tuple[torch.Tensor</em>, <em class="sig-param">Optional[torch.Tensor]]] = None</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/stateless_decoder.html#StatelessDecoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.stateless_decoder.StatelessDecoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Encode source label sequences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>labels</strong> – Label ID sequences. (B, L)</p></li>
<li><p><strong>states</strong> – Decoder hidden states. None</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Decoder output sequences. (B, U, D_emb)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dec_embed</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.stateless_decoder.StatelessDecoder.init_state">
<code class="sig-name descname">init_state</code><span class="sig-paren">(</span><em class="sig-param">batch_size: int</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/stateless_decoder.html#StatelessDecoder.init_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.stateless_decoder.StatelessDecoder.init_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize decoder states.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>batch_size</strong> – Batch size.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Initial decoder hidden states. None</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.stateless_decoder.StatelessDecoder.score">
<code class="sig-name descname">score</code><span class="sig-paren">(</span><em class="sig-param">label: torch.Tensor, label_sequence: List[int], state: None</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, None]<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/stateless_decoder.html#StatelessDecoder.score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.stateless_decoder.StatelessDecoder.score" title="Permalink to this definition">¶</a></dt>
<dd><p>One-step forward hypothesis.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>label</strong> – Previous label. (1, 1)</p></li>
<li><p><strong>label_sequence</strong> – Current label sequence.</p></li>
<li><p><strong>state</strong> – Previous decoder hidden states. None</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Decoder output sequence. (1, D_emb)
state: Decoder hidden states. None</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dec_out</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.stateless_decoder.StatelessDecoder.select_state">
<code class="sig-name descname">select_state</code><span class="sig-paren">(</span><em class="sig-param">states: Optional[torch.Tensor], idx: int</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/stateless_decoder.html#StatelessDecoder.select_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.stateless_decoder.StatelessDecoder.select_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Get specified ID state from decoder hidden states.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>states</strong> – Decoder hidden states. None</p></li>
<li><p><strong>idx</strong> – State ID to extract.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Decoder hidden state for given ID. None</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.stateless_decoder.StatelessDecoder.set_device">
<code class="sig-name descname">set_device</code><span class="sig-paren">(</span><em class="sig-param">device: torch.device</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/stateless_decoder.html#StatelessDecoder.set_device"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.stateless_decoder.StatelessDecoder.set_device" title="Permalink to this definition">¶</a></dt>
<dd><p>Set GPU device to use.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>device</strong> – Device ID.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-transducer-decoder-init">
<span id="id25"></span><h2>espnet2.asr_transducer.decoder.__init__<a class="headerlink" href="#espnet2-asr-transducer-decoder-init" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.decoder.__init__"></span></section>
<section id="espnet2-asr-transducer-decoder-abs-decoder">
<span id="id26"></span><h2>espnet2.asr_transducer.decoder.abs_decoder<a class="headerlink" href="#espnet2-asr-transducer-decoder-abs-decoder" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.decoder.abs_decoder"></span><p>Abstract decoder definition for Transducer models.</p>
<dl class="class">
<dt id="espnet2.asr_transducer.decoder.abs_decoder.AbsDecoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr_transducer.decoder.abs_decoder.</code><code class="sig-name descname">AbsDecoder</code><a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/abs_decoder.html#AbsDecoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.abs_decoder.AbsDecoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code></p>
<p>Abstract decoder module.</p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="method">
<dt id="espnet2.asr_transducer.decoder.abs_decoder.AbsDecoder.batch_score">
<em class="property">abstract </em><code class="sig-name descname">batch_score</code><span class="sig-paren">(</span><em class="sig-param">hyps: List[Any]</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, Optional[Tuple[torch.Tensor, Optional[torch.Tensor]]]]<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/abs_decoder.html#AbsDecoder.batch_score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.abs_decoder.AbsDecoder.batch_score" title="Permalink to this definition">¶</a></dt>
<dd><p>One-step forward hypotheses.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>hyps</strong> – Hypotheses.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>Decoder output sequences. (B, D_dec) or (B, D_emb)
states: Decoder hidden states.</p>
<blockquote>
<div><p>((N, B, D_dec), (N, B, D_dec) or None) or None</p>
</div></blockquote>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dec_out</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.abs_decoder.AbsDecoder.forward">
<em class="property">abstract </em><code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">labels: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/abs_decoder.html#AbsDecoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.abs_decoder.AbsDecoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Encode source label sequences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>labels</strong> – Label ID sequences. (B, L)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Decoder output sequences. (B, T, D_dec)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dec_out</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.abs_decoder.AbsDecoder.init_state">
<em class="property">abstract </em><code class="sig-name descname">init_state</code><span class="sig-paren">(</span><em class="sig-param">batch_size: int</em><span class="sig-paren">)</span> &#x2192; Optional[Tuple[torch.Tensor, Optional[torch._VariableFunctionsClass.tensor]]]<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/abs_decoder.html#AbsDecoder.init_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.abs_decoder.AbsDecoder.init_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize decoder states.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>batch_size</strong> – Batch size.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>Initial decoder hidden states.</dt><dd><p>((N, B, D_dec), (N, B, D_dec) or None) or None</p>
</dd>
</dl>
</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.abs_decoder.AbsDecoder.score">
<em class="property">abstract </em><code class="sig-name descname">score</code><span class="sig-paren">(</span><em class="sig-param">label: torch.Tensor, label_sequence: List[int], dec_state: Optional[Tuple[torch.Tensor, Optional[torch.Tensor]]]</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, Optional[Tuple[torch.Tensor, Optional[torch.Tensor]]]]<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/abs_decoder.html#AbsDecoder.score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.abs_decoder.AbsDecoder.score" title="Permalink to this definition">¶</a></dt>
<dd><p>One-step forward hypothesis.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>label</strong> – Previous label. (1, 1)</p></li>
<li><p><strong>label_sequence</strong> – Current label sequence.</p></li>
<li><p><strong>dec_state</strong> – Previous decoder hidden states.
((N, 1, D_dec), (N, 1, D_dec) or None) or None</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>Decoder output sequence. (1, D_dec) or (1, D_emb)
dec_state: Decoder hidden states.</p>
<blockquote>
<div><p>((N, 1, D_dec), (N, 1, D_dec) or None) or None</p>
</div></blockquote>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dec_out</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.abs_decoder.AbsDecoder.select_state">
<em class="property">abstract </em><code class="sig-name descname">select_state</code><span class="sig-paren">(</span><em class="sig-param">states: Optional[Tuple[torch.Tensor</em>, <em class="sig-param">Optional[torch.Tensor]]] = None</em>, <em class="sig-param">idx: int = 0</em><span class="sig-paren">)</span> &#x2192; Optional[Tuple[torch.Tensor, Optional[torch.Tensor]]]<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/abs_decoder.html#AbsDecoder.select_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.abs_decoder.AbsDecoder.select_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Get specified ID state from batch of states, if provided.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>states</strong> – Decoder hidden states.
((N, B, D_dec), (N, B, D_dec) or None) or None</p></li>
<li><p><strong>idx</strong> – State ID to extract.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>Decoder hidden state for given ID.</dt><dd><p>((N, 1, D_dec), (N, 1, D_dec) or None) or None</p>
</dd>
</dl>
</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.abs_decoder.AbsDecoder.set_device">
<em class="property">abstract </em><code class="sig-name descname">set_device</code><span class="sig-paren">(</span><em class="sig-param">device: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/abs_decoder.html#AbsDecoder.set_device"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.abs_decoder.AbsDecoder.set_device" title="Permalink to this definition">¶</a></dt>
<dd><p>Set GPU device to use.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>device</strong> – Device ID.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="espnet2.enh.html" class="btn btn-neutral float-left" title="espnet2.enh package" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../apis/espnet_bin.html" class="btn btn-neutral float-right" title="core tools" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2017, Shinji Watanabe.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>