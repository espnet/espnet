<!doctype html>
<html lang="en-US" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.14" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.51" />
    <style>
      html {
        background: var(--bg-color, #fff);
      }

      html[data-theme="dark"] {
        background: var(--bg-color, #1d1e1f);
      }

      body {
        background: var(--bg-color);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <link rel="icon" href="/espnet/assets/image/espnet.png"><title>Text-to-Speech</title><meta name="description" content="A documentation for ESPnet">
    <link rel="preload" href="/espnet/assets/style-CiXYLHjk.css" as="style"><link rel="stylesheet" href="/espnet/assets/style-CiXYLHjk.css">
    <link rel="modulepreload" href="/espnet/assets/app-B6Ithpv3.js">
    
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">Skip to main content</a><!--]--><!--[--><div class="theme-container external-link-icon"><!--[--><header id="navbar" class="vp-navbar"><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!----><!--[--><a class="route-link vp-brand" href="/espnet/"><img class="vp-nav-logo" src="/espnet/assets/image/espnet_logo1.png" alt><!----><!----></a><!--]--><!----></div><div class="vp-navbar-center"><!----><!--[--><nav class="vp-nav-links"><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="Demos"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="fa-solid:laptop-code" width="1em" height="1em"></iconify-icon>Demos<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/notebook/" aria-label="Roadmap"><!---->Roadmap<!----></a></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">ESPnet2</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/notebook/ESPnet2/Demo/" aria-label="Demo"><!---->Demo<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/notebook/ESPnet2/Course/" aria-label="Course"><!---->Course<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">ESPnet-EZ</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/notebook/ESPnetEZ/" aria-label="ESPnet EZ"><!---->ESPnet EZ<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">ESPnet1 (Legacy)</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/notebook/ESPnet1/" aria-label="ESPnet1"><!---->ESPnet1<!----></a></li></ul></li></ul></button></div></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="Recipes"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="fa-solid:mug-hot" width="1em" height="1em"></iconify-icon>Recipes<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link route-link-active auto-link" href="/espnet/recipe/" aria-label="What is a recipe template?"><!---->What is a recipe template?<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/asr1.html" aria-label="Automatic Speech Recognition (Multi-tasking)"><!---->Automatic Speech Recognition (Multi-tasking)<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/asr2.html" aria-label="Automatic Speech Recognition with Discrete Units"><!---->Automatic Speech Recognition with Discrete Units<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/asvspoof1.html" aria-label="Speaker Verification Spoofing and Countermeasures"><!---->Speaker Verification Spoofing and Countermeasures<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/codec1.html" aria-label="Speech Codec"><!---->Speech Codec<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/diar1.html" aria-label="Speaker Diarisation"><!---->Speaker Diarisation<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/enh1.html" aria-label="Speech Enhancement"><!---->Speech Enhancement<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/enh_asr1.html" aria-label="Speech Recognition with Speech Enhancement"><!---->Speech Recognition with Speech Enhancement<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/enh_diar1.html" aria-label="Speaker Diarisation with Speech Enhancement"><!---->Speaker Diarisation with Speech Enhancement<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/enh_st1.html" aria-label="Speech-to-Text Translation with Speech Enhancement"><!---->Speech-to-Text Translation with Speech Enhancement<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/lm1.html" aria-label="Language Modeling"><!---->Language Modeling<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/mt1.html" aria-label="Machine Translation"><!---->Machine Translation<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/s2st1.html" aria-label="Speech-to-Speech Translation"><!---->Speech-to-Speech Translation<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/s2t1.html" aria-label="Weakly-supervised Learning (Speech-to-Text)"><!---->Weakly-supervised Learning (Speech-to-Text)<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/slu1.html" aria-label="Spoken Language Understanding"><!---->Spoken Language Understanding<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/speechlm1.html" aria-label="Speech Language Model"><!---->Speech Language Model<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/spk1.html" aria-label="Speaker Representation"><!---->Speaker Representation<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/ssl1.html" aria-label="Self-supervised Learning"><!---->Self-supervised Learning<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/st1.html" aria-label="Speech-to-Text Translation"><!---->Speech-to-Text Translation<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/svs1.html" aria-label="Singing Voice Synthesis"><!---->Singing Voice Synthesis<!----></a></li><li class="vp-dropdown-item"><a class="route-link route-link-active auto-link" href="/espnet/recipe/tts1.html" aria-label="Text-to-Speech"><!---->Text-to-Speech<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/tts2.html" aria-label="Text-to-Speech with Discrete Units"><!---->Text-to-Speech with Discrete Units<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/uasr1.html" aria-label="Unsupervised Automatic Speech Recognition"><!---->Unsupervised Automatic Speech Recognition<!----></a></li></ul></button></div></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="Python API"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="fa-solid:book" width="1em" height="1em"></iconify-icon>Python API<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">espnet</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet/asr/" aria-label="asr"><!---->asr<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet/distributed/" aria-label="distributed"><!---->distributed<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet/lm/" aria-label="lm"><!---->lm<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet/mt/" aria-label="mt"><!---->mt<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet/nets/" aria-label="nets"><!---->nets<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet/optimizer/" aria-label="optimizer"><!---->optimizer<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet/scheduler/" aria-label="scheduler"><!---->scheduler<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet/st/" aria-label="st"><!---->st<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet/transform/" aria-label="transform"><!---->transform<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet/tts/" aria-label="tts"><!---->tts<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet/utils/" aria-label="utils"><!---->utils<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet/vc/" aria-label="vc"><!---->vc<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">espnet2</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/asr/" aria-label="asr"><!---->asr<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/asr_transducer/" aria-label="asr_transducer"><!---->asr_transducer<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/asvspoof/" aria-label="asvspoof"><!---->asvspoof<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/diar/" aria-label="diar"><!---->diar<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/enh/" aria-label="enh"><!---->enh<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/fileio/" aria-label="fileio"><!---->fileio<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/fst/" aria-label="fst"><!---->fst<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/gan_codec/" aria-label="gan_codec"><!---->gan_codec<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/gan_svs/" aria-label="gan_svs"><!---->gan_svs<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/gan_tts/" aria-label="gan_tts"><!---->gan_tts<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/hubert/" aria-label="hubert"><!---->hubert<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/iterators/" aria-label="iterators"><!---->iterators<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/layers/" aria-label="layers"><!---->layers<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/lm/" aria-label="lm"><!---->lm<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/main_funcs/" aria-label="main_funcs"><!---->main_funcs<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/mt/" aria-label="mt"><!---->mt<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/optimizers/" aria-label="optimizers"><!---->optimizers<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/s2st/" aria-label="s2st"><!---->s2st<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/s2t/" aria-label="s2t"><!---->s2t<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/samplers/" aria-label="samplers"><!---->samplers<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/schedulers/" aria-label="schedulers"><!---->schedulers<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/slu/" aria-label="slu"><!---->slu<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/speechlm/" aria-label="speechlm"><!---->speechlm<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/spk/" aria-label="spk"><!---->spk<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/st/" aria-label="st"><!---->st<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/svs/" aria-label="svs"><!---->svs<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/tasks/" aria-label="tasks"><!---->tasks<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/text/" aria-label="text"><!---->text<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/torch_utils/" aria-label="torch_utils"><!---->torch_utils<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/train/" aria-label="train"><!---->train<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/tts/" aria-label="tts"><!---->tts<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/tts2/" aria-label="tts2"><!---->tts2<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/uasr/" aria-label="uasr"><!---->uasr<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/utils/" aria-label="utils"><!---->utils<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">espnetez</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnetez/config/" aria-label="config"><!---->config<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnetez/data/" aria-label="data"><!---->data<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnetez/dataloader/" aria-label="dataloader"><!---->dataloader<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnetez/dataset/" aria-label="dataset"><!---->dataset<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnetez/preprocess/" aria-label="preprocess"><!---->preprocess<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnetez/task/" aria-label="task"><!---->task<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnetez/trainer/" aria-label="trainer"><!---->trainer<!----></a></li></ul></li></ul></button></div></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="Shell API"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="fa-solid:wrench" width="1em" height="1em"></iconify-icon>Shell API<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/tools/espnet2_bin/" aria-label="espnet2_bin"><!---->espnet2_bin<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/tools/espnet_bin/" aria-label="espnet_bin"><!---->espnet_bin<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/tools/spm/" aria-label="spm"><!---->spm<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/tools/utils/" aria-label="utils"><!---->utils<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/tools/utils_py/" aria-label="utils_py"><!---->utils_py<!----></a></li></ul></button></div></div></nav><!--]--><!----></div><div class="vp-navbar-end"><!----><!--[--><!----><div class="vp-nav-item vp-action"><a class="vp-action-link" href="https://github.com/espnet/espnet" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" name="github" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><!----><!--[--><button type="button" class="search-pro-button" aria-label="Search"><svg xmlns="http://www.w3.org/2000/svg" class="icon search-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="search icon" name="search"><path d="M192 480a256 256 0 1 1 512 0 256 256 0 0 1-512 0m631.776 362.496-143.2-143.168A318.464 318.464 0 0 0 768 480c0-176.736-143.264-320-320-320S128 303.264 128 480s143.264 320 320 320a318.016 318.016 0 0 0 184.16-58.592l146.336 146.368c12.512 12.48 32.768 12.48 45.28 0 12.48-12.512 12.48-32.768 0-45.28"></path></svg><div class="search-pro-placeholder">Search</div><div class="search-pro-key-hints"><kbd class="search-pro-key">Ctrl</kbd><kbd class="search-pro-key">K</kbd></div></button><!--]--><!--]--><!----><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar"><!----><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><p class="vp-sidebar-header"><iconify-icon class="font-icon icon" style="" mode="style" inline icon="fa-solid:laptop-code" width="1em" height="1em"></iconify-icon><span class="vp-sidebar-title">Demos</span><!----></p><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/notebook/" aria-label="ESPnet Notebooks"><!---->ESPnet Notebooks<!----></a></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">ESPnet EZ</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">ESPnet1</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">ESPnet2</span><span class="vp-arrow end"></span></button><!----></section></li></ul></section></li><li><section class="vp-sidebar-group"><p class="vp-sidebar-header active"><iconify-icon class="font-icon icon" style="" mode="style" inline icon="fa-solid:mug-hot" width="1em" height="1em"></iconify-icon><span class="vp-sidebar-title">Recipes</span><!----></p><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/" aria-label="Recipe Template"><!---->Recipe Template<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/asr1.html" aria-label="Automatic Speech Recognition (Multi-tasking)"><!---->Automatic Speech Recognition (Multi-tasking)<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/asr2.html" aria-label="Automatic Speech Recognition with Discrete Units"><!---->Automatic Speech Recognition with Discrete Units<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/lm1.html" aria-label="Language Modeling"><!---->Language Modeling<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/mt1.html" aria-label="Machine Translation"><!---->Machine Translation<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/ssl1.html" aria-label="Self-supervised Learning"><!---->Self-supervised Learning<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/svs1.html" aria-label="Singing Voice Synthesis"><!---->Singing Voice Synthesis<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/diar1.html" aria-label="Speaker Diarisation"><!---->Speaker Diarisation<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/enh_diar1.html" aria-label="Speaker Diarisation with Speech Enhancement"><!---->Speaker Diarisation with Speech Enhancement<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/spk1.html" aria-label="Speaker Representation"><!---->Speaker Representation<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/asvspoof1.html" aria-label="Speaker Verification Spoofing and Countermeasures"><!---->Speaker Verification Spoofing and Countermeasures<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/codec1.html" aria-label="Speech Codec"><!---->Speech Codec<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/enh1.html" aria-label="Speech Enhancement"><!---->Speech Enhancement<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/speechlm1.html" aria-label="Speech Language Model"><!---->Speech Language Model<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/enh_asr1.html" aria-label="Speech Recognition with Speech Enhancement"><!---->Speech Recognition with Speech Enhancement<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/s2st1.html" aria-label="Speech-to-Speech Translation"><!---->Speech-to-Speech Translation<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/st1.html" aria-label="Speech-to-Text Translation"><!---->Speech-to-Text Translation<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/enh_st1.html" aria-label="Speech-to-Text Translation with Speech Enhancement"><!---->Speech-to-Text Translation with Speech Enhancement<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/slu1.html" aria-label="Spoken Language Understanding"><!---->Spoken Language Understanding<!----></a></li><li><a class="route-link route-link-active auto-link vp-sidebar-link active" href="/espnet/recipe/tts1.html" aria-label="Text-to-Speech"><!---->Text-to-Speech<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/tts2.html" aria-label="Text-to-Speech with Discrete Units"><!---->Text-to-Speech with Discrete Units<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/uasr1.html" aria-label="Unsupervised Automatic Speech Recognition"><!---->Unsupervised Automatic Speech Recognition<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/s2t1.html" aria-label="Weakly-supervised Learning (Speech-to-Text)"><!---->Weakly-supervised Learning (Speech-to-Text)<!----></a></li></ul></section></li><li><section class="vp-sidebar-group"><p class="vp-sidebar-header"><iconify-icon class="font-icon icon" style="" mode="style" inline icon="fa-solid:book" width="1em" height="1em"></iconify-icon><span class="vp-sidebar-title">Python API</span><!----></p><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Espnet</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Espnet2</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Espnetez</span><span class="vp-arrow end"></span></button><!----></section></li></ul></section></li><li><section class="vp-sidebar-group"><p class="vp-sidebar-header"><iconify-icon class="font-icon icon" style="" mode="style" inline icon="fa-solid:wrench" width="1em" height="1em"></iconify-icon><span class="vp-sidebar-title">Shell API</span><!----></p><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Espnet Bin</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Espnet2 Bin</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Spm</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Utils</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Utils Py</span><span class="vp-arrow end"></span></button><!----></section></li></ul></section></li></ul><!----></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!----><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><!---->Text-to-Speech</h1><div class="page-info"><!----><!----><!----><!----><span class="page-reading-time-info" aria-label="Reading Time⌛" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon" name="timer"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>About 19 min</span><meta property="timeRequired" content="PT19M"></span><!----><!----></div><hr></div><!----><!----><div class="theme-hope-content"><h1 id="text-to-speech" tabindex="-1"><a class="header-anchor" href="#text-to-speech"><span>Text-to-Speech</span></a></h1><p>This is a template of TTS recipe for ESPnet2.</p><h2 id="table-of-contents" tabindex="-1"><a class="header-anchor" href="#table-of-contents"><span>Table of Contents</span></a></h2><ul><li><a href="#recipe-flow">Recipe flow</a><ul><li><a href="#1-data-preparation">1. Data preparation</a><ul><li><a href="#espnet-format">ESPnet format:</a></li><li><a href="#new-mfa-aligments-generation">(New) MFA Aligments generation</a></li></ul></li><li><a href="#2-wav-dump--embedding-preparation">2. Wav dump / Embedding preparation</a></li><li><a href="#3-extract-speaker-embeddings">3. Extract speaker embeddings</a></li><li><a href="#4-removal-of-long--short-data">4. Removal of long / short data</a></li><li><a href="#5-token-list-generation">5. Token list generation</a></li><li><a href="#6-tts-statistics-collection">6. TTS statistics collection</a></li><li><a href="#7-tts-training">7. TTS training</a></li><li><a href="#8-tts-decoding">8. TTS decoding</a></li><li><a href="#9-optional-pack-results-for-upload">9. (Optional) Pack results for upload</a></li><li><a href="#10-optional-upload-model-to-hugging-face">10. (Optional) Upload model to Hugging Face</a></li></ul></li><li><a href="#how-to-run">How to run</a><ul><li><a href="#fastspeech-training">FastSpeech training</a></li><li><a href="#fastspeech2-training">FastSpeech2 training</a></li><li><a href="#multi-speaker-model-with-speaker-embedding-training">Multi-speaker model with speaker embedding training</a><ul><li><a href="#optional-train-on-speaker-averaged-speaker-embeddings">(Optional) Train on speaker-averaged speaker embeddings</a></li></ul></li><li><a href="#multi-speaker-model-with-speaker-id-embedding-training">Multi-speaker model with speaker ID embedding training</a></li><li><a href="#multi-language-model-with-language-id-embedding-training">Multi-language model with language ID embedding training</a></li><li><a href="#vits-training">VITS training</a></li><li><a href="#joint-text2wav-training">Joint text2wav training</a></li><li><a href="#evaluation">Evaluation</a></li></ul></li><li><a href="#supported-text-frontend">Supported text frontend</a></li><li><a href="#supported-text-cleaner">Supported text cleaner</a></li><li><a href="#supported-models">Supported Models</a><ul><li><a href="#single-speaker-model">Single speaker model</a></li><li><a href="#multi-speaker-model-extension">Multi speaker model extension</a></li></ul></li><li><a href="#faq">FAQ</a><ul><li><a href="#espnet1-model-is-compatible-with-espnet2">ESPnet1 model is compatible with ESPnet2?</a></li><li><a href="#how-to-change-minibatch-size-in-training">How to change minibatch size in training?</a></li><li><a href="#how-to-make-a-new-recipe-for-my-own-dataset">How to make a new recipe for my own dataset?</a></li><li><a href="#how-to-add-a-new-g2p-module">How to add a new <code>g2p</code> module?</a></li><li><a href="#how-to-add-a-new-cleaner-module">How to add a new <code>cleaner</code> module?</a></li><li><a href="#how-to-use-trained-model-in-python">How to use trained model in python?</a></li><li><a href="#how-to-get-pretrained-models">How to get pretrained models?</a></li><li><a href="#how-to-load-the-pretrained-parameters">How to load the pretrained parameters?</a></li><li><a href="#how-to-finetune-the-pretrained-model">How to finetune the pretrained model?</a></li><li><a href="#how-to-add-a-new-model">How to add a new model?</a></li><li><a href="#how-to-test-my-model-with-an-arbitrary-given-text">How to test my model with an arbitrary given text?</a></li><li><a href="#how-to-train-vocoder">How to train vocoder?</a></li><li><a href="#how-to-train-vocoder-with-text2mel-gta-outputs">How to train vocoder with text2mel GTA outputs?</a></li><li><a href="#how-to-handle-the-errors-in-validate_data_dirsh">How to handle the errors in <code>validate_data_dir.sh</code>?</a></li><li><a href="#why-the-model-generate-meaningless-speech-at-the-end">Why the model generate meaningless speech at the end?</a></li><li><a href="#why-the-model-cannot-be-trained-well-with-my-own-dataset">Why the model cannot be trained well with my own dataset?</a></li><li><a href="#why-the-outputs-contains-metallic-noise-when-combining-neural-vocoder">Why the outputs contains metallic noise when combining neural vocoder?</a></li><li><a href="#how-is-the-duration-for-fastspeech2-generated">How is the duration for FastSpeech2 generated?</a></li><li><a href="#why-the-output-of-tacotron2-or-transformer-is-non-deterministic">Why the output of Tacotron2 or Transformer is non-deterministic?</a></li></ul></li></ul><h2 id="recipe-flow" tabindex="-1"><a class="header-anchor" href="#recipe-flow"><span>Recipe flow</span></a></h2><p>TTS recipe consists of 9 stages.</p><h3 id="_1-data-preparation" tabindex="-1"><a class="header-anchor" href="#_1-data-preparation"><span>1. Data preparation</span></a></h3><p>Data preparation stage. You have two methods to generate the data:</p><h4 id="espnet-format" tabindex="-1"><a class="header-anchor" href="#espnet-format"><span>ESPnet format:</span></a></h4><p>It calls <code>local/data.sh</code> to creates Kaldi-style data directories in <code>data/</code> for training, validation, and evaluation sets.</p><p>See also:</p><ul><li><a href="https://github.com/espnet/espnet/tree/master/egs2/TEMPLATE#about-kaldi-style-data-directory" target="_blank" rel="noopener noreferrer">About Kaldi-style data directory</a></li></ul><h4 id="new-mfa-aligments-generation" tabindex="-1"><a class="header-anchor" href="#new-mfa-aligments-generation"><span>(New) MFA Aligments generation</span></a></h4><p>You can generate aligments using the <a href="https://github.com/MontrealCorpusTools/Montreal-Forced-Aligner" target="_blank" rel="noopener noreferrer">Montreal-Forced-Aligner tool</a> Use the script <code>scripts/mfa.sh</code> to generate the required mfa aligments and train a model that employs these alignments.</p><p>Because the script <code>scripts/mfa.sh</code> prepares the data, it is not required to execute <code>local/data.sh</code> previously. However, you will need to set some additional flags, such as <code>--split_sets</code>, <code>--samplerate</code>, or <code>--acoustic_model</code>:</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" data-title="bash" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">./scripts/mfa.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --split_sets</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> &quot;train_set dev_set test_set&quot;</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --stage</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 1</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --stop-stage</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 2</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --train</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> true</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --nj</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 36</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --g2p_model</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> espeak_ng_english_vits</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>You can find a reference at <code>egs2/ljspeech/tts1/local/run_mfa.sh</code>.</p><p>The script <code>scripts/mfa.sh</code> will generate the aligments using a given <code>g2p_model</code> &amp; <code>acoustic_model</code> and store it in the <code>&lt;split_sets&gt;_phn</code> directory. This script download a pretrained model (if <code>--train false</code>) or trains the mfa g2p and acoustic model (if <code>--train true</code>), for then generate the aligments.</p><p>Then, you can continue the training on the main script:</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" data-title="bash" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">./run.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --train-set</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> train_set_phn</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">         --dev-set</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> dev_set_phn</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">         --test_sets</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> &quot;dev_set_phn test_set_phn&quot;</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">         --stage</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 2</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">         --g2p</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> none</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">         --cleaner</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> none</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">         --teacher_dumpdir</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> &quot;data&quot;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_2-wav-dump-embedding-preparation" tabindex="-1"><a class="header-anchor" href="#_2-wav-dump-embedding-preparation"><span>2. Wav dump / Embedding preparation</span></a></h3><p>Wav dumping stage. This stage reformats <code>wav.scp</code> in data directories.</p><p>Additionally, We support speaker embedding extraction in this stage as you can use in ESPnet1. If you specify <code>--use_spk_embed true</code> (Default: <code>use_spk_embed=false</code>), we extract speaker embeddings. You can select the type of toolkit to use (kaldi, speechbrain, or espnet) when you specify <code>--spk_embed_tool &lt;option&gt;</code> (Default: <code>spk_embed_tool=espnet</code>). If you specify kaldi, then we additionally extract mfcc features and vad decision. In that case, <code>spk_embed_tag</code> will be set to <code>xvector</code> automatically. This processing requires the compiled kaldi, please be careful.</p><p>Also, speaker ID embedding and language ID embedding preparation will be performed in this stage if you specify <code>--use_sid true</code> and <code>--use_lid true</code> options. Note that this processing assume that <code>utt2spk</code> or <code>utt2lang</code> are correctly created in stage 1, please be careful.</p><h3 id="_3-extract-speaker-embeddings" tabindex="-1"><a class="header-anchor" href="#_3-extract-speaker-embeddings"><span>3. Extract speaker embeddings</span></a></h3><p>Extract speaker embeddings.</p><h3 id="_4-removal-of-long-short-data" tabindex="-1"><a class="header-anchor" href="#_4-removal-of-long-short-data"><span>4. Removal of long / short data</span></a></h3><p>Processing stage to remove long and short utterances from the training and validation data. You can change the threshold values via <code>--min_wav_duration</code> and <code>--max_wav_duration</code>.</p><h3 id="_5-token-list-generation" tabindex="-1"><a class="header-anchor" href="#_5-token-list-generation"><span>5. Token list generation</span></a></h3><p>Token list generation stage. It generates token list (dictionary) from <code>srctexts</code>. You can change the tokenization type via <code>--token_type</code> option. <code>token_type=char</code> and <code>token_type=phn</code> are supported. If <code>--cleaner</code> option is specified, the input text will be cleaned with the specified cleaner. If <code>token_type=phn</code>, the input text will be converted with G2P module specified by <code>--g2p</code> option.</p><p>See also:</p><ul><li><a href="#supported-text-cleaner">Supported text cleaner</a>.</li><li><a href="#supported-text-frontend">Supported text frontend</a>.</li></ul><h3 id="_6-tts-statistics-collection" tabindex="-1"><a class="header-anchor" href="#_6-tts-statistics-collection"><span>6. TTS statistics collection</span></a></h3><p>Statistics calculation stage. It collects the shape information of the input and output and calculates statistics for feature normalization (mean and variance over training data).</p><h3 id="_7-tts-training" tabindex="-1"><a class="header-anchor" href="#_7-tts-training"><span>7. TTS training</span></a></h3><p>TTS model training stage. You can change the training setting via <code>--train_config</code> and <code>--train_args</code> options.</p><p>See also:</p><ul><li><a href="#supported-models">Supported models</a>.</li><li><a href="https://espnet.github.io/espnet/espnet2_training_option.html" target="_blank" rel="noopener noreferrer">Change the configuration for training</a></li><li><a href="https://espnet.github.io/espnet/espnet2_distributed.html" target="_blank" rel="noopener noreferrer">Distributed training</a></li></ul><h3 id="_8-tts-decoding" tabindex="-1"><a class="header-anchor" href="#_8-tts-decoding"><span>8. TTS decoding</span></a></h3><p>TTS model decoding stage. You can change the decoding setting via <code>--inference_config</code> and <code>--inference_args</code>.</p><p>See also:</p><ul><li><a href="https://espnet.github.io/espnet/espnet2_training_option.html" target="_blank" rel="noopener noreferrer">Change the configuration for training</a></li></ul><h3 id="_9-optional-pack-results-for-upload" tabindex="-1"><a class="header-anchor" href="#_9-optional-pack-results-for-upload"><span>9. (Optional) Pack results for upload</span></a></h3><p>Packing stage. It packs the trained model files as a preparation for uploading to Hugging Face.</p><h3 id="_10-optional-upload-model-to-hugging-face" tabindex="-1"><a class="header-anchor" href="#_10-optional-upload-model-to-hugging-face"><span>10. (Optional) Upload model to Hugging Face</span></a></h3><p>Upload the trained model to Hugging Face for sharing. Additional information at <a href="https://espnet.github.io/espnet/espnet2_tutorial.html#packing-and-sharing-your-trained-model" target="_blank" rel="noopener noreferrer">Docs</a>.</p><h2 id="how-to-run" tabindex="-1"><a class="header-anchor" href="#how-to-run"><span>How to run</span></a></h2><p>Here, we show the procedure to run the recipe using <code>egs2/ljspeech/tts1</code>.</p><p>Move on the recipe directory.</p><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" data-title="sh" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">$</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> cd</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> egs2/ljspeech/tts1</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>Modify <code>LJSPEECH</code> variable in <code>db.sh</code> if you want to change the download directory.</p><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" data-title="sh" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">$</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> vim</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> db.sh</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>Modify <code>cmd.sh</code> and <code>conf/*.conf</code> if you want to use job scheduler. See the detail in <a href="https://espnet.github.io/espnet/parallelization.html" target="_blank" rel="noopener noreferrer">using job scheduling system</a>.</p><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" data-title="sh" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">$</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> vim</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> cmd.sh</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>Run <code>run.sh</code>, which conducts all of the stages explained above.</p><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" data-title="sh" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">$</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> ./run.sh</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>As a default, we train Tacotron2 (<code>conf/train.yaml</code>) with <code>feats_type=raw</code> + <code>token_type=phn</code>.</p><p>Then, you can get the following directories in the recipe directory.</p><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" data-title="sh" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">├──</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> data/</span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"> # Kaldi-style data directory</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">│  </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> ├──</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> dev/</span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">        # validation set</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">│  </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> ├──</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> eval1/</span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">      # evaluation set</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">│  </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> └──</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> tr_no_dev/</span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">  # training set</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">├──</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> dump/</span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"> # feature dump directory</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">│  </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> ├──</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> token_list/</span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">    # token list (dictionary)</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">│  </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> └──</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> raw/</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">│</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">       ├──</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> org/</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">│</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">       │</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">    ├──</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> tr_no_dev/</span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"> # training set before filtering</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">│</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">       │</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">    └──</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> dev/</span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">       # validation set before filtering</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">│</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">       ├──</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> srctexts</span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">   # text to create token list</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">│</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">       ├──</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> eval1/</span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">     # evaluation set</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">│</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">       ├──</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> dev/</span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">       # validation set after filtering</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">│</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">       └──</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> tr_no_dev/</span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"> # training set after filtering</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">└──</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> exp/</span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"> # experiment directory</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">    ├──</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> tts_stats_raw_phn_tacotron_g2p_en_no_space</span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"> # statistics</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">    └──</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> tts_train_raw_phn_tacotron_g2p_en_no_space</span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"> # model</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">        ├──</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> att_ws/</span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">                # attention plot during training</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">        ├──</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> tensorboard/</span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">           # tensorboard log</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">        ├──</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> images/</span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">                # plot of training curves</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">        ├──</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> decode_train.loss.ave/</span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"> # decoded results</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">        │</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">    ├──</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> dev/</span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">   # validation set</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">        │</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">    └──</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> eval1/</span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"> # evaluation set</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">        │</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">        ├──</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> att_ws/</span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">      # attention plot in decoding</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">        │</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">        ├──</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> probs/</span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">       # stop probability plot in decoding</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">        │</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">        ├──</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> norm/</span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">        # generated features</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">        │</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">        ├──</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> denorm/</span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">      # generated denormalized features</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">        │</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">        ├──</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> wav/</span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">         # generated wav via Griffin-Lim</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">        │</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">        ├──</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> log/</span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">         # log directory</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">        │</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">        ├──</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> durations</span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">    # duration of each input tokens</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">        │</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">        ├──</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> feats_type</span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">   # feature type</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">        │</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">        ├──</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> focus_rates</span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">  # focus rate</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">        │</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">        └──</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> speech_shape</span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"> # shape info of generated features</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">        ├──</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> config.yaml</span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">             # config used for the training</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">        ├──</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> train.log</span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">               # training log</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">        ├──</span><span style="--shiki-light:#005CC5;--shiki-dark:#E5C07B;"> *</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">epoch.pth</span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">              # model parameter file</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">        ├──</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> checkpoint.pth</span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">          # model + optimizer + scheduler parameter file</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">        ├──</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> latest.pth</span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">              # symlink to latest model parameter</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">        ├──</span><span style="--shiki-light:#005CC5;--shiki-dark:#E5C07B;"> *</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">.ave_5best.pth</span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">         # model averaged parameters</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">        └──</span><span style="--shiki-light:#005CC5;--shiki-dark:#E5C07B;"> *</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">.best.pth</span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">              # symlink to the best model parameter loss</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>In decoding, we use Griffin-Lim for waveform generation as a default (End-to-end text-to-wav model can generate waveform directly such as VITS and Joint training model). If you want to combine with neural vocoders, you can combine with <a href="https://github.com/kan-bayashi/ParallelWaveGAN" target="_blank" rel="noopener noreferrer">kan-bayashi/ParallelWaveGAN</a>.</p><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" data-title="sh" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># Make sure you already install parallel_wavegan repo</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">$</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> .</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> ./path.sh</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> &amp;&amp; </span><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">pip</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> install</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> -U</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> parallel_wavegan</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># Use parallel_wavegan provided pretrained ljspeech style melgan as a vocoder</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">$</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> ./run.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --stage</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 8</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --inference_args</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> &quot;--vocoder_tag parallel_wavegan/ljspeech_style_melgan.v1&quot;</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --inference_tag</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> decode_with_ljspeech_style_melgan.v1</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># Use the vocoder trained by `parallel_wavegan` repo manually</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">$</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> ./run.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --stage</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 8</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --vocoder_file</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> /path/to/checkpoint-xxxxxxsteps.pkl</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --inference_tag</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> decode_with_my_vocoder</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>If you want to generate waveform from dumped features, please check <a href="https://github.com/kan-bayashi/ParallelWaveGAN#decoding-with-espnet-tts-models-features" target="_blank" rel="noopener noreferrer">decoding with ESPnet-TTS model&#39;s feature</a>.</p><p>For the first time, we recommend performing each stage step-by-step via <code>--stage</code> and <code>--stop-stage</code> options.</p><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" data-title="sh" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">$</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> ./run.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --stage</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 1</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --stop-stage</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 1</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">$</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> ./run.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --stage</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 2</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --stop-stage</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 2</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;">...</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">$</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> ./run.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --stage</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 8</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --stop-stage</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 8</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>This might helps you to understand each stage&#39;s processing and directory structure.</p><h3 id="fastspeech-training" tabindex="-1"><a class="header-anchor" href="#fastspeech-training"><span>FastSpeech training</span></a></h3><p>If you want to train FastSpeech, additional steps with the teacher model are needed. Please make sure you already finished the training of the teacher model (Tacotron2 or Transformer-TTS).</p><p>First, decode all of data including training, validation, and evaluation set.</p><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" data-title="sh" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># specify teacher model directory via --tts_exp option</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">$</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> ./run.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --stage</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 8</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --tts_exp</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> exp/tts_train_raw_phn_tacotron_g2p_en_no_space</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --test_sets</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> &quot;tr_no_dev dev eval1&quot;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>This will generate <code>durations</code> for training, validation, and evaluation sets in <code>exp/tts_train_raw_phn_tacotron_g2p_en_no_space/decode_train.loss.ave</code>.</p><p>Then, you can train FastSpeech by specifying the directory including <code>durations</code> via <code>--teacher_dumpdir</code> option.</p><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" data-title="sh" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">$</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> ./run.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --stage</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 7</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --train_config</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> conf/tuning/train_fastspeech.yaml</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --teacher_dumpdir</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> exp/tts_train_raw_phn_tacotron_g2p_en_no_space/decode_train.loss.ave</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>In the above example, we use generated mel-spectrogram as the target, which is known as knowledge distillation training. If you want to use groundtruth mel-spectrogram as the target, we need to use teacher forcing in decoding.</p><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" data-title="sh" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">$</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> ./run.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --stage</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 8</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --tts_exp</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> exp/tts_train_raw_phn_tacotron_g2p_en_no_space</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --inference_args</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> &quot;--use_teacher_forcing true&quot;</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --test_sets</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> &quot;tr_no_dev dev eval1&quot;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>You can get the groundtruth aligned durations in <code>exp/tts_train_raw_phn_tacotron_g2p_en_no_space/decode_use_teacher_forcingtrue_train.loss.ave</code>.</p><p>Then, you can train FastSpeech without knowledge distillation.</p><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" data-title="sh" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">$</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> ./run.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --stage</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 7</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --train_config</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> conf/tuning/train_fastspeech.yaml</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --teacher_dumpdir</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> exp/tts_train_raw_phn_tacotron_g2p_en_no_space/decode_use_teacher_forcingtrue_train.loss.ave</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="fastspeech2-training" tabindex="-1"><a class="header-anchor" href="#fastspeech2-training"><span>FastSpeech2 training</span></a></h3><p>The procedure is almost the same as FastSpeech but we <strong>MUST</strong> use teacher forcing in decoding.</p><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" data-title="sh" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">$</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> ./run.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --stage</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 8</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --tts_exp</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> exp/tts_train_raw_phn_tacotron_g2p_en_no_space</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --inference_args</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> &quot;--use_teacher_forcing true&quot;</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --test_sets</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> &quot;tr_no_dev dev eval1&quot;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>To train FastSpeech2, we use additional feature (F0 and energy). Therefore, we need to start from <code>stage 5</code> to calculate additional statistics.</p><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" data-title="sh" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">$</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> ./run.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --stage</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 6</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --train_config</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> conf/tuning/train_fastspeech2.yaml</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --teacher_dumpdir</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> exp/tts_train_raw_phn_tacotron_g2p_en_no_space/decode_use_teacher_forcingtrue_train.loss.ave</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --tts_stats_dir</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> exp/tts_train_raw_phn_tacotron_g2p_en_no_space/decode_use_teacher_forcingtrue_train.loss.ave/stats</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --write_collected_feats</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> true</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>where <code>--tts_stats_dir</code> is the option to specify the directory to dump Statistics, and <code>--write_collected_feats</code> is the option to dump features in statistics calculation. The use of <code>--write_collected_feats</code> is optional but it helps to accelerate the training.</p><h3 id="multi-speaker-model-with-speaker-embedding-training" tabindex="-1"><a class="header-anchor" href="#multi-speaker-model-with-speaker-embedding-training"><span>Multi-speaker model with speaker embedding training</span></a></h3><p>First, you need to run from the stage 2 and 3 with <code>--use_spk_embed true</code> to extract speaker embedding.</p><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" data-title="sh" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">$</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> ./run.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --stage</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 3</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --stop-stage</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 4</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --use_spk_embed</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> true</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>You can find the extracted speaker embedding in <code>dump/${spk_embed_tag}/*/${spk_embed_tag}.{ark,scp}</code>. Then, you can run the training with the config which has <code>spk_embed_dim: 512</code> in <code>tts_conf</code>.</p><div class="language-yaml line-numbers-mode" data-highlighter="shiki" data-ext="yaml" data-title="yaml" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># e.g.</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">tts_conf</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">:</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">    spk_embed_dim</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">512</span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">               # dimension of speaker embedding</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">    spk_embed_integration_type</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">add</span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">  # how to integrate speaker embedding</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="optional-train-on-speaker-averaged-speaker-embeddings" tabindex="-1"><a class="header-anchor" href="#optional-train-on-speaker-averaged-speaker-embeddings"><span>(Optional) Train on speaker-averaged speaker embeddings</span></a></h4><p>Models trained using speaker-averaged speaker embeddings may generalise better to inference tasks where the utterance-specific speaker embedding is unknown, compared to models trained using embeddings derived from individual training utterances. After you perform the above extraction step, if you want to train and evaluate using speaker-averaged speaker embeddings, you can use the following command to replace utterance-level speaker embeddings with speaker-averaged values. Make sure to set your <code>train_set</code> <code>dev_set</code> and <code>test_set</code> variables beforehand:</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span>for dset in &quot;${train_set}&quot; &quot;${dev_set}&quot; &quot;${test_set}&quot;</span></span>
<span class="line"><span>do</span></span>
<span class="line"><span>    ./pyscripts/utils/convert_to_avg_spk_embed.py \</span></span>
<span class="line"><span>        --utt-embed-path dump/${spk_embed_tag}/${dset}/${spk_embed_tag}.scp \</span></span>
<span class="line"><span>        --utt2spk data/${dset}/utt2spk \</span></span>
<span class="line"><span>        --spk-embed-path dump/${spk_embed_tag}/${dset}/spk_${spk_embed_tag}.scp</span></span>
<span class="line"><span>done</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>The original <code>${spk_embed_tag}.scp</code> files are renamed to xvector.scp.bak in case you wish to revert the changes.</p><hr><p>Once you&#39;ve performed extraction and optionally the speaker-averaged replacement step, please run the training from stage 6.</p><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" data-title="sh" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">$</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> ./run.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --stage</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 7</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --use_xvector</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> true</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --train_config</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> /path/to/your_xvector_config.yaml</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>You can find the example config in <a href="../../vctk/tts1/conf/tuning"><code>egs2/vctk/tts1/conf/tuning</code></a>.</p><h3 id="multi-speaker-model-with-speaker-id-embedding-training" tabindex="-1"><a class="header-anchor" href="#multi-speaker-model-with-speaker-id-embedding-training"><span>Multi-speaker model with speaker ID embedding training</span></a></h3><p>First, you need to run from the stage 2 and 3 with <code>--use_sid true</code> to extract speaker ID.</p><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" data-title="sh" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">$</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> ./run.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --stage</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 3</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --stop-stage</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 4</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --use_sid</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> true</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>You can find the speaker ID file in <code>dump/raw/*/utt2sid</code>. Note that you need to correctly create <code>utt2spk</code> in data prep stage to generate <code>utt2sid</code>. Then, you can run the training with the config which has <code>spks: #spks</code> in <code>tts_conf</code>.</p><div class="language-yaml line-numbers-mode" data-highlighter="shiki" data-ext="yaml" data-title="yaml" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># e.g.</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">tts_conf</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">:</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">    spks</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">128</span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">  # Number of speakers</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>Please run the training from stage 6.</p><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" data-title="sh" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">$</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> ./run.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --stage</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 7</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --use_sid</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> true</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --train_config</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> /path/to/your_multi_spk_config.yaml</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h3 id="multi-language-model-with-language-id-embedding-training" tabindex="-1"><a class="header-anchor" href="#multi-language-model-with-language-id-embedding-training"><span>Multi-language model with language ID embedding training</span></a></h3><p>First, you need to run from the stage 2 and 3 with <code>--use_lid true</code> to extract speaker ID.</p><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" data-title="sh" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">$</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> ./run.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --stage</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 3</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --stop-stage</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 4</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --use_lid</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> true</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>You can find the speaker ID file in <code>dump/raw/*/utt2lid</code>. <strong>Note that you need to additionally create <code>utt2lang</code> file in data prep stage to generate <code>utt2lid</code>.</strong> Then, you can run the training with the config which has <code>langs: #langs</code> in <code>tts_conf</code>.</p><div class="language-yaml line-numbers-mode" data-highlighter="shiki" data-ext="yaml" data-title="yaml" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># e.g.</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">tts_conf</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">:</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">    langs</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">4</span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">  # Number of languages</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>Please run the training from stage 6.</p><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" data-title="sh" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">$</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> ./run.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --stage</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 7</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --use_lid</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> true</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --train_config</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> /path/to/your_multi_lang_config.yaml</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>Of course you can further combine with x-vector or speaker ID embedding. If you want to use both sid and lid, the process should be like this:</p><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" data-title="sh" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">$</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> ./run.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --stage</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 3</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --stop-stage</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 4</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --use_lid</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> true</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --use_sid</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> true</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>Make your config.</p><div class="language-yaml line-numbers-mode" data-highlighter="shiki" data-ext="yaml" data-title="yaml" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># e.g.</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">tts_conf</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">:</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">    langs</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">4</span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">   # Number of languages</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">    spks</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">128</span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">  # Number of speakers</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>Please run the training from stage 6.</p><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" data-title="sh" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">$</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> ./run.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --stage</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 7</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --use_lid</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> true</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --use_sid</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> true</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --train_config</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> /path/to/your_multi_spk_multi_lang_config.yaml</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h3 id="vits-training" tabindex="-1"><a class="header-anchor" href="#vits-training"><span>VITS training</span></a></h3><p>First, the VITS config is <strong>hard coded for 22.05 khz or 44.1 khz</strong> and use different feature extraction method. (Note that you can use any feature extraction method but the default method is <code>linear_spectrogram</code>.) If you want to use it with 24 khz or 16 khz dataset, please be careful about these point.</p><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" data-title="sh" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># Assume that data prep stage (stage 1) is finished</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">$</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> ./run.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --stage</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 1</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --stop-stage</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 1</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># Single speaker 22.05 khz case</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">$</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> ./run.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --stage</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 2</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --ngpu</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 4</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --fs</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 22050</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --n_fft</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 1024</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --n_shift</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 256</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --win_length</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> null</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --dumpdir</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> dump/22k</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --expdir</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> exp/22k</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --tts_task</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> gan_tts</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --feats_extract</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> linear_spectrogram</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --feats_normalize</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> none</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --train_config</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> ./conf/tuning/train_vits.yaml</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --inference_config</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> ./conf/tuning/decode_vits.yaml</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --inference_model</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> latest.pth</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># Single speaker 44.1 khz case</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">$</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> ./run.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --stage</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 2</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --ngpu</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 4</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --fs</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 44100</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --n_fft</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 2048</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --n_shift</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 512</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --win_length</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> null</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --dumpdir</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> dump/44k</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --expdir</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> exp/44k</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --tts_task</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> gan_tts</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --feats_extract</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> linear_spectrogram</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --feats_normalize</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> none</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --train_config</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> ./conf/tuning/train_full_band_vits.yaml</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --inference_config</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> ./conf/tuning/decode_vits.yaml</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --inference_model</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> latest.pth</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># Multi speaker with SID 22.05 khz case</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">$</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> ./run.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --stage</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 2</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --use_sid</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> true</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --ngpu</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 4</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --fs</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 22050</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --n_fft</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 1024</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --n_shift</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 256</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --win_length</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> null</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --dumpdir</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> dump/22k</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --expdir</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> exp/22k</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --tts_task</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> gan_tts</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --feats_extract</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> linear_spectrogram</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --feats_normalize</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> none</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --train_config</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> ./conf/tuning/train_multi_spk_vits.yaml</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --inference_config</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> ./conf/tuning/decode_vits.yaml</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --inference_model</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> latest.pth</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># Multi speaker with SID 44.1 khz case</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">$</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> ./run.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --stage</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 2</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --use_sid</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> true</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --ngpu</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 4</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --fs</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 44100</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --n_fft</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 2048</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --n_shift</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 512</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --win_length</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> null</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --dumpdir</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> dump/44k</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --expdir</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> exp/44k</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --tts_task</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> gan_tts</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --feats_extract</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> linear_spectrogram</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --feats_normalize</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> none</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --train_config</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> ./conf/tuning/train_full_band_multi_spk_vits.yaml</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --inference_config</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> ./conf/tuning/decode_vits.yaml</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --inference_model</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> latest.pth</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># Multi speaker with speaker embedding 22.05 khz case (need compiled kaldi to run if use Kaldi toolkit)</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">$</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> ./run.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --stage</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 2</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --use_spk_embed</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> true</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --ngpu</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 4</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --fs</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 22050</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --n_fft</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 1024</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --n_shift</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 256</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --win_length</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> null</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --dumpdir</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> dump/22k</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --expdir</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> exp/22k</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --tts_task</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> gan_tts</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --feats_extract</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> linear_spectrogram</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --feats_normalize</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> none</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --train_config</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> ./conf/tuning/train_xvector_vits.yaml</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --inference_config</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> ./conf/tuning/decode_vits.yaml</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --inference_model</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> latest.pth</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>The training time requires long times (around several weeks) but around 100k samples can generate a reasonable sounds.</p><p>You can find the example configs in:</p><ul><li><a href="../../ljspeech/tts1/conf/tuning/train_vits.yaml"><code>egs2/ljspeech/tts1/conf/tuning/train_vits.yaml</code>: Single speaker 22.05 khz config</a>.</li><li><a href="../../jsut/tts1/conf/tuning/train_full_band_vits.yaml"><code>egs2/jsut/tts1/conf/tuning/train_full_band_vits.yaml</code>: Single speaker 44.1 khz config</a>.</li><li><a href="../../vctk/tts1/conf/tuning/train_multi_spk_vits.yaml"><code>egs2/vctk/tts1/conf/tuning/train_multi_spk_vits.yaml</code>: Multi speaker with SID 22.05 khz config</a>.</li><li><a href="../../vctk/tts1/conf/tuning/train_full_band_multi_spk_vits.yaml"><code>egs2/vctk/tts1/conf/tuning/train_full_band_multi_spk_vits.yaml</code>: Multi speaker with SID 44.1 khz config</a>.</li><li><a href="../../libritts/tts1/conf/tuning/train_xvector_vits.yaml"><code>egs2/libritts/tts1/conf/tuning/train_xvector_vits.yaml</code>: Multi speaker with X-vector 22.05 khz config</a>.</li></ul><p>During VITS and JETS training, you can monitor pseudo MOS values predicted by a MOS prediction model. You can enable it by setting <code>tts_conf.plot_pred_mos: true</code> in training configs. Take a look at <code>egs2/ljspeech/tts1/conf/tuning/train_vits.yaml</code> to see how to set the flag.</p><h3 id="joint-text2wav-training" tabindex="-1"><a class="header-anchor" href="#joint-text2wav-training"><span>Joint text2wav training</span></a></h3><p>Joint training enables us to train both text2mel and vocoder model jointly with GAN-based training. Currently, we tested on only for non-autoregressive text2mel models with ljspeech dataset but the following models and vocoders are supported.</p><p><strong>Text2mel</strong></p><ul><li>Tacotron2</li><li>Transformer</li><li>FastSpeech</li><li>FastSpeech2</li></ul><p><strong>Vocoder</strong></p><ul><li>ParallelWaveGAN G / D</li><li>(Multi-band) MelGAN G / D</li><li>HiFiGAN G / D</li><li>StyleMelGAN G / D</li></ul><p>Here, we show the example procedure to train conformer fastspeech2 + hifigan jointly with two training strategy (training from scratch and fine-tuning of pretrained text2mel and vocoder).</p><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" data-title="sh" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># Make sure you are ready to train fastspeech2 (already prepared durations file with teacher model)</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">$</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> ...</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># Case 1: Train conformer fastspeech2 + hifigan G + hifigan D from scratch</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">$</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> ./run.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --stage</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 7</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --tts_task</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> gan_tts</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --train_config</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> ./conf/tuning/train_joint_conformer_fastspeech2_hifigan.yaml</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># Case 2: Fine-tuning of pretrained conformer fastspeech2 + hifigan G + hifigan D</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># (a) Prepare pretrained models as follows</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">$</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> tree</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> -L</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 2</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> exp</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">exp</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;">...</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">├──</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> ljspeech_hifigan.v1</span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">  # pretrained vocoder</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">│  </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> ├──</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> checkpoint-2500000steps.pkl</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">│  </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> ├──</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> config.yml</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">│  </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> └──</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> stats.h5</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">├──</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> tts_train_conformer_fastspeech2_raw_phn_tacotron_g2p_en_no_space</span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">  # pretrained text2mel</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">│  </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> ├──</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> config.yaml</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">│  </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> ├──</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> images</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">│  </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> └──</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> train.loss.ave_5best.pth</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;">...</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># If you want to use the same files of this example</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">$</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> ipython</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># Download text2mel model</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">[ins] In [1]: from espnet_model_zoo.downloader import ModelDownloader</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">[ins] In [2]: d = ModelDownloader(</span><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">&quot;./downloads&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">[ins] In [3]: d.download_and_unpack(</span><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">&quot;kan-bayashi/ljspeech_conformer_fastspeech2&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># Download vocoder</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">[ins] In [4]: from parallel_wavegan.utils import download_pretrained_model</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">[ins] In [5]: download_pretrained_model(</span><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">&quot;ljspeech_hifigan.v1&quot;</span><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">,</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> &quot;downloads&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># Move them to exp directory</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">$</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> mv</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> download/59c43ac0d40b121060bd71dd418f5ece/exp/tts_train_conformer_fastspeech2_raw_phn_tacotron_g2p_en_no_space</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> exp</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">$</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> mv</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> downloads/ljspeech_hifigan.v1</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> exp</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># (b) Convert .pkl checkpoint to espnet loadable format</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">$</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> ipython</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">[ins] In [1]: import torch</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">[ins] In [2]: d = torch.load(</span><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">&quot;./exp/ljspeech_hifigan.v1/checkpoint-2500000steps.pkl&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">[ins] In [3]: torch.save(</span><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">d[</span><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">&quot;model&quot;</span><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">][</span><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">&quot;generator&quot;</span><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">],</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> &quot;generator.pth&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">[ins] In [4]: torch.save(</span><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">d[</span><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">&quot;model&quot;</span><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">][</span><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">&quot;discriminator&quot;</span><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">],</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> &quot;discriminator.pth&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># (c) Prepare configuration</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">$</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> vim</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> conf/tuning/finetune_joint_conformer_fastspeech2_hifigan.yaml</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># edit text2mel_params / generator_params / discriminator_params to be the same as the pretrained model</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># edit init_param part to specify the correct path of the pretrained model</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># (d) Run training</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">$</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> ./run.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --stage</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 7</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --tts_task</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> gan_tts</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --train_config</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> ./conf/tuning/finetune_joint_conformer_fastspeech2_hifigan.yaml</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>You can find the example configs in:</p><ul><li><a href="../../ljspeech/tts1/conf/tuning/train_joint_conformer_fastspeech2_hifigan.yaml"><code>egs2/ljspeech/tts1/conf/tuning/train_joint_conformer_fastspeech2_hifigan.yaml</code>: Joint training of conformer fastspeech2 + hifigan</a>.</li><li><a href="../../ljspeech/tts1/conf/tuning/finetune_joint_conformer_fastspeech2_hifigan.yaml"><code>egs2/ljspeech/tts1/conf/tuning/finetune_joint_conformer_fastspeech2_hifigan.yaml</code>: Joint fine-tuning of conformer fastspeech2 + hifigan</a>.</li></ul><h3 id="evaluation" tabindex="-1"><a class="header-anchor" href="#evaluation"><span>Evaluation</span></a></h3><p>We provide five objective evaluation metrics:</p><ul><li>Mel-cepstral distortion (MCD)</li><li>Log-F0 root mean square error (log-F0 RMSE)</li><li>Character error rate (CER)</li><li>Conditional Fréchet Speech Distance (CFSD)</li><li>Speaker Embedding Cosine Similarity (SECS)</li><li>Discrete speech metrics</li></ul><p>MCD and log-F0 RMSE reflect speaker, prosody, and phonetic content similarities, and CER can reflect the intelligibility. For MCD and log-F0 RMSE, we apply dynamic time-warping (DTW) to match the length difference between ground-truth speech and generated speech. Discrete speech metrics better correlate with human subjective judgements than MCD.</p><p>Here we show the example command to calculate objective metrics:</p><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" data-title="sh" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;">cd</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> egs2/</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&lt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">recipe_nam</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">e</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&gt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">/tts1</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;">.</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> ./path.sh</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># Evaluate MCD</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">./pyscripts/utils/evaluate_mcd.py</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">    exp/</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&lt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">model_dir_nam</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">e</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&gt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">/</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&lt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">decode_dir_nam</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">e</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&gt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">/eval1/wav/wav.scp</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">    dump/raw/eval1/wav.scp</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># Evaluate log-F0 RMSE</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">./pyscripts/utils/evaluate_f0.py</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">    exp/</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&lt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">model_dir_nam</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">e</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&gt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">/</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&lt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">decode_dir_nam</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">e</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&gt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">/eval1/wav/wav.scp</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">    dump/raw/eval1/wav.scp</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># If you want to calculate more precisely, limit the F0 range</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">./pyscripts/utils/evaluate_f0.py</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --f0min</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> xxx</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --f0max</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> yyy</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">    exp/</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&lt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">model_dir_nam</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">e</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&gt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">/</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&lt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">decode_dir_nam</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">e</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&gt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">/eval1/wav/wav.scp</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">    dump/raw/eval1/wav.scp</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># Evaluate with automatic MOS prediction models.</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">./pyscripts/utils/evaluate_pseudomos.py</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">    exp/</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&lt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">model_dir_nam</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">e</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&gt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">/</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&lt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">decode_dir_nam</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">e</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&gt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">/eval1/wav/wav.scp</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">    dump/raw/eval1/wav.scp</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># Evaluate CER</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">./scripts/utils/evaluate_asr.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --model_tag</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;"> &lt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">asr_model_ta</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">g</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --nj</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 1</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --inference_args</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> &quot;--beam_size 10 --ctc_weight 0.4 --lm_weight 0.0&quot;</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --gt_text</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> &quot;dump/raw/eval1/text&quot;</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">    exp/</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&lt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">model_dir_nam</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">e</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&gt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">/</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&lt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">decode_dir_nam</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">e</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&gt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">/eval1/wav/wav.scp</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">    exp/</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&lt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">model_dir_nam</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">e</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&gt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">/</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&lt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">decode_dir_nam</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">e</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&gt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">/asr_results</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># You can also use openai whisper for evaluation</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">./scripts/utils/evaluate_asr.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --whisper_tag</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> base</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --nj</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 1</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --gt_text</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> &quot;dump/raw/eval1/text&quot;</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">    exp/</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&lt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">model_dir_nam</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">e</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&gt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">/</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&lt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">decode_dir_nam</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">e</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&gt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">/eval1/wav/wav.scp</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">    exp/</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&lt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">model_dir_nam</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">e</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&gt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">/</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&lt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">decode_dir_nam</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">e</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&gt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">/asr_results</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># Since ASR model does not use punctuation, it is better to remove punctuations if it contains</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">./scripts/utils/remove_punctuation.pl</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;"> &lt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> dump/raw/eval1/text</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;"> &gt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> dump/raw/eval1/text.no_punc</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">./scripts/utils/evaluate_asr.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --model_tag</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;"> &lt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">asr_model_ta</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">g</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --nj</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 1</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --inference_args</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> &quot;--beam_size 10 --ctc_weight 0.4 --lm_weight 0.0&quot;</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --gt_text</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> &quot;dump/raw/eval1/text.no_punc&quot;</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">    exp/</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&lt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">model_dir_nam</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">e</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&gt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">/</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&lt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">decode_dir_nam</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">e</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&gt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">/eval1/wav/wav.scp</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">    exp/</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&lt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">model_dir_nam</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">e</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&gt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">/</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&lt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">decode_dir_nam</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">e</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&gt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">/asr_results</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># Some ASR models assume the existence of silence at the beginning and the end of audio</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># Then, you can perform silence padding with sox to get more reasonable ASR results</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">awk</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;"> &lt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> &quot;exp/&lt;model_dir_name&gt;/&lt;decode_dir_name&gt;/eval1/wav/wav.scp&quot;</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">    &#39;{print $1 &quot; sox &quot; $2 &quot; -t wav - pad 0.25 0.25 |&quot;}&#39;</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">    &gt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> exp/</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&lt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">model_dir_nam</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">e</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&gt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">/</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&lt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">decode_dir_nam</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">e</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&gt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">/eval1/wav/wav_pad.scp</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">./scripts/utils/evaluate_asr.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --model_tag</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;"> &lt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">asr_model_ta</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">g</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --nj</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 1</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --inference_args</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> &quot;--beam_size 10 --ctc_weight 0.4 --lm_weight 0.0&quot;</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">    --gt_text</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> &quot;dump/raw/eval1/text.no_punc&quot;</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">    exp/</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&lt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">model_dir_nam</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">e</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&gt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">/</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&lt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">decode_dir_nam</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">e</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&gt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">/eval1/wav/wav_pad.scp</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">    exp/</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&lt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">model_dir_nam</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">e</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&gt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">/</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&lt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">decode_dir_nam</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">e</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&gt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">/asr_results</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># Evaluate CFSD</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">./pyscripts/utils/evaluate_cfsd.py</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">    exp/</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&lt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">model_dir_nam</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">e</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&gt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">/</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&lt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">decode_dir_nam</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">e</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&gt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">/eval1/wav/wav.scp</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">    dump/raw/eval1/wav.scp</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># Evaluate SECS</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">./pyscripts/utils/evaluate_secs.py</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">    exp/</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&lt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">model_dir_nam</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">e</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&gt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">/</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&lt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">decode_dir_nam</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">e</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&gt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">/eval1/wav/wav.scp</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">    dump/raw/eval1/wav.scp</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># Evaluate SpeechBERTScore</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">./pyscripts/utils/evaluate_speechbertscore.py</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">    exp/</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&lt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">model_dir_nam</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">e</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&gt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">/</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&lt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">decode_dir_nam</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">e</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&gt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">/eval1/wav/wav.scp</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">    dump/raw/eval1/wav.scp</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># Evaluate SpeechBLEU</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">./pyscripts/utils/evaluate_speechbleu.py</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">    exp/</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&lt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">model_dir_nam</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">e</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&gt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">/</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&lt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">decode_dir_nam</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">e</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&gt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">/eval1/wav/wav.scp</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">    dump/raw/eval1/wav.scp</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>While these objective metrics can estimate the quality of synthesized speech, it is still difficult to fully determine human perceptual quality from these values, especially with high-fidelity generated speech. Therefore, we recommend performing the subjective evaluation if you want to check perceptual quality in detail.</p><p>You can refer <a href="https://github.com/kan-bayashi/webMUSHRA/blob/master/HOW_TO_SETUP.md" target="_blank" rel="noopener noreferrer">this page</a> to launch web-based subjective evaluation system with <a href="https://github.com/audiolabs/webMUSHRA" target="_blank" rel="noopener noreferrer">webMUSHRA</a>.</p><h2 id="supported-text-frontend" tabindex="-1"><a class="header-anchor" href="#supported-text-frontend"><span>Supported text frontend</span></a></h2><p>You can change via <code>--g2p</code> option in <code>tts.sh</code>.</p><ul><li><code>none</code>: Just separate by space <ul><li>e.g.: <code>HH AH0 L OW1 &lt;space&gt; W ER1 L D</code> -&gt; <code>[HH, AH0, L, OW1, &lt;space&gt;, W, ER1, L D]</code></li></ul></li><li><code>g2p_en</code>: <a href="https://github.com/Kyubyong/g2p" target="_blank" rel="noopener noreferrer">Kyubyong/g2p</a><ul><li>e.g. <code>Hello World</code> -&gt; <code>[HH, AH0, L, OW1, &lt;space&gt;, W, ER1, L D]</code></li></ul></li><li><code>g2p_en_no_space</code>: <a href="https://github.com/Kyubyong/g2p" target="_blank" rel="noopener noreferrer">Kyubyong/g2p</a><ul><li>Same G2P but do not use word separator</li><li>e.g. <code>Hello World</code> -&gt; <code>[HH, AH0, L, OW1, W, ER1, L, D]</code></li></ul></li><li><code>pyopenjtalk</code>: <a href="https://github.com/r9y9/pyopenjtalk" target="_blank" rel="noopener noreferrer">r9y9/pyopenjtalk</a><ul><li>e.g. <code>こ、こんにちは</code> -&gt; <code>[k, o, pau, k, o, N, n, i, ch, i, w, a]</code></li></ul></li><li><code>pyopenjtalk_kana</code>: <a href="https://github.com/r9y9/pyopenjtalk" target="_blank" rel="noopener noreferrer">r9y9/pyopenjtalk</a><ul><li>Use kana instead of phoneme</li><li>e.g. <code>こ、こんにちは</code> -&gt; <code>[コ, 、, コ, ン, ニ, チ, ワ]</code></li></ul></li><li><code>pyopenjtalk_accent</code>: <a href="https://github.com/r9y9/pyopenjtalk" target="_blank" rel="noopener noreferrer">r9y9/pyopenjtalk</a><ul><li>Add accent labels in addition to phoneme labels</li><li>Based on <a href="https://jglobal.jst.go.jp/detail?JGLOBAL_ID=202102244593559954" target="_blank" rel="noopener noreferrer">Developing a Japanese End-to-End Speech Synthesis Server Considering Accent Phrases</a></li><li>e.g. <code>こ、こんにちは</code> -&gt; <code>[k, 1, 0, o, 1, 0, k, 5, -4, o, 5, -4, N, 5, -3, n, 5, -2, i, 5, -2, ch, 5, -1, i, 5, -1, w, 5, 0, a, 5, 0]</code></li></ul></li><li><code>pyopenjtalk_accent_with_pause</code>: <a href="https://github.com/r9y9/pyopenjtalk" target="_blank" rel="noopener noreferrer">r9y9/pyopenjtalk</a><ul><li>Add a pause label in addition to phoneme and accent labels</li><li>Based on <a href="https://jglobal.jst.go.jp/detail?JGLOBAL_ID=202102244593559954" target="_blank" rel="noopener noreferrer">Developing a Japanese End-to-End Speech Synthesis Server Considering Accent Phrases</a></li><li>e.g. <code>こ、こんにちは</code> -&gt; <code>[k, 1, 0, o, 1, 0, pau, k, 5, -4, o, 5, -4, N, 5, -3, n, 5, -2, i, 5, -2, ch, 5, -1, i, 5, -1, w, 5, 0, a, 5, 0]</code></li></ul></li><li><code>pyopenjtalk_prosody</code>: <a href="https://github.com/r9y9/pyopenjtalk" target="_blank" rel="noopener noreferrer">r9y9/pyopenjtalk</a><ul><li>Use special symbols for prosody control</li><li>Based on <a href="https://doi.org/10.1587/transinf.2020EDP7104" target="_blank" rel="noopener noreferrer">Prosodic features control by symbols as input of sequence-to-sequence acoustic modeling for neural TTS</a></li><li>e.g. <code>こ、こんにちは</code> -&gt; <code>[^, k, #, o, _, k, o, [, N, n, i, ch, i, w, a, $]</code></li></ul></li><li><code>pypinyin</code>: <a href="https://github.com/mozillazg/python-pinyin" target="_blank" rel="noopener noreferrer">mozillanzg/python-pinyin</a><ul><li>e.g. <code>卡尔普陪外孙玩滑梯。</code> -&gt; <code>[ka3, er3, pu3, pei2, wai4, sun1, wan2, hua2, ti1, 。]</code></li></ul></li><li><code>pypinyin_phone</code>: <a href="https://github.com/mozillazg/python-pinyin" target="_blank" rel="noopener noreferrer">mozillanzg/python-pinyin</a><ul><li>Separate into first and last parts</li><li>e.g. <code>卡尔普陪外孙玩滑梯。</code> -&gt; <code>[k, a3, er3, p, u3, p, ei2, wai4, s, un1, uan2, h, ua2, t, i1, 。]</code></li></ul></li><li><code>espeak_ng_arabic</code>: <a href="https://github.com/espeak-ng/espeak-ng" target="_blank" rel="noopener noreferrer">espeak-ng/espeak-ng</a><ul><li>e.g. <code>السلام عليكم</code> -&gt; <code>[ʔ, a, s, s, ˈa, l, aː, m, ʕ, l, ˈiː, k, m]</code></li><li>This result provided by the wrapper library <a href="https://github.com/bootphon/phonemizer" target="_blank" rel="noopener noreferrer">bootphon/phonemizer</a></li></ul></li><li><code>espeak_ng_german</code>: <a href="https://github.com/espeak-ng/espeak-ng" target="_blank" rel="noopener noreferrer">espeak-ng/espeak-ng</a><ul><li>e.g. <code>Das hört sich gut an.</code> -&gt; <code>[d, a, s, h, ˈœ, ɾ, t, z, ɪ, ç, ɡ, ˈuː, t, ˈa, n, .]</code></li><li>This result provided by the wrapper library <a href="https://github.com/bootphon/phonemizer" target="_blank" rel="noopener noreferrer">bootphon/phonemizer</a></li></ul></li><li><code>espeak_ng_french</code>: <a href="https://github.com/espeak-ng/espeak-ng" target="_blank" rel="noopener noreferrer">espeak-ng/espeak-ng</a><ul><li>e.g. <code>Bonjour le monde.</code> -&gt; <code>[b, ɔ̃, ʒ, ˈu, ʁ, l, ə-, m, ˈɔ̃, d, .]</code></li><li>This result provided by the wrapper library <a href="https://github.com/bootphon/phonemizer" target="_blank" rel="noopener noreferrer">bootphon/phonemizer</a></li></ul></li><li><code>espeak_ng_spanish</code>: <a href="https://github.com/espeak-ng/espeak-ng" target="_blank" rel="noopener noreferrer">espeak-ng/espeak-ng</a><ul><li>e.g. <code>Hola Mundo.</code> -&gt; <code>[ˈo, l, a, m, ˈu, n, d, o, .]</code></li><li>This result provided by the wrapper library <a href="https://github.com/bootphon/phonemizer" target="_blank" rel="noopener noreferrer">bootphon/phonemizer</a></li></ul></li><li><code>espeak_ng_russian</code>: <a href="https://github.com/espeak-ng/espeak-ng" target="_blank" rel="noopener noreferrer">espeak-ng/espeak-ng</a><ul><li>e.g. <code>Привет мир.</code> -&gt; <code>[p, rʲ, i, vʲ, ˈe, t, mʲ, ˈi, r, .]</code></li><li>This result provided by the wrapper library <a href="https://github.com/bootphon/phonemizer" target="_blank" rel="noopener noreferrer">bootphon/phonemizer</a></li></ul></li><li><code>espeak_ng_greek</code>: <a href="https://github.com/espeak-ng/espeak-ng" target="_blank" rel="noopener noreferrer">espeak-ng/espeak-ng</a><ul><li>e.g. <code>Γειά σου Κόσμε.</code> -&gt; <code>[j, ˈa, s, u, k, ˈo, s, m, e, .]</code></li><li>This result provided by the wrapper library <a href="https://github.com/bootphon/phonemizer" target="_blank" rel="noopener noreferrer">bootphon/phonemizer</a></li></ul></li><li><code>espeak_ng_finnish</code>: <a href="https://github.com/espeak-ng/espeak-ng" target="_blank" rel="noopener noreferrer">espeak-ng/espeak-ng</a><ul><li>e.g. <code>Hei maailma.</code> -&gt; <code>[h, ˈei, m, ˈaː, ɪ, l, m, a, .]</code></li><li>This result provided by the wrapper library <a href="https://github.com/bootphon/phonemizer" target="_blank" rel="noopener noreferrer">bootphon/phonemizer</a></li></ul></li><li><code>espeak_ng_hungarian</code>: <a href="https://github.com/espeak-ng/espeak-ng" target="_blank" rel="noopener noreferrer">espeak-ng/espeak-ng</a><ul><li>e.g. <code>Helló Világ.</code> -&gt; <code>[h, ˈɛ, l, l, oː, v, ˈi, l, aː, ɡ, .]</code></li><li>This result provided by the wrapper library <a href="https://github.com/bootphon/phonemizer" target="_blank" rel="noopener noreferrer">bootphon/phonemizer</a></li></ul></li><li><code>espeak_ng_dutch</code>: <a href="https://github.com/espeak-ng/espeak-ng" target="_blank" rel="noopener noreferrer">espeak-ng/espeak-ng</a><ul><li>e.g. <code>Hallo Wereld.</code> -&gt; <code>[h, ˈɑ, l, oː, ʋ, ˈɪː, r, ə, l, t, .]</code></li><li>This result provided by the wrapper library <a href="https://github.com/bootphon/phonemizer" target="_blank" rel="noopener noreferrer">bootphon/phonemizer</a></li></ul></li><li><code>espeak_ng_hindi</code>: <a href="https://github.com/espeak-ng/espeak-ng" target="_blank" rel="noopener noreferrer">espeak-ng/espeak-ng</a><ul><li>e.g. <code>नमस्ते दुनिया</code> -&gt; <code>[n, ə, m, ˈʌ, s, t, eː, d, ˈʊ, n, ɪ, j, ˌaː]</code></li><li>This result provided by the wrapper library <a href="https://github.com/bootphon/phonemizer" target="_blank" rel="noopener noreferrer">bootphon/phonemizer</a></li></ul></li><li><code>espeak_ng_italian</code>: <a href="https://github.com/espeak-ng/espeak-ng" target="_blank" rel="noopener noreferrer">espeak-ng/espeak-ng</a><ul><li>e.g. <code>Ciao mondo.</code> -&gt; <code>[tʃ, ˈa, o, m, ˈo, n, d, o, .]</code></li><li>This result provided by the wrapper library <a href="https://github.com/bootphon/phonemizer" target="_blank" rel="noopener noreferrer">bootphon/phonemizer</a></li></ul></li><li><code>espeak_ng_polish</code>: <a href="https://github.com/espeak-ng/espeak-ng" target="_blank" rel="noopener noreferrer">espeak-ng/espeak-ng</a><ul><li>e.g. <code>Witaj świecie.</code> -&gt; <code>[v, ˈi, t, a, j, ɕ, fʲ, ˈɛ, tɕ, ɛ, .]</code></li><li>This result provided by the wrapper library <a href="https://github.com/bootphon/phonemizer" target="_blank" rel="noopener noreferrer">bootphon/phonemizer</a></li></ul></li><li><code>espeak_ng_english_us_vits</code>: <a href="https://github.com/espeak-ng/espeak-ng" target="_blank" rel="noopener noreferrer">espeak-ng/espeak-ng</a><ul><li>VITS official implementation-like processing (https://github.com/jaywalnut310/vits)</li><li>e.g. <code>Hello World.</code> -&gt; <code>[h, ə, l, ˈ, o, ʊ, , &lt;space&gt;, w, ˈ, ɜ, ː, l, d, .]</code></li><li>This result provided by the wrapper library <a href="https://github.com/bootphon/phonemizer" target="_blank" rel="noopener noreferrer">bootphon/phonemizer</a></li></ul></li><li><code>g2pk</code>: <a href="https://github.com/Kyubyong/g2pK" target="_blank" rel="noopener noreferrer">Kyubyong/g2pK</a><ul><li>e.g. <code>안녕하세요 세계입니다.</code> -&gt; <code>[ᄋ, ᅡ, ᆫ, ᄂ, ᅧ, ᆼ, ᄒ, ᅡ, ᄉ, ᅦ, ᄋ, ᅭ, , ᄉ, ᅦ, ᄀ, ᅨ, ᄋ, ᅵ, ᆷ, ᄂ, ᅵ, ᄃ, ᅡ, .]</code></li></ul></li><li><code>g2pk_no_space</code>: <a href="https://github.com/Kyubyong/g2pK" target="_blank" rel="noopener noreferrer">Kyubyong/g2pK</a><ul><li>Same G2P but do not use word separator</li><li>e.g. <code>안녕하세요 세계입니다.</code> -&gt; <code>[ᄋ, ᅡ, ᆫ, ᄂ, ᅧ, ᆼ, ᄒ, ᅡ, ᄉ, ᅦ, ᄋ, ᅭ, ᄉ, ᅦ, ᄀ, ᅨ, ᄋ, ᅵ, ᆷ, ᄂ, ᅵ, ᄃ, ᅡ, .]</code></li></ul></li><li><code>g2pk_explicit_space</code>: <a href="https://github.com/Kyubyong/g2pK" target="_blank" rel="noopener noreferrer">Kyubyong/g2pK</a><ul><li>Same G2P but use explicit word separator</li><li>e.g. <code>안녕하세요 세계입니다.</code> -&gt; <code>[ᄋ, ᅡ, ᆫ, ᄂ, ᅧ, ᆼ, ᄒ, ᅡ, ᄉ, ᅦ, ᄋ, ᅭ, &lt;space&gt;, ᄉ, ᅦ, ᄀ, ᅨ, ᄋ, ᅵ, ᆷ, ᄂ, ᅵ, ᄃ, ᅡ, .]</code></li></ul></li><li><code>korean_jaso</code>: <a href="https://github.com/jdongian/python-jamo" target="_blank" rel="noopener noreferrer">jdongian/python-jamo</a><ul><li>e.g. <code>나는 학교에 갑니다.</code> -&gt; <code>[ᄂ, ᅡ, ᄂ, ᅳ, ᆫ, &lt;space&gt;, ᄒ, ᅡ, ᆨ, ᄀ, ᅭ, ᄋ, ᅦ, &lt;space&gt;, ᄀ, ᅡ, ᆸ, ᄂ, ᅵ, ᄃ, ᅡ, .]</code></li></ul></li><li><code>korean_jaso_no_space</code>: <a href="https://github.com/jdongian/python-jamo" target="_blank" rel="noopener noreferrer">jdongian/python-jamo</a><ul><li>e.g. <code>나는 학교에 갑니다.</code> -&gt; <code>[ᄂ, ᅡ, ᄂ, ᅳ, ᆫ, ᄒ, ᅡ, ᆨ, ᄀ, ᅭ, ᄋ, ᅦ, ᄀ, ᅡ, ᆸ, ᄂ, ᅵ, ᄃ, ᅡ, .]</code></li></ul></li></ul><p>You can see the code example from <a href="https://github.com/espnet/espnet/blob/cd7d28e987b00b30f8eb8efd7f4796f048dc3be9/test/espnet2/text/test_phoneme_tokenizer.py" target="_blank" rel="noopener noreferrer">here</a>.</p><h2 id="supported-text-cleaner" tabindex="-1"><a class="header-anchor" href="#supported-text-cleaner"><span>Supported text cleaner</span></a></h2><p>You can change via <code>--cleaner</code> option in <code>tts.sh</code>.</p><ul><li><code>none</code>: No text cleaner.</li><li><code>tacotron</code>: <a href="https://github.com/keithito/tacotron" target="_blank" rel="noopener noreferrer">keithito/tacotron</a><ul><li>e.g.<code>&quot;(Hello-World); &amp; jr. &amp; dr.&quot;</code> -&gt;<code>HELLO WORLD, AND JUNIOR AND DOCTOR</code></li></ul></li><li><code>jaconv</code>: <a href="https://github.com/kazuhikoarase/jaconv" target="_blank" rel="noopener noreferrer">kazuhikoarase/jaconv</a><ul><li>e.g. <code>”あらゆる”　現実を　〜　’すべて’ 自分の　ほうへ　ねじ曲げたのだ。&quot;</code> -&gt; <code>&quot;あらゆる&quot; 現実を ー \&#39;すべて\&#39; 自分の ほうへ ねじ曲げたのだ。</code></li></ul></li></ul><p>You can see the code example from <a href="https://github.com/espnet/espnet/blob/cd7d28e987b00b30f8eb8efd7f4796f048dc3be9/test/espnet2/text/test_cleaner.py" target="_blank" rel="noopener noreferrer">here</a>.</p><h2 id="supported-models" tabindex="-1"><a class="header-anchor" href="#supported-models"><span>Supported Models</span></a></h2><p>You can train the following models by changing <code>*.yaml</code> config for <code>--train_config</code> option in <code>tts.sh</code>.</p><h3 id="single-speaker-model" tabindex="-1"><a class="header-anchor" href="#single-speaker-model"><span>Single speaker model</span></a></h3><ul><li><a href="https://arxiv.org/abs/1712.05884" target="_blank" rel="noopener noreferrer">Tacotron 2</a></li><li><a href="https://arxiv.org/abs/1809.08895" target="_blank" rel="noopener noreferrer">Transformer-TTS</a></li><li><a href="https://arxiv.org/abs/1905.09263" target="_blank" rel="noopener noreferrer">FastSpeech</a></li><li><a href="https://arxiv.org/abs/2006.04558" target="_blank" rel="noopener noreferrer">FastSpeech2</a> (<a href="https://arxiv.org/abs/2006.06873" target="_blank" rel="noopener noreferrer">FastPitch</a>)</li><li><a href="https://arxiv.org/abs/2005.08100" target="_blank" rel="noopener noreferrer">Conformer</a>-based FastSpeech / FastSpeech2</li><li><a href="https://arxiv.org/abs/2106.06103" target="_blank" rel="noopener noreferrer">VITS</a></li><li><a href="https://arxiv.org/abs/2203.16852" target="_blank" rel="noopener noreferrer">JETS</a></li></ul><p>You can find example configs of the above models in <a href="../../ljspeech/tts1/conf/tuning"><code>egs2/ljspeech/tts1/conf/tuning</code></a>.</p><h3 id="multi-speaker-model-extension" tabindex="-1"><a class="header-anchor" href="#multi-speaker-model-extension"><span>Multi speaker model extension</span></a></h3><p>You can use / combine the following embedding to build multi-speaker model:</p><ul><li><a href="https://ieeexplore.ieee.org/abstract/document/8461375" target="_blank" rel="noopener noreferrer">X-Vector</a></li><li><a href="https://arxiv.org/abs/1803.09017" target="_blank" rel="noopener noreferrer">GST</a></li><li>Speaker ID embedding (One-hot vector -&gt; Continuous embedding)</li><li>Language ID embedding (One-hot vector -&gt; Continuous embedding)</li></ul><p>X-Vector is provided by kaldi and pretrained with VoxCeleb corpus. You can find example configs of the above models in:</p><ul><li><a href="../../vctk/tts1/conf/tuning"><code>egs2/vctk/tts1/conf/tuning</code></a>.</li><li><a href="../../vctk/libritts/conf/tuning"><code>egs2/libritts/tts1/conf/tuning</code></a>.</li></ul><p>And now we support other toolkit&#39;s speaker embeddings: Please check the following options.</p><p>https://github.com/espnet/espnet/blob/df053b8c13c26fe289fc882751801fd781e9d43e/egs2/TEMPLATE/tts1/tts.sh#L69-L71</p><h2 id="faq" tabindex="-1"><a class="header-anchor" href="#faq"><span>FAQ</span></a></h2><h3 id="espnet1-model-is-compatible-with-espnet2" tabindex="-1"><a class="header-anchor" href="#espnet1-model-is-compatible-with-espnet2"><span>ESPnet1 model is compatible with ESPnet2?</span></a></h3><p>No. We cannot use the ESPnet1 model in ESPnet2.</p><h3 id="how-to-change-minibatch-size-in-training" tabindex="-1"><a class="header-anchor" href="#how-to-change-minibatch-size-in-training"><span>How to change minibatch size in training?</span></a></h3><p>See <a href="https://espnet.github.io/espnet/espnet2_training_option.html#change-mini-batch-type" target="_blank" rel="noopener noreferrer">change mini-batch type</a>. As a default, we use <code>batch_type=numel</code> and <code>batch_bins</code> instead of <code>batch_size</code> to enable us to use dynamic batch size. See the following config as an example. https://github.com/espnet/espnet/blob/96b2fd08d4fd9276aabd7ad41ec5e02a88b30958/egs2/ljspeech/tts1/conf/tuning/train_tacotron2.yaml#L61-L62</p><h3 id="how-to-make-a-new-recipe-for-my-own-dataset" tabindex="-1"><a class="header-anchor" href="#how-to-make-a-new-recipe-for-my-own-dataset"><span>How to make a new recipe for my own dataset?</span></a></h3><p>See <a href="https://github.com/espnet/espnet/tree/master/egs2/TEMPLATE#how-to-makeport-new-recipe" target="_blank" rel="noopener noreferrer">how to make/port new recipe</a>.</p><h3 id="how-to-add-a-new-g2p-module" tabindex="-1"><a class="header-anchor" href="#how-to-add-a-new-g2p-module"><span>How to add a new <code>g2p</code> module?</span></a></h3><p>Add a new module in <a href="https://github.com/espnet/espnet/blob/master/espnet2/text/phoneme_tokenizer.py" target="_blank" rel="noopener noreferrer"><code>espnet2/text/phoneme_tokenizer.py</code></a> and add it to <code>g2p_choices</code> in <a href="https://github.com/espnet/espnet/blob/master/espnet2/text/phoneme_tokenizer.py" target="_blank" rel="noopener noreferrer"><code>espnet2/text/phoneme_tokenizer.py</code></a>.</p><p>We have the wrapper module of <a href="https://github.com/bootphon/phonemizer" target="_blank" rel="noopener noreferrer">bootphon/phonemizer</a>. You can find the module <a href="https://github.com/kan-bayashi/espnet/blob/7cc12c6a25924892b281c2c1513de52365a1be0b/espnet2/text/phoneme_tokenizer.py#L110" target="_blank" rel="noopener noreferrer"><code>espnet2/text/phoneme_tokenizer.py</code></a>. If the g2p you wanted is implemented in <a href="https://github.com/bootphon/phonemizer" target="_blank" rel="noopener noreferrer">bootphon/phonemizer</a>, we can easily add it <a href="https://github.com/kan-bayashi/espnet/blob/7cc12c6a25924892b281c2c1513de52365a1be0b/espnet2/text/phoneme_tokenizer.py#L172-L173" target="_blank" rel="noopener noreferrer">like this</a> (Note that you need to update the choice as I mentioned the above).</p><p>Example PRs may help you:</p><ul><li><a href="https://github.com/espnet/espnet/pull/3382" target="_blank" rel="noopener noreferrer">#3382 Support Korean G2P</a></li><li><a href="https://github.com/espnet/espnet/pull/3463" target="_blank" rel="noopener noreferrer">#3463 Support G2P functions for various languages </a></li></ul><h3 id="how-to-add-a-new-cleaner-module" tabindex="-1"><a class="header-anchor" href="#how-to-add-a-new-cleaner-module"><span>How to add a new <code>cleaner</code> module?</span></a></h3><p>Update <a href="https://github.com/espnet/espnet/blob/master/espnet2/text/cleaner.py" target="_blank" rel="noopener noreferrer"><code>espnet2/text/cleaner.py</code></a> to add new module. Then, add new choice in the argument parser of <a href="https://github.com/espnet/espnet/blob/cd7d28e987b00b30f8eb8efd7f4796f048dc3be9/espnet2/bin/tokenize_text.py#L219-L225" target="_blank" rel="noopener noreferrer"><code>espnet2/bin/tokenize_text.py</code></a> and <a href="https://github.com/espnet/espnet/blob/cd7d28e987b00b30f8eb8efd7f4796f048dc3be9/espnet2/tasks/tts.py#L173-L179" target="_blank" rel="noopener noreferrer"><code>espnet2/tasks/tts.py</code></a>.</p><h3 id="how-to-use-trained-model-in-python" tabindex="-1"><a class="header-anchor" href="#how-to-use-trained-model-in-python"><span>How to use trained model in python?</span></a></h3><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> espnet2.bin.tts_inference </span><span style="--shiki-light:#D73A49;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> Text2Speech</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># without vocoder</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">tts </span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> Text2Speech.</span><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;">from_pretrained</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#E36209;--shiki-dark:#E06C75;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">model_file</span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&quot;/path/to/model.pth&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">wav </span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;"> tts</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&quot;Hello, world&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">)[</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&quot;wav&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">]</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># with local vocoder</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">tts </span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> Text2Speech.</span><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;">from_pretrained</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#E36209;--shiki-dark:#E06C75;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">model_file</span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&quot;/path/to/model.pth&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#E06C75;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">vocoder_file</span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&quot;/path/to/vocoder.pkl&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">wav </span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;"> tts</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&quot;Hello, world&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">)[</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&quot;wav&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">]</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># with pretrained vocoder (use ljseepch style melgan as an example)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">tts </span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> Text2Speech.</span><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;">from_pretrained</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#E36209;--shiki-dark:#E06C75;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">model_file</span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&quot;/path/to/model.pth&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#E06C75;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">vocoder_tag</span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&quot;parallel_wavegan/ljspeech_style_melgan.v1&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">wav </span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;"> tts</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&quot;Hello, world&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">)[</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&quot;wav&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">]</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>See <a href="https://github.com/espnet/espnet_model_zoo#use-a-pretrained-model-for-inference" target="_blank" rel="noopener noreferrer">use a pretrained model for inference</a>.</p><h3 id="how-to-get-pretrained-models" tabindex="-1"><a class="header-anchor" href="#how-to-get-pretrained-models"><span>How to get pretrained models?</span></a></h3><p>Use <a href="https://github.com/espnet/espnet_model_zoo" target="_blank" rel="noopener noreferrer">ESPnet model zoo</a>. You can find the all of the pretrained model list from <a href="https://github.com/espnet/espnet_model_zoo/blob/master/espnet_model_zoo/table.csv" target="_blank" rel="noopener noreferrer">here</a> or search for pretrained models at <a href="https://huggingface.co/models?library=espnet" target="_blank" rel="noopener noreferrer">Hugging Face</a>.</p><p>If you want to use pretrained models written in <code>egs2/hogehoge/tts1/README.md</code>, go to Zenodo URL and copy the URL of download in the below of the page. Then, you can use as follows:</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> espnet2.bin.tts_inference </span><span style="--shiki-light:#D73A49;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> Text2Speech</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># provide copied URL directly</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">tts </span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> Text2Speech.</span><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;">from_pretrained</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">    &quot;https://zenodo.org/record/5414980/files/tts_train_vits_raw_phn_jaconv_pyopenjtalk_accent_with_pause_train.total_count.ave.zip?download=1&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">wav </span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;"> tts</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&quot;こんにちは、世界。&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">)[</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&quot;wav&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">]</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="how-to-load-the-pretrained-parameters" tabindex="-1"><a class="header-anchor" href="#how-to-load-the-pretrained-parameters"><span>How to load the pretrained parameters?</span></a></h3><p>Please use <code>--init_param</code> option or add it in training config (<code>*.yaml</code>).</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" data-title="bash" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># Usage</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">--init_param</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;"> &lt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">file_pat</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">h</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&gt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">:</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&lt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">src_ke</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">y</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&gt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">:</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&lt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">dst_ke</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">y</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&gt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">:</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&lt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">exclude_key</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">s</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&gt;</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># Load all parameters</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">python</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> -m</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> espnet2.bin.tts_train</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --init_param</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> model.pth</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># Load only the parameters starting with &quot;decoder&quot;</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">python</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> -m</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> espnet2.bin.tts_train</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --init_param</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> model.pth:tts.dec</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># Load only the parameters starting with &quot;decoder&quot; and set it to model.tts.dec</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">python</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> -m</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> espnet2.bin.tts_train</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --init_param</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> model.pth:decoder:tts.dec</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># Set parameters to model.tts.dec</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">python</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> -m</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> espnet2.bin.tts_train</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --init_param</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> decoder.pth::tts.dec</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># Load all parameters excluding &quot;tts.enc.embed&quot;</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">python</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> -m</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> espnet2.bin.tts_train</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --init_param</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> model.pth:::tts.enc.embed</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># Load all parameters excluding &quot;tts.enc.embed&quot; and &quot;tts.dec&quot;</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">python</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> -m</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> espnet2.bin.tts_train</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --init_param</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> model.pth:::tts.enc.embed,tts.dec</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="how-to-finetune-the-pretrained-model" tabindex="-1"><a class="header-anchor" href="#how-to-finetune-the-pretrained-model"><span>How to finetune the pretrained model?</span></a></h3><p>See <a class="route-link" href="/espnet/jvs/tts1/">jvs recipe example</a>.</p><h3 id="how-to-add-a-new-model" tabindex="-1"><a class="header-anchor" href="#how-to-add-a-new-model"><span>How to add a new model?</span></a></h3><p>Under construction.</p><h3 id="how-to-test-my-model-with-an-arbitrary-given-text" tabindex="-1"><a class="header-anchor" href="#how-to-test-my-model-with-an-arbitrary-given-text"><span>How to test my model with an arbitrary given text?</span></a></h3><p>See Google Colab demo notebook: <a href="https://colab.research.google.com/github/espnet/notebook/blob/master/espnet2_tts_realtime_demo.ipynb" target="_blank" rel="noopener noreferrer"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" loading="lazy"></a></p><p>If you want to try in local:</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> espnet2.bin.tts_inference </span><span style="--shiki-light:#D73A49;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> Text2Speech</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># with local model</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">tts </span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> Text2Speech.</span><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;">from_pretrained</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#E36209;--shiki-dark:#E06C75;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">model_file</span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&quot;/path/to/model.pth&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">wav </span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;"> tts</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&quot;Hello, world&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">)[</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&quot;wav&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">]</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># with local model and local vocoder</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">tts </span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> Text2Speech.</span><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;">from_pretrained</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#E36209;--shiki-dark:#E06C75;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">model_file</span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&quot;/path/to/model.pth&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#E06C75;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">vocoder_file</span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&quot;/path/to/vocoder.pkl&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">wav </span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;"> tts</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&quot;Hello, world&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">)[</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&quot;wav&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">]</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># with local model and pretrained vocoder (use ljseepch as an example)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">tts </span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> Text2Speech.</span><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;">from_pretrained</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#E36209;--shiki-dark:#E06C75;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">model_file</span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&quot;/path/to/model.pth&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#E06C75;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">vocoder_tag</span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&quot;parallel_wavegan/ljspeech_style_melgan.v1&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">wav </span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;"> tts</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&quot;Hello, world&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">)[</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&quot;wav&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">]</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># with pretrained model and pretrained vocoder (use ljseepch as an example)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">tts </span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> Text2Speech.</span><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;">from_pretrained</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#E36209;--shiki-dark:#E06C75;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">model_tag</span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&quot;kan-bayashi/ljspeech_conformer_fastspeech2&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#E06C75;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">vocoder_tag</span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&quot;parallel_wavegan/ljspeech_style_melgan.v1&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">wav </span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;"> tts</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&quot;Hello, world&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">)[</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&quot;wav&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">]</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="how-to-train-vocoder" tabindex="-1"><a class="header-anchor" href="#how-to-train-vocoder"><span>How to train vocoder?</span></a></h3><p>Please use <a href="https://github.com/kan-bayashi/ParallelWaveGAN" target="_blank" rel="noopener noreferrer">kan-bayashi/ParallelWaveGAN</a>, which provides the recipes to train various GAN-based vocoders. If the recipe is not prepared, you can quickly start the training with espnet2 TTS recipe. See <a href="https://github.com/kan-bayashi/ParallelWaveGAN/tree/master/egs#run-training-using-espnet2-tts-recipe-within-5-minutes" target="_blank" rel="noopener noreferrer">Run training using ESPnet2-TTS recipe within 5 minutes</a>.</p><p>Or you can try <a href="#joint-text2wav-training">joint training of text2mel &amp; vocoder</a>.</p><p>The trained vocoder can be used as follows:</p><ul><li><p>With python</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> espnet2.bin.tts_inference </span><span style="--shiki-light:#D73A49;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> Text2Speech</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">tts </span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> Text2Speech.</span><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;">from_pretrained</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#E36209;--shiki-dark:#E06C75;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">model_file</span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&quot;/path/to/model.pth&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#E06C75;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">vocoder_file</span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&quot;/path/to/your_trained_vocoder_checkpoint.pkl&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">wav </span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;"> tts</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&quot;Hello, world&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">)[</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&quot;wav&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">]</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p>With TTS recipe</p><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" data-title="sh" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">$</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> ./run.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --stage</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 8</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --vocoder_file</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> /path/to/your_trained_vocoder_checkpoint.pkl</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --inference_tag</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> decode_with_my_vocoder</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div></li><li><p><a href="https://github.com/kan-bayashi/ParallelWaveGAN#decoding-with-espnet-tts-models-features" target="_blank" rel="noopener noreferrer">With command line</a></p></li></ul><h3 id="how-to-train-vocoder-with-text2mel-gta-outputs" tabindex="-1"><a class="header-anchor" href="#how-to-train-vocoder-with-text2mel-gta-outputs"><span>How to train vocoder with text2mel GTA outputs?</span></a></h3><p>Sometimes, we want to finetune the vocoder with text2mel groundtruth aligned (GTA) outputs. See <a href="https://github.com/kan-bayashi/ParallelWaveGAN/tree/master/egs#run-finetuning-using-espnet2-tts-gta-outputs" target="_blank" rel="noopener noreferrer">Run finetuning using ESPnet2-TTS GTA outputs</a>.</p><h3 id="how-to-handle-the-errors-in-validate-data-dir-sh" tabindex="-1"><a class="header-anchor" href="#how-to-handle-the-errors-in-validate-data-dir-sh"><span>How to handle the errors in <code>validate_data_dir.sh</code>?</span></a></h3><blockquote><p><code>utils/validate_data_dir.sh: text contains N lines with non-printable characters which occurs at this line</code></p></blockquote><p>This is caused by the recent change in kaldi. We recommend modifying the following part in <code>utils/validate_data_dir.sh</code> to be <code>non_print=true</code>.</p><p>https://github.com/kaldi-asr/kaldi/blob/40c71c5ee3ee5dffa1ad2c53b1b089e16d967bb5/egs/wsj/s5/utils/validate_data_dir.sh#L9</p><blockquote><p><code>utils/validate_text.pl: The line for utterance xxx contains disallowed Unicode whitespaces</code><code>utils/validate_text.pl: ERROR: text file &#39;data/xxx&#39; contains disallowed UTF-8 whitespace character(s)</code></p></blockquote><p>The use of zenkaku whitespace in <code>text</code> is not allowed. Please changes it to hankaku whitespace or the other symbol.</p><h3 id="why-the-model-generate-meaningless-speech-at-the-end" tabindex="-1"><a class="header-anchor" href="#why-the-model-generate-meaningless-speech-at-the-end"><span>Why the model generate meaningless speech at the end?</span></a></h3><p>This is because the model failed to predict the stop token. There are several solutions to solve this issue:</p><ul><li>Use attention constraint in the inference (<code>use_attention_constraint=True</code> in inference config, only for Tacotron 2).</li><li>Train the model with a large <code>bce_pos_weight</code> (e.g., <code>bce_pos_weight=10.0</code>).</li><li>Use non-autoregressive models (FastSpeech or FastSpeech2)</li></ul><h3 id="why-the-model-cannot-be-trained-well-with-my-own-dataset" tabindex="-1"><a class="header-anchor" href="#why-the-model-cannot-be-trained-well-with-my-own-dataset"><span>Why the model cannot be trained well with my own dataset?</span></a></h3><p>The most of the problems are caused by the bad cleaning of the dataset. Please check the following items carefully:</p><ul><li>Check the attention plot during the training. Loss value is not so meaningful in TTS. <ul><li>You can check <a href="https://github.com/espnet/espnet/pull/2807" target="_blank" rel="noopener noreferrer">this PR</a> as an example.</li></ul></li><li>Remove the silence at the beginning and end of the speech. <ul><li>You can use silence trimming scripts in <a href="https://github.com/espnet/espnet/blob/52ea42d8abfbfb63500e91a150a285aa7d14bfd6/egs2/hui_acg/tts1/local/data.sh#L61-L70" target="_blank" rel="noopener noreferrer">this example</a>.</li></ul></li><li>Separate speech if it contains a long silence at the middle of speech.</li><li>Use phonemes instead of characters if G2P is available.</li><li>Clean the text as possible as you can (abbreviation, number, etc...)</li><li>Add the pose symbol in text if the speech contains the silence.</li><li>If the dataset is small, please consider the use of adaptation with pretrained model.</li><li>If the dataset is small, please consider the use of large reduction factor, which helps the attention learning.</li></ul><h3 id="why-the-outputs-contains-metallic-noise-when-combining-neural-vocoder" tabindex="-1"><a class="header-anchor" href="#why-the-outputs-contains-metallic-noise-when-combining-neural-vocoder"><span>Why the outputs contains metallic noise when combining neural vocoder?</span></a></h3><p>This will be happened especially when the neural vocoders did not use noise as the input (e.g., MelGAN, HiFiGAN), which are less robust to the mismatch of acoustic features. The metallic sound can reduce by performing vocoder <a href="#how-to-train-vocoder-with-text2mel-gta-outputs">finetuning with text2mel GTA outputs</a> or <a href="#joint-text2wav-training">joint training / finetuning of text2mel and vocoder</a>.</p><h3 id="how-is-the-duration-for-fastspeech2-generated" tabindex="-1"><a class="header-anchor" href="#how-is-the-duration-for-fastspeech2-generated"><span>How is the duration for FastSpeech2 generated?</span></a></h3><p>We use the teacher model attention weight to calculate the duration as the same as FastSpeech. See more info in <a href="https://arxiv.org/abs/1905.09263" target="_blank" rel="noopener noreferrer">FastSpeech paper</a>.</p><h3 id="why-the-output-of-tacotron2-or-transformer-is-non-deterministic" tabindex="-1"><a class="header-anchor" href="#why-the-output-of-tacotron2-or-transformer-is-non-deterministic"><span>Why the output of Tacotron2 or Transformer is non-deterministic?</span></a></h3><p>This is because we use prenet in the decoder, which always applies dropout. See more info in <a href="https://arxiv.org/abs/1712.05884" target="_blank" rel="noopener noreferrer">Tacotron2 paper</a>.</p><p>If you want to fix the results, you can use <a href="https://github.com/espnet/espnet/blob/f03101557753517ebac8c432f0793d97d68fa5f0/espnet2/bin/tts_inference.py#L601-L606" target="_blank" rel="noopener noreferrer"><code>--always_fix_seed</code> option</a>.</p></div><!----><footer class="vp-page-meta"><!----><div class="vp-meta-item git-info"><!----><!----></div></footer><nav class="vp-page-nav"><a class="route-link auto-link prev" href="/espnet/recipe/slu1.html" aria-label="Spoken Language Understanding"><div class="hint"><span class="arrow start"></span>Prev</div><div class="link"><!---->Spoken Language Understanding</div></a><a class="route-link auto-link next" href="/espnet/recipe/tts2.html" aria-label="Text-to-Speech with Discrete Units"><div class="hint">Next<span class="arrow end"></span></div><div class="link">Text-to-Speech with Discrete Units<!----></div></a></nav><!----><!----><!--]--></main><!--]--><footer class="vp-footer-wrapper"><div class="vp-footer">Copyright © 2024 ESPnet Community. All rights reserved.</div><!----></footer></div><!--]--><!--]--><!--[--><!----><!----><!--]--><!--]--></div>
    <script type="module" src="/espnet/assets/app-B6Ithpv3.js" defer></script>
  </body>
</html>
