<!doctype html>
<html lang="en-US" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.14" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.51" />
    <style>
      html {
        background: var(--bg-color, #fff);
      }

      html[data-theme="dark"] {
        background: var(--bg-color, #1d1e1f);
      }

      body {
        background: var(--bg-color);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <link rel="icon" href="/espnet/assets/image/espnet.png"><title>ESPnet2</title><meta name="description" content="A documentation for ESPnet">
    <link rel="preload" href="/espnet/assets/style-CiXYLHjk.css" as="style"><link rel="stylesheet" href="/espnet/assets/style-CiXYLHjk.css">
    <link rel="modulepreload" href="/espnet/assets/app-B6Ithpv3.js">
    
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">Skip to main content</a><!--]--><!--[--><div class="theme-container external-link-icon"><!--[--><header id="navbar" class="vp-navbar"><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!----><!--[--><a class="route-link vp-brand" href="/espnet/"><img class="vp-nav-logo" src="/espnet/assets/image/espnet_logo1.png" alt><!----><!----></a><!--]--><!----></div><div class="vp-navbar-center"><!----><!--[--><nav class="vp-nav-links"><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="Demos"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="fa-solid:laptop-code" width="1em" height="1em"></iconify-icon>Demos<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/notebook/" aria-label="Roadmap"><!---->Roadmap<!----></a></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">ESPnet2</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/notebook/ESPnet2/Demo/" aria-label="Demo"><!---->Demo<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/notebook/ESPnet2/Course/" aria-label="Course"><!---->Course<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">ESPnet-EZ</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/notebook/ESPnetEZ/" aria-label="ESPnet EZ"><!---->ESPnet EZ<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">ESPnet1 (Legacy)</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/notebook/ESPnet1/" aria-label="ESPnet1"><!---->ESPnet1<!----></a></li></ul></li></ul></button></div></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="Recipes"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="fa-solid:mug-hot" width="1em" height="1em"></iconify-icon>Recipes<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/" aria-label="What is a recipe template?"><!---->What is a recipe template?<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/asr1.html" aria-label="Automatic Speech Recognition (Multi-tasking)"><!---->Automatic Speech Recognition (Multi-tasking)<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/asr2.html" aria-label="Automatic Speech Recognition with Discrete Units"><!---->Automatic Speech Recognition with Discrete Units<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/asvspoof1.html" aria-label="Speaker Verification Spoofing and Countermeasures"><!---->Speaker Verification Spoofing and Countermeasures<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/codec1.html" aria-label="Speech Codec"><!---->Speech Codec<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/diar1.html" aria-label="Speaker Diarisation"><!---->Speaker Diarisation<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/enh1.html" aria-label="Speech Enhancement"><!---->Speech Enhancement<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/enh_asr1.html" aria-label="Speech Recognition with Speech Enhancement"><!---->Speech Recognition with Speech Enhancement<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/enh_diar1.html" aria-label="Speaker Diarisation with Speech Enhancement"><!---->Speaker Diarisation with Speech Enhancement<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/enh_st1.html" aria-label="Speech-to-Text Translation with Speech Enhancement"><!---->Speech-to-Text Translation with Speech Enhancement<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/lm1.html" aria-label="Language Modeling"><!---->Language Modeling<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/mt1.html" aria-label="Machine Translation"><!---->Machine Translation<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/s2st1.html" aria-label="Speech-to-Speech Translation"><!---->Speech-to-Speech Translation<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/s2t1.html" aria-label="Weakly-supervised Learning (Speech-to-Text)"><!---->Weakly-supervised Learning (Speech-to-Text)<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/slu1.html" aria-label="Spoken Language Understanding"><!---->Spoken Language Understanding<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/speechlm1.html" aria-label="Speech Language Model"><!---->Speech Language Model<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/spk1.html" aria-label="Speaker Representation"><!---->Speaker Representation<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/ssl1.html" aria-label="Self-supervised Learning"><!---->Self-supervised Learning<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/st1.html" aria-label="Speech-to-Text Translation"><!---->Speech-to-Text Translation<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/svs1.html" aria-label="Singing Voice Synthesis"><!---->Singing Voice Synthesis<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/tts1.html" aria-label="Text-to-Speech"><!---->Text-to-Speech<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/tts2.html" aria-label="Text-to-Speech with Discrete Units"><!---->Text-to-Speech with Discrete Units<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/recipe/uasr1.html" aria-label="Unsupervised Automatic Speech Recognition"><!---->Unsupervised Automatic Speech Recognition<!----></a></li></ul></button></div></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="Python API"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="fa-solid:book" width="1em" height="1em"></iconify-icon>Python API<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">espnet</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet/asr/" aria-label="asr"><!---->asr<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet/distributed/" aria-label="distributed"><!---->distributed<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet/lm/" aria-label="lm"><!---->lm<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet/mt/" aria-label="mt"><!---->mt<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet/nets/" aria-label="nets"><!---->nets<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet/optimizer/" aria-label="optimizer"><!---->optimizer<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet/scheduler/" aria-label="scheduler"><!---->scheduler<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet/st/" aria-label="st"><!---->st<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet/transform/" aria-label="transform"><!---->transform<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet/tts/" aria-label="tts"><!---->tts<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet/utils/" aria-label="utils"><!---->utils<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet/vc/" aria-label="vc"><!---->vc<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">espnet2</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/asr/" aria-label="asr"><!---->asr<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/asr_transducer/" aria-label="asr_transducer"><!---->asr_transducer<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/asvspoof/" aria-label="asvspoof"><!---->asvspoof<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/diar/" aria-label="diar"><!---->diar<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/enh/" aria-label="enh"><!---->enh<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/fileio/" aria-label="fileio"><!---->fileio<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/fst/" aria-label="fst"><!---->fst<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/gan_codec/" aria-label="gan_codec"><!---->gan_codec<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/gan_svs/" aria-label="gan_svs"><!---->gan_svs<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/gan_tts/" aria-label="gan_tts"><!---->gan_tts<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/hubert/" aria-label="hubert"><!---->hubert<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/iterators/" aria-label="iterators"><!---->iterators<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/layers/" aria-label="layers"><!---->layers<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/lm/" aria-label="lm"><!---->lm<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/main_funcs/" aria-label="main_funcs"><!---->main_funcs<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/mt/" aria-label="mt"><!---->mt<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/optimizers/" aria-label="optimizers"><!---->optimizers<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/s2st/" aria-label="s2st"><!---->s2st<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/s2t/" aria-label="s2t"><!---->s2t<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/samplers/" aria-label="samplers"><!---->samplers<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/schedulers/" aria-label="schedulers"><!---->schedulers<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/slu/" aria-label="slu"><!---->slu<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/speechlm/" aria-label="speechlm"><!---->speechlm<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/spk/" aria-label="spk"><!---->spk<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/st/" aria-label="st"><!---->st<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/svs/" aria-label="svs"><!---->svs<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/tasks/" aria-label="tasks"><!---->tasks<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/text/" aria-label="text"><!---->text<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/torch_utils/" aria-label="torch_utils"><!---->torch_utils<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/train/" aria-label="train"><!---->train<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/tts/" aria-label="tts"><!---->tts<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/tts2/" aria-label="tts2"><!---->tts2<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/uasr/" aria-label="uasr"><!---->uasr<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnet2/utils/" aria-label="utils"><!---->utils<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">espnetez</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnetez/config/" aria-label="config"><!---->config<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnetez/data/" aria-label="data"><!---->data<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnetez/dataloader/" aria-label="dataloader"><!---->dataloader<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnetez/dataset/" aria-label="dataset"><!---->dataset<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnetez/preprocess/" aria-label="preprocess"><!---->preprocess<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnetez/task/" aria-label="task"><!---->task<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet/guide/espnetez/trainer/" aria-label="trainer"><!---->trainer<!----></a></li></ul></li></ul></button></div></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="Shell API"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="fa-solid:wrench" width="1em" height="1em"></iconify-icon>Shell API<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/tools/espnet2_bin/" aria-label="espnet2_bin"><!---->espnet2_bin<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/tools/espnet_bin/" aria-label="espnet_bin"><!---->espnet_bin<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/tools/spm/" aria-label="spm"><!---->spm<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/tools/utils/" aria-label="utils"><!---->utils<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet/tools/utils_py/" aria-label="utils_py"><!---->utils_py<!----></a></li></ul></button></div></div></nav><!--]--><!----></div><div class="vp-navbar-end"><!----><!--[--><!----><div class="vp-nav-item vp-action"><a class="vp-action-link" href="https://github.com/espnet/espnet" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" name="github" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><!----><!--[--><button type="button" class="search-pro-button" aria-label="Search"><svg xmlns="http://www.w3.org/2000/svg" class="icon search-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="search icon" name="search"><path d="M192 480a256 256 0 1 1 512 0 256 256 0 0 1-512 0m631.776 362.496-143.2-143.168A318.464 318.464 0 0 0 768 480c0-176.736-143.264-320-320-320S128 303.264 128 480s143.264 320 320 320a318.016 318.016 0 0 0 184.16-58.592l146.336 146.368c12.512 12.48 32.768 12.48 45.28 0 12.48-12.512 12.48-32.768 0-45.28"></path></svg><div class="search-pro-placeholder">Search</div><div class="search-pro-key-hints"><kbd class="search-pro-key">Ctrl</kbd><kbd class="search-pro-key">K</kbd></div></button><!--]--><!--]--><!----><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar"><!----><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><p class="vp-sidebar-header"><iconify-icon class="font-icon icon" style="" mode="style" inline icon="fa-solid:laptop-code" width="1em" height="1em"></iconify-icon><span class="vp-sidebar-title">Demos</span><!----></p><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/notebook/" aria-label="ESPnet Notebooks"><!---->ESPnet Notebooks<!----></a></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">ESPnet EZ</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">ESPnet1</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">ESPnet2</span><span class="vp-arrow end"></span></button><!----></section></li></ul></section></li><li><section class="vp-sidebar-group"><p class="vp-sidebar-header"><iconify-icon class="font-icon icon" style="" mode="style" inline icon="fa-solid:mug-hot" width="1em" height="1em"></iconify-icon><span class="vp-sidebar-title">Recipes</span><!----></p><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/" aria-label="Recipe Template"><!---->Recipe Template<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/asr1.html" aria-label="Automatic Speech Recognition (Multi-tasking)"><!---->Automatic Speech Recognition (Multi-tasking)<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/asr2.html" aria-label="Automatic Speech Recognition with Discrete Units"><!---->Automatic Speech Recognition with Discrete Units<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/lm1.html" aria-label="Language Modeling"><!---->Language Modeling<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/mt1.html" aria-label="Machine Translation"><!---->Machine Translation<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/ssl1.html" aria-label="Self-supervised Learning"><!---->Self-supervised Learning<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/svs1.html" aria-label="Singing Voice Synthesis"><!---->Singing Voice Synthesis<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/diar1.html" aria-label="Speaker Diarisation"><!---->Speaker Diarisation<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/enh_diar1.html" aria-label="Speaker Diarisation with Speech Enhancement"><!---->Speaker Diarisation with Speech Enhancement<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/spk1.html" aria-label="Speaker Representation"><!---->Speaker Representation<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/asvspoof1.html" aria-label="Speaker Verification Spoofing and Countermeasures"><!---->Speaker Verification Spoofing and Countermeasures<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/codec1.html" aria-label="Speech Codec"><!---->Speech Codec<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/enh1.html" aria-label="Speech Enhancement"><!---->Speech Enhancement<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/speechlm1.html" aria-label="Speech Language Model"><!---->Speech Language Model<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/enh_asr1.html" aria-label="Speech Recognition with Speech Enhancement"><!---->Speech Recognition with Speech Enhancement<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/s2st1.html" aria-label="Speech-to-Speech Translation"><!---->Speech-to-Speech Translation<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/st1.html" aria-label="Speech-to-Text Translation"><!---->Speech-to-Text Translation<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/enh_st1.html" aria-label="Speech-to-Text Translation with Speech Enhancement"><!---->Speech-to-Text Translation with Speech Enhancement<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/slu1.html" aria-label="Spoken Language Understanding"><!---->Spoken Language Understanding<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/tts1.html" aria-label="Text-to-Speech"><!---->Text-to-Speech<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/tts2.html" aria-label="Text-to-Speech with Discrete Units"><!---->Text-to-Speech with Discrete Units<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/uasr1.html" aria-label="Unsupervised Automatic Speech Recognition"><!---->Unsupervised Automatic Speech Recognition<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet/recipe/s2t1.html" aria-label="Weakly-supervised Learning (Speech-to-Text)"><!---->Weakly-supervised Learning (Speech-to-Text)<!----></a></li></ul></section></li><li><section class="vp-sidebar-group"><p class="vp-sidebar-header"><iconify-icon class="font-icon icon" style="" mode="style" inline icon="fa-solid:book" width="1em" height="1em"></iconify-icon><span class="vp-sidebar-title">Python API</span><!----></p><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Espnet</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Espnet2</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Espnetez</span><span class="vp-arrow end"></span></button><!----></section></li></ul></section></li><li><section class="vp-sidebar-group"><p class="vp-sidebar-header"><iconify-icon class="font-icon icon" style="" mode="style" inline icon="fa-solid:wrench" width="1em" height="1em"></iconify-icon><span class="vp-sidebar-title">Shell API</span><!----></p><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Espnet Bin</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Espnet2 Bin</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Spm</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Utils</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Utils Py</span><span class="vp-arrow end"></span></button><!----></section></li></ul></section></li></ul><!----></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!----><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><!---->ESPnet2</h1><div class="page-info"><!----><!----><!----><!----><span class="page-reading-time-info" aria-label="Reading TimeâŒ›" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon" name="timer"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>About 18 min</span><meta property="timeRequired" content="PT18M"></span><!----><!----></div><hr></div><!----><!----><div class="theme-hope-content"><h1 id="espnet2" tabindex="-1"><a class="header-anchor" href="#espnet2"><span>ESPnet2</span></a></h1><nav class="table-of-contents"><ul><li><a aria-current="page" href="/espnet/espnet2_tutorial.html#main-changes-from-espnet1" class="router-link-active router-link-exact-active">Main changes from ESPnet1</a></li><li><a aria-current="page" href="/espnet/espnet2_tutorial.html#understanding-espnet2-recipes" class="router-link-active router-link-exact-active">Understanding ESPnet2 Recipes</a><ul><li><a aria-current="page" href="/espnet/espnet2_tutorial.html#change-directory-to-the-base-directory" class="router-link-active router-link-exact-active">Change directory to the base directory</a></li><li><a aria-current="page" href="/espnet/espnet2_tutorial.html#directory-structure-of-each-recipe" class="router-link-active router-link-exact-active">Directory structure of each recipe</a></li><li><a aria-current="page" href="/espnet/espnet2_tutorial.html#change-the-configuration" class="router-link-active router-link-exact-active">Change the configuration</a></li><li><a aria-current="page" href="/espnet/espnet2_tutorial.html#run-sh" class="router-link-active router-link-exact-active">run.sh</a></li></ul></li><li><a aria-current="page" href="/espnet/espnet2_tutorial.html#seeing-the-training-status" class="router-link-active router-link-exact-active">Seeing the training status</a><ul><li><a aria-current="page" href="/espnet/espnet2_tutorial.html#show-the-log-file" class="router-link-active router-link-exact-active">Show the log file</a></li><li><a aria-current="page" href="/espnet/espnet2_tutorial.html#show-the-training-status-in-a-image-file" class="router-link-active router-link-exact-active">Show the training status in a image file</a></li><li><a aria-current="page" href="/espnet/espnet2_tutorial.html#use-tensorboard" class="router-link-active router-link-exact-active">Use tensorboard</a></li></ul></li><li><a aria-current="page" href="/espnet/espnet2_tutorial.html#instruction-for-run-sh" class="router-link-active router-link-exact-active">Instruction for run.sh</a><ul><li><a aria-current="page" href="/espnet/espnet2_tutorial.html#how-to-parse-command-line-arguments-in-shell-scripts" class="router-link-active router-link-exact-active">How to parse command-line arguments in shell scripts?</a></li><li><a aria-current="page" href="/espnet/espnet2_tutorial.html#start-from-a-specified-stage-and-stop-at-a-specified-stage" class="router-link-active router-link-exact-active">Start from a specified stage and stop at a specified stage</a></li><li><a aria-current="page" href="/espnet/espnet2_tutorial.html#change-the-configuration-for-training" class="router-link-active router-link-exact-active">Change the configuration for training</a></li><li><a aria-current="page" href="/espnet/espnet2_tutorial.html#change-the-number-of-parallel-jobs" class="router-link-active router-link-exact-active">Change the number of parallel jobs</a></li><li><a aria-current="page" href="/espnet/espnet2_tutorial.html#multi-gpus-training-and-distributed-training" class="router-link-active router-link-exact-active">Multi GPUs training and distributed training</a></li></ul></li><li><a aria-current="page" href="/espnet/espnet2_tutorial.html#various-tips" class="router-link-active router-link-exact-active">Various tips</a><ul><li><a aria-current="page" href="/espnet/espnet2_tutorial.html#relationship-between-mini-batch-size-and-number-of-gpus" class="router-link-active router-link-exact-active">Relationship between mini-batch size and number of GPUs</a></li><li><a aria-current="page" href="/espnet/espnet2_tutorial.html#use-specified-experiment-directory-for-evaluation" class="router-link-active router-link-exact-active">Use specified experiment directory for evaluation</a></li><li><a aria-current="page" href="/espnet/espnet2_tutorial.html#evaluation-without-training-using-pretrained-model" class="router-link-active router-link-exact-active">Evaluation without training using pretrained model</a></li><li><a aria-current="page" href="/espnet/espnet2_tutorial.html#evaluation-using-openai-whisper" class="router-link-active router-link-exact-active">Evaluation using OpenAI Whisper</a></li><li><a aria-current="page" href="/espnet/espnet2_tutorial.html#packing-and-sharing-your-trained-model" class="router-link-active router-link-exact-active">Packing and sharing your trained model</a></li><li><a aria-current="page" href="/espnet/espnet2_tutorial.html#usage-of-self-supervised-learning-representations-as-feature" class="router-link-active router-link-exact-active">Usage of Self-Supervised Learning Representations as feature</a></li></ul></li><li><a aria-current="page" href="/espnet/espnet2_tutorial.html#streaming-asr" class="router-link-active router-link-exact-active">Streaming ASR</a><ul><li><a aria-current="page" href="/espnet/espnet2_tutorial.html#training" class="router-link-active router-link-exact-active">Training</a></li><li><a aria-current="page" href="/espnet/espnet2_tutorial.html#decoding" class="router-link-active router-link-exact-active">Decoding</a></li><li><a aria-current="page" href="/espnet/espnet2_tutorial.html#faq" class="router-link-active router-link-exact-active">FAQ</a></li></ul></li><li><a aria-current="page" href="/espnet/espnet2_tutorial.html#real-time-factor-and-latency" class="router-link-active router-link-exact-active">Real-Time-Factor and Latency</a><ul><li><a aria-current="page" href="/espnet/espnet2_tutorial.html#usage" class="router-link-active router-link-exact-active">Usage</a></li><li><a aria-current="page" href="/espnet/espnet2_tutorial.html#notes" class="router-link-active router-link-exact-active">Notes</a></li><li><a aria-current="page" href="/espnet/espnet2_tutorial.html#example" class="router-link-active router-link-exact-active">Example</a></li><li><a aria-current="page" href="/espnet/espnet2_tutorial.html#limitations" class="router-link-active router-link-exact-active">Limitations</a></li></ul></li><li><a aria-current="page" href="/espnet/espnet2_tutorial.html#transducer-asr" class="router-link-active router-link-exact-active">Transducer ASR</a><ul><li><a aria-current="page" href="/espnet/espnet2_tutorial.html#general-usage" class="router-link-active router-link-exact-active">General usage</a></li><li><a aria-current="page" href="/espnet/espnet2_tutorial.html#architecture" class="router-link-active router-link-exact-active">Architecture</a></li><li><a aria-current="page" href="/espnet/espnet2_tutorial.html#multi-task-learning" class="router-link-active router-link-exact-active">Multi-task learning</a></li><li><a aria-current="page" href="/espnet/espnet2_tutorial.html#inference" class="router-link-active router-link-exact-active">Inference</a></li><li><a aria-current="page" href="/espnet/espnet2_tutorial.html#streaming" class="router-link-active router-link-exact-active">Streaming</a></li><li><a aria-current="page" href="/espnet/espnet2_tutorial.html#faq-1" class="router-link-active router-link-exact-active">FAQ</a></li></ul></li></ul></nav><h2 id="main-changes-from-espnet1" tabindex="-1"><a class="header-anchor" href="#main-changes-from-espnet1"><span>Main changes from ESPnet1</span></a></h2><ul><li><strong>Chainer free</strong><ul><li>Discarding Chainer completely.</li><li>The development of Chainer is stopped at v7: https://chainer.org/announcement/2019/12/05/released-v7.html</li></ul></li><li><strong>Kaldi free</strong><ul><li>It&#39;s not mandatory to compile Kaldi.</li><li><strong>If you find some recipes requiring Kaldi mandatory, please report it. It should be dealt with as a bug in ESPnet2.</strong></li><li>We still support the features made by Kaldi optionally.</li><li>We still follow Kaldi style. i.e. depending on <code>utils/</code> of Kaldi.</li></ul></li><li><strong>On the fly</strong> feature extraction &amp; text preprocessing for training <ul><li>You don&#39;t need to create the feature file before training, but just input wave data directly.</li><li>We support both raw wave input and extracted features.</li><li>The preprocessing for text, tokenization to characters, or sentencepieces, can be also applied during training.</li><li>Support <strong>self-supervised learning representations</strong> from s3prl</li></ul></li><li>Discarding the JSON format describing the training corpus. <ul><li>Why do we discard the JSON format? Because a dict object generated from a large JSON file requires much memory and it also takes much time to parse such a large JSON file.</li></ul></li><li>Support distributed data-parallel training (Not enough tested) <ul><li>Single node multi GPU training with <code>DistributedDataParallel</code> is also supported.</li></ul></li></ul><h2 id="understanding-espnet2-recipes" tabindex="-1"><a class="header-anchor" href="#understanding-espnet2-recipes"><span>Understanding ESPnet2 Recipes</span></a></h2><p><strong>Recipe</strong> is a set of scripts that enables users to fully reproduce the experiment, such as data preparation, model definition, training, evaluation, and model release.</p><p>You can find the new recipes in <code>egs2</code> (shorthand for <em>Examples for ESPnet2</em>):</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span>espnet/  # Python modules of espnet1</span></span>
<span class="line"><span>espnet2/ # Python modules of espnet2</span></span>
<span class="line"><span>egs/     # espnet1 recipes</span></span>
<span class="line"><span>egs2/    # espnet2 recipes</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>The <code>egs2</code> recipes are always structured by <code>egs2/&lt;dataset&gt;/&lt;task&gt;</code>. So, for example, the user should be able to fully reproduce the experiment by the following:</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span># Dataset: an4, Task: ASR</span></span>
<span class="line"><span>cd egs2/an4/asr1/</span></span>
<span class="line"><span></span></span>
<span class="line"><span># Run the full experiment</span></span>
<span class="line"><span>./run.sh</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>Note that the usage of recipes is <strong>almost the same</strong> as that of ESPnet1.</p><p>Now, let&#39;s go step-by-step on how exactly the recipes work.</p><h3 id="change-directory-to-the-base-directory" tabindex="-1"><a class="header-anchor" href="#change-directory-to-the-base-directory"><span>Change directory to the base directory</span></a></h3><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" data-title="bash" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># e.g.</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;">cd</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> egs2/an4/asr1/</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><p><code>an4</code> is a tiny corpus and can be freely obtained, so it might be suitable for this tutorial. You can perform any other recipes as the same way. e.g. <code>wsj</code>, <code>librispeech</code>, and etc.</p><p>Keep in mind that all scripts should be ran at the level of <code>egs2/&lt;dataset&gt;/&lt;task&gt;</code>.</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" data-title="bash" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># Doesn&#39;t work</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;">cd</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> egs2/an4/</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">./asr1/run.sh</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">./asr1/scripts/</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">&lt;some-script&gt;.sh</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># Doesn&#39;t work</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;">cd</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> egs2/an4/asr1/local/</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">./data.sh</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># Works</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;">cd</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> egs2/an4/asr1</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">./run.sh</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">./scripts/</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">&lt;some-script&gt;.sh</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="directory-structure-of-each-recipe" tabindex="-1"><a class="header-anchor" href="#directory-structure-of-each-recipe"><span>Directory structure of each recipe</span></a></h3><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span>egs2/an4/asr1/</span></span>
<span class="line"><span>  - conf/      # Configuration files for training, inference, etc.</span></span>
<span class="line"><span>  - scripts/   # Bash utilities of espnet2</span></span>
<span class="line"><span>  - pyscripts/ # Python utilities of espnet2</span></span>
<span class="line"><span>  - steps/     # From Kaldi utilities</span></span>
<span class="line"><span>  - utils/     # From Kaldi utilities</span></span>
<span class="line"><span>  - db.sh      # The directory path of each corpora</span></span>
<span class="line"><span>  - path.sh    # Setup script for environment variables</span></span>
<span class="line"><span>  - cmd.sh     # Configuration for your backend of job scheduler</span></span>
<span class="line"><span>  - run.sh     # Entry point</span></span>
<span class="line"><span>  - asr.sh     # Invoked by run.sh</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="change-the-configuration" tabindex="-1"><a class="header-anchor" href="#change-the-configuration"><span>Change the configuration</span></a></h3><ul><li>You need to modify <code>db.sh</code> for specifying your corpus before executing <code>run.sh</code>. For example, when you touch the recipe of <code>egs2/wsj</code>, you need to change the paths of <code>WSJ0</code> and <code>WSJ1</code> in <code>db.sh</code>.</li><li>Some corpora can be freely obtained from the WEB and they are written as &quot;downloads/&quot; at the initial state. You can also change them to your corpus path if it&#39;s already downloaded.</li><li><code>path.sh</code> is used to set up the environment for <code>run.sh</code>. Note that the Python interpreter used for ESPnet is not the current Python of your terminal, but it&#39;s the Python which was installed at <code>tools/</code>. Thus you need to source <code>path.sh</code> to use this Python.<div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" data-title="bash" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;">.</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> path.sh</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">python</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div></li><li><code>cmd.sh</code> is used for specifying the backend of the job scheduler. If you don&#39;t have such a system in your local machine environment, you don&#39;t need to change anything about this file. See <a class="route-link" href="/espnet/parallelization.html">Using Job scheduling system</a></li></ul><h3 id="run-sh" tabindex="-1"><a class="header-anchor" href="#run-sh"><span><code>run.sh</code></span></a></h3><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" data-title="bash" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">./run.sh</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p><code>run.sh</code> is an example script, which we often call as &quot;recipe&quot;, to run all stages related to DNN experiments; data-preparation, training, and evaluation.</p><h2 id="seeing-the-training-status" tabindex="-1"><a class="header-anchor" href="#seeing-the-training-status"><span>Seeing the training status</span></a></h2><h3 id="show-the-log-file" tabindex="-1"><a class="header-anchor" href="#show-the-log-file"><span>Show the log file</span></a></h3><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" data-title="bash" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">%</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> tail</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> -f</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> exp/</span><span style="--shiki-light:#005CC5;--shiki-dark:#E5C07B;">*</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">_train_</span><span style="--shiki-light:#005CC5;--shiki-dark:#E5C07B;">*</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">/train.log</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">[host] 2020-04-05 16:34:54,278 (</span><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">trainer:192</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">) INFO: 2/40epoch started. Estimated </span><span style="--shiki-light:#D73A49;--shiki-dark:#C678DD;">time</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> to finish: 7 minutes and 58.63 seconds</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">[host] 2020-04-05 16:34:56,315 (</span><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">trainer:453</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">) INFO: 2epoch:train:1-10batch: </span><span style="--shiki-light:#24292E;--shiki-dark:#E06C75;">iter_time</span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">0.006,</span><span style="--shiki-light:#24292E;--shiki-dark:#E06C75;"> forward_time</span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">0.076,</span><span style="--shiki-light:#24292E;--shiki-dark:#E06C75;"> loss</span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">50.873,</span><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;"> los</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E06C75;">s_att</span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">35.801,</span><span style="--shiki-light:#24292E;--shiki-dark:#E06C75;"> loss_ctc</span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">65.945,</span><span style="--shiki-light:#24292E;--shiki-dark:#E06C75;"> acc</span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">0.471,</span><span style="--shiki-light:#24292E;--shiki-dark:#E06C75;"> backward_time</span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">0.072,</span><span style="--shiki-light:#24292E;--shiki-dark:#E06C75;"> optim_step_time</span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">0.006,</span><span style="--shiki-light:#24292E;--shiki-dark:#E06C75;"> lr_0</span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">1.000,</span><span style="--shiki-light:#24292E;--shiki-dark:#E06C75;"> train_time</span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">0.203</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">[host] 2020-04-05 16:34:58,046 (</span><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">trainer:453</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">) INFO: 2epoch:train:11-20batch: </span><span style="--shiki-light:#24292E;--shiki-dark:#E06C75;">iter_time</span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">4.280e-05,</span><span style="--shiki-light:#24292E;--shiki-dark:#E06C75;"> forward_time</span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">0.068,</span><span style="--shiki-light:#24292E;--shiki-dark:#E06C75;"> loss</span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">44.369</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">,</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> loss_att=28.776,</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> loss_ctc=59.962,</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> acc=0.506,</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> backward_time=0.055,</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> optim_step_time=0.006,</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> lr_0=1.000,</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> train_time=</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">0.173</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="show-the-training-status-in-a-image-file" tabindex="-1"><a class="header-anchor" href="#show-the-training-status-in-a-image-file"><span>Show the training status in a image file</span></a></h3><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" data-title="bash" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># Accuracy plot</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># (eog is Eye of GNOME Image Viewer)</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">eog</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> exp/</span><span style="--shiki-light:#005CC5;--shiki-dark:#E5C07B;">*</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">_train_</span><span style="--shiki-light:#005CC5;--shiki-dark:#E5C07B;">*</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">/images/acc.img</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># Attention plot</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">eog</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> exp/</span><span style="--shiki-light:#005CC5;--shiki-dark:#E5C07B;">*</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">_train_</span><span style="--shiki-light:#005CC5;--shiki-dark:#E5C07B;">*</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">/att_ws/</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&lt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">sample-i</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">d</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&gt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">/</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&lt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">param-nam</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">e</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&gt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">.img</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="use-tensorboard" tabindex="-1"><a class="header-anchor" href="#use-tensorboard"><span>Use tensorboard</span></a></h3><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" data-title="sh" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">tensorboard</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --logdir</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> exp/</span><span style="--shiki-light:#005CC5;--shiki-dark:#E5C07B;">*</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">_train_</span><span style="--shiki-light:#005CC5;--shiki-dark:#E5C07B;">*</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">/tensorboard/</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h2 id="instruction-for-run-sh" tabindex="-1"><a class="header-anchor" href="#instruction-for-run-sh"><span>Instruction for run.sh</span></a></h2><h3 id="how-to-parse-command-line-arguments-in-shell-scripts" tabindex="-1"><a class="header-anchor" href="#how-to-parse-command-line-arguments-in-shell-scripts"><span>How to parse command-line arguments in shell scripts?</span></a></h3><p>All shell scripts in espnet/espnet2 depend on <a href="https://github.com/kaldi-asr/kaldi/blob/master/egs/wsj/s5/utils/parse_options.sh" target="_blank" rel="noopener noreferrer">utils/parse_options.sh</a> to parase command line arguments.</p><p>e.g. If the script has <code>ngpu</code> option</p><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" data-title="sh" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">#!/usr/bin/env bash</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># run.sh</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E06C75;">ngpu</span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">1</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;">.</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> utils/parse_options.sh</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;">echo</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> ${</span><span style="--shiki-light:#24292E;--shiki-dark:#E06C75;">ngpu</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">}</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>Then you can change the value as follows:</p><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" data-title="sh" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">$</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> ./run.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --ngpu</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 2</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;">echo</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 2</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><p>You can also show the help message:</p><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" data-title="sh" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">./run.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --help</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h3 id="start-from-a-specified-stage-and-stop-at-a-specified-stage" tabindex="-1"><a class="header-anchor" href="#start-from-a-specified-stage-and-stop-at-a-specified-stage"><span>Start from a specified stage and stop at a specified stage</span></a></h3><p>The procedures in <code>run.sh</code> can be divided into some stages, e.g. data preparation, training, and evaluation. You can specify the starting stage and the stopping stage.</p><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" data-title="sh" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">./run.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --stage</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 2</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --stop-stage</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 6</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>There are also some altenative otpions to skip specified stages:</p><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" data-title="sh" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">run.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --skip_data_prep</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> true</span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">  # Skip data preparation stages.</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">run.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --skip_train</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> true</span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">      # Skip training stages.</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">run.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --skip_eval</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> true</span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">       # Skip decoding and evaluation stages.</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">run.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --skip_packing</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> false</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --skip_upload_hf</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> false</span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">  # Enable packing and uploading to huggingface stages.</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>Note that <code>skip_upload</code> and <code>skip_upload_hf</code> are true by default. Please change them to false when uploading your model.</p><h3 id="change-the-configuration-for-training" tabindex="-1"><a class="header-anchor" href="#change-the-configuration-for-training"><span>Change the configuration for training</span></a></h3><p>Please keep in mind that <code>run.sh</code> is a wrapper script of several tools including DNN training command. You need to do one of the following two ways to change the training configuration.</p><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" data-title="sh" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># Give a configuration file</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">./run.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --asr_config</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> conf/train_asr.yaml</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># Give arguments to &quot;espnet2/bin/asr_train.py&quot; directly</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">./run.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --asr_args</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> &quot;--foo arg --bar arg2&quot;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>e.g. To change learning rate for the LM training</p><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" data-title="sh" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">./run.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --lm_args</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> &quot;--optim_conf lr=0.1&quot;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>This is the case of ASR training and you need to replace it accordingly for the other task. e.g. For TTS</p><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" data-title="sh" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">./run.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --tts_args</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> &quot;--optim_conf lr=0.1&quot;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>See <a class="route-link" href="/espnet/espnet2_training_option.html">Change the configuration for training</a> for more detail about the usage of training tools.</p><h3 id="change-the-number-of-parallel-jobs" tabindex="-1"><a class="header-anchor" href="#change-the-number-of-parallel-jobs"><span>Change the number of parallel jobs</span></a></h3><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" data-title="sh" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">./run.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --nj</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 10</span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">             # Chnage the number of parallels for data preparation stages.</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">./run.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --inference_nj</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 10</span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">   # Chnage the number of parallels for inference jobs.</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><p>We also support submitting jobs to multiple hosts to accelerate your experiment: See <a class="route-link" href="/espnet/parallelization.html">Using Job scheduling system</a></p><h3 id="multi-gpus-training-and-distributed-training" tabindex="-1"><a class="header-anchor" href="#multi-gpus-training-and-distributed-training"><span>Multi GPUs training and distributed training</span></a></h3><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" data-title="sh" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">./run.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --ngpu</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 4</span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"> # 4GPUs in a single node</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">./run.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --ngpu</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 2</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --num_nodes</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 2</span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"> # 2GPUs x 2nodes</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><p>Note that you need to setup your environment correctly to use distributed training. See the following two:</p><ul><li><a class="route-link" href="/espnet/espnet2_distributed.html">Distributed training</a></li><li><a class="route-link" href="/espnet/parallelization.html">Using Job scheduling system</a></li></ul><h2 id="various-tips" tabindex="-1"><a class="header-anchor" href="#various-tips"><span>Various tips</span></a></h2><h3 id="relationship-between-mini-batch-size-and-number-of-gpus" tabindex="-1"><a class="header-anchor" href="#relationship-between-mini-batch-size-and-number-of-gpus"><span>Relationship between mini-batch size and number of GPUs</span></a></h3><p>The behavior of batch size in ESPnet2 during multi-GPU training is different from that in ESPnet1. <strong>In ESPnet2, the total batch size is not changed regardless of the number of GPUs.</strong> Therefore, you need to manually increase the batch size if you increase the number of GPUs. Please refer to this <a href="https://espnet.github.io/espnet/espnet2_training_option.html#the-relation-between-mini-batch-size-and-number-of-gpus" target="_blank" rel="noopener noreferrer">doc</a> for more information.</p><h3 id="use-specified-experiment-directory-for-evaluation" tabindex="-1"><a class="header-anchor" href="#use-specified-experiment-directory-for-evaluation"><span>Use specified experiment directory for evaluation</span></a></h3><p>If you already have trained a model, you may wonder how to give it to run.sh when you&#39;ll evaluate it later. By default the directory name is determined according to given options, <code>asr_args</code>, <code>lm_args</code>, or etc. You can overwrite it by <code>--asr_exp</code> and <code>--lm_exp</code>.</p><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" data-title="sh" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># For ASR recipe</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">./run.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --skip_data_prep</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> true</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --skip_train</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> true</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --asr_exp</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;"> &lt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">your_asr_exp_director</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">y</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --lm_exp</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;"> &lt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">your_lm_exp_director</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">y</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&gt;</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># For TTS recipe</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">./run.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --skip_data_prep</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> true</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --skip_train</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> true</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --tts_exp</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;"> &lt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">your_tts_exp_director</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">y</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&gt;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="evaluation-without-training-using-pretrained-model" tabindex="-1"><a class="header-anchor" href="#evaluation-without-training-using-pretrained-model"><span>Evaluation without training using pretrained model</span></a></h3><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" data-title="sh" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">./run.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --download_model</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;"> &lt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">model_nam</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">e</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --skip_train</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> true</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>You need to fill <code>model_name</code> by yourself. You can search for pretrained models on Hugging Face using the tag <a href="https://huggingface.co/models?library=espnet" target="_blank" rel="noopener noreferrer">espnet</a> See the following link about our pretrained models: https://github.com/espnet/espnet_model_zoo</p><h3 id="evaluation-using-openai-whisper" tabindex="-1"><a class="header-anchor" href="#evaluation-using-openai-whisper"><span>Evaluation using OpenAI Whisper</span></a></h3><p>ESPnet2 provides a <a href="../egs2/TEMPLATE/asr1/scripts/utils/evaluate_asr.sh">script</a> to run inference and scoring using OpenAI&#39;s Whisper. This can be used to evaluate speech generation models. Here is an example:</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" data-title="bash" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">#!/usr/bin/env bash</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># Set bash to &#39;debug&#39; mode, it will exit on :</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># -e &#39;error&#39;, -u &#39;undefined variable&#39;, -o ... &#39;error in pipeline&#39;, -x &#39;print commands&#39;,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;">set</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> -e</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;">set</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> -u</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;">set</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> -o</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> pipefail</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E06C75;">whisper_tag</span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">medium</span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">    # whisper model tag, e.g., small, medium, large, etc</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E06C75;">cleaner</span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">whisper_en</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E06C75;">hyp_cleaner</span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">whisper_en</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E06C75;">nj</span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">1</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E06C75;">test_sets</span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&quot;test/WSJ/test_eval92&quot;</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># decode_options is used in Whisper model&#39;s transcribe method</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E06C75;">decode_options</span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&quot;{language: en, task: transcribe, temperature: 0, beam_size: 10, fp16: False}&quot;</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#C678DD;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E06C75;"> x</span><span style="--shiki-light:#D73A49;--shiki-dark:#C678DD;"> in</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> ${</span><span style="--shiki-light:#24292E;--shiki-dark:#E06C75;">test_sets</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">}; </span><span style="--shiki-light:#D73A49;--shiki-dark:#C678DD;">do</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E06C75;">    wavscp</span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">dump/raw/</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">${</span><span style="--shiki-light:#24292E;--shiki-dark:#E06C75;">x</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">/wav.scp</span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">    # path to wav.scp</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E06C75;">    outdir</span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">whisper-</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">${</span><span style="--shiki-light:#24292E;--shiki-dark:#E06C75;">whisper_tag</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">_outputs/</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">${</span><span style="--shiki-light:#24292E;--shiki-dark:#E06C75;">x</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">}  </span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># path to save output</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E06C75;">    gt_text</span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">dump/raw/</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">${</span><span style="--shiki-light:#24292E;--shiki-dark:#E06C75;">x</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">/text</span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">      # path to groundtruth text file (for scoring only)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">    scripts/utils/evaluate_asr.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">        --whisper_tag</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> ${</span><span style="--shiki-light:#24292E;--shiki-dark:#E06C75;">whisper_tag</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">} </span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;">\</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">        --nj</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> ${</span><span style="--shiki-light:#24292E;--shiki-dark:#E06C75;">nj</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">} </span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;">\</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">        --gpu_inference</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> true</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">        --stage</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 2</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">        --stop_stage</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 3</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">        --cleaner</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> ${</span><span style="--shiki-light:#24292E;--shiki-dark:#E06C75;">cleaner</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">} </span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;">\</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">        --hyp_cleaner</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> ${</span><span style="--shiki-light:#24292E;--shiki-dark:#E06C75;">hyp_cleaner</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">} </span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;">\</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">        --decode_options</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> &quot;${</span><span style="--shiki-light:#24292E;--shiki-dark:#E06C75;">decode_options</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">}&quot;</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">        --gt_text</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> ${</span><span style="--shiki-light:#24292E;--shiki-dark:#E06C75;">gt_text</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">} </span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;">\</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">        ${</span><span style="--shiki-light:#24292E;--shiki-dark:#E06C75;">wavscp</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">} </span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;">\</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">        ${</span><span style="--shiki-light:#24292E;--shiki-dark:#E06C75;">outdir</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">}</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#C678DD;">done</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="packing-and-sharing-your-trained-model" tabindex="-1"><a class="header-anchor" href="#packing-and-sharing-your-trained-model"><span>Packing and sharing your trained model</span></a></h3><p>ESPnet encourages you to share your results using platforms like <a href="https://huggingface.co/" target="_blank" rel="noopener noreferrer">Hugging Face</a>.</p><p>For sharing your models, the last three stages of each task simplify this process. The model is packed into a zip file and uploaded to the selected platform (one or both).</p><p>For <strong>Hugging Face</strong>, you need to first create a repository (<code>&lt;my_repo&gt; = &lt;user_name&gt;/&lt;repo_name&gt;</code>). Remember to install <code>git-lfs </code> before continuing. Then, execute <code>run.sh</code> as follows:</p><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" data-title="sh" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">./run.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --stage</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;"> &lt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">packing</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> stag</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">e</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --skip-packing</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> false</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --skip-upload-hf</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> false</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --hf-repo</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;"> &lt;</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">my_rep</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">o</span><span style="--shiki-light:#D73A49;--shiki-dark:#ABB2BF;">&gt;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>The stage number differs according to the task. Please read the task-specific shell script (e.g., <code>asr1/asr.sh</code>) to see the number to specify. The packed model can be uploaded to huggingface by setting the previously mentioned flags.</p><h3 id="usage-of-self-supervised-learning-representations-as-feature" tabindex="-1"><a class="header-anchor" href="#usage-of-self-supervised-learning-representations-as-feature"><span>Usage of Self-Supervised Learning Representations as feature</span></a></h3><p>ESPnet supports self-supervised learning representations (SSLR) to replace traditional spectrum features. In some cases, SSLRs can boost the performance.</p><p>To use SSLRs in your task, you need to make several modifications.</p><ol><li>Install <a href="https://github.com/s3prl/s3prl" target="_blank" rel="noopener noreferrer">S3PRL</a> by <code>tools/installers/install_s3prl.sh</code>.</li><li>If HuBERT / Wav2Vec is needed, <a href="https://github.com/pytorch/fairseq" target="_blank" rel="noopener noreferrer">fairseq</a> should be installed by <code>tools/installers/install_fairseq.sh</code>.</li></ol><p>Here&#39;s various tips for using SSLRs.</p><ol><li>To reduce the time used in <code>collect_stats</code> step, please specify <code>--feats_normalize uttmvn</code> in <code>run.sh</code> and pass it as arguments to <code>asr.sh</code> or other task-specific scripts. (Recommended)</li><li>In the configuration file, specify the <code>frontend</code> and <code>preencoder</code>. Taking <code>HuBERT</code> as an example: The <code>upstream</code> name can be whatever supported in S3PRL. <code>multilayer-feature=True</code> means the final representation is a weighted-sum of all layers&#39; hidden states from SSLR model.<div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span>frontend: s3prl</span></span>
<span class="line"><span>frontend_conf:</span></span>
<span class="line"><span>   frontend_conf:</span></span>
<span class="line"><span>      upstream: hubert_large_ll60k  # Note: If the upstream is changed, please change the input_size in the preencoder.</span></span>
<span class="line"><span>   download_dir: ./hub</span></span>
<span class="line"><span>   multilayer_feature: True</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>Here the <code>preencoder</code> is to reduce the input dimension to the encoder, to reduce the memory cost. The <code>input_size</code> depends on the upstream model, while the <code>output_size</code> can be set to any values.<div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span>preencoder: linear</span></span>
<span class="line"><span>preencoder_conf:</span></span>
<span class="line"><span>   input_size: 1024  # Note: If the upstream is changed, please change this value accordingly.</span></span>
<span class="line"><span>   output_size: 80</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li><li>Because the shift sizes of different <code>upstream</code> models are different, e.g. <code>HuBERT</code> and <code>Wav2Vec2.0</code> have <code>20ms</code> frameshift. Sometimes, the downsampling rate (<code>input_layer</code>) in the <code>encoder</code> configuration need to be changed. For example, using <code>input_layer: conv2d2</code> will results in a total frameshift of <code>40ms</code>, which is enough for some tasks.</li></ol><h2 id="streaming-asr" tabindex="-1"><a class="header-anchor" href="#streaming-asr"><span>Streaming ASR</span></a></h2><p>ESPnet supports streaming Transformer/Conformer ASR with blockwise synchronous beam search. For more details, please refer to the <a href="https://arxiv.org/pdf/2006.14941.pdf" target="_blank" rel="noopener noreferrer">paper</a>.</p><h3 id="training" tabindex="-1"><a class="header-anchor" href="#training"><span>Training</span></a></h3><p>To achieve streaming ASR, please employ blockwise Transformer/Conformer encoder in the configuration file. Taking <code>blockwise Transformer</code> as an example: The <code>encoder</code> name can be <code>contextual_block_transformer</code> or <code>contextual_block_conformer</code>.</p><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" data-title="sh" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">encoder:</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> contextual_block_transformer</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">encoder_conf:</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">    block_size:</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 40</span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">         # block size for block processing</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">    hop_size:</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 16</span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">           # hop size for block processing</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">    look_ahead:</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 16</span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">         # look-ahead size for block processing</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">    init_average:</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> true</span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">     # whether to use average input as initial context</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">    ctx_pos_enc:</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> true</span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">      # whether to use positional encoding for the context vectors</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="decoding" tabindex="-1"><a class="header-anchor" href="#decoding"><span>Decoding</span></a></h3><p>To enable online decoding, the argument <code>--use_streaming true</code> should be added to <code>run.sh</code>.</p><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" data-title="sh" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">./run.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --stage</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 12</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --use_streaming</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> true</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h3 id="faq" tabindex="-1"><a class="header-anchor" href="#faq"><span>FAQ</span></a></h3><ol><li>Issue about <code>&#39;NoneType&#39; object has no attribute &#39;max&#39;</code> during training: Please make sure you employ <code>forward_train</code> function during traininig, check more details <a href="https://github.com/espnet/espnet/issues/3803" target="_blank" rel="noopener noreferrer">here</a>.</li><li>I successfully trained the model, but encountered the above issue during decoding: You may forget to specify <code>--use_streaming true</code> to select streaming inference.</li></ol><h2 id="real-time-factor-and-latency" tabindex="-1"><a class="header-anchor" href="#real-time-factor-and-latency"><span>Real-Time-Factor and Latency</span></a></h2><p>In order to calculate real-time-factor and (non-streaming) latency the script <code>utils/calculate_rtf.py</code> has been reworked and can now be used for both ESPnet1 and ESPnet2. The script calculates inference times based on time markers in the decoding log files and reports the average real-time-factor (RTF) and average latency over all decoded utterances. For ESPnet2, the script will automatically be run (see <a href="#limitations">Limitations</a> section below) after the decoding stage has finished but can also be run as a stand-alone script:</p><h3 id="usage" tabindex="-1"><a class="header-anchor" href="#usage"><span>Usage</span></a></h3><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span>usage: calculate_rtf.py [-h] [--log-dir LOG_DIR]</span></span>
<span class="line"><span>                        [--log-name {decode,asr_inference}]</span></span>
<span class="line"><span>                        [--input-shift INPUT_SHIFT]</span></span>
<span class="line"><span>                        [--start-times-marker {input lengths,speech length}]</span></span>
<span class="line"><span>                        [--end-times-marker {prediction,best hypo}]</span></span>
<span class="line"><span></span></span>
<span class="line"><span>calculate real time factor (RTF)</span></span>
<span class="line"><span></span></span>
<span class="line"><span>optional arguments:</span></span>
<span class="line"><span>  -h, --help            show this help message and exit</span></span>
<span class="line"><span>  --log-dir LOG_DIR     path to logging directory</span></span>
<span class="line"><span>  --log-name {decode,asr_inference}</span></span>
<span class="line"><span>                        name of logfile, e.g., &#39;decode&#39; (espnet1) and</span></span>
<span class="line"><span>                        &#39;asr_inference&#39; (espnet2)</span></span>
<span class="line"><span>  --input-shift INPUT_SHIFT</span></span>
<span class="line"><span>                        shift of inputs in milliseconds</span></span>
<span class="line"><span>  --start-times-marker {input lengths,speech length}</span></span>
<span class="line"><span>                        String marking start of decoding in logfile, e.g.,</span></span>
<span class="line"><span>                        &#39;input lengths&#39; (espnet1) and &#39;speech length&#39;</span></span>
<span class="line"><span>                        (espnet2)</span></span>
<span class="line"><span>  --end-times-marker {prediction,best hypo}</span></span>
<span class="line"><span>                        String marking end of decoding in logfile, e.g.,</span></span>
<span class="line"><span>                        &#39;prediction&#39; (espnet1) and &#39;best hypo&#39; (espnet2)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="notes" tabindex="-1"><a class="header-anchor" href="#notes"><span>Notes</span></a></h3><ul><li>Default settings still target ESPnet1 usage:<div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span>--log-name &#39;decode&#39;</span></span>
<span class="line"><span>--input-shift 10.0</span></span>
<span class="line"><span>--start-times-marker &#39;input lengths&#39;</span></span>
<span class="line"><span>--end-times-marker &#39;prediction&#39;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li><li>For ESPnet2, other frame shifts than 10ms are possible via different front-end/feature configurations. So different to ESPnet1, which logs the input feature frames at a fixed 10ms frame shift, in ESPnet2 the number of speech samples is logged instead and the audio sample shift in milliseconds (1/sampleRate x 1000) needs to be specified for <code>--input-shift</code> parameter (see <code>--input-shift 0.0625</code> in example below for 16000 Hz sample rate).</li></ul><h3 id="example" tabindex="-1"><a class="header-anchor" href="#example"><span>Example</span></a></h3><p>From <code>espnet/egs2/librispeech/asr1</code> the following call runs the decoding stage with pretrained ESPnet2 model:</p><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" data-title="sh" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">./run.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --stage</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 12</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">  --use_streaming</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> false</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --skip_data_prep</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> true</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --skip_train</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> true</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --download_model</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> byan/librispeech_asr_train_asr_conformer_raw_bpe_batch_bins30000000_accum_grad3_optim_conflr0.001_sp</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>Results for latency and rtf calculation on Librispeech test_clean subset can then be found in <code>espnet/egs2/librispeech/asr1/exp/byan/librispeech_asr_train_asr_conformer_raw_bpe_batch_bins30000000_accum_grad3_optim_conflr0.001_sp/decode_asr_lm_lm_train_lm_transformer2_en_bpe5000_valid.loss.ave_asr_model_valid.acc.ave/test_clean/logdir/calculate_rtf.log</code> file:</p><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" data-title="sh" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># ../../../utils/calculate_rtf.py --log-dir exp/byan/librispeech_asr_train_asr_conformer_raw_bpe_batch_bins30000000_accum_grad3_optim_conflr0.001_sp/decode_as</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">r_lm_lm_train_lm_transformer2_en_bpe5000_valid.loss.ave_asr_model_valid.acc.ave/test_clean/logdir</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --log-name</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> asr_inference</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --input-shift</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 0.0625</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --start-times-</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">marker</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> &quot;speech length&quot;</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --end-times-marker</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> &quot;best hypo&quot;</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">Total</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> audio</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> duration:</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 19452.481</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> [sec]</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">Total</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> decoding</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> time:</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 137762.231</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> [sec]</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">RTF:</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 7.082</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">Latency:</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 52581.004</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> [ms/sentence]</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="limitations" tabindex="-1"><a class="header-anchor" href="#limitations"><span>Limitations</span></a></h3><ul><li>Only non-streaming inference mode is supported currently</li><li>The decoding stage 12 in <code>asr.sh</code> automatically runs the rtf &amp; latency calculation if <code>&quot;asr_inference_tool == &quot;espnet2.bin.asr_inference&quot;</code>; other inference tools like k2 &amp; maskctc are still left to do</li></ul><h2 id="transducer-asr" tabindex="-1"><a class="header-anchor" href="#transducer-asr"><span>Transducer ASR</span></a></h2><blockquote><p><em><strong>Important</strong></em>: If you encounter any issue related to <code>warp-transducer</code>, please open an issue in <a href="https://github.com/b-flo/warp-transducer" target="_blank" rel="noopener noreferrer">our forked repo</a>.</p></blockquote><p>ESPnet2 supports models trained with the (RNN-)Tranducer loss, aka Transducer models. Currently, two versions of these models exist within ESPnet2: one under <code>asr</code> and the other under <code>asr_transducer</code>. The first one is designed as a supplement of CTC-Attention ASR models while the second is designed independently and purely for the Transducer task. For that, we rely on <code>ESPnetASRTransducerModel</code> instead of <code>ESPnetASRModel</code> and a new task called <code>ASRTransducerTask</code> is used in place of <code>ASRTask</code>.</p><p>For the user, it means two things. First, some features or modules may not be supported depending on the version used. Second, the usage of some common ASR features or modules may differ between the models. In addition, some core modules (e.g.: <code>preencoder</code> or <code>postencoder</code>) may be missing in the standalone version until validation.</p><p><em><strong>The following sections of this tutorial are dedicated to the introduction of the version under asr_transducer</strong></em>. Thus, the user should keep in mind that most features described here may not be available in the other version.</p><h3 id="general-usage" tabindex="-1"><a class="header-anchor" href="#general-usage"><span>General usage</span></a></h3><p>To enable Transducer model training or decoding in your experiments, the following option should be supplied to <code>asr.sh</code> in your <code>run.sh</code>:</p><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" data-title="sh" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">asr.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --asr_task</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> asr_transducer</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> [...]</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>For Transducer loss computation during training, we rely by default on a fork of <code>warp-transducer</code>. The installation procedure is described <a href="https://espnet.github.io/espnet/installation.html#step-3-optional-custom-tool-installation" target="_blank" rel="noopener noreferrer">here</a>.</p><p><strong>Note:</strong> We made available FastEmit regularization <a href="https://arxiv.org/pdf/2010.11148" target="_blank" rel="noopener noreferrer">[Yu et al., 2021]</a> during loss computation. To enable it, <code>fastemit_lambda</code> need to be set in <code>model_conf</code>:</p><pre><code>model_conf:
  fastemit_lambda: Regularization parameter for FastEmit. (float, default = 0.0)
</code></pre><p>Optionnaly, we also support training with the Pruned RNN-T loss <a href="https://arxiv.org/pdf/2206.13236.pdf" target="_blank" rel="noopener noreferrer">[Kuang et al. 2022]</a> made available in the <a href="https://github.com/k2-fsa/k2" target="_blank" rel="noopener noreferrer">k2</a> toolkit. To use it, the parameter <code>use_k2_pruned_loss</code> should be set to <code>True</code> in <code>model_conf</code>. From here, the loss computation can be controlled by setting the following parameters through <code>k2_pruned_loss_args</code> in <code>model_conf</code>:</p><pre><code>model_conf:
  use_k2_pruned_loss: True
  k2_pruned_loss_args:
    prune_range: How many tokens by frame are used compute the pruned loss. (int, default = 5)
    simple_loss_scaling: The weight to scale the simple loss after warm-up. (float, default = 0.5)
    lm_scale: The scale factor to smooth the LM part. (float, default = 0.0)
    am_scale: The scale factor to smooth the AM part. (float, default = 0.0)
    loss_type: Define the type of path to take for loss computation, either &#39;regular&#39;, &#39;smoothed&#39; or &#39;constrained&#39;. (str, default = &quot;regular&quot;)
</code></pre><p><strong>Note:</strong> Because the number of tokens emitted by timestep can be restricted during training with this version, we also make available the parameter <code>validation_nstep</code>. It let the users apply similar constraints during the validation process, when reporting CER or/and WER:</p><pre><code>model_conf:
  validation_nstep: Maximum number of symbol expansions at each time step when reporting CER or/and WER using mAES.
</code></pre><p>For more information, see section Inference and &quot;modified Adaptive Expansion Search&quot; algorithm.</p><h3 id="architecture" tabindex="-1"><a class="header-anchor" href="#architecture"><span>Architecture</span></a></h3><p>The architecture is composed of three modules: encoder, decoder and joint network. Each module has one (or three) config(s) with various parameters in order to configure the internal parts. The following sections describe the mandatory and optional parameters for each module.</p><h4 id="encoder" tabindex="-1"><a class="header-anchor" href="#encoder"><span>Encoder</span></a></h4><p>For the encoder, we propose a unique encoder type encapsulating the following blocks: Branchformer, Conformer, Conv 1D and E-Branchformer. It is similar to the custom encoder in ESPnet1, meaning we don&#39;t need to set the parameter <code>encoder: [type]</code> here. Instead, the encoder architecture is defined by three configurations passed to <code>encoder_conf</code>:</p><ol><li><code>input_conf</code> (<strong>Dict</strong>): The configuration for the input block.</li><li><code>main_conf</code> (<strong>Dict</strong>): The main configuration for the parameters shared across all blocks.</li><li><code>body_conf</code> (<strong>List[Dict]</strong>): The list of configurations for each block of the encoder architecture but the input block.</li></ol><p>The first and second configurations are optional. If needed, the following parameters can be modified in each configuration:</p><pre><code>main_conf:
  pos_wise_act_type: Conformer position-wise feed-forward activation type. (str, default = &quot;swish&quot;)
  conv_mod_act_type: Conformer convolution module activation type. (str, default = &quot;swish&quot;)
  pos_enc_dropout_rate: Dropout rate for the positional encoding layer, if used. (float, default = 0.0)
  pos_enc_max_len: Positional encoding maximum length. (int, default = 5000)
  simplified_att_score: Whether to use simplified attention score computation. (bool, default = False)
  norm_type: X-former normalization module type. (str, default = &quot;layer_norm&quot;)
  conv_mod_norm_type: Branchformer convolution module normalization type. (str, default = &quot;layer_norm&quot;)
  after_norm_eps: Epsilon value for the final normalization module. (float, default = 1e-05 or 0.25 for BasicNorm)
  after_norm_partial: Partial value for the final normalization module, if norm_type = &#39;rms_norm&#39;. (float, default = -1.0)
  blockdrop_rate: Probability threshold of dropping out each encoder block. (float, default = 0.0)
  # For more information on the parameters below, please refer to espnet2/asr_transducer/activation.py
  ftswish_threshold: Threshold value for FTSwish activation formulation.
  ftswish_mean_shift: Mean shifting value for FTSwish activation formulation.
  hardtanh_min_val: Minimum value of the linear region range for HardTanh activation. (float, default = -1.0)
  hardtanh_max_val: Maximum value of the linear region range for HardTanh. (float, default = 1.0)
  leakyrelu_neg_slope: Negative slope value for LeakyReLU activation formulation.
  smish_alpha: Alpha value for Smish variant activation fomulation. (float, default = 1.0)
  smish_beta: Beta value for Smish variant activation formulation. (float, default = 1.0)
  softplus_beta: Beta value for softplus activation formulation in Mish activation. (float, default = 1.0)
  softplus_threshold: Values above this revert to a linear function in Mish activation. (int, default = 20)
  swish_beta: Beta value for E-Swish activation formulation. (float, default = 20)

input_conf:
  block_type: Input block type, either &quot;conv2d&quot; or &quot;vgg&quot;. (str, default = &quot;conv2d&quot;)
  conv_size: Convolution output size. For &quot;vgg&quot;, the two convolution outputs can be controlled by passing a tuple. (int, default = 256)
  subsampling_factor: Subsampling factor of the input block, either 2 (only conv2d), 4 or 6. (int, default = 4)
</code></pre><p>The only mandatory configuration is <code>body_conf</code>, defining the encoder body architecture block by block. Each block has its own set of mandatory and optional parameters depending on the type, defined by <code>block_type</code>:</p><pre><code># Branchformer
- block_type: branchformer
  hidden_size: Hidden (and output) dimension. (int)
  linear_size: Dimension of the Linear layers. (int)
  conv_mod_kernel_size: Size of the convolving kernel in the ConvolutionalSpatialGatingUnit module. (int)
  heads (optional): Number of heads in multi-head attention. (int, default = 4)
  norm_eps (optional): Epsilon value for the normalization module. (float, default = 1e-05 or 0.25 for BasicNorm)
  norm_partial (optional): Partial value for the normalization module, if norm_type = &#39;rms_norm&#39;. (float, default = -1.0)
  conv_mod_norm_eps (optional): Epsilon value for ConvolutionalSpatialGatingUnit module normalization. (float, default = 1e-05 or 0.25 for BasicNorm)
  conv_mod_norm_partial (optional): Partial value for the ConvolutionalSpatialGatingUnit module normalization, if conv_norm_type = &#39;rms_norm&#39;. (float, default = -1.0)
  dropout_rate (optional): Dropout rate for some intermediate layers. (float, default = 0.0)
  att_dropout_rate (optional): Dropout rate for the attention module. (float, default = 0.0)

# Conformer
- block_type: conformer
  hidden_size: Hidden (and output) dimension. (int)
  linear_size: Dimension of feed-forward module. (int)
  conv_mod_kernel_size: Size of the convolving kernel in the ConformerConvolution module. (int)
  heads (optional): Number of heads in multi-head attention. (int, default = 4)
  norm_eps (optional): Epsilon value for normalization module. (float, default = 1e-05 or 0.25 for BasicNorm)
  norm_partial (optional): Partial value for the normalization module, if norm_type = &#39;rms_norm&#39;. (float, default = -1.0)
  conv_mod_norm_eps (optional): Epsilon value for Batchnorm1d in the ConformerConvolution module. (float, default = 1e-05)
  conv_mod_norm_momentum (optional): Momentum value for Batchnorm1d in the ConformerConvolution module. (float, default = 0.1)
  dropout_rate (optional): Dropout rate for some intermediate layers. (float, default = 0.0)
  att_dropout_rate (optional): Dropout rate for the attention module. (float, default = 0.0)
  pos_wise_dropout_rate (optional): Dropout rate for the position-wise feed-forward module. (float, default = 0.0)

# Conv 1D
- block_type: conv1d
  output_size: Output size. (int)
  kernel_size: Size of the convolving kernel. (int or Tuple)
  stride (optional): Stride of the sliding blocks. (int or tuple, default = 1)
  dilation (optional): Parameter to control the stride of elements within the neighborhood. (int or tuple, default = 1)
  groups (optional): Number of blocked connections from input channels to output channels. (int, default = 1)
  bias (optional): Whether to add a learnable bias to the output. (bool, default = True)
  relu (optional): Whether to use a ReLU activation after convolution. (bool, default = True)
  batch_norm: Whether to use batch normalization after convolution. (bool, default = False)
  dropout_rate (optional): Dropout rate for the Conv1d outputs. (float, default = 0.0)

# E-Branchformer
- block_type: ebranchformer
  hidden_size: Hidden (and output) dimension. (int)
  linear_size: Dimension of the feed-forward module and othger linear layers. (int)
  conv_mod_kernel_size: Size of the convolving kernel in the ConvolutionalSpatialGatingUnit module. (int)
  depthwise_conv_kernel_size: Size of the convolving kernel in the DepthwiseConvolution module. (int, default = conv_mod_kernel_size)
  heads (optional): Number of heads in multi-head attention. (int, default = 4)
  norm_eps (optional): Epsilon value for the normalization module. (float, default = 1e-05 or 0.25 for BasicNorm)
  norm_partial (optional): Partial value for the normalization module, if norm_type = &#39;rms_norm&#39;. (float, default = -1.0)
  conv_mod_norm_eps (optional): Epsilon value for ConvolutionalSpatialGatingUnit module normalization. (float, default = 1e-05 or 0.25 for BasicNorm)
  conv_mod_norm_partial (optional): Partial value for the ConvolutionalSpatialGatingUnit module normalization, if conv_norm_type = &#39;rms_norm&#39;. (float, default = -1.0)
  dropout_rate (optional): Dropout rate for some intermediate layers. (float, default = 0.0)
  att_dropout_rate (optional): Dropout rate for the attention module. (float, default = 0.0)
</code></pre><p>In addition, each block has a parameter <code>num_blocks</code> to build <strong>N</strong> times the defined block (int, default = 1). This is useful if you want to use a group of blocks sharing the same parameters without writing each configuration.</p><p><strong>Example 1: conv 2D + 2x Conv 1D + 14x Conformer.</strong></p><div class="language-yaml line-numbers-mode" data-highlighter="shiki" data-ext="yaml" data-title="yaml" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">encoder_conf</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">:</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">    main_conf</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">:</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">      pos_wise_act_type</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">swish</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">      pos_enc_dropout_rate</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">0.1</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">      conv_mod_act_type</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">swish</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">    input_conf</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">:</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">      block_type</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">conv2d</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">      conv_size</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">256</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">      subsampling_factor</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">4</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">    body_conf</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">:</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">    - </span><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">block_type</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">conv1d</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">      output_size</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">128</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">      kernel_size</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">3</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">    - </span><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">block_type</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">conv1d</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">      output_size</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">256</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">      kernel_size</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">2</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">    - </span><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">block_type</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">conformer</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">      linear_size</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">1024</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">      hidden_size</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">256</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">      heads</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">8</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">      dropout_rate</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">0.1</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">      pos_wise_dropout_rate</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">0.1</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">      att_dropout_rate</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">0.1</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">      conv_mod_kernel_size</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">31</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">      num_blocks</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">14</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="decoder" tabindex="-1"><a class="header-anchor" href="#decoder"><span>Decoder</span></a></h4><p>For the decoder, four types of blocks are available: stateless (&#39;stateless&#39;), RNN (&#39;rnn&#39;), MEGA (&#39;mega&#39;) or RWKV (&#39;rwkv&#39;). Contrary to the encoder, the parameters are shared across the blocks, meaning we only define one block in the configuration. The type of the stack of blocks is defined by passing the corresponding type string to the parameter <code>decoder</code>. The internal parts are defined through the field <code>decoder_conf</code> containing the following controlable parameters:</p><pre><code>decoder_conf:
  embed_size: Size of the embedding layer (int, default = 256).
  num_blocks: Number of decoder blocks/layers (int, default = 4 for MEGA or 1 for RNN).
  rnn_type (RNN only): Type of RNN cells (int, default = &quot;lstm&quot;).
  hidden_size (RNN only): Size of the hidden layers (int, default = 256).
  block_size (MEGA/RWKV only): Size of the block&#39;s input/output (int, default = 512).
  linear_size (MEGA/RWKV only): Feed-Forward module hidden size (int, default = 1024).
  attention_size (RWKV only): Hidden-size of the attention module. (int, default = None).
  context_size (RWKV only): Context size for the WKV kernel module (int, default = 1024).
  qk_size (MEGA only): Shared query and key size for attention module (int, default = 128).
  v_size (MEGA only): Value size for attention module (int, default = 1024).
  chunk_size (MEGA only): Chunk size for attention computation (int, default = -1, i.e. full context).
  num_heads (MEGA only): Number of EMA heads (int, default = 4).
  rel_pos_bias (MEGA only): Type of relative position bias in attention module (str, default = &quot;simple&quot;).
  max_positions (MEGA only): Maximum number of position for RelativePositionBias (int, default = 2048).
  truncation_length (MEGA only): Maximum length for truncation in EMA module (int, default = None).
  normalization_type (MEGA/RWKV only): Normalization layer type (str, default = &quot;layer_norm&quot;).
  normalization_args (MEGA/RKWV only): Normalization layer arguments (dict, default = {}).
  activation_type (MEGA only): Activation function type (str, default = &quot;swish&quot;).
  activation_args (MEGA only): Activation function arguments (dict, default = {}).
  rescale_every (RWKV only): Whether to rescale input every N blocks during inference (int, default = 0)
  dropout_rate (excl. RWKV): Dropout rate for main block modules (float, default = 0.0).
  embed_dropout_rate: Dropout rate for embedding layer (float, default = 0.0).
  att_dropout_rate (MEGA/RWKV only): Dropout rate for the attention module.
  ema_dropout_rate (MEGA only): Dropout rate for the EMA module.
  ffn_dropout_rate (MEGA/RWKV only): Dropout rate for the feed-forward module.
</code></pre><p><strong>Example 1: RNN decoder.</strong></p><div class="language-yaml line-numbers-mode" data-highlighter="shiki" data-ext="yaml" data-title="yaml" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">decoder</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">rnn</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">decoder_conf</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">:</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">    rnn_type</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">lstm</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">    num_layers</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">2</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">    embed_size</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">256</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">    hidden_size</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">256</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">    dropout_rate</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">0.1</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">    embed_dropout_rate</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">0.1</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>Example 2: MEGA decoder.</strong></p><div class="language-yaml line-numbers-mode" data-highlighter="shiki" data-ext="yaml" data-title="yaml" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">decoder</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">mega</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">decoder_conf</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">:</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">    block_size</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">256</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">    linear_size</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">2048</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">    qk_size</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">128</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">    v_size</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">1024</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">    max_positions</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">1024</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">    num_heads</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">4</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">    rel_pos_bias_type</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&quot;rotary&quot;</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">    chunk_size</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">256</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">    num_blocks</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">6</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">    dropout_rate</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">0.1</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">    ffn_dropout_rate</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">0.1</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">    att_dropout_rate</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">0.1</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#E06C75;">    embed_dropout_rate</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">0.1</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="joint-network" tabindex="-1"><a class="header-anchor" href="#joint-network"><span>Joint network</span></a></h4><p>Currently, we only propose the standard joint network module composed of three linear layers and an activation function. The module definition is optional but the following parameters can be modified through the configuration parameter <code>joint_network_conf</code>:</p><pre><code>joint_network_conf:
  joint_space_size: Size of the joint space (int, default = 256).
  joint_act_type: Type of activation in the joint network (str, default = &quot;tanh&quot;).
</code></pre><p>The options related to the activation functions can also be modified through the parameters introduced in the Encoder section (See <code>main_conf</code> description).</p><h3 id="multi-task-learning" tabindex="-1"><a class="header-anchor" href="#multi-task-learning"><span>Multi-task learning</span></a></h3><p>We also support multi-task learning with two auxiliary tasks: CTC and cross-entropy w/ label smoothing option (called LM loss here). The auxiliary tasks contribute to the overal task defined as:</p><p><strong>L_tot = (Î»_trans x L_trans) + (Î»_auxCTC x L_auxCTC) + (Î»_auxLM x L_auxLM)</strong></p><p>where the losses (L_*) are respectively, in order: The Transducer loss, the CTC loss and the LM loss. Lambda values define their respective contribution to the total loss. Each task can be parameterized using the following options, passed to <code>model_conf</code>:</p><pre><code>model_conf:
  transducer_weight: Weight of the Transducer loss (float, default = 1.0)
  auxiliary_ctc_weight: Weight of the CTC loss. (float, default = 0.0)
  auxiliary_ctc_dropout_rate: Dropout rate for the CTC loss inputs. (float, default = 0.0)
  auxiliary_lm_loss_weight: Weight of the LM loss. (float, default = 0.2)
  auxiliary_lm_loss_smoothing: Smoothing rate for LM loss. If &gt; 0, label smoothing is enabled. (float, default = 0.0)
</code></pre><p><strong>Note:</strong> We do not support other auxiliary tasks in ESPnet2 yet.</p><h3 id="inference" tabindex="-1"><a class="header-anchor" href="#inference"><span>Inference</span></a></h3><p>Various decoding algorithms are also available for Transducer by setting <code>search_type</code> parameter in your decode config:</p><ul><li>Beam search algorithm without prefix search <a href="https://arxiv.org/pdf/1211.3711.pdf" target="_blank" rel="noopener noreferrer">[Graves, 2012]</a>. (<code>search_type: default</code>)</li><li>Time Synchronous Decoding <a href="https://ieeexplore.ieee.org/abstract/document/9053040" target="_blank" rel="noopener noreferrer">[Saon et al., 2020]</a>. (<code>search_type: tsd</code>)</li><li>Alignment-Length Synchronous Decoding <a href="https://ieeexplore.ieee.org/abstract/document/9053040" target="_blank" rel="noopener noreferrer">[Saon et al., 2020]</a>. (<code>search_type: alsd</code>)</li><li>modified Adaptive Expansion Search, based on <a href="https://ieeexplore.ieee.org/abstract/document/9250505" target="_blank" rel="noopener noreferrer">[Kim et al., 2021]</a> and <a href="https://arxiv.org/pdf/2201.05420.pdf" target="_blank" rel="noopener noreferrer">[Boyer et al., 2021]</a>. (<code>search_type: maes</code>)</li></ul><p>The algorithms share two parameters to control the beam size (<code>beam_size</code>) and the partial/final hypotheses normalization (<code>score_norm</code>). In addition, three algorithms have specific parameters:</p><pre><code># Time-synchronous decoding
search_type: tsd
max_sym_exp : Number of maximum symbol expansions at each time step. (int &gt; 1, default = 3)

# Alignement-Length Synchronous decoding
search_type: alsd
u_max: Maximum expected target sequence length. (int, default = 50)

# modified Adaptive Expansion Search
search_type: maes
nstep: Number of maximum expansion steps at each time step (int, default = 2)
expansion_gamma: Number of additional candidates in expanded hypotheses selection. (int, default = 2)
expansion_beta: Allowed logp difference for prune-by-value method. (float, default = 2.3)
</code></pre><p><em><strong>Note:</strong></em> Except for the default algorithm, the described parameters are used to control the performance and decoding speed. The optimal values for each parameter are task-dependent; a high value will typically increase decoding time to focus on performance while a low value will improve decoding time at the expense of performance.</p><p><em><strong>Note 2:</strong></em> The algorithms in the standalone version are the same as the one in the other version.. However, due to design choices, some parts were reworked and minor optimizations were added in the same time.</p><h3 id="streaming" tabindex="-1"><a class="header-anchor" href="#streaming"><span>Streaming</span></a></h3><p>To enable streaming capabilities for Transducer models, we support dynamic chunk training and chunk-by-chunk decoding as proposed in <a href="https://arxiv.org/pdf/2012.05481.pdf" target="_blank" rel="noopener noreferrer">[Zhang et al., 2021]</a>. Our implementation is based on the version proposed in <a href="https://github.com/k2-fsa/icefall/" target="_blank" rel="noopener noreferrer">Icefall</a>, based itself on the original <a href="https://github.com/wenet-e2e/wenet/" target="_blank" rel="noopener noreferrer">WeNet</a> one.</p><p>For a complete explanation on the different procedure and parameters, we refer the reader to the corresponding paper.</p><h4 id="training-1" tabindex="-1"><a class="header-anchor" href="#training-1"><span>Training</span></a></h4><p>To train a streaming model, the parameter <code>dynamic_chunk_training</code> should be set to <code>True</code> in <code>main_conf</code> (See section <a href="https://github.com/espnet/espnet/blob/master/doc/espnet2_tutorial.md#encoder" target="_blank" rel="noopener noreferrer">Encoder</a>. From here, the user has access to two parameters in order to control the dynamic chunk selection (<code>short_chunk_threshold</code> and <code>short_chunk_size</code>) and another one to control the left context in the causal convolution and the attention module (<code>num_left_chunks</code>).</p><p>All these parameters can be configured through <code>main_conf</code>, introduced in the Encoder section:</p><pre><code>dynamic_chunk_training: Whether to train streaming model with dynamic chunks. (bool, default = False)
short_chunk_threshold: Chunk length threshold (in percent) for dynamic chunk selection. (int, default = 0.75)
short_chunk_size: Minimum number of frames during dynamic chunk training. (int, default = 25)
num_left_chunks: The number of left chunks the attention module can see during training, where the actual size is defined by `short_chunk_threshold` and `short_chunk_size`. (int, default = 0, i.e. full context)
</code></pre><h4 id="decoding-1" tabindex="-1"><a class="header-anchor" href="#decoding-1"><span>Decoding</span></a></h4><p>To perform chunk-by-chunk inference, the parameter <code>streaming</code> should be set to True in the decoding configuration (otherwise, offline decoding will be performed). Two parameters are available to control the decoding process:</p><pre><code>decoding_window: The input audio length, in milliseconds, to process during decoding. (int, default = 640)
left_context: Number of previous frames (AFTER subsampling) the attention module can see in current chunk. (int, default = 32)
</code></pre><p><em><strong>Note:</strong></em> All search algorithms but ALSD are available with chunk-by-chunk inference.</p><h3 id="faq-1" tabindex="-1"><a class="header-anchor" href="#faq-1"><span>FAQ</span></a></h3><h4 id="how-to-add-a-new-block-type-to-the-custom-encoder" tabindex="-1"><a class="header-anchor" href="#how-to-add-a-new-block-type-to-the-custom-encoder"><span>How to add a new block type to the custom encoder?</span></a></h4><p><em><strong>Provided paths are relative to the directory: <code>espnet2/asr_transducer/encoder/</code></strong></em></p><p>Adding support to a new block type can be achieved in three main steps:</p><ol><li>Write your need block class in <code>encoder/blocks/</code>. The class should have the following methods: <code>__init__(...)</code>, <code>forward(...)</code> (training + offline), <code>chunk_forward(...)</code> (online decoding), <code>reset_streaming_cache(...)</code> (online cache definition). For more details on implementing internal parts, we refer the user to the existing block definition and the Streaming section.</li><li>In <code>building.py</code>, write a block constructor method and add a new condition in <code>build_body_blocks(...)</code> for your block type, calling the constructor method. If you need additional parameters to share across blocks, you can add them in <code>build_main_parameters(...)</code> and pass <code>main_conf</code> to your constructor.</li><li>In <code>validation.py</code>, add new conditions to `validate_block_arguments(...) in order to set and validate the mandatory block parameters before building (if not already covered).</li></ol><p>For additional information or examples, please refer to the named files. If you need to add other classes related to the new block, they should be added within the block class or in <code>modules/</code>.</p></div><!----><footer class="vp-page-meta"><!----><div class="vp-meta-item git-info"><!----><!----></div></footer><!----><!----><!----><!--]--></main><!--]--><footer class="vp-footer-wrapper"><div class="vp-footer">Copyright Â© 2024 ESPnet Community. All rights reserved.</div><!----></footer></div><!--]--><!--]--><!--[--><!----><!----><!--]--><!--]--></div>
    <script type="module" src="/espnet/assets/app-B6Ithpv3.js" defer></script>
  </body>
</html>
