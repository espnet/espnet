# load default config
defaults:
  - train.yaml

num_nodes: 1
num_device: 4
expdir: ${recipedir}/exp/node_${num_nodes}_gpu_${num_device}

dataloader:
  train:
    multiple_iterator: true
    num_shards: 12
    iter_factory:
    batch_size: 32
    shuffle: true
    num_workers: 16
  valid:
    iter_factory:
    batch_size: 32
    shuffle: false
    num_workers: 16

trainer:
  max_epochs: 10
  precision: bf16-mixed
  accumulate_grad_batches: 2
  log_every_n_steps: 200 # consistent with espnet
  limit_train_batches: 10000

  logger:
    - _target_: lightning.pytorch.loggers.WandbLogger
      project: OWSM Debug Run for ESPnet-3
      save_dir: ${expdir}/wandb
      name: node_${num_nodes}_gpu_${num_device}
