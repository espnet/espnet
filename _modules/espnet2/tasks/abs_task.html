<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>espnet2.tasks.abs_task &mdash; ESPnet 202204 documentation</title><link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../../../_static/jquery.js"></script>
        <script type="text/javascript" src="../../../_static/underscore.js"></script>
        <script type="text/javascript" src="../../../_static/doctools.js"></script>
        <script type="text/javascript" src="../../../_static/language_data.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "tex2jax_ignore|mathjax_ignore|document", "processClass": "tex2jax_process|mathjax_process|math|output_area"}})</script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../index.html" class="icon icon-home"> ESPnet
          </a>
              <div class="version">
                202204
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p><span class="caption-text">Tutorial:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorial.html">Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../parallelization.html">Using Job scheduling system</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq.html">FAQ</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../docker.html">Docker</a></li>
</ul>
<p><span class="caption-text">ESPnet2:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../espnet2_tutorial.html">ESPnet2</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../espnet2_tutorial.html#instruction-for-run-sh">Instruction for run.sh</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../espnet2_training_option.html">Change the configuration for training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../espnet2_task.html">Task class and data input system for training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../espnet2_distributed.html">Distributed training</a></li>
</ul>
<p><span class="caption-text">Notebook:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../notebook/asr_cli.html">Speech Recognition (Recipe)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notebook/asr_library.html">Speech Recognition (Library)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notebook/espnet2_asr_realtime_demo.html">ESPnet2-ASR realtime demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notebook/espnet2_asr_transfer_learning_demo.html"><strong>Use transfer learning for ASR in ESPnet2</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notebook/espnet2_asr_transfer_learning_demo.html#Abstract">Abstract</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notebook/espnet2_asr_transfer_learning_demo.html#ESPnet-installation-(about-10-minutes-in-total)">ESPnet installation (about 10 minutes in total)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notebook/espnet2_asr_transfer_learning_demo.html#mini_an4-recipe-as-a-transfer-learning-example">mini_an4 recipe as a transfer learning example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notebook/espnet2_streaming_asr_demo.html">ESPnet2 real streaming Transformer demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notebook/espnet2_tts_realtime_demo.html">ESPnet2-TTS realtime demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notebook/espnet2_tutorial_2021_CMU_11751_18781.html">CMU 11751/18781 2021: ESPnet Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notebook/espnet2_tutorial_2021_CMU_11751_18781.html#Run-an-inference-example">Run an inference example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notebook/espnet2_tutorial_2021_CMU_11751_18781.html#Full-installation">Full installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notebook/espnet2_tutorial_2021_CMU_11751_18781.html#Run-a-recipe-example">Run a recipe example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notebook/espnet_se_demonstration_for_waspaa_2021.html">ESPnet Speech Enhancement Demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notebook/espnet_se_demonstration_for_waspaa_2021.html#Contents">Contents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notebook/espnet_se_demonstration_for_waspaa_2021.html#(1)-Tutorials-on-the-Basic-Usage">(1) Tutorials on the Basic Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notebook/espnet_se_demonstration_for_waspaa_2021.html#(2)-Tutorials-on-Contributing-to-ESPNet-SE-Project">(2) Tutorials on Contributing to ESPNet-SE Project</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notebook/pretrained.html">Pretrained Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notebook/se_demo.html">ESPnet Speech Enhancement Demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notebook/st_demo.html">ESPnet Speech Translation Demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notebook/tts_cli.html">Text-to-Speech (Recipe)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notebook/tts_realtime_demo.html">ESPnet real time E2E-TTS demonstration</a></li>
</ul>
<p><span class="caption-text">Package Reference:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../_gen/espnet.lm.html">espnet.lm package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../_gen/espnet.utils.html">espnet.utils package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../_gen/espnet.bin.html">espnet.bin package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../_gen/espnet.nets.html">espnet.nets package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../_gen/espnet.mt.html">espnet.mt package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../_gen/espnet.optimizer.html">espnet.optimizer package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../_gen/espnet.scheduler.html">espnet.scheduler package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../_gen/espnet.asr.html">espnet.asr package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../_gen/espnet.transform.html">espnet.transform package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../_gen/espnet.st.html">espnet.st package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../_gen/espnet.tts.html">espnet.tts package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../_gen/espnet.vc.html">espnet.vc package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../_gen/espnet2.lm.html">espnet2.lm package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../_gen/espnet2.enh.html">espnet2.enh package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../_gen/espnet2.fileio.html">espnet2.fileio package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../_gen/espnet2.train.html">espnet2.train package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../_gen/espnet2.hubert.html">espnet2.hubert package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../_gen/espnet2.torch_utils.html">espnet2.torch_utils package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../_gen/espnet2.layers.html">espnet2.layers package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../_gen/espnet2.gan_tts.html">espnet2.gan_tts package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../_gen/espnet2.main_funcs.html">espnet2.main_funcs package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../_gen/espnet2.utils.html">espnet2.utils package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../_gen/espnet2.text.html">espnet2.text package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../_gen/espnet2.bin.html">espnet2.bin package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../_gen/espnet2.optimizers.html">espnet2.optimizers package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../_gen/espnet2.mt.html">espnet2.mt package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../_gen/espnet2.tasks.html">espnet2.tasks package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../_gen/espnet2.asr.html">espnet2.asr package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../_gen/espnet2.samplers.html">espnet2.samplers package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../_gen/espnet2.schedulers.html">espnet2.schedulers package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../_gen/espnet2.st.html">espnet2.st package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../_gen/espnet2.iterators.html">espnet2.iterators package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../_gen/espnet2.fst.html">espnet2.fst package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../_gen/espnet2.tts.html">espnet2.tts package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../_gen/espnet2.diar.html">espnet2.diar package</a></li>
</ul>
<p><span class="caption-text">Tool Reference:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../apis/espnet_bin.html">core tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../apis/espnet2_bin.html">core tools (espnet2)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../apis/utils_py.html">python utility tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../apis/utils_sh.html">bash utility tools</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">ESPnet</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../../index.html">Module code</a> &raquo;</li>
      <li>espnet2.tasks.abs_task</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for espnet2.tasks.abs_task</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;Abstract task module.&quot;&quot;&quot;</span>
<span class="kn">from</span> <span class="nn">abc</span> <span class="kn">import</span> <span class="n">ABC</span>
<span class="kn">from</span> <span class="nn">abc</span> <span class="kn">import</span> <span class="n">abstractmethod</span>
<span class="kn">import</span> <span class="nn">argparse</span>
<span class="kn">from</span> <span class="nn">dataclasses</span> <span class="kn">import</span> <span class="n">dataclass</span>
<span class="kn">import</span> <span class="nn">functools</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">packaging.version</span> <span class="kn">import</span> <span class="n">parse</span> <span class="k">as</span> <span class="n">V</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Any</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Callable</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Dict</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Optional</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Sequence</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Tuple</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Union</span>

<span class="kn">import</span> <span class="nn">humanfriendly</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.multiprocessing</span>
<span class="kn">import</span> <span class="nn">torch.nn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="nn">typeguard</span> <span class="kn">import</span> <span class="n">check_argument_types</span>
<span class="kn">from</span> <span class="nn">typeguard</span> <span class="kn">import</span> <span class="n">check_return_type</span>
<span class="kn">import</span> <span class="nn">yaml</span>

<span class="kn">from</span> <span class="nn">espnet</span> <span class="kn">import</span> <span class="n">__version__</span>
<span class="kn">from</span> <span class="nn">espnet.utils.cli_utils</span> <span class="kn">import</span> <span class="n">get_commandline_args</span>
<span class="kn">from</span> <span class="nn">espnet2.iterators.abs_iter_factory</span> <span class="kn">import</span> <span class="n">AbsIterFactory</span>
<span class="kn">from</span> <span class="nn">espnet2.iterators.chunk_iter_factory</span> <span class="kn">import</span> <span class="n">ChunkIterFactory</span>
<span class="kn">from</span> <span class="nn">espnet2.iterators.multiple_iter_factory</span> <span class="kn">import</span> <span class="n">MultipleIterFactory</span>
<span class="kn">from</span> <span class="nn">espnet2.iterators.sequence_iter_factory</span> <span class="kn">import</span> <span class="n">SequenceIterFactory</span>
<span class="kn">from</span> <span class="nn">espnet2.main_funcs.collect_stats</span> <span class="kn">import</span> <span class="n">collect_stats</span>
<span class="kn">from</span> <span class="nn">espnet2.optimizers.sgd</span> <span class="kn">import</span> <span class="n">SGD</span>
<span class="kn">from</span> <span class="nn">espnet2.samplers.build_batch_sampler</span> <span class="kn">import</span> <span class="n">BATCH_TYPES</span>
<span class="kn">from</span> <span class="nn">espnet2.samplers.build_batch_sampler</span> <span class="kn">import</span> <span class="n">build_batch_sampler</span>
<span class="kn">from</span> <span class="nn">espnet2.samplers.unsorted_batch_sampler</span> <span class="kn">import</span> <span class="n">UnsortedBatchSampler</span>
<span class="kn">from</span> <span class="nn">espnet2.schedulers.noam_lr</span> <span class="kn">import</span> <span class="n">NoamLR</span>
<span class="kn">from</span> <span class="nn">espnet2.schedulers.warmup_lr</span> <span class="kn">import</span> <span class="n">WarmupLR</span>
<span class="kn">from</span> <span class="nn">espnet2.torch_utils.load_pretrained_model</span> <span class="kn">import</span> <span class="n">load_pretrained_model</span>
<span class="kn">from</span> <span class="nn">espnet2.torch_utils.model_summary</span> <span class="kn">import</span> <span class="n">model_summary</span>
<span class="kn">from</span> <span class="nn">espnet2.torch_utils.pytorch_version</span> <span class="kn">import</span> <span class="n">pytorch_cudnn_version</span>
<span class="kn">from</span> <span class="nn">espnet2.torch_utils.set_all_random_seed</span> <span class="kn">import</span> <span class="n">set_all_random_seed</span>
<span class="kn">from</span> <span class="nn">espnet2.train.abs_espnet_model</span> <span class="kn">import</span> <span class="n">AbsESPnetModel</span>
<span class="kn">from</span> <span class="nn">espnet2.train.class_choices</span> <span class="kn">import</span> <span class="n">ClassChoices</span>
<span class="kn">from</span> <span class="nn">espnet2.train.dataset</span> <span class="kn">import</span> <span class="n">AbsDataset</span>
<span class="kn">from</span> <span class="nn">espnet2.train.dataset</span> <span class="kn">import</span> <span class="n">DATA_TYPES</span>
<span class="kn">from</span> <span class="nn">espnet2.train.dataset</span> <span class="kn">import</span> <span class="n">ESPnetDataset</span>
<span class="kn">from</span> <span class="nn">espnet2.train.distributed_utils</span> <span class="kn">import</span> <span class="n">DistributedOption</span>
<span class="kn">from</span> <span class="nn">espnet2.train.distributed_utils</span> <span class="kn">import</span> <span class="n">free_port</span>
<span class="kn">from</span> <span class="nn">espnet2.train.distributed_utils</span> <span class="kn">import</span> <span class="n">get_master_port</span>
<span class="kn">from</span> <span class="nn">espnet2.train.distributed_utils</span> <span class="kn">import</span> <span class="n">get_node_rank</span>
<span class="kn">from</span> <span class="nn">espnet2.train.distributed_utils</span> <span class="kn">import</span> <span class="n">get_num_nodes</span>
<span class="kn">from</span> <span class="nn">espnet2.train.distributed_utils</span> <span class="kn">import</span> <span class="n">resolve_distributed_mode</span>
<span class="kn">from</span> <span class="nn">espnet2.train.iterable_dataset</span> <span class="kn">import</span> <span class="n">IterableESPnetDataset</span>
<span class="kn">from</span> <span class="nn">espnet2.train.trainer</span> <span class="kn">import</span> <span class="n">Trainer</span>
<span class="kn">from</span> <span class="nn">espnet2.utils.build_dataclass</span> <span class="kn">import</span> <span class="n">build_dataclass</span>
<span class="kn">from</span> <span class="nn">espnet2.utils</span> <span class="kn">import</span> <span class="n">config_argparse</span>
<span class="kn">from</span> <span class="nn">espnet2.utils.get_default_kwargs</span> <span class="kn">import</span> <span class="n">get_default_kwargs</span>
<span class="kn">from</span> <span class="nn">espnet2.utils.nested_dict_action</span> <span class="kn">import</span> <span class="n">NestedDictAction</span>
<span class="kn">from</span> <span class="nn">espnet2.utils.types</span> <span class="kn">import</span> <span class="n">humanfriendly_parse_size_or_none</span>
<span class="kn">from</span> <span class="nn">espnet2.utils.types</span> <span class="kn">import</span> <span class="n">int_or_none</span>
<span class="kn">from</span> <span class="nn">espnet2.utils.types</span> <span class="kn">import</span> <span class="n">str2bool</span>
<span class="kn">from</span> <span class="nn">espnet2.utils.types</span> <span class="kn">import</span> <span class="n">str2triple_str</span>
<span class="kn">from</span> <span class="nn">espnet2.utils.types</span> <span class="kn">import</span> <span class="n">str_or_int</span>
<span class="kn">from</span> <span class="nn">espnet2.utils.types</span> <span class="kn">import</span> <span class="n">str_or_none</span>
<span class="kn">from</span> <span class="nn">espnet2.utils.yaml_no_alias_safe_dump</span> <span class="kn">import</span> <span class="n">yaml_no_alias_safe_dump</span>

<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">wandb</span>
<span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
    <span class="n">wandb</span> <span class="o">=</span> <span class="kc">None</span>

<span class="k">if</span> <span class="n">V</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">V</span><span class="p">(</span><span class="s2">&quot;1.5.0&quot;</span><span class="p">):</span>
    <span class="kn">from</span> <span class="nn">torch.multiprocessing.spawn</span> <span class="kn">import</span> <span class="n">ProcessContext</span>
<span class="k">else</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">torch.multiprocessing.spawn</span> <span class="kn">import</span> <span class="n">SpawnContext</span> <span class="k">as</span> <span class="n">ProcessContext</span>


<span class="n">optim_classes</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
    <span class="n">adam</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">,</span>
    <span class="n">adamw</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">,</span>
    <span class="n">sgd</span><span class="o">=</span><span class="n">SGD</span><span class="p">,</span>
    <span class="n">adadelta</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adadelta</span><span class="p">,</span>
    <span class="n">adagrad</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adagrad</span><span class="p">,</span>
    <span class="n">adamax</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adamax</span><span class="p">,</span>
    <span class="n">asgd</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">ASGD</span><span class="p">,</span>
    <span class="n">lbfgs</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">LBFGS</span><span class="p">,</span>
    <span class="n">rmsprop</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">RMSprop</span><span class="p">,</span>
    <span class="n">rprop</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Rprop</span><span class="p">,</span>
<span class="p">)</span>
<span class="k">if</span> <span class="n">V</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">V</span><span class="p">(</span><span class="s2">&quot;1.10.0&quot;</span><span class="p">):</span>
    <span class="c1"># From 1.10.0, RAdam is officially supported</span>
    <span class="n">optim_classes</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
        <span class="n">radam</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">RAdam</span><span class="p">,</span>
    <span class="p">)</span>
<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">torch_optimizer</span>

    <span class="n">optim_classes</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
        <span class="n">accagd</span><span class="o">=</span><span class="n">torch_optimizer</span><span class="o">.</span><span class="n">AccSGD</span><span class="p">,</span>
        <span class="n">adabound</span><span class="o">=</span><span class="n">torch_optimizer</span><span class="o">.</span><span class="n">AdaBound</span><span class="p">,</span>
        <span class="n">adamod</span><span class="o">=</span><span class="n">torch_optimizer</span><span class="o">.</span><span class="n">AdaMod</span><span class="p">,</span>
        <span class="n">diffgrad</span><span class="o">=</span><span class="n">torch_optimizer</span><span class="o">.</span><span class="n">DiffGrad</span><span class="p">,</span>
        <span class="n">lamb</span><span class="o">=</span><span class="n">torch_optimizer</span><span class="o">.</span><span class="n">Lamb</span><span class="p">,</span>
        <span class="n">novograd</span><span class="o">=</span><span class="n">torch_optimizer</span><span class="o">.</span><span class="n">NovoGrad</span><span class="p">,</span>
        <span class="n">pid</span><span class="o">=</span><span class="n">torch_optimizer</span><span class="o">.</span><span class="n">PID</span><span class="p">,</span>
        <span class="c1"># torch_optimizer&lt;=0.0.1a10 doesn&#39;t support</span>
        <span class="c1"># qhadam=torch_optimizer.QHAdam,</span>
        <span class="n">qhm</span><span class="o">=</span><span class="n">torch_optimizer</span><span class="o">.</span><span class="n">QHM</span><span class="p">,</span>
        <span class="n">sgdw</span><span class="o">=</span><span class="n">torch_optimizer</span><span class="o">.</span><span class="n">SGDW</span><span class="p">,</span>
        <span class="n">yogi</span><span class="o">=</span><span class="n">torch_optimizer</span><span class="o">.</span><span class="n">Yogi</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="n">V</span><span class="p">(</span><span class="n">torch_optimizer</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">V</span><span class="p">(</span><span class="s2">&quot;0.2.0&quot;</span><span class="p">):</span>
        <span class="c1"># From 0.2.0, RAdam is dropped</span>
        <span class="n">optim_classes</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
            <span class="n">radam</span><span class="o">=</span><span class="n">torch_optimizer</span><span class="o">.</span><span class="n">RAdam</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">del</span> <span class="n">torch_optimizer</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="k">pass</span>
<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">apex</span>

    <span class="n">optim_classes</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
        <span class="n">fusedadam</span><span class="o">=</span><span class="n">apex</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">FusedAdam</span><span class="p">,</span>
        <span class="n">fusedlamb</span><span class="o">=</span><span class="n">apex</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">FusedLAMB</span><span class="p">,</span>
        <span class="n">fusednovograd</span><span class="o">=</span><span class="n">apex</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">FusedNovoGrad</span><span class="p">,</span>
        <span class="n">fusedsgd</span><span class="o">=</span><span class="n">apex</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">FusedSGD</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">del</span> <span class="n">apex</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="k">pass</span>
<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">fairscale</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="n">fairscale</span> <span class="o">=</span> <span class="kc">None</span>


<span class="n">scheduler_classes</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
    <span class="n">ReduceLROnPlateau</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">ReduceLROnPlateau</span><span class="p">,</span>
    <span class="n">lambdalr</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">LambdaLR</span><span class="p">,</span>
    <span class="n">steplr</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">StepLR</span><span class="p">,</span>
    <span class="n">multisteplr</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">MultiStepLR</span><span class="p">,</span>
    <span class="n">exponentiallr</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">ExponentialLR</span><span class="p">,</span>
    <span class="n">CosineAnnealingLR</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">CosineAnnealingLR</span><span class="p">,</span>
    <span class="n">noamlr</span><span class="o">=</span><span class="n">NoamLR</span><span class="p">,</span>
    <span class="n">warmuplr</span><span class="o">=</span><span class="n">WarmupLR</span><span class="p">,</span>
    <span class="n">cycliclr</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">CyclicLR</span><span class="p">,</span>
    <span class="n">onecyclelr</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">OneCycleLR</span><span class="p">,</span>
    <span class="n">CosineAnnealingWarmRestarts</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">CosineAnnealingWarmRestarts</span><span class="p">,</span>
<span class="p">)</span>
<span class="c1"># To lower keys</span>
<span class="n">optim_classes</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="o">.</span><span class="n">lower</span><span class="p">():</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">optim_classes</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
<span class="n">scheduler_classes</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="o">.</span><span class="n">lower</span><span class="p">():</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">scheduler_classes</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>


<div class="viewcode-block" id="IteratorOptions"><a class="viewcode-back" href="../../../_gen/espnet2.tasks.html#espnet2.tasks.abs_task.IteratorOptions">[docs]</a><span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">IteratorOptions</span><span class="p">:</span>
    <span class="n">preprocess_fn</span><span class="p">:</span> <span class="n">callable</span>
    <span class="n">collate_fn</span><span class="p">:</span> <span class="n">callable</span>
    <span class="n">data_path_and_name_and_type</span><span class="p">:</span> <span class="nb">list</span>
    <span class="n">shape_files</span><span class="p">:</span> <span class="nb">list</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">batch_bins</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">batch_type</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">max_cache_size</span><span class="p">:</span> <span class="nb">float</span>
    <span class="n">max_cache_fd</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">distributed</span><span class="p">:</span> <span class="nb">bool</span>
    <span class="n">num_batches</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span>
    <span class="n">num_iters_per_epoch</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span>
    <span class="n">train</span><span class="p">:</span> <span class="nb">bool</span></div>


<div class="viewcode-block" id="AbsTask"><a class="viewcode-back" href="../../../_gen/espnet2.tasks.html#espnet2.tasks.abs_task.AbsTask">[docs]</a><span class="k">class</span> <span class="nc">AbsTask</span><span class="p">(</span><span class="n">ABC</span><span class="p">):</span>
    <span class="c1"># Use @staticmethod, or @classmethod,</span>
    <span class="c1"># instead of instance method to avoid God classes</span>

    <span class="c1"># If you need more than one optimizers, change this value in inheritance</span>
    <span class="n">num_optimizers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span>
    <span class="n">class_choices_list</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">ClassChoices</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;This class can&#39;t be instantiated.&quot;</span><span class="p">)</span>

<div class="viewcode-block" id="AbsTask.add_task_arguments"><a class="viewcode-back" href="../../../_gen/espnet2.tasks.html#espnet2.tasks.abs_task.AbsTask.add_task_arguments">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">add_task_arguments</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">parser</span><span class="p">:</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">):</span>
        <span class="k">pass</span></div>

<div class="viewcode-block" id="AbsTask.build_collate_fn"><a class="viewcode-back" href="../../../_gen/espnet2.tasks.html#espnet2.tasks.abs_task.AbsTask.build_collate_fn">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">build_collate_fn</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span> <span class="n">args</span><span class="p">:</span> <span class="n">argparse</span><span class="o">.</span><span class="n">Namespace</span><span class="p">,</span> <span class="n">train</span><span class="p">:</span> <span class="nb">bool</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">Sequence</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]]],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;Return &quot;collate_fn&quot;, which is a callable object and given to DataLoader.</span>

<span class="sd">        &gt;&gt;&gt; from torch.utils.data import DataLoader</span>
<span class="sd">        &gt;&gt;&gt; loader = DataLoader(collate_fn=cls.build_collate_fn(args, train=True), ...)</span>

<span class="sd">        In many cases, you can use our common collate_fn.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span></div>

<div class="viewcode-block" id="AbsTask.build_preprocess_fn"><a class="viewcode-back" href="../../../_gen/espnet2.tasks.html#espnet2.tasks.abs_task.AbsTask.build_preprocess_fn">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">build_preprocess_fn</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span> <span class="n">args</span><span class="p">:</span> <span class="n">argparse</span><span class="o">.</span><span class="n">Namespace</span><span class="p">,</span> <span class="n">train</span><span class="p">:</span> <span class="nb">bool</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">]],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]]]:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span></div>

<div class="viewcode-block" id="AbsTask.required_data_names"><a class="viewcode-back" href="../../../_gen/espnet2.tasks.html#espnet2.tasks.abs_task.AbsTask.required_data_names">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">required_data_names</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span> <span class="n">train</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">inference</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="o">...</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Define the required names by Task</span>

<span class="sd">        This function is used by</span>
<span class="sd">        &gt;&gt;&gt; cls.check_task_requirements()</span>
<span class="sd">        If your model is defined as following,</span>

<span class="sd">        &gt;&gt;&gt; from espnet2.train.abs_espnet_model import AbsESPnetModel</span>
<span class="sd">        &gt;&gt;&gt; class Model(AbsESPnetModel):</span>
<span class="sd">        ...     def forward(self, input, output, opt=None):  pass</span>

<span class="sd">        then &quot;required_data_names&quot; should be as</span>

<span class="sd">        &gt;&gt;&gt; required_data_names = (&#39;input&#39;, &#39;output&#39;)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span></div>

<div class="viewcode-block" id="AbsTask.optional_data_names"><a class="viewcode-back" href="../../../_gen/espnet2.tasks.html#espnet2.tasks.abs_task.AbsTask.optional_data_names">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">optional_data_names</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span> <span class="n">train</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">inference</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="o">...</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Define the optional names by Task</span>

<span class="sd">        This function is used by</span>
<span class="sd">        &gt;&gt;&gt; cls.check_task_requirements()</span>
<span class="sd">        If your model is defined as follows,</span>

<span class="sd">        &gt;&gt;&gt; from espnet2.train.abs_espnet_model import AbsESPnetModel</span>
<span class="sd">        &gt;&gt;&gt; class Model(AbsESPnetModel):</span>
<span class="sd">        ...     def forward(self, input, output, opt=None):  pass</span>

<span class="sd">        then &quot;optional_data_names&quot; should be as</span>

<span class="sd">        &gt;&gt;&gt; optional_data_names = (&#39;opt&#39;,)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span></div>

<div class="viewcode-block" id="AbsTask.build_model"><a class="viewcode-back" href="../../../_gen/espnet2.tasks.html#espnet2.tasks.abs_task.AbsTask.build_model">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">build_model</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">args</span><span class="p">:</span> <span class="n">argparse</span><span class="o">.</span><span class="n">Namespace</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">AbsESPnetModel</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span></div>

<div class="viewcode-block" id="AbsTask.get_parser"><a class="viewcode-back" href="../../../_gen/espnet2.tasks.html#espnet2.tasks.abs_task.AbsTask.get_parser">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">get_parser</span><span class="p">(</span><span class="bp">cls</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">config_argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">check_argument_types</span><span class="p">()</span>

        <span class="k">class</span> <span class="nc">ArgumentDefaultsRawTextHelpFormatter</span><span class="p">(</span>
            <span class="n">argparse</span><span class="o">.</span><span class="n">RawTextHelpFormatter</span><span class="p">,</span>
            <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentDefaultsHelpFormatter</span><span class="p">,</span>
        <span class="p">):</span>
            <span class="k">pass</span>

        <span class="n">parser</span> <span class="o">=</span> <span class="n">config_argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">(</span>
            <span class="n">description</span><span class="o">=</span><span class="s2">&quot;base parser&quot;</span><span class="p">,</span>
            <span class="n">formatter_class</span><span class="o">=</span><span class="n">ArgumentDefaultsRawTextHelpFormatter</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># NOTE(kamo): Use &#39;_&#39; instead of &#39;-&#39; to avoid confusion.</span>
        <span class="c1">#  I think &#39;-&#39; looks really confusing if it&#39;s written in yaml.</span>

        <span class="c1"># NOTE(kamo): add_arguments(..., required=True) can&#39;t be used</span>
        <span class="c1">#  to provide --print_config mode. Instead of it, do as</span>
        <span class="n">parser</span><span class="o">.</span><span class="n">set_defaults</span><span class="p">(</span><span class="n">required</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;output_dir&quot;</span><span class="p">])</span>

        <span class="n">group</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">add_argument_group</span><span class="p">(</span><span class="s2">&quot;Common configuration&quot;</span><span class="p">)</span>

        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--print_config&quot;</span><span class="p">,</span>
            <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
            <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Print the config file and exit&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--log_level&quot;</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">upper</span><span class="p">(),</span>
            <span class="n">default</span><span class="o">=</span><span class="s2">&quot;INFO&quot;</span><span class="p">,</span>
            <span class="n">choices</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;ERROR&quot;</span><span class="p">,</span> <span class="s2">&quot;WARNING&quot;</span><span class="p">,</span> <span class="s2">&quot;INFO&quot;</span><span class="p">,</span> <span class="s2">&quot;DEBUG&quot;</span><span class="p">,</span> <span class="s2">&quot;NOTSET&quot;</span><span class="p">),</span>
            <span class="n">help</span><span class="o">=</span><span class="s2">&quot;The verbose level of logging&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--dry_run&quot;</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="n">str2bool</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Perform process without training&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--iterator_type&quot;</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
            <span class="n">choices</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;sequence&quot;</span><span class="p">,</span> <span class="s2">&quot;chunk&quot;</span><span class="p">,</span> <span class="s2">&quot;task&quot;</span><span class="p">,</span> <span class="s2">&quot;none&quot;</span><span class="p">],</span>
            <span class="n">default</span><span class="o">=</span><span class="s2">&quot;sequence&quot;</span><span class="p">,</span>
            <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Specify iterator type&quot;</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--output_dir&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="n">str_or_none</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--ngpu&quot;</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="n">help</span><span class="o">=</span><span class="s2">&quot;The number of gpus. 0 indicates CPU mode&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--seed&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Random seed&quot;</span><span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--num_workers&quot;</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">help</span><span class="o">=</span><span class="s2">&quot;The number of workers used for DataLoader&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--num_att_plot&quot;</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
            <span class="n">help</span><span class="o">=</span><span class="s2">&quot;The number images to plot the outputs from attention. &quot;</span>
            <span class="s2">&quot;This option makes sense only when attention-based model. &quot;</span>
            <span class="s2">&quot;We can also disable the attention plot by setting it 0&quot;</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">group</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">add_argument_group</span><span class="p">(</span><span class="s2">&quot;distributed training related&quot;</span><span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--dist_backend&quot;</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="s2">&quot;nccl&quot;</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
            <span class="n">help</span><span class="o">=</span><span class="s2">&quot;distributed backend&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--dist_init_method&quot;</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="s2">&quot;env://&quot;</span><span class="p">,</span>
            <span class="n">help</span><span class="o">=</span><span class="s1">&#39;if init_method=&quot;env://&quot;, env values of &quot;MASTER_PORT&quot;, &quot;MASTER_ADDR&quot;, &#39;</span>
            <span class="s1">&#39;&quot;WORLD_SIZE&quot;, and &quot;RANK&quot; are referred.&#39;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--dist_world_size&quot;</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="n">int_or_none</span><span class="p">,</span>
            <span class="n">help</span><span class="o">=</span><span class="s2">&quot;number of nodes for distributed training&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--dist_rank&quot;</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="n">int_or_none</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">help</span><span class="o">=</span><span class="s2">&quot;node rank for distributed training&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="c1"># Not starting with &quot;dist_&quot; for compatibility to launch.py</span>
            <span class="s2">&quot;--local_rank&quot;</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="n">int_or_none</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">help</span><span class="o">=</span><span class="s2">&quot;local rank for distributed training. This option is used if &quot;</span>
            <span class="s2">&quot;--multiprocessing_distributed=false&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--dist_master_addr&quot;</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="n">str_or_none</span><span class="p">,</span>
            <span class="n">help</span><span class="o">=</span><span class="s2">&quot;The master address for distributed training. &quot;</span>
            <span class="s2">&quot;This value is used when dist_init_method == &#39;env://&#39;&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--dist_master_port&quot;</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="n">int_or_none</span><span class="p">,</span>
            <span class="n">help</span><span class="o">=</span><span class="s2">&quot;The master port for distributed training&quot;</span>
            <span class="s2">&quot;This value is used when dist_init_method == &#39;env://&#39;&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--dist_launcher&quot;</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="n">str_or_none</span><span class="p">,</span>
            <span class="n">choices</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;slurm&quot;</span><span class="p">,</span> <span class="s2">&quot;mpi&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
            <span class="n">help</span><span class="o">=</span><span class="s2">&quot;The launcher type for distributed training&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--multiprocessing_distributed&quot;</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="n">str2bool</span><span class="p">,</span>
            <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Use multi-processing distributed training to launch &quot;</span>
            <span class="s2">&quot;N processes per node, which has N GPUs. This is the &quot;</span>
            <span class="s2">&quot;fastest way to use PyTorch for either single node or &quot;</span>
            <span class="s2">&quot;multi node data parallel training&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--unused_parameters&quot;</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="n">str2bool</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Whether to use the find_unused_parameters in &quot;</span>
            <span class="s2">&quot;torch.nn.parallel.DistributedDataParallel &quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--sharded_ddp&quot;</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="n">str2bool</span><span class="p">,</span>
            <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Enable sharded training provided by fairscale&quot;</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">group</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">add_argument_group</span><span class="p">(</span><span class="s2">&quot;cudnn mode related&quot;</span><span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--cudnn_enabled&quot;</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="n">str2bool</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">enabled</span><span class="p">,</span>
            <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Enable CUDNN&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--cudnn_benchmark&quot;</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="n">str2bool</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">benchmark</span><span class="p">,</span>
            <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Enable cudnn-benchmark mode&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--cudnn_deterministic&quot;</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="n">str2bool</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Enable cudnn-deterministic mode&quot;</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">group</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">add_argument_group</span><span class="p">(</span><span class="s2">&quot;collect stats mode related&quot;</span><span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--collect_stats&quot;</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="n">str2bool</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">help</span><span class="o">=</span><span class="s1">&#39;Perform on &quot;collect stats&quot; mode&#39;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--write_collected_feats&quot;</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="n">str2bool</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">help</span><span class="o">=</span><span class="s1">&#39;Write the output features from the model when &quot;collect stats&quot; mode&#39;</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">group</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">add_argument_group</span><span class="p">(</span><span class="s2">&quot;Trainer related&quot;</span><span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--max_epoch&quot;</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span>
            <span class="n">help</span><span class="o">=</span><span class="s2">&quot;The maximum number epoch to train&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--patience&quot;</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="n">int_or_none</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Number of epochs to wait without improvement &quot;</span>
            <span class="s2">&quot;before stopping the training&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--val_scheduler_criterion&quot;</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
            <span class="n">nargs</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;valid&quot;</span><span class="p">,</span> <span class="s2">&quot;loss&quot;</span><span class="p">),</span>
            <span class="n">help</span><span class="o">=</span><span class="s2">&quot;The criterion used for the value given to the lr scheduler. &quot;</span>
            <span class="s1">&#39;Give a pair referring the phase, &quot;train&quot; or &quot;valid&quot;,&#39;</span>
            <span class="s1">&#39;and the criterion name. The mode specifying &quot;min&quot; or &quot;max&quot; can &#39;</span>
            <span class="s2">&quot;be changed by --scheduler_conf&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--early_stopping_criterion&quot;</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
            <span class="n">nargs</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;valid&quot;</span><span class="p">,</span> <span class="s2">&quot;loss&quot;</span><span class="p">,</span> <span class="s2">&quot;min&quot;</span><span class="p">),</span>
            <span class="n">help</span><span class="o">=</span><span class="s2">&quot;The criterion used for judging of early stopping. &quot;</span>
            <span class="s1">&#39;Give a pair referring the phase, &quot;train&quot; or &quot;valid&quot;,&#39;</span>
            <span class="s1">&#39;the criterion name and the mode, &quot;min&quot; or &quot;max&quot;, e.g. &quot;acc,max&quot;.&#39;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--best_model_criterion&quot;</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="n">str2triple_str</span><span class="p">,</span>
            <span class="n">nargs</span><span class="o">=</span><span class="s2">&quot;+&quot;</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="p">[</span>
                <span class="p">(</span><span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="s2">&quot;loss&quot;</span><span class="p">,</span> <span class="s2">&quot;min&quot;</span><span class="p">),</span>
                <span class="p">(</span><span class="s2">&quot;valid&quot;</span><span class="p">,</span> <span class="s2">&quot;loss&quot;</span><span class="p">,</span> <span class="s2">&quot;min&quot;</span><span class="p">),</span>
                <span class="p">(</span><span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="s2">&quot;acc&quot;</span><span class="p">,</span> <span class="s2">&quot;max&quot;</span><span class="p">),</span>
                <span class="p">(</span><span class="s2">&quot;valid&quot;</span><span class="p">,</span> <span class="s2">&quot;acc&quot;</span><span class="p">,</span> <span class="s2">&quot;max&quot;</span><span class="p">),</span>
            <span class="p">],</span>
            <span class="n">help</span><span class="o">=</span><span class="s2">&quot;The criterion used for judging of the best model. &quot;</span>
            <span class="s1">&#39;Give a pair referring the phase, &quot;train&quot; or &quot;valid&quot;,&#39;</span>
            <span class="s1">&#39;the criterion name, and the mode, &quot;min&quot; or &quot;max&quot;, e.g. &quot;acc,max&quot;.&#39;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--keep_nbest_models&quot;</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
            <span class="n">nargs</span><span class="o">=</span><span class="s2">&quot;+&quot;</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="p">[</span><span class="mi">10</span><span class="p">],</span>
            <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Remove previous snapshots excluding the n-best scored epochs&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--nbest_averaging_interval&quot;</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="n">help</span><span class="o">=</span><span class="s2">&quot;The epoch interval to apply model averaging and save nbest models&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--grad_clip&quot;</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="mf">5.0</span><span class="p">,</span>
            <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Gradient norm threshold to clip&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--grad_clip_type&quot;</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span>
            <span class="n">help</span><span class="o">=</span><span class="s2">&quot;The type of the used p-norm for gradient clip. Can be inf&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--grad_noise&quot;</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="n">str2bool</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">help</span><span class="o">=</span><span class="s2">&quot;The flag to switch to use noise injection to &quot;</span>
            <span class="s2">&quot;gradients during training&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--accum_grad&quot;</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">help</span><span class="o">=</span><span class="s2">&quot;The number of gradient accumulation&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--no_forward_run&quot;</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="n">str2bool</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Just only iterating data loading without &quot;</span>
            <span class="s2">&quot;model forwarding and training&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--resume&quot;</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="n">str2bool</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Enable resuming if checkpoint is existing&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--train_dtype&quot;</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">,</span>
            <span class="n">choices</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;float16&quot;</span><span class="p">,</span> <span class="s2">&quot;float32&quot;</span><span class="p">,</span> <span class="s2">&quot;float64&quot;</span><span class="p">],</span>
            <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Data type for training.&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--use_amp&quot;</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="n">str2bool</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Enable Automatic Mixed Precision. This feature requires pytorch&gt;=1.6&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--log_interval&quot;</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="n">int_or_none</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Show the logs every the number iterations in each epochs at the &quot;</span>
            <span class="s2">&quot;training phase. If None is given, it is decided according the number &quot;</span>
            <span class="s2">&quot;of training samples automatically .&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--use_matplotlib&quot;</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="n">str2bool</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Enable matplotlib logging&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--use_tensorboard&quot;</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="n">str2bool</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Enable tensorboard logging&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--use_wandb&quot;</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="n">str2bool</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Enable wandb logging&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--wandb_project&quot;</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Specify wandb project&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--wandb_id&quot;</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Specify wandb id&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--wandb_entity&quot;</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Specify wandb entity&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--wandb_name&quot;</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Specify wandb run name&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--wandb_model_log_interval&quot;</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Set the model log period&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--detect_anomaly&quot;</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="n">str2bool</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Set torch.autograd.set_detect_anomaly&quot;</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">group</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">add_argument_group</span><span class="p">(</span><span class="s2">&quot;Pretraining model related&quot;</span><span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--pretrain_path&quot;</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;This option is obsoleted&quot;</span><span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--init_param&quot;</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="p">[],</span>
            <span class="n">nargs</span><span class="o">=</span><span class="s2">&quot;*&quot;</span><span class="p">,</span>
            <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Specify the file path used for initialization of parameters. &quot;</span>
            <span class="s2">&quot;The format is &#39;&lt;file_path&gt;:&lt;src_key&gt;:&lt;dst_key&gt;:&lt;exclude_keys&gt;&#39;, &quot;</span>
            <span class="s2">&quot;where file_path is the model file path, &quot;</span>
            <span class="s2">&quot;src_key specifies the key of model states to be used in the model file, &quot;</span>
            <span class="s2">&quot;dst_key specifies the attribute of the model to be initialized, &quot;</span>
            <span class="s2">&quot;and exclude_keys excludes keys of model states for the initialization.&quot;</span>
            <span class="s2">&quot;e.g.</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="s2">&quot;  # Load all parameters&quot;</span>
            <span class="s2">&quot;  --init_param some/where/model.pth</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="s2">&quot;  # Load only decoder parameters&quot;</span>
            <span class="s2">&quot;  --init_param some/where/model.pth:decoder:decoder</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="s2">&quot;  # Load only decoder parameters excluding decoder.embed&quot;</span>
            <span class="s2">&quot;  --init_param some/where/model.pth:decoder:decoder:decoder.embed</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="s2">&quot;  --init_param some/where/model.pth:decoder:decoder:decoder.embed</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--ignore_init_mismatch&quot;</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="n">str2bool</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Ignore size mismatch when loading pre-trained model&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--freeze_param&quot;</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="p">[],</span>
            <span class="n">nargs</span><span class="o">=</span><span class="s2">&quot;*&quot;</span><span class="p">,</span>
            <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Freeze parameters&quot;</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">group</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">add_argument_group</span><span class="p">(</span><span class="s2">&quot;BatchSampler related&quot;</span><span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--num_iters_per_epoch&quot;</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="n">int_or_none</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Restrict the number of iterations for training per epoch&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--batch_size&quot;</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
            <span class="n">help</span><span class="o">=</span><span class="s2">&quot;The mini-batch size used for training. Used if batch_type=&#39;unsorted&#39;,&quot;</span>
            <span class="s2">&quot; &#39;sorted&#39;, or &#39;folded&#39;.&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--valid_batch_size&quot;</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="n">int_or_none</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">help</span><span class="o">=</span><span class="s2">&quot;If not given, the value of --batch_size is used&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--batch_bins&quot;</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="mi">1000000</span><span class="p">,</span>
            <span class="n">help</span><span class="o">=</span><span class="s2">&quot;The number of batch bins. Used if batch_type=&#39;length&#39; or &#39;numel&#39;&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--valid_batch_bins&quot;</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="n">int_or_none</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">help</span><span class="o">=</span><span class="s2">&quot;If not given, the value of --batch_bins is used&quot;</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--train_shape_file&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">action</span><span class="o">=</span><span class="s2">&quot;append&quot;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="p">[])</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--valid_shape_file&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">action</span><span class="o">=</span><span class="s2">&quot;append&quot;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="p">[])</span>

        <span class="n">group</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">add_argument_group</span><span class="p">(</span><span class="s2">&quot;Sequence iterator related&quot;</span><span class="p">)</span>
        <span class="n">_batch_type_help</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">BATCH_TYPES</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">_batch_type_help</span> <span class="o">+=</span> <span class="sa">f</span><span class="s1">&#39;&quot;</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s1">&quot;:</span><span class="se">\n</span><span class="si">{</span><span class="n">value</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--batch_type&quot;</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="s2">&quot;folded&quot;</span><span class="p">,</span>
            <span class="n">choices</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">BATCH_TYPES</span><span class="p">),</span>
            <span class="n">help</span><span class="o">=</span><span class="n">_batch_type_help</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--valid_batch_type&quot;</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="n">str_or_none</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">choices</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">BATCH_TYPES</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="kc">None</span><span class="p">],</span>
            <span class="n">help</span><span class="o">=</span><span class="s2">&quot;If not given, the value of --batch_type is used&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--fold_length&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">action</span><span class="o">=</span><span class="s2">&quot;append&quot;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="p">[])</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--sort_in_batch&quot;</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="s2">&quot;descending&quot;</span><span class="p">,</span>
            <span class="n">choices</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;descending&quot;</span><span class="p">,</span> <span class="s2">&quot;ascending&quot;</span><span class="p">],</span>
            <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Sort the samples in each mini-batches by the sample &quot;</span>
            <span class="s1">&#39;lengths. To enable this, &quot;shape_file&quot; must have the length information.&#39;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--sort_batch&quot;</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="s2">&quot;descending&quot;</span><span class="p">,</span>
            <span class="n">choices</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;descending&quot;</span><span class="p">,</span> <span class="s2">&quot;ascending&quot;</span><span class="p">],</span>
            <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Sort mini-batches by the sample lengths&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--multiple_iterator&quot;</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="n">str2bool</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Use multiple iterator mode&quot;</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">group</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">add_argument_group</span><span class="p">(</span><span class="s2">&quot;Chunk iterator related&quot;</span><span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--chunk_length&quot;</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="n">str_or_int</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
            <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Specify chunk length. e.g. &#39;300&#39;, &#39;300,400,500&#39;, or &#39;300-400&#39;.&quot;</span>
            <span class="s2">&quot;If multiple numbers separated by command are given, &quot;</span>
            <span class="s2">&quot;one of them is selected randomly for each samples. &quot;</span>
            <span class="s2">&quot;If two numbers are given with &#39;-&#39;, it indicates the range of the choices. &quot;</span>
            <span class="s2">&quot;Note that if the sequence length is shorter than the all chunk_lengths, &quot;</span>
            <span class="s2">&quot;the sample is discarded. &quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--chunk_shift_ratio&quot;</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
            <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Specify the shift width of chunks. If it&#39;s less than 1, &quot;</span>
            <span class="s2">&quot;allows the overlapping and if bigger than 1, there are some gaps &quot;</span>
            <span class="s2">&quot;between each chunk.&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--num_cache_chunks&quot;</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
            <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Shuffle in the specified number of chunks and generate mini-batches &quot;</span>
            <span class="s2">&quot;More larger this value, more randomness can be obtained.&quot;</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">group</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">add_argument_group</span><span class="p">(</span><span class="s2">&quot;Dataset related&quot;</span><span class="p">)</span>
        <span class="n">_data_path_and_name_and_type_help</span> <span class="o">=</span> <span class="p">(</span>
            <span class="s2">&quot;Give three words splitted by comma. It&#39;s used for the training data. &quot;</span>
            <span class="s2">&quot;e.g. &#39;--train_data_path_and_name_and_type some/path/a.scp,foo,sound&#39;. &quot;</span>
            <span class="s2">&quot;The first value, some/path/a.scp, indicates the file path, &quot;</span>
            <span class="s2">&quot;and the second, foo, is the key name used for the mini-batch data, &quot;</span>
            <span class="s2">&quot;and the last, sound, decides the file type. &quot;</span>
            <span class="s2">&quot;This option is repeatable, so you can input any number of features &quot;</span>
            <span class="s2">&quot;for your task. Supported file types are as follows:</span><span class="se">\n\n</span><span class="s2">&quot;</span>
        <span class="p">)</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">dic</span> <span class="ow">in</span> <span class="n">DATA_TYPES</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">_data_path_and_name_and_type_help</span> <span class="o">+=</span> <span class="sa">f</span><span class="s1">&#39;&quot;</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s1">&quot;:</span><span class="se">\n</span><span class="si">{</span><span class="n">dic</span><span class="p">[</span><span class="s2">&quot;help&quot;</span><span class="p">]</span><span class="si">}</span><span class="se">\n\n</span><span class="s1">&#39;</span>

        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--train_data_path_and_name_and_type&quot;</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="n">str2triple_str</span><span class="p">,</span>
            <span class="n">action</span><span class="o">=</span><span class="s2">&quot;append&quot;</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="p">[],</span>
            <span class="n">help</span><span class="o">=</span><span class="n">_data_path_and_name_and_type_help</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--valid_data_path_and_name_and_type&quot;</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="n">str2triple_str</span><span class="p">,</span>
            <span class="n">action</span><span class="o">=</span><span class="s2">&quot;append&quot;</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="p">[],</span>
        <span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--allow_variable_data_keys&quot;</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="n">str2bool</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Allow the arbitrary keys for mini-batch with ignoring &quot;</span>
            <span class="s2">&quot;the task requirements&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--max_cache_size&quot;</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="n">humanfriendly</span><span class="o">.</span><span class="n">parse_size</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
            <span class="n">help</span><span class="o">=</span><span class="s2">&quot;The maximum cache size for data loader. e.g. 10MB, 20GB.&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--max_cache_fd&quot;</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
            <span class="n">help</span><span class="o">=</span><span class="s2">&quot;The maximum number of file descriptors to be kept &quot;</span>
            <span class="s2">&quot;as opened for ark files. &quot;</span>
            <span class="s2">&quot;This feature is only valid when data type is &#39;kaldi_ark&#39;.&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
            <span class="s2">&quot;--valid_max_cache_size&quot;</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="n">humanfriendly_parse_size_or_none</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">help</span><span class="o">=</span><span class="s2">&quot;The maximum cache size for validation data loader. e.g. 10MB, 20GB. &quot;</span>
            <span class="s2">&quot;If None, the 5 percent size of --max_cache_size&quot;</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">group</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">add_argument_group</span><span class="p">(</span><span class="s2">&quot;Optimizer related&quot;</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">cls</span><span class="o">.</span><span class="n">num_optimizers</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">suf</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span> <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
            <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;--optim</span><span class="si">{</span><span class="n">suf</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="nb">type</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">lower</span><span class="p">(),</span>
                <span class="n">default</span><span class="o">=</span><span class="s2">&quot;adadelta&quot;</span><span class="p">,</span>
                <span class="n">choices</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">optim_classes</span><span class="p">),</span>
                <span class="n">help</span><span class="o">=</span><span class="s2">&quot;The optimizer type&quot;</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;--optim</span><span class="si">{</span><span class="n">suf</span><span class="si">}</span><span class="s2">_conf&quot;</span><span class="p">,</span>
                <span class="n">action</span><span class="o">=</span><span class="n">NestedDictAction</span><span class="p">,</span>
                <span class="n">default</span><span class="o">=</span><span class="nb">dict</span><span class="p">(),</span>
                <span class="n">help</span><span class="o">=</span><span class="s2">&quot;The keyword arguments for optimizer&quot;</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;--scheduler</span><span class="si">{</span><span class="n">suf</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="nb">type</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">str_or_none</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">lower</span><span class="p">()),</span>
                <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">choices</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">scheduler_classes</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="kc">None</span><span class="p">],</span>
                <span class="n">help</span><span class="o">=</span><span class="s2">&quot;The lr scheduler type&quot;</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;--scheduler</span><span class="si">{</span><span class="n">suf</span><span class="si">}</span><span class="s2">_conf&quot;</span><span class="p">,</span>
                <span class="n">action</span><span class="o">=</span><span class="n">NestedDictAction</span><span class="p">,</span>
                <span class="n">default</span><span class="o">=</span><span class="nb">dict</span><span class="p">(),</span>
                <span class="n">help</span><span class="o">=</span><span class="s2">&quot;The keyword arguments for lr scheduler&quot;</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="bp">cls</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">add_arguments</span><span class="p">(</span><span class="n">parser</span><span class="p">)</span>
        <span class="bp">cls</span><span class="o">.</span><span class="n">add_task_arguments</span><span class="p">(</span><span class="n">parser</span><span class="p">)</span>

        <span class="k">assert</span> <span class="n">check_return_type</span><span class="p">(</span><span class="n">parser</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">parser</span></div>

<div class="viewcode-block" id="AbsTask.build_optimizers"><a class="viewcode-back" href="../../../_gen/espnet2.tasks.html#espnet2.tasks.abs_task.AbsTask.build_optimizers">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">build_optimizers</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">args</span><span class="p">:</span> <span class="n">argparse</span><span class="o">.</span><span class="n">Namespace</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">]:</span>
        <span class="k">if</span> <span class="bp">cls</span><span class="o">.</span><span class="n">num_optimizers</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;build_optimizers() must be overridden if num_optimizers != 1&quot;</span>
            <span class="p">)</span>

        <span class="n">optim_class</span> <span class="o">=</span> <span class="n">optim_classes</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">optim</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">optim_class</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;must be one of </span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">optim_classes</span><span class="p">)</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">args</span><span class="o">.</span><span class="n">optim</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">sharded_ddp</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">fairscale</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Requiring fairscale. Do &#39;pip install fairscale&#39;&quot;</span><span class="p">)</span>
            <span class="n">optim</span> <span class="o">=</span> <span class="n">fairscale</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">oss</span><span class="o">.</span><span class="n">OSS</span><span class="p">(</span>
                <span class="n">params</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">optim</span><span class="o">=</span><span class="n">optim_class</span><span class="p">,</span> <span class="o">**</span><span class="n">args</span><span class="o">.</span><span class="n">optim_conf</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">optim</span> <span class="o">=</span> <span class="n">optim_class</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="o">**</span><span class="n">args</span><span class="o">.</span><span class="n">optim_conf</span><span class="p">)</span>

        <span class="n">optimizers</span> <span class="o">=</span> <span class="p">[</span><span class="n">optim</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">optimizers</span></div>

<div class="viewcode-block" id="AbsTask.exclude_opts"><a class="viewcode-back" href="../../../_gen/espnet2.tasks.html#espnet2.tasks.abs_task.AbsTask.exclude_opts">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">exclude_opts</span><span class="p">(</span><span class="bp">cls</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="o">...</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;The options not to be shown by --print_config&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="s2">&quot;required&quot;</span><span class="p">,</span> <span class="s2">&quot;print_config&quot;</span><span class="p">,</span> <span class="s2">&quot;config&quot;</span><span class="p">,</span> <span class="s2">&quot;ngpu&quot;</span></div>

<div class="viewcode-block" id="AbsTask.get_default_config"><a class="viewcode-back" href="../../../_gen/espnet2.tasks.html#espnet2.tasks.abs_task.AbsTask.get_default_config">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">get_default_config</span><span class="p">(</span><span class="bp">cls</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Return the configuration as dict.</span>

<span class="sd">        This method is used by print_config()</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">def</span> <span class="nf">get_class_type</span><span class="p">(</span><span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">classes</span><span class="p">:</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="n">_cls</span> <span class="o">=</span> <span class="n">classes</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">_cls</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;must be one of </span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">classes</span><span class="p">)</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">_cls</span>

        <span class="c1"># This method is used only for --print_config</span>
        <span class="k">assert</span> <span class="n">check_argument_types</span><span class="p">()</span>
        <span class="n">parser</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">get_parser</span><span class="p">()</span>
        <span class="n">args</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_known_args</span><span class="p">()</span>
        <span class="n">config</span> <span class="o">=</span> <span class="nb">vars</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
        <span class="c1"># Excludes the options not to be shown</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">AbsTask</span><span class="o">.</span><span class="n">exclude_opts</span><span class="p">():</span>
            <span class="n">config</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">cls</span><span class="o">.</span><span class="n">num_optimizers</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">suf</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span> <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
            <span class="n">name</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;optim</span><span class="si">{</span><span class="n">suf</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span>
            <span class="n">optim_class</span> <span class="o">=</span> <span class="n">get_class_type</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">optim_classes</span><span class="p">)</span>
            <span class="n">conf</span> <span class="o">=</span> <span class="n">get_default_kwargs</span><span class="p">(</span><span class="n">optim_class</span><span class="p">)</span>
            <span class="c1"># Overwrite the default by the arguments,</span>
            <span class="n">conf</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;optim</span><span class="si">{</span><span class="n">suf</span><span class="si">}</span><span class="s2">_conf&quot;</span><span class="p">])</span>
            <span class="c1"># and set it again</span>
            <span class="n">config</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;optim</span><span class="si">{</span><span class="n">suf</span><span class="si">}</span><span class="s2">_conf&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">conf</span>

            <span class="n">name</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;scheduler</span><span class="si">{</span><span class="n">suf</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">scheduler_class</span> <span class="o">=</span> <span class="n">get_class_type</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">scheduler_classes</span><span class="p">)</span>
                <span class="n">conf</span> <span class="o">=</span> <span class="n">get_default_kwargs</span><span class="p">(</span><span class="n">scheduler_class</span><span class="p">)</span>
                <span class="c1"># Overwrite the default by the arguments,</span>
                <span class="n">conf</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;scheduler</span><span class="si">{</span><span class="n">suf</span><span class="si">}</span><span class="s2">_conf&quot;</span><span class="p">])</span>
                <span class="c1"># and set it again</span>
                <span class="n">config</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;scheduler</span><span class="si">{</span><span class="n">suf</span><span class="si">}</span><span class="s2">_conf&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">conf</span>

        <span class="k">for</span> <span class="n">class_choices</span> <span class="ow">in</span> <span class="bp">cls</span><span class="o">.</span><span class="n">class_choices_list</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">class_choices</span><span class="o">.</span><span class="n">name</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">class_obj</span> <span class="o">=</span> <span class="n">class_choices</span><span class="o">.</span><span class="n">get_class</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">class_choices</span><span class="o">.</span><span class="n">name</span><span class="p">))</span>
                <span class="n">conf</span> <span class="o">=</span> <span class="n">get_default_kwargs</span><span class="p">(</span><span class="n">class_obj</span><span class="p">)</span>
                <span class="n">name</span> <span class="o">=</span> <span class="n">class_choices</span><span class="o">.</span><span class="n">name</span>
                <span class="c1"># Overwrite the default by the arguments,</span>
                <span class="n">conf</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">_conf&quot;</span><span class="p">])</span>
                <span class="c1"># and set it again</span>
                <span class="n">config</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">_conf&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">conf</span>
        <span class="k">return</span> <span class="n">config</span></div>

<div class="viewcode-block" id="AbsTask.check_required_command_args"><a class="viewcode-back" href="../../../_gen/espnet2.tasks.html#espnet2.tasks.abs_task.AbsTask.check_required_command_args">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">check_required_command_args</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">args</span><span class="p">:</span> <span class="n">argparse</span><span class="o">.</span><span class="n">Namespace</span><span class="p">):</span>
        <span class="k">assert</span> <span class="n">check_argument_types</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">vars</span><span class="p">(</span><span class="n">args</span><span class="p">):</span>
            <span class="k">if</span> <span class="s2">&quot;-&quot;</span> <span class="ow">in</span> <span class="n">k</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Use &quot;_&quot; instead of &quot;-&quot;: parser.get_parser(&quot;</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s1">&quot;)&#39;</span><span class="p">)</span>

        <span class="n">required</span> <span class="o">=</span> <span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;--</span><span class="si">{</span><span class="n">a</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">args</span><span class="o">.</span><span class="n">required</span> <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">None</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">required</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">parser</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">get_parser</span><span class="p">()</span>
            <span class="n">parser</span><span class="o">.</span><span class="n">print_help</span><span class="p">(</span><span class="n">file</span><span class="o">=</span><span class="n">sys</span><span class="o">.</span><span class="n">stderr</span><span class="p">)</span>
            <span class="n">p</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">name</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">file</span><span class="o">=</span><span class="n">sys</span><span class="o">.</span><span class="n">stderr</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">p</span><span class="si">}</span><span class="s2">: error: the following arguments are required: &quot;</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">required</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="n">file</span><span class="o">=</span><span class="n">sys</span><span class="o">.</span><span class="n">stderr</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span></div>

<div class="viewcode-block" id="AbsTask.check_task_requirements"><a class="viewcode-back" href="../../../_gen/espnet2.tasks.html#espnet2.tasks.abs_task.AbsTask.check_task_requirements">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">check_task_requirements</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">dataset</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">AbsDataset</span><span class="p">,</span> <span class="n">IterableESPnetDataset</span><span class="p">],</span>
        <span class="n">allow_variable_data_keys</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">train</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">inference</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Check if the dataset satisfy the requirement of current Task&quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="n">check_argument_types</span><span class="p">()</span>
        <span class="n">mes</span> <span class="o">=</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;If you intend to use an additional input, modify &quot;</span>
            <span class="sa">f</span><span class="s1">&#39;&quot;</span><span class="si">{</span><span class="bp">cls</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s1">.required_data_names()&quot; or &#39;</span>
            <span class="sa">f</span><span class="s1">&#39;&quot;</span><span class="si">{</span><span class="bp">cls</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s1">.optional_data_names()&quot;. &#39;</span>
            <span class="sa">f</span><span class="s2">&quot;Otherwise you need to set --allow_variable_data_keys true &quot;</span>
        <span class="p">)</span>

        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">cls</span><span class="o">.</span><span class="n">required_data_names</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">inference</span><span class="p">):</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">dataset</span><span class="o">.</span><span class="n">has_name</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s1">&#39;&quot;</span><span class="si">{</span><span class="bp">cls</span><span class="o">.</span><span class="n">required_data_names</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">inference</span><span class="p">)</span><span class="si">}</span><span class="s1">&quot; are required for&#39;</span>
                    <span class="sa">f</span><span class="s1">&#39; </span><span class="si">{</span><span class="bp">cls</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s1">. but &quot;</span><span class="si">{</span><span class="n">dataset</span><span class="o">.</span><span class="n">names</span><span class="p">()</span><span class="si">}</span><span class="s1">&quot; are input.</span><span class="se">\n</span><span class="si">{</span><span class="n">mes</span><span class="si">}</span><span class="s1">&#39;</span>
                <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">allow_variable_data_keys</span><span class="p">:</span>
            <span class="n">task_keys</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">required_data_names</span><span class="p">(</span>
                <span class="n">train</span><span class="p">,</span> <span class="n">inference</span>
            <span class="p">)</span> <span class="o">+</span> <span class="bp">cls</span><span class="o">.</span><span class="n">optional_data_names</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">inference</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">names</span><span class="p">():</span>
                <span class="k">if</span> <span class="n">k</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">task_keys</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;The data-name must be one of </span><span class="si">{</span><span class="n">task_keys</span><span class="si">}</span><span class="s2"> &quot;</span>
                        <span class="sa">f</span><span class="s1">&#39;for </span><span class="si">{</span><span class="bp">cls</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s1">: &quot;</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s1">&quot; is not allowed.</span><span class="se">\n</span><span class="si">{</span><span class="n">mes</span><span class="si">}</span><span class="s1">&#39;</span>
                    <span class="p">)</span></div>

<div class="viewcode-block" id="AbsTask.print_config"><a class="viewcode-back" href="../../../_gen/espnet2.tasks.html#espnet2.tasks.abs_task.AbsTask.print_config">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">print_config</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">file</span><span class="o">=</span><span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">check_argument_types</span><span class="p">()</span>
        <span class="c1"># Shows the config: e.g. python train.py asr --print_config</span>
        <span class="n">config</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">get_default_config</span><span class="p">()</span>
        <span class="n">file</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">yaml_no_alias_safe_dump</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">indent</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">sort_keys</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span></div>

<div class="viewcode-block" id="AbsTask.main"><a class="viewcode-back" href="../../../_gen/espnet2.tasks.html#espnet2.tasks.abs_task.AbsTask.main">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">main</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">args</span><span class="p">:</span> <span class="n">argparse</span><span class="o">.</span><span class="n">Namespace</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">cmd</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="k">assert</span> <span class="n">check_argument_types</span><span class="p">()</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">get_commandline_args</span><span class="p">(),</span> <span class="n">file</span><span class="o">=</span><span class="n">sys</span><span class="o">.</span><span class="n">stderr</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">args</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">parser</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">get_parser</span><span class="p">()</span>
            <span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">(</span><span class="n">cmd</span><span class="p">)</span>
        <span class="n">args</span><span class="o">.</span><span class="n">version</span> <span class="o">=</span> <span class="n">__version__</span>
        <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">pretrain_path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;--pretrain_path is deprecated. Use --init_param&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">print_config</span><span class="p">:</span>
            <span class="bp">cls</span><span class="o">.</span><span class="n">print_config</span><span class="p">()</span>
            <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="bp">cls</span><span class="o">.</span><span class="n">check_required_command_args</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>

        <span class="c1"># &quot;distributed&quot; is decided using the other command args</span>
        <span class="n">resolve_distributed_mode</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">args</span><span class="o">.</span><span class="n">distributed</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">args</span><span class="o">.</span><span class="n">multiprocessing_distributed</span><span class="p">:</span>
            <span class="bp">cls</span><span class="o">.</span><span class="n">main_worker</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">args</span><span class="o">.</span><span class="n">ngpu</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">ngpu</span>
            <span class="c1"># Multi-processing distributed mode: e.g. 2node-4process-4GPU</span>
            <span class="c1"># |   Host1     |    Host2    |</span>
            <span class="c1"># |   Process1  |   Process2  |  &lt;= Spawn processes</span>
            <span class="c1"># |Child1|Child2|Child1|Child2|</span>
            <span class="c1"># |GPU1  |GPU2  |GPU1  |GPU2  |</span>

            <span class="c1"># See also the following usage of --multiprocessing-distributed:</span>
            <span class="c1"># https://github.com/pytorch/examples/blob/master/imagenet/main.py</span>
            <span class="n">num_nodes</span> <span class="o">=</span> <span class="n">get_num_nodes</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">dist_world_size</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">dist_launcher</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">num_nodes</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">args</span><span class="o">.</span><span class="n">dist_master_addr</span> <span class="o">=</span> <span class="s2">&quot;localhost&quot;</span>
                <span class="n">args</span><span class="o">.</span><span class="n">dist_rank</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="c1"># Single node distributed training with multi-GPUs</span>
                <span class="k">if</span> <span class="p">(</span>
                    <span class="n">args</span><span class="o">.</span><span class="n">dist_init_method</span> <span class="o">==</span> <span class="s2">&quot;env://&quot;</span>
                    <span class="ow">and</span> <span class="n">get_master_port</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">dist_master_port</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">None</span>
                <span class="p">):</span>
                    <span class="c1"># Get the unused port</span>
                    <span class="n">args</span><span class="o">.</span><span class="n">dist_master_port</span> <span class="o">=</span> <span class="n">free_port</span><span class="p">()</span>

            <span class="c1"># Assume that nodes use same number of GPUs each other</span>
            <span class="n">args</span><span class="o">.</span><span class="n">dist_world_size</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">ngpu</span> <span class="o">*</span> <span class="n">num_nodes</span>
            <span class="n">node_rank</span> <span class="o">=</span> <span class="n">get_node_rank</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">dist_rank</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">dist_launcher</span><span class="p">)</span>

            <span class="c1"># The following block is copied from:</span>
            <span class="c1"># https://github.com/pytorch/pytorch/blob/master/torch/multiprocessing/spawn.py</span>
            <span class="n">error_queues</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">processes</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">mp</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">multiprocessing</span><span class="o">.</span><span class="n">get_context</span><span class="p">(</span><span class="s2">&quot;spawn&quot;</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">ngpu</span><span class="p">):</span>
                <span class="c1"># Copy args</span>
                <span class="n">local_args</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">Namespace</span><span class="p">(</span><span class="o">**</span><span class="nb">vars</span><span class="p">(</span><span class="n">args</span><span class="p">))</span>

                <span class="n">local_args</span><span class="o">.</span><span class="n">local_rank</span> <span class="o">=</span> <span class="n">i</span>
                <span class="n">local_args</span><span class="o">.</span><span class="n">dist_rank</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">ngpu</span> <span class="o">*</span> <span class="n">node_rank</span> <span class="o">+</span> <span class="n">i</span>
                <span class="n">local_args</span><span class="o">.</span><span class="n">ngpu</span> <span class="o">=</span> <span class="mi">1</span>

                <span class="n">process</span> <span class="o">=</span> <span class="n">mp</span><span class="o">.</span><span class="n">Process</span><span class="p">(</span>
                    <span class="n">target</span><span class="o">=</span><span class="bp">cls</span><span class="o">.</span><span class="n">main_worker</span><span class="p">,</span>
                    <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">local_args</span><span class="p">,),</span>
                    <span class="n">daemon</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">process</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
                <span class="n">processes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">process</span><span class="p">)</span>
                <span class="n">error_queues</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mp</span><span class="o">.</span><span class="n">SimpleQueue</span><span class="p">())</span>
            <span class="c1"># Loop on join until it returns True or raises an exception.</span>
            <span class="k">while</span> <span class="ow">not</span> <span class="n">ProcessContext</span><span class="p">(</span><span class="n">processes</span><span class="p">,</span> <span class="n">error_queues</span><span class="p">)</span><span class="o">.</span><span class="n">join</span><span class="p">():</span>
                <span class="k">pass</span></div>

<div class="viewcode-block" id="AbsTask.main_worker"><a class="viewcode-back" href="../../../_gen/espnet2.tasks.html#espnet2.tasks.abs_task.AbsTask.main_worker">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">main_worker</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">args</span><span class="p">:</span> <span class="n">argparse</span><span class="o">.</span><span class="n">Namespace</span><span class="p">):</span>
        <span class="k">assert</span> <span class="n">check_argument_types</span><span class="p">()</span>

        <span class="c1"># 0. Init distributed process</span>
        <span class="n">distributed_option</span> <span class="o">=</span> <span class="n">build_dataclass</span><span class="p">(</span><span class="n">DistributedOption</span><span class="p">,</span> <span class="n">args</span><span class="p">)</span>
        <span class="c1"># Setting distributed_option.dist_rank, etc.</span>
        <span class="n">distributed_option</span><span class="o">.</span><span class="n">init_options</span><span class="p">()</span>

        <span class="c1"># NOTE(kamo): Don&#39;t use logging before invoking logging.basicConfig()</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">distributed_option</span><span class="o">.</span><span class="n">distributed</span> <span class="ow">or</span> <span class="n">distributed_option</span><span class="o">.</span><span class="n">dist_rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">distributed_option</span><span class="o">.</span><span class="n">distributed</span><span class="p">:</span>
                <span class="n">_rank</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">_rank</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;:</span><span class="si">{</span><span class="n">distributed_option</span><span class="o">.</span><span class="n">dist_rank</span><span class="si">}</span><span class="s2">/&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">distributed_option</span><span class="o">.</span><span class="n">dist_world_size</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>

            <span class="c1"># NOTE(kamo):</span>
            <span class="c1"># logging.basicConfig() is invoked in main_worker() instead of main()</span>
            <span class="c1"># because it can be invoked only once in a process.</span>
            <span class="c1"># FIXME(kamo): Should we use logging.getLogger()?</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span>
                <span class="n">level</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">log_level</span><span class="p">,</span>
                <span class="nb">format</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;[</span><span class="si">{</span><span class="n">os</span><span class="o">.</span><span class="n">uname</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="si">}{</span><span class="n">_rank</span><span class="si">}</span><span class="s2">]&quot;</span>
                <span class="sa">f</span><span class="s2">&quot; %(asctime)s (%(module)s:%(lineno)d) %(levelname)s: %(message)s&quot;</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Suppress logging if RANK != 0</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span>
                <span class="n">level</span><span class="o">=</span><span class="s2">&quot;ERROR&quot;</span><span class="p">,</span>
                <span class="nb">format</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;[</span><span class="si">{</span><span class="n">os</span><span class="o">.</span><span class="n">uname</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="sa">f</span><span class="s2">&quot;:</span><span class="si">{</span><span class="n">distributed_option</span><span class="o">.</span><span class="n">dist_rank</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">distributed_option</span><span class="o">.</span><span class="n">dist_world_size</span><span class="si">}</span><span class="s2">]&quot;</span>
                <span class="sa">f</span><span class="s2">&quot; %(asctime)s (%(module)s:%(lineno)d) %(levelname)s: %(message)s&quot;</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="c1"># Invoking torch.distributed.init_process_group</span>
        <span class="n">distributed_option</span><span class="o">.</span><span class="n">init_torch_distributed</span><span class="p">()</span>

        <span class="c1"># 1. Set random-seed</span>
        <span class="n">set_all_random_seed</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">enabled</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">cudnn_enabled</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">benchmark</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">cudnn_benchmark</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">deterministic</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">cudnn_deterministic</span>
        <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">detect_anomaly</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Invoking torch.autograd.set_detect_anomaly(True)&quot;</span><span class="p">)</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">set_detect_anomaly</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">detect_anomaly</span><span class="p">)</span>

        <span class="c1"># 2. Build model</span>
        <span class="n">model</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">build_model</span><span class="p">(</span><span class="n">args</span><span class="o">=</span><span class="n">args</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">AbsESPnetModel</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;model must inherit </span><span class="si">{</span><span class="n">AbsESPnetModel</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">, but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">model</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span>
            <span class="n">dtype</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="n">torch</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">train_dtype</span><span class="p">),</span>
            <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">ngpu</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">args</span><span class="o">.</span><span class="n">freeze_param</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
                <span class="k">if</span> <span class="n">k</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="n">t</span> <span class="o">+</span> <span class="s2">&quot;.&quot;</span><span class="p">)</span> <span class="ow">or</span> <span class="n">k</span> <span class="o">==</span> <span class="n">t</span><span class="p">:</span>
                    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Setting </span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2">.requires_grad = False&quot;</span><span class="p">)</span>
                    <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="c1"># 3. Build optimizer</span>
        <span class="n">optimizers</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">build_optimizers</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">)</span>

        <span class="c1"># 4. Build schedulers</span>
        <span class="n">schedulers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">optim</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">optimizers</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">suf</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span> <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
            <span class="n">name</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;scheduler</span><span class="si">{</span><span class="n">suf</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">conf</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;scheduler</span><span class="si">{</span><span class="n">suf</span><span class="si">}</span><span class="s2">_conf&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">cls_</span> <span class="o">=</span> <span class="n">scheduler_classes</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">cls_</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;must be one of </span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">scheduler_classes</span><span class="p">)</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&quot;</span>
                    <span class="p">)</span>
                <span class="n">scheduler</span> <span class="o">=</span> <span class="n">cls_</span><span class="p">(</span><span class="n">optim</span><span class="p">,</span> <span class="o">**</span><span class="n">conf</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">scheduler</span> <span class="o">=</span> <span class="kc">None</span>

            <span class="n">schedulers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">scheduler</span><span class="p">)</span>

        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">pytorch_cudnn_version</span><span class="p">())</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">model_summary</span><span class="p">(</span><span class="n">model</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">o</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">optimizers</span><span class="p">,</span> <span class="n">schedulers</span><span class="p">),</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">suf</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span> <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Optimizer</span><span class="si">{</span><span class="n">suf</span><span class="si">}</span><span class="s2">:</span><span class="se">\n</span><span class="si">{</span><span class="n">o</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Scheduler</span><span class="si">{</span><span class="n">suf</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">s</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># 5. Dump &quot;args&quot; to config.yaml</span>
        <span class="c1"># NOTE(kamo): &quot;args&quot; should be saved after object-buildings are done</span>
        <span class="c1">#  because they are allowed to modify &quot;args&quot;.</span>
        <span class="n">output_dir</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">output_dir</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">distributed_option</span><span class="o">.</span><span class="n">distributed</span> <span class="ow">or</span> <span class="n">distributed_option</span><span class="o">.</span><span class="n">dist_rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">output_dir</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">with</span> <span class="p">(</span><span class="n">output_dir</span> <span class="o">/</span> <span class="s2">&quot;config.yaml&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s2">&quot;w&quot;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s1">&#39;Saving the configuration in </span><span class="si">{</span><span class="n">output_dir</span> <span class="o">/</span> <span class="s2">&quot;config.yaml&quot;</span><span class="si">}</span><span class="s1">&#39;</span>
                <span class="p">)</span>
                <span class="n">yaml_no_alias_safe_dump</span><span class="p">(</span><span class="nb">vars</span><span class="p">(</span><span class="n">args</span><span class="p">),</span> <span class="n">f</span><span class="p">,</span> <span class="n">indent</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">sort_keys</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">dry_run</span><span class="p">:</span>
            <span class="k">pass</span>
        <span class="k">elif</span> <span class="n">args</span><span class="o">.</span><span class="n">collect_stats</span><span class="p">:</span>
            <span class="c1"># Perform on collect_stats mode. This mode has two roles</span>
            <span class="c1"># - Derive the length and dimension of all input data</span>
            <span class="c1"># - Accumulate feats, square values, and the length for whitening</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">valid_batch_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">args</span><span class="o">.</span><span class="n">valid_batch_size</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">batch_size</span>

            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">train_shape_file</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">train_key_file</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">train_shape_file</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">train_key_file</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">valid_shape_file</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">valid_key_file</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">valid_shape_file</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">valid_key_file</span> <span class="o">=</span> <span class="kc">None</span>

            <span class="n">collect_stats</span><span class="p">(</span>
                <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
                <span class="n">train_iter</span><span class="o">=</span><span class="bp">cls</span><span class="o">.</span><span class="n">build_streaming_iterator</span><span class="p">(</span>
                    <span class="n">data_path_and_name_and_type</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">train_data_path_and_name_and_type</span><span class="p">,</span>
                    <span class="n">key_file</span><span class="o">=</span><span class="n">train_key_file</span><span class="p">,</span>
                    <span class="n">batch_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
                    <span class="n">dtype</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">train_dtype</span><span class="p">,</span>
                    <span class="n">num_workers</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">num_workers</span><span class="p">,</span>
                    <span class="n">allow_variable_data_keys</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">allow_variable_data_keys</span><span class="p">,</span>
                    <span class="n">ngpu</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">ngpu</span><span class="p">,</span>
                    <span class="n">preprocess_fn</span><span class="o">=</span><span class="bp">cls</span><span class="o">.</span><span class="n">build_preprocess_fn</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
                    <span class="n">collate_fn</span><span class="o">=</span><span class="bp">cls</span><span class="o">.</span><span class="n">build_collate_fn</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
                <span class="p">),</span>
                <span class="n">valid_iter</span><span class="o">=</span><span class="bp">cls</span><span class="o">.</span><span class="n">build_streaming_iterator</span><span class="p">(</span>
                    <span class="n">data_path_and_name_and_type</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">valid_data_path_and_name_and_type</span><span class="p">,</span>
                    <span class="n">key_file</span><span class="o">=</span><span class="n">valid_key_file</span><span class="p">,</span>
                    <span class="n">batch_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">valid_batch_size</span><span class="p">,</span>
                    <span class="n">dtype</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">train_dtype</span><span class="p">,</span>
                    <span class="n">num_workers</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">num_workers</span><span class="p">,</span>
                    <span class="n">allow_variable_data_keys</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">allow_variable_data_keys</span><span class="p">,</span>
                    <span class="n">ngpu</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">ngpu</span><span class="p">,</span>
                    <span class="n">preprocess_fn</span><span class="o">=</span><span class="bp">cls</span><span class="o">.</span><span class="n">build_preprocess_fn</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
                    <span class="n">collate_fn</span><span class="o">=</span><span class="bp">cls</span><span class="o">.</span><span class="n">build_collate_fn</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
                <span class="p">),</span>
                <span class="n">output_dir</span><span class="o">=</span><span class="n">output_dir</span><span class="p">,</span>
                <span class="n">ngpu</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">ngpu</span><span class="p">,</span>
                <span class="n">log_interval</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">log_interval</span><span class="p">,</span>
                <span class="n">write_collected_feats</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">write_collected_feats</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># 6. Loads pre-trained model</span>
            <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">args</span><span class="o">.</span><span class="n">init_param</span><span class="p">:</span>
                <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading pretrained params from </span><span class="si">{</span><span class="n">p</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">load_pretrained_model</span><span class="p">(</span>
                    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
                    <span class="n">init_param</span><span class="o">=</span><span class="n">p</span><span class="p">,</span>
                    <span class="n">ignore_init_mismatch</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">ignore_init_mismatch</span><span class="p">,</span>
                    <span class="c1"># NOTE(kamo): &quot;cuda&quot; for torch.load always indicates cuda:0</span>
                    <span class="c1">#   in PyTorch&lt;=1.4</span>
                    <span class="n">map_location</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;cuda:</span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_device</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
                    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">ngpu</span> <span class="o">&gt;</span> <span class="mi">0</span>
                    <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
                <span class="p">)</span>

            <span class="c1"># 7. Build iterator factories</span>
            <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">multiple_iterator</span><span class="p">:</span>
                <span class="n">train_iter_factory</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">build_multiple_iter_factory</span><span class="p">(</span>
                    <span class="n">args</span><span class="o">=</span><span class="n">args</span><span class="p">,</span>
                    <span class="n">distributed_option</span><span class="o">=</span><span class="n">distributed_option</span><span class="p">,</span>
                    <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">train_iter_factory</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">build_iter_factory</span><span class="p">(</span>
                    <span class="n">args</span><span class="o">=</span><span class="n">args</span><span class="p">,</span>
                    <span class="n">distributed_option</span><span class="o">=</span><span class="n">distributed_option</span><span class="p">,</span>
                    <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="n">valid_iter_factory</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">build_iter_factory</span><span class="p">(</span>
                <span class="n">args</span><span class="o">=</span><span class="n">args</span><span class="p">,</span>
                <span class="n">distributed_option</span><span class="o">=</span><span class="n">distributed_option</span><span class="p">,</span>
                <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;valid&quot;</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">args</span><span class="o">.</span><span class="n">use_matplotlib</span> <span class="ow">and</span> <span class="n">args</span><span class="o">.</span><span class="n">num_att_plot</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">args</span><span class="o">.</span><span class="n">num_att_plot</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;--use_matplotlib false =&gt; Changing --num_att_plot to 0&quot;</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">num_att_plot</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">plot_attention_iter_factory</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">build_iter_factory</span><span class="p">(</span>
                    <span class="n">args</span><span class="o">=</span><span class="n">args</span><span class="p">,</span>
                    <span class="n">distributed_option</span><span class="o">=</span><span class="n">distributed_option</span><span class="p">,</span>
                    <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;plot_att&quot;</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">plot_attention_iter_factory</span> <span class="o">=</span> <span class="kc">None</span>

            <span class="c1"># 8. Start training</span>
            <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">use_wandb</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">wandb</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Please install wandb&quot;</span><span class="p">)</span>

                <span class="k">try</span><span class="p">:</span>
                    <span class="n">wandb</span><span class="o">.</span><span class="n">login</span><span class="p">()</span>
                <span class="k">except</span> <span class="n">wandb</span><span class="o">.</span><span class="n">errors</span><span class="o">.</span><span class="n">UsageError</span><span class="p">:</span>
                    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;wandb not configured! run `wandb login` to enable&quot;</span><span class="p">)</span>
                    <span class="n">args</span><span class="o">.</span><span class="n">use_wandb</span> <span class="o">=</span> <span class="kc">False</span>

            <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">use_wandb</span><span class="p">:</span>
                <span class="k">if</span> <span class="p">(</span>
                    <span class="ow">not</span> <span class="n">distributed_option</span><span class="o">.</span><span class="n">distributed</span>
                    <span class="ow">or</span> <span class="n">distributed_option</span><span class="o">.</span><span class="n">dist_rank</span> <span class="o">==</span> <span class="mi">0</span>
                <span class="p">):</span>
                    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">wandb_project</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">project</span> <span class="o">=</span> <span class="s2">&quot;ESPnet_&quot;</span> <span class="o">+</span> <span class="bp">cls</span><span class="o">.</span><span class="vm">__name__</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">project</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">wandb_project</span>

                    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">wandb_name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">name</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">Path</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">resolve</span><span class="p">())</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;/&quot;</span><span class="p">,</span> <span class="s2">&quot;_&quot;</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">name</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">wandb_name</span>

                    <span class="n">wandb</span><span class="o">.</span><span class="n">init</span><span class="p">(</span>
                        <span class="n">entity</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">wandb_entity</span><span class="p">,</span>
                        <span class="n">project</span><span class="o">=</span><span class="n">project</span><span class="p">,</span>
                        <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
                        <span class="nb">dir</span><span class="o">=</span><span class="n">output_dir</span><span class="p">,</span>
                        <span class="nb">id</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">wandb_id</span><span class="p">,</span>
                        <span class="n">resume</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">resume</span><span class="p">,</span>
                    <span class="p">)</span>
                    <span class="n">wandb</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># wandb also supports grouping for distributed training,</span>
                    <span class="c1"># but we only logs aggregated data,</span>
                    <span class="c1"># so it&#39;s enough to perform on rank0 node.</span>
                    <span class="n">args</span><span class="o">.</span><span class="n">use_wandb</span> <span class="o">=</span> <span class="kc">False</span>

            <span class="c1"># Don&#39;t give args to trainer.run() directly!!!</span>
            <span class="c1"># Instead of it, define &quot;Options&quot; object and build here.</span>
            <span class="n">trainer_options</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">build_options</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
            <span class="bp">cls</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
                <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
                <span class="n">optimizers</span><span class="o">=</span><span class="n">optimizers</span><span class="p">,</span>
                <span class="n">schedulers</span><span class="o">=</span><span class="n">schedulers</span><span class="p">,</span>
                <span class="n">train_iter_factory</span><span class="o">=</span><span class="n">train_iter_factory</span><span class="p">,</span>
                <span class="n">valid_iter_factory</span><span class="o">=</span><span class="n">valid_iter_factory</span><span class="p">,</span>
                <span class="n">plot_attention_iter_factory</span><span class="o">=</span><span class="n">plot_attention_iter_factory</span><span class="p">,</span>
                <span class="n">trainer_options</span><span class="o">=</span><span class="n">trainer_options</span><span class="p">,</span>
                <span class="n">distributed_option</span><span class="o">=</span><span class="n">distributed_option</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="k">if</span> <span class="n">wandb</span><span class="o">.</span><span class="n">run</span><span class="p">:</span>
                <span class="n">wandb</span><span class="o">.</span><span class="n">finish</span><span class="p">()</span></div>

<div class="viewcode-block" id="AbsTask.build_iter_options"><a class="viewcode-back" href="../../../_gen/espnet2.tasks.html#espnet2.tasks.abs_task.AbsTask.build_iter_options">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">build_iter_options</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">args</span><span class="p">:</span> <span class="n">argparse</span><span class="o">.</span><span class="n">Namespace</span><span class="p">,</span>
        <span class="n">distributed_option</span><span class="p">:</span> <span class="n">DistributedOption</span><span class="p">,</span>
        <span class="n">mode</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;train&quot;</span><span class="p">:</span>
            <span class="n">preprocess_fn</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">build_preprocess_fn</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">collate_fn</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">build_collate_fn</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">data_path_and_name_and_type</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">train_data_path_and_name_and_type</span>
            <span class="n">shape_files</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">train_shape_file</span>
            <span class="n">batch_size</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">batch_size</span>
            <span class="n">batch_bins</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">batch_bins</span>
            <span class="n">batch_type</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">batch_type</span>
            <span class="n">max_cache_size</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">max_cache_size</span>
            <span class="n">max_cache_fd</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">max_cache_fd</span>
            <span class="n">distributed</span> <span class="o">=</span> <span class="n">distributed_option</span><span class="o">.</span><span class="n">distributed</span>
            <span class="n">num_batches</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">num_iters_per_epoch</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">num_iters_per_epoch</span>
            <span class="n">train</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;valid&quot;</span><span class="p">:</span>
            <span class="n">preprocess_fn</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">build_preprocess_fn</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">collate_fn</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">build_collate_fn</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">data_path_and_name_and_type</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">valid_data_path_and_name_and_type</span>
            <span class="n">shape_files</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">valid_shape_file</span>

            <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">valid_batch_type</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">batch_type</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">batch_type</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">batch_type</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">valid_batch_type</span>
            <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">valid_batch_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">batch_size</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">batch_size</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">batch_size</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">valid_batch_size</span>
            <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">valid_batch_bins</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">batch_bins</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">batch_bins</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">batch_bins</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">valid_batch_bins</span>
            <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">valid_max_cache_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># Cache 5% of maximum size for validation loader</span>
                <span class="n">max_cache_size</span> <span class="o">=</span> <span class="mf">0.05</span> <span class="o">*</span> <span class="n">args</span><span class="o">.</span><span class="n">max_cache_size</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">max_cache_size</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">valid_max_cache_size</span>
            <span class="n">max_cache_fd</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">max_cache_fd</span>
            <span class="n">distributed</span> <span class="o">=</span> <span class="n">distributed_option</span><span class="o">.</span><span class="n">distributed</span>
            <span class="n">num_batches</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">num_iters_per_epoch</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">train</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;plot_att&quot;</span><span class="p">:</span>
            <span class="n">preprocess_fn</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">build_preprocess_fn</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">collate_fn</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">build_collate_fn</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">data_path_and_name_and_type</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">valid_data_path_and_name_and_type</span>
            <span class="n">shape_files</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">valid_shape_file</span>
            <span class="n">batch_type</span> <span class="o">=</span> <span class="s2">&quot;unsorted&quot;</span>
            <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="n">batch_bins</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">num_batches</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">num_att_plot</span>
            <span class="n">max_cache_fd</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">max_cache_fd</span>
            <span class="c1"># num_att_plot should be a few sample ~ 3, so cache all data.</span>
            <span class="n">max_cache_size</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span> <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">max_cache_size</span> <span class="o">!=</span> <span class="mf">0.0</span> <span class="k">else</span> <span class="mf">0.0</span>
            <span class="c1"># always False because plot_attention performs on RANK0</span>
            <span class="n">distributed</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="n">num_iters_per_epoch</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">train</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;mode=</span><span class="si">{</span><span class="n">mode</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">IteratorOptions</span><span class="p">(</span>
            <span class="n">preprocess_fn</span><span class="o">=</span><span class="n">preprocess_fn</span><span class="p">,</span>
            <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_fn</span><span class="p">,</span>
            <span class="n">data_path_and_name_and_type</span><span class="o">=</span><span class="n">data_path_and_name_and_type</span><span class="p">,</span>
            <span class="n">shape_files</span><span class="o">=</span><span class="n">shape_files</span><span class="p">,</span>
            <span class="n">batch_type</span><span class="o">=</span><span class="n">batch_type</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">batch_bins</span><span class="o">=</span><span class="n">batch_bins</span><span class="p">,</span>
            <span class="n">num_batches</span><span class="o">=</span><span class="n">num_batches</span><span class="p">,</span>
            <span class="n">max_cache_size</span><span class="o">=</span><span class="n">max_cache_size</span><span class="p">,</span>
            <span class="n">max_cache_fd</span><span class="o">=</span><span class="n">max_cache_fd</span><span class="p">,</span>
            <span class="n">distributed</span><span class="o">=</span><span class="n">distributed</span><span class="p">,</span>
            <span class="n">num_iters_per_epoch</span><span class="o">=</span><span class="n">num_iters_per_epoch</span><span class="p">,</span>
            <span class="n">train</span><span class="o">=</span><span class="n">train</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="AbsTask.build_iter_factory"><a class="viewcode-back" href="../../../_gen/espnet2.tasks.html#espnet2.tasks.abs_task.AbsTask.build_iter_factory">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">build_iter_factory</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">args</span><span class="p">:</span> <span class="n">argparse</span><span class="o">.</span><span class="n">Namespace</span><span class="p">,</span>
        <span class="n">distributed_option</span><span class="p">:</span> <span class="n">DistributedOption</span><span class="p">,</span>
        <span class="n">mode</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">kwargs</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">AbsIterFactory</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Build a factory object of mini-batch iterator.</span>

<span class="sd">        This object is invoked at every epochs to build the iterator for each epoch</span>
<span class="sd">        as following:</span>

<span class="sd">        &gt;&gt;&gt; iter_factory = cls.build_iter_factory(...)</span>
<span class="sd">        &gt;&gt;&gt; for epoch in range(1, max_epoch):</span>
<span class="sd">        ...     for keys, batch in iter_fatory.build_iter(epoch):</span>
<span class="sd">        ...         model(**batch)</span>

<span class="sd">        The mini-batches for each epochs are fully controlled by this class.</span>
<span class="sd">        Note that the random seed used for shuffling is decided as &quot;seed + epoch&quot; and</span>
<span class="sd">        the generated mini-batches can be reproduces when resuming.</span>

<span class="sd">        Note that the definition of &quot;epoch&quot; doesn&#39;t always indicate</span>
<span class="sd">        to run out of the whole training corpus.</span>
<span class="sd">        &quot;--num_iters_per_epoch&quot; option restricts the number of iterations for each epoch</span>
<span class="sd">        and the rest of samples for the originally epoch are left for the next epoch.</span>
<span class="sd">        e.g. If The number of mini-batches equals to 4, the following two are same:</span>

<span class="sd">        - 1 epoch without &quot;--num_iters_per_epoch&quot;</span>
<span class="sd">        - 4 epoch with &quot;--num_iters_per_epoch&quot; == 4</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="n">check_argument_types</span><span class="p">()</span>
        <span class="n">iter_options</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">build_iter_options</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">distributed_option</span><span class="p">,</span> <span class="n">mode</span><span class="p">)</span>

        <span class="c1"># Overwrite iter_options if any kwargs is given</span>
        <span class="k">if</span> <span class="n">kwargs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="nb">setattr</span><span class="p">(</span><span class="n">iter_options</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">iterator_type</span> <span class="o">==</span> <span class="s2">&quot;sequence&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">cls</span><span class="o">.</span><span class="n">build_sequence_iter_factory</span><span class="p">(</span>
                <span class="n">args</span><span class="o">=</span><span class="n">args</span><span class="p">,</span>
                <span class="n">iter_options</span><span class="o">=</span><span class="n">iter_options</span><span class="p">,</span>
                <span class="n">mode</span><span class="o">=</span><span class="n">mode</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">args</span><span class="o">.</span><span class="n">iterator_type</span> <span class="o">==</span> <span class="s2">&quot;chunk&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">cls</span><span class="o">.</span><span class="n">build_chunk_iter_factory</span><span class="p">(</span>
                <span class="n">args</span><span class="o">=</span><span class="n">args</span><span class="p">,</span>
                <span class="n">iter_options</span><span class="o">=</span><span class="n">iter_options</span><span class="p">,</span>
                <span class="n">mode</span><span class="o">=</span><span class="n">mode</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">args</span><span class="o">.</span><span class="n">iterator_type</span> <span class="o">==</span> <span class="s2">&quot;task&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">cls</span><span class="o">.</span><span class="n">build_task_iter_factory</span><span class="p">(</span>
                <span class="n">args</span><span class="o">=</span><span class="n">args</span><span class="p">,</span>
                <span class="n">iter_options</span><span class="o">=</span><span class="n">iter_options</span><span class="p">,</span>
                <span class="n">mode</span><span class="o">=</span><span class="n">mode</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Not supported: iterator_type=</span><span class="si">{</span><span class="n">args</span><span class="o">.</span><span class="n">iterator_type</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span></div>

<div class="viewcode-block" id="AbsTask.build_sequence_iter_factory"><a class="viewcode-back" href="../../../_gen/espnet2.tasks.html#espnet2.tasks.abs_task.AbsTask.build_sequence_iter_factory">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">build_sequence_iter_factory</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span> <span class="n">args</span><span class="p">:</span> <span class="n">argparse</span><span class="o">.</span><span class="n">Namespace</span><span class="p">,</span> <span class="n">iter_options</span><span class="p">:</span> <span class="n">IteratorOptions</span><span class="p">,</span> <span class="n">mode</span><span class="p">:</span> <span class="nb">str</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">AbsIterFactory</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">check_argument_types</span><span class="p">()</span>

        <span class="n">dataset</span> <span class="o">=</span> <span class="n">ESPnetDataset</span><span class="p">(</span>
            <span class="n">iter_options</span><span class="o">.</span><span class="n">data_path_and_name_and_type</span><span class="p">,</span>
            <span class="n">float_dtype</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">train_dtype</span><span class="p">,</span>
            <span class="n">preprocess</span><span class="o">=</span><span class="n">iter_options</span><span class="o">.</span><span class="n">preprocess_fn</span><span class="p">,</span>
            <span class="n">max_cache_size</span><span class="o">=</span><span class="n">iter_options</span><span class="o">.</span><span class="n">max_cache_size</span><span class="p">,</span>
            <span class="n">max_cache_fd</span><span class="o">=</span><span class="n">iter_options</span><span class="o">.</span><span class="n">max_cache_fd</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">cls</span><span class="o">.</span><span class="n">check_task_requirements</span><span class="p">(</span>
            <span class="n">dataset</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">allow_variable_data_keys</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="n">iter_options</span><span class="o">.</span><span class="n">train</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">Path</span><span class="p">(</span>
            <span class="n">Path</span><span class="p">(</span><span class="n">iter_options</span><span class="o">.</span><span class="n">data_path_and_name_and_type</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">parent</span><span class="p">,</span> <span class="s2">&quot;utt2category&quot;</span>
        <span class="p">)</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
            <span class="n">utt2category_file</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span>
                <span class="n">Path</span><span class="p">(</span>
                    <span class="n">Path</span><span class="p">(</span><span class="n">iter_options</span><span class="o">.</span><span class="n">data_path_and_name_and_type</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">parent</span><span class="p">,</span>
                    <span class="s2">&quot;utt2category&quot;</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">utt2category_file</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">batch_sampler</span> <span class="o">=</span> <span class="n">build_batch_sampler</span><span class="p">(</span>
            <span class="nb">type</span><span class="o">=</span><span class="n">iter_options</span><span class="o">.</span><span class="n">batch_type</span><span class="p">,</span>
            <span class="n">shape_files</span><span class="o">=</span><span class="n">iter_options</span><span class="o">.</span><span class="n">shape_files</span><span class="p">,</span>
            <span class="n">fold_lengths</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">fold_length</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">iter_options</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">batch_bins</span><span class="o">=</span><span class="n">iter_options</span><span class="o">.</span><span class="n">batch_bins</span><span class="p">,</span>
            <span class="n">sort_in_batch</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">sort_in_batch</span><span class="p">,</span>
            <span class="n">sort_batch</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">sort_batch</span><span class="p">,</span>
            <span class="n">drop_last</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">min_batch_size</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">get_world_size</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">iter_options</span><span class="o">.</span><span class="n">distributed</span>
            <span class="k">else</span> <span class="mi">1</span><span class="p">,</span>
            <span class="n">utt2category_file</span><span class="o">=</span><span class="n">utt2category_file</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">batches</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">batch_sampler</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">iter_options</span><span class="o">.</span><span class="n">num_batches</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">batches</span> <span class="o">=</span> <span class="n">batches</span><span class="p">[:</span> <span class="n">iter_options</span><span class="o">.</span><span class="n">num_batches</span><span class="p">]</span>

        <span class="n">bs_list</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span> <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">batches</span><span class="p">]</span>

        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[</span><span class="si">{</span><span class="n">mode</span><span class="si">}</span><span class="s2">] dataset:</span><span class="se">\n</span><span class="si">{</span><span class="n">dataset</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[</span><span class="si">{</span><span class="n">mode</span><span class="si">}</span><span class="s2">] Batch sampler: </span><span class="si">{</span><span class="n">batch_sampler</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;[</span><span class="si">{</span><span class="n">mode</span><span class="si">}</span><span class="s2">] mini-batch sizes summary: N-batch=</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">bs_list</span><span class="p">)</span><span class="si">}</span><span class="s2">, &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;mean=</span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">bs_list</span><span class="p">)</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">, min=</span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">bs_list</span><span class="p">)</span><span class="si">}</span><span class="s2">, max=</span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">bs_list</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">iter_options</span><span class="o">.</span><span class="n">distributed</span><span class="p">:</span>
            <span class="n">world_size</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">get_world_size</span><span class="p">()</span>
            <span class="n">rank</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">get_rank</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">batches</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">world_size</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;The batch-size must be equal or more than world_size: &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span><span class="si">}</span><span class="s2"> &lt; </span><span class="si">{</span><span class="n">world_size</span><span class="si">}</span><span class="s2">&quot;</span>
                    <span class="p">)</span>
            <span class="n">batches</span> <span class="o">=</span> <span class="p">[</span><span class="n">batch</span><span class="p">[</span><span class="n">rank</span><span class="p">::</span><span class="n">world_size</span><span class="p">]</span> <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">batches</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">SequenceIterFactory</span><span class="p">(</span>
            <span class="n">dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">,</span>
            <span class="n">batches</span><span class="o">=</span><span class="n">batches</span><span class="p">,</span>
            <span class="n">seed</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">seed</span><span class="p">,</span>
            <span class="n">num_iters_per_epoch</span><span class="o">=</span><span class="n">iter_options</span><span class="o">.</span><span class="n">num_iters_per_epoch</span><span class="p">,</span>
            <span class="n">shuffle</span><span class="o">=</span><span class="n">iter_options</span><span class="o">.</span><span class="n">train</span><span class="p">,</span>
            <span class="n">num_workers</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">num_workers</span><span class="p">,</span>
            <span class="n">collate_fn</span><span class="o">=</span><span class="n">iter_options</span><span class="o">.</span><span class="n">collate_fn</span><span class="p">,</span>
            <span class="n">pin_memory</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">ngpu</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="AbsTask.build_chunk_iter_factory"><a class="viewcode-back" href="../../../_gen/espnet2.tasks.html#espnet2.tasks.abs_task.AbsTask.build_chunk_iter_factory">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">build_chunk_iter_factory</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">args</span><span class="p">:</span> <span class="n">argparse</span><span class="o">.</span><span class="n">Namespace</span><span class="p">,</span>
        <span class="n">iter_options</span><span class="p">:</span> <span class="n">IteratorOptions</span><span class="p">,</span>
        <span class="n">mode</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">AbsIterFactory</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">check_argument_types</span><span class="p">()</span>

        <span class="n">dataset</span> <span class="o">=</span> <span class="n">ESPnetDataset</span><span class="p">(</span>
            <span class="n">iter_options</span><span class="o">.</span><span class="n">data_path_and_name_and_type</span><span class="p">,</span>
            <span class="n">float_dtype</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">train_dtype</span><span class="p">,</span>
            <span class="n">preprocess</span><span class="o">=</span><span class="n">iter_options</span><span class="o">.</span><span class="n">preprocess_fn</span><span class="p">,</span>
            <span class="n">max_cache_size</span><span class="o">=</span><span class="n">iter_options</span><span class="o">.</span><span class="n">max_cache_size</span><span class="p">,</span>
            <span class="n">max_cache_fd</span><span class="o">=</span><span class="n">iter_options</span><span class="o">.</span><span class="n">max_cache_fd</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">cls</span><span class="o">.</span><span class="n">check_task_requirements</span><span class="p">(</span>
            <span class="n">dataset</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">allow_variable_data_keys</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="n">iter_options</span><span class="o">.</span><span class="n">train</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">iter_options</span><span class="o">.</span><span class="n">shape_files</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">key_file</span> <span class="o">=</span> <span class="n">iter_options</span><span class="o">.</span><span class="n">data_path_and_name_and_type</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">key_file</span> <span class="o">=</span> <span class="n">iter_options</span><span class="o">.</span><span class="n">shape_files</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="n">batch_sampler</span> <span class="o">=</span> <span class="n">UnsortedBatchSampler</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">key_file</span><span class="o">=</span><span class="n">key_file</span><span class="p">)</span>
        <span class="n">batches</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">batch_sampler</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">iter_options</span><span class="o">.</span><span class="n">num_batches</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">batches</span> <span class="o">=</span> <span class="n">batches</span><span class="p">[:</span> <span class="n">iter_options</span><span class="o">.</span><span class="n">num_batches</span><span class="p">]</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[</span><span class="si">{</span><span class="n">mode</span><span class="si">}</span><span class="s2">] dataset:</span><span class="se">\n</span><span class="si">{</span><span class="n">dataset</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">iter_options</span><span class="o">.</span><span class="n">distributed</span><span class="p">:</span>
            <span class="n">world_size</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">get_world_size</span><span class="p">()</span>
            <span class="n">rank</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">get_rank</span><span class="p">()</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">batches</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">world_size</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Number of samples is smaller than world_size&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">iter_options</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">&lt;</span> <span class="n">world_size</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;batch_size must be equal or more than world_size&quot;</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">rank</span> <span class="o">&lt;</span> <span class="n">iter_options</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">%</span> <span class="n">world_size</span><span class="p">:</span>
                <span class="n">batch_size</span> <span class="o">=</span> <span class="n">iter_options</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">//</span> <span class="n">world_size</span> <span class="o">+</span> <span class="mi">1</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">batch_size</span> <span class="o">=</span> <span class="n">iter_options</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">//</span> <span class="n">world_size</span>
            <span class="n">num_cache_chunks</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">num_cache_chunks</span> <span class="o">//</span> <span class="n">world_size</span>
            <span class="c1"># NOTE(kamo): Split whole corpus by sample numbers without considering</span>
            <span class="c1">#   each of the lengths, therefore the number of iteration counts are not</span>
            <span class="c1">#   always equal to each other and the iterations are limitted</span>
            <span class="c1">#   by the fewest iterations.</span>
            <span class="c1">#   i.e. the samples over the counts are discarded.</span>
            <span class="n">batches</span> <span class="o">=</span> <span class="n">batches</span><span class="p">[</span><span class="n">rank</span><span class="p">::</span><span class="n">world_size</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">batch_size</span> <span class="o">=</span> <span class="n">iter_options</span><span class="o">.</span><span class="n">batch_size</span>
            <span class="n">num_cache_chunks</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">num_cache_chunks</span>

        <span class="k">return</span> <span class="n">ChunkIterFactory</span><span class="p">(</span>
            <span class="n">dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">,</span>
            <span class="n">batches</span><span class="o">=</span><span class="n">batches</span><span class="p">,</span>
            <span class="n">seed</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">seed</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="c1"># For chunk iterator,</span>
            <span class="c1"># --num_iters_per_epoch doesn&#39;t indicate the number of iterations,</span>
            <span class="c1"># but indicates the number of samples.</span>
            <span class="n">num_samples_per_epoch</span><span class="o">=</span><span class="n">iter_options</span><span class="o">.</span><span class="n">num_iters_per_epoch</span><span class="p">,</span>
            <span class="n">shuffle</span><span class="o">=</span><span class="n">iter_options</span><span class="o">.</span><span class="n">train</span><span class="p">,</span>
            <span class="n">num_workers</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">num_workers</span><span class="p">,</span>
            <span class="n">collate_fn</span><span class="o">=</span><span class="n">iter_options</span><span class="o">.</span><span class="n">collate_fn</span><span class="p">,</span>
            <span class="n">pin_memory</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">ngpu</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span>
            <span class="n">chunk_length</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">chunk_length</span><span class="p">,</span>
            <span class="n">chunk_shift_ratio</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">chunk_shift_ratio</span><span class="p">,</span>
            <span class="n">num_cache_chunks</span><span class="o">=</span><span class="n">num_cache_chunks</span><span class="p">,</span>
        <span class="p">)</span></div>

    <span class="c1"># NOTE(kamo): Not abstract class</span>
<div class="viewcode-block" id="AbsTask.build_task_iter_factory"><a class="viewcode-back" href="../../../_gen/espnet2.tasks.html#espnet2.tasks.abs_task.AbsTask.build_task_iter_factory">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">build_task_iter_factory</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">args</span><span class="p">:</span> <span class="n">argparse</span><span class="o">.</span><span class="n">Namespace</span><span class="p">,</span>
        <span class="n">iter_options</span><span class="p">:</span> <span class="n">IteratorOptions</span><span class="p">,</span>
        <span class="n">mode</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">AbsIterFactory</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Build task specific iterator factory</span>

<span class="sd">        Example:</span>

<span class="sd">            &gt;&gt;&gt; class YourTask(AbsTask):</span>
<span class="sd">            ... @classmethod</span>
<span class="sd">            ... def add_task_arguments(cls, parser: argparse.ArgumentParser):</span>
<span class="sd">            ...     parser.set_defaults(iterator_type=&quot;task&quot;)</span>
<span class="sd">            ...</span>
<span class="sd">            ... @classmethod</span>
<span class="sd">            ... def build_task_iter_factory(</span>
<span class="sd">            ...     cls,</span>
<span class="sd">            ...     args: argparse.Namespace,</span>
<span class="sd">            ...     iter_options: IteratorOptions,</span>
<span class="sd">            ...     mode: str,</span>
<span class="sd">            ... ):</span>
<span class="sd">            ...     return FooIterFactory(...)</span>
<span class="sd">            ...</span>
<span class="sd">            ... @classmethod</span>
<span class="sd">            ... def build_iter_options(</span>
<span class="sd">            ....    args: argparse.Namespace,</span>
<span class="sd">            ...     distributed_option: DistributedOption,</span>
<span class="sd">            ...     mode: str</span>
<span class="sd">            ... ):</span>
<span class="sd">            ...     # if you need to customize options object</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span></div>

<div class="viewcode-block" id="AbsTask.build_multiple_iter_factory"><a class="viewcode-back" href="../../../_gen/espnet2.tasks.html#espnet2.tasks.abs_task.AbsTask.build_multiple_iter_factory">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">build_multiple_iter_factory</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span> <span class="n">args</span><span class="p">:</span> <span class="n">argparse</span><span class="o">.</span><span class="n">Namespace</span><span class="p">,</span> <span class="n">distributed_option</span><span class="p">:</span> <span class="n">DistributedOption</span><span class="p">,</span> <span class="n">mode</span><span class="p">:</span> <span class="nb">str</span>
    <span class="p">):</span>
        <span class="k">assert</span> <span class="n">check_argument_types</span><span class="p">()</span>
        <span class="n">iter_options</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">build_iter_options</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">distributed_option</span><span class="p">,</span> <span class="n">mode</span><span class="p">)</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">iter_options</span><span class="o">.</span><span class="n">data_path_and_name_and_type</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span>
            <span class="n">iter_options</span><span class="o">.</span><span class="n">data_path_and_name_and_type</span>
        <span class="p">)</span>

        <span class="c1"># 1. Sanity check</span>
        <span class="n">num_splits</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">for</span> <span class="n">path</span> <span class="ow">in</span> <span class="p">[</span>
            <span class="n">path</span> <span class="k">for</span> <span class="n">path</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">iter_options</span><span class="o">.</span><span class="n">data_path_and_name_and_type</span>
        <span class="p">]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">iter_options</span><span class="o">.</span><span class="n">shape_files</span><span class="p">):</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">Path</span><span class="p">(</span><span class="n">path</span><span class="p">)</span><span class="o">.</span><span class="n">is_dir</span><span class="p">():</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s2"> is not a directory&quot;</span><span class="p">)</span>
            <span class="n">p</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">path</span><span class="p">)</span> <span class="o">/</span> <span class="s2">&quot;num_splits&quot;</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">p</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
                <span class="k">raise</span> <span class="ne">FileNotFoundError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">p</span><span class="si">}</span><span class="s2"> is not found&quot;</span><span class="p">)</span>
            <span class="k">with</span> <span class="n">p</span><span class="o">.</span><span class="n">open</span><span class="p">()</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                <span class="n">_num_splits</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">())</span>
                <span class="k">if</span> <span class="n">num_splits</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">num_splits</span> <span class="o">!=</span> <span class="n">_num_splits</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Number of splits are mismathed: &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">iter_options</span><span class="o">.</span><span class="n">data_path_and_name_and_type</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2"> and </span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s2">&quot;</span>
                    <span class="p">)</span>
                <span class="n">num_splits</span> <span class="o">=</span> <span class="n">_num_splits</span>

            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_splits</span><span class="p">):</span>
                <span class="n">p</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">path</span><span class="p">)</span> <span class="o">/</span> <span class="sa">f</span><span class="s2">&quot;split.</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">p</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
                    <span class="k">raise</span> <span class="ne">FileNotFoundError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">p</span><span class="si">}</span><span class="s2"> is not found&quot;</span><span class="p">)</span>

        <span class="c1"># 2. Create functions to build an iter factory for each splits</span>
        <span class="n">data_path_and_name_and_type_list</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">[</span>
                <span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">Path</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="o">/</span> <span class="sa">f</span><span class="s2">&quot;split.</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">),</span> <span class="n">n</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">p</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">iter_options</span><span class="o">.</span><span class="n">data_path_and_name_and_type</span>
            <span class="p">]</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_splits</span><span class="p">)</span>
        <span class="p">]</span>
        <span class="n">shape_files_list</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">Path</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="o">/</span> <span class="sa">f</span><span class="s2">&quot;split.</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">iter_options</span><span class="o">.</span><span class="n">shape_files</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_splits</span><span class="p">)</span>
        <span class="p">]</span>
        <span class="n">num_iters_per_epoch_list</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">(</span><span class="n">iter_options</span><span class="o">.</span><span class="n">num_iters_per_epoch</span> <span class="o">+</span> <span class="n">i</span><span class="p">)</span> <span class="o">//</span> <span class="n">num_splits</span>
            <span class="k">if</span> <span class="n">iter_options</span><span class="o">.</span><span class="n">num_iters_per_epoch</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="k">else</span> <span class="kc">None</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_splits</span><span class="p">)</span>
        <span class="p">]</span>
        <span class="n">max_cache_size</span> <span class="o">=</span> <span class="n">iter_options</span><span class="o">.</span><span class="n">max_cache_size</span> <span class="o">/</span> <span class="n">num_splits</span>

        <span class="c1"># Note that iter-factories are built for each epoch at runtime lazily.</span>
        <span class="n">build_funcs</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">functools</span><span class="o">.</span><span class="n">partial</span><span class="p">(</span>
                <span class="bp">cls</span><span class="o">.</span><span class="n">build_iter_factory</span><span class="p">,</span>
                <span class="n">args</span><span class="p">,</span>
                <span class="n">distributed_option</span><span class="p">,</span>
                <span class="n">mode</span><span class="p">,</span>
                <span class="n">kwargs</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
                    <span class="n">data_path_and_name_and_type</span><span class="o">=</span><span class="n">_data_path_and_name_and_type</span><span class="p">,</span>
                    <span class="n">shape_files</span><span class="o">=</span><span class="n">_shape_files</span><span class="p">,</span>
                    <span class="n">num_iters_per_epoch</span><span class="o">=</span><span class="n">_num_iters_per_epoch</span><span class="p">,</span>
                    <span class="n">max_cache_size</span><span class="o">=</span><span class="n">max_cache_size</span><span class="p">,</span>
                <span class="p">),</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="p">(</span>
                <span class="n">_data_path_and_name_and_type</span><span class="p">,</span>
                <span class="n">_shape_files</span><span class="p">,</span>
                <span class="n">_num_iters_per_epoch</span><span class="p">,</span>
            <span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
                <span class="n">data_path_and_name_and_type_list</span><span class="p">,</span>
                <span class="n">shape_files_list</span><span class="p">,</span>
                <span class="n">num_iters_per_epoch_list</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">]</span>

        <span class="c1"># 3. Build MultipleIterFactory</span>
        <span class="k">return</span> <span class="n">MultipleIterFactory</span><span class="p">(</span>
            <span class="n">build_funcs</span><span class="o">=</span><span class="n">build_funcs</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="n">iter_options</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">seed</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="AbsTask.build_streaming_iterator"><a class="viewcode-back" href="../../../_gen/espnet2.tasks.html#espnet2.tasks.abs_task.AbsTask.build_streaming_iterator">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">build_streaming_iterator</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">data_path_and_name_and_type</span><span class="p">,</span>
        <span class="n">preprocess_fn</span><span class="p">,</span>
        <span class="n">collate_fn</span><span class="p">,</span>
        <span class="n">key_file</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">dtype</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
        <span class="n">num_workers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">allow_variable_data_keys</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">ngpu</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">inference</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DataLoader</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Build DataLoader using iterable dataset&quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="n">check_argument_types</span><span class="p">()</span>
        <span class="c1"># For backward compatibility for pytorch DataLoader</span>
        <span class="k">if</span> <span class="n">collate_fn</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">kwargs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_fn</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="n">dataset</span> <span class="o">=</span> <span class="n">IterableESPnetDataset</span><span class="p">(</span>
            <span class="n">data_path_and_name_and_type</span><span class="p">,</span>
            <span class="n">float_dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span>
            <span class="n">preprocess</span><span class="o">=</span><span class="n">preprocess_fn</span><span class="p">,</span>
            <span class="n">key_file</span><span class="o">=</span><span class="n">key_file</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">dataset</span><span class="o">.</span><span class="n">apply_utt2category</span><span class="p">:</span>
            <span class="n">kwargs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">kwargs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>

        <span class="bp">cls</span><span class="o">.</span><span class="n">check_task_requirements</span><span class="p">(</span>
            <span class="n">dataset</span><span class="p">,</span> <span class="n">allow_variable_data_keys</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">inference</span><span class="o">=</span><span class="n">inference</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">DataLoader</span><span class="p">(</span>
            <span class="n">dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">,</span>
            <span class="n">pin_memory</span><span class="o">=</span><span class="n">ngpu</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span>
            <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span></div>

    <span class="c1"># ~~~~~~~~~ The methods below are mainly used for inference ~~~~~~~~~</span>
<div class="viewcode-block" id="AbsTask.build_model_from_file"><a class="viewcode-back" href="../../../_gen/espnet2.tasks.html#espnet2.tasks.abs_task.AbsTask.build_model_from_file">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">build_model_from_file</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">config_file</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Path</span><span class="p">,</span> <span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">model_file</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Path</span><span class="p">,</span> <span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">device</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">AbsESPnetModel</span><span class="p">,</span> <span class="n">argparse</span><span class="o">.</span><span class="n">Namespace</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Build model from the files.</span>

<span class="sd">        This method is used for inference or fine-tuning.</span>

<span class="sd">        Args:</span>
<span class="sd">            config_file: The yaml file saved when training.</span>
<span class="sd">            model_file: The model file saved when training.</span>
<span class="sd">            device: Device type, &quot;cpu&quot;, &quot;cuda&quot;, or &quot;cuda:N&quot;.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="n">check_argument_types</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">config_file</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">model_file</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="p">(</span>
                <span class="s2">&quot;The argument &#39;model_file&#39; must be provided &quot;</span>
                <span class="s2">&quot;if the argument &#39;config_file&#39; is not specified.&quot;</span>
            <span class="p">)</span>
            <span class="n">config_file</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">model_file</span><span class="p">)</span><span class="o">.</span><span class="n">parent</span> <span class="o">/</span> <span class="s2">&quot;config.yaml&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">config_file</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">config_file</span><span class="p">)</span>

        <span class="k">with</span> <span class="n">config_file</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s2">&quot;r&quot;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">args</span> <span class="o">=</span> <span class="n">yaml</span><span class="o">.</span><span class="n">safe_load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
        <span class="n">args</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">Namespace</span><span class="p">(</span><span class="o">**</span><span class="n">args</span><span class="p">)</span>
        <span class="n">model</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">build_model</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">AbsESPnetModel</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;model must inherit </span><span class="si">{</span><span class="n">AbsESPnetModel</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">, but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">model</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">model_file</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">device</span> <span class="o">==</span> <span class="s2">&quot;cuda&quot;</span><span class="p">:</span>
                <span class="c1"># NOTE(kamo): &quot;cuda&quot; for torch.load always indicates cuda:0</span>
                <span class="c1">#   in PyTorch&lt;=1.4</span>
                <span class="n">device</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;cuda:</span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_device</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">model_file</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">device</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">model</span><span class="p">,</span> <span class="n">args</span></div></div>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2017, Shinji Watanabe.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>