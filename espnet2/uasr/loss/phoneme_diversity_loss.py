import torch
from typeguard import typechecked

from espnet2.uasr.loss.abs_loss import AbsUASRLoss
from espnet2.utils.types import str2bool


class UASRPhonemeDiversityLoss(AbsUASRLoss):
    """
    Phoneme diversity loss for UASR (Unsupervised Automatic Speech Recognition).

    This loss function encourages diversity in the phoneme predictions made by
    the model, which can help improve the overall performance of the UASR system.

    Attributes:
        weight (float): Weighting factor for the loss, default is 1.0.

    Args:
        weight (float): A scalar to scale the contribution of the loss.

    Returns:
        torch.Tensor: The computed phoneme diversity loss, which is a scalar
        value.

    Raises:
        ValueError: If `dense_x` is not a 3D tensor.

    Examples:
        >>> loss_function = UASRPhonemeDiversityLoss(weight=0.5)
        >>> dense_x = torch.randn(10, 20, 30)  # (batch_size, time_length, channels)
        >>> sample_size = 10
        >>> is_discriminative_step = False
        >>> loss = loss_function(dense_x, sample_size, is_discriminative_step)
        >>> print(loss)

    Note:
        The loss is computed only when `weight` is greater than 0 and
        `is_discriminative_step` is False. Otherwise, the loss will return 0.

    Todo:
        Add more validation checks for inputs in the future.
    """

    @typechecked
    def __init__(
        self,
        weight: float = 1.0,
    ):
        super().__init__()

        self.weight = weight

    def forward(
        self, dense_x: torch.Tensor, sample_size: int, is_discriminative_step: str2bool
    ):
        """
        Computes the phoneme diversity loss for Unsupervised Automatic Speech
        Recognition (UASR).

        This loss encourages diversity in the phonemes generated by the model
        by penalizing low-entropy distributions in the predicted logits. It is
        typically used during the training phase when the model is not in a
        discriminative step.

        Args:
            dense_x (torch.Tensor): Predicted logits of generated samples with
                shape (batch_size, time_length, channel_size).
            sample_size (int): The batch size used in the current training
                iteration.
            is_discriminative_step (str2bool): A boolean indicating whether the
                model is currently in a discriminative training step. If True,
                the diversity loss will not be calculated.

        Returns:
            torch.Tensor: The computed phoneme diversity loss. Returns 0 if
            the weight is less than or equal to 0 or if in a discriminative
            training step.

        Examples:
            >>> loss_fn = UASRPhonemeDiversityLoss(weight=1.0)
            >>> logits = torch.randn(4, 10, 20)  # Example logits for a batch
            >>> loss = loss_fn.forward(logits, sample_size=4,
            ...                          is_discriminative_step=False)
            >>> print(loss)

        Note:
            The loss calculation is performed only if the weight is greater
            than 0 and the model is not in a discriminative step.
        """
        if self.weight > 0 and not is_discriminative_step:
            batch_size, time_length, channel_size = dense_x.shape

            avg_probs = torch.softmax(
                dense_x.reshape(-1, channel_size).float(), dim=-1
            ).mean(dim=0)
            phoneme_ppl = torch.exp(
                -torch.sum(avg_probs * torch.log(avg_probs + 1e-7), dim=-1)
            )
            phoneme_diversity_loss = (
                (channel_size - phoneme_ppl) / channel_size
            ) * sample_size

            return phoneme_diversity_loss
        else:
            return 0
