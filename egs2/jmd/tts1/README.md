# JMD RECIPE

This is the recipe of Japanese single speaker TTS model with [JMD](https://sites.google.com/site/shinnosuketakamichi/research-topics/jmd_corpus) corpus.

See the following pages for the usage:
- [How to run the recipe](../../TEMPLATE/tts1/README.md#how-to-run)
- [How to train FastSpeech](../../TEMPLATE/tts1/README.md#fastspeech-training)
- [How to train FastSpeech2](../../TEMPLATE/tts1/README.md#fastspeech2-training)
- [How to train VITS](../../TEMPLATE/tts1/README.md#vits-training)
- [How to train joint text2wav](../../TEMPLATE/tts1/README.md#joint-text2wav-training)

See the following pages before asking the question:
- [ESPnet2 Tutorial](https://espnet.github.io/espnet/espnet2_tutorial.html)
- [ESPnet2 TTS FAQ](../../TEMPLATE/tts1/README.md#faq)

# INITIAL RESULTS

## Environments
- date: `Fri Aug 27 10:19:55 JST 2021`
- python version: `3.6.8 (default, Nov 16 2020, 16:55:22)  [GCC 4.8.5 20150623 (Red Hat 4.8.5-44)]`
- espnet version: `espnet 0.10.0`
- pytorch version: `pytorch 1.9.0+cu102`
- Git hash: `9afbd27f5ec406819f33f7e9205ec15d2b41f0d3`
  - Commit date: `Mon Aug 2 10:28:43 2021 +0900`

## Pretrained Models

### jmd_tts_train_tacotron2_kumamoto_raw_phn_jaconv_pyopenjtalk_train.loss.ave
- https://zenodo.org/record/5278073

### jmd_tts_train_tacotron2_osaka_raw_phn_jaconv_pyopenjtalk_train.loss.ave
- https://zenodo.org/record/5277863
