# https://github.com/espnet/espnet/blob/master/egs2/librispeech_100/asr1/conf/tuning/train_asr_transformer_win400_hop160_ctc0.3_lr2e-3_warmup15k_timemask5_amp_no-deterministic.yaml
encoder: transformer
encoder_conf:
  output_size: 256
  attention_heads: 4
  linear_units: 1024
  num_blocks: 18
  dropout_rate: 0.1
  positional_dropout_rate: 0.1
  attention_dropout_rate: 0.1
  input_layer: conv2d2 # subsampling rate = 2
  normalize_before: true

decoder: transformer
decoder_conf:
  attention_heads: 4
  linear_units: 2048
  num_blocks: 6
  dropout_rate: 0.1
  positional_dropout_rate: 0.1
  self_attention_dropout_rate: 0.1
  src_attention_dropout_rate: 0.1

model_conf:
  ctc_weight: 0.3
  lsm_weight: 0.1
  length_normalized_loss: false

frontend_conf:
  n_fft: 512
  win_length: 400
  hop_length: 160

seed: 2022
log_interval: 200
num_att_plot: 0
num_workers: 4
sort_in_batch: descending
sort_batch: descending
batch_type: numel
batch_bins: 6000000
accum_grad: 8
grad_clip: 5
max_epoch: 60
patience: none
init: none
best_model_criterion:
  - - valid
    - acc
    - max
keep_nbest_models: 10

use_amp: true
cudnn_deterministic: false
cudnn_benchmark: false

optim: adam
optim_conf:
  lr: 0.001
  weight_decay: 0.000001
scheduler: warmuplr
scheduler_conf:
  warmup_steps: 2500

specaug: specaug
specaug_conf:
  apply_time_warp: true
  time_warp_window: 5
  time_warp_mode: bicubic
  apply_freq_mask: true
  freq_mask_width_range:
    - 0
    - 27
  num_freq_mask: 2
  apply_time_mask: true
  time_mask_width_ratio_range:
    - 0.
    - 0.05
  num_time_mask: 5
