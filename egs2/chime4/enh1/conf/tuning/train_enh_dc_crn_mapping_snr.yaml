init: xavier_uniform
max_epoch: 200
batch_type: folded
batch_size:  16
iterator_type: chunk
chunk_length: 32000
num_workers: 4
optim: adam
optim_conf:
    lr: 1.0e-03
    eps: 1.0e-08
    weight_decay: 1.0e-7
    amsgrad: true
patience: 10
grad_clip: 5
val_scheduler_criterion:
- valid
- loss
best_model_criterion:
-   - valid
    - si_snr
    - max
-   - valid
    - loss
    - min
keep_nbest_models: 1
scheduler: steplr
scheduler_conf:
    step_size: 2
    gamma: 0.98

# A list for criterions
# The overlall loss in the multi-task learning will be:
# loss = weight_1 * loss_1 + ... + weight_N * loss_N
# The default `weight` for each sub-loss is 1.0
criterions: 
  # The first criterion
  - name: snr 
    conf:
      eps: 1.0e-7
    # the wrapper for the current criterion
    # PIT is widely used in the speech separation task
    wrapper: pit
    wrapper_conf:
      weight: 1.0


encoder: stft
encoder_conf:
    n_fft: 256
    hop_length: 128
decoder: stft
decoder_conf:
    n_fft: 256
    hop_length: 128
separator: dc_crn
separator_conf:
    num_spk: 1
    input_channels: [10, 16, 32, 64, 128, 256]  # 5x2=10 input channels
    enc_hid_channels: 8
    enc_layers: 5
    glstm_groups: 2
    glstm_layers: 2
    glstm_bidirectional: true
    glstm_rearrange: false
    mode: mapping
    ref_channel: 3
