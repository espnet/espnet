# Benchmark of Animal Sounds Recipe
This recipe implements the audio classification task with a BEATs encoder and linear layer decoder model on the [The Benchmark of Animal Sounds (BEAN)](https://arxiv.org/abs/2210.12300).
The data processing code is adapted from https://github.com/earthspecies/beans 

# Training Details and Requirements
Most of the datasets complete within 5 hours and on a single L40 gpu.

## Steps to run

For Cornell Bird Identification you have to download kaggle api key and put it in ~/.kaggle/kaggle.json, and accept competition conditions- [Cornell Birdcall Identification-Kaggle](https://www.kaggle.com/competitions/birdsong-recognition)

1. Download the BEATs checkpoint: [BEATs_iter3](https://github.com/microsoft/unilm/tree/master/beats) and change the `beats_ckpt_path` path in `conf/beats_[dataset].yaml`
3. Launch data preparation and training for all datasets with `run.sh` or for a dataset with `run_[dataset].sh`

## Trained checkpoints
All trained checkpoints are available at:
* Cornell Bird Identification: https://huggingface.co/espnet/BEATs-BEAN.CornellBirdIdentification
* Bats: https://huggingface.co/espnet/BEATs-BEAN.Bats
* Watkins: https://huggingface.co/espnet/BEATs-BEAN.Watkins
* HumBugDB: https://huggingface.co/espnet/BEATs-BEAN.HumBugDB
* Dogs: https://huggingface.co/espnet/BEATs-BEAN.Dogs

<!-- Generated by scripts/utils/show_cls_result.sh -->
# RESULTS
## Environments
- date: `Wed Jan  8 05:51:08 EST 2025`
- python version: `3.9.20 (main, Oct  3 2024, 07:27:41)  [GCC 11.2.0]`
- espnet version: `espnet 202412`
- pytorch version: `pytorch 2.4.0`
- Git hash: `9191aa59acc7d3ceaca1f48dcc8fbdad2e03484b`
  - Commit date: `Tue Jan 7 04:34:03 2025 -0500`

|Dataset|[BioLingual](https://arxiv.org/pdf/2308.04978)(Table 3)|[NatureLM](https://arxiv.org/abs/2411.07186)(ZS-Table 3)|BEATs|
|-|-|-|-|
|cbi|74.4|75.5|64.0|
|bats|76.6|-|76.8|
|watkins|89.4|64.6|89.4|
|humbugdb|81.7|7.3|80.6|
|dogs|97.1|-|91.4|