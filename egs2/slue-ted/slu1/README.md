<!-- Generated by ./scripts/utils/show_asr_result.sh -->
# RESULTS

## Environments
- date: `Fri Mar  8 14:12:05 CST 2024`
- python version: `3.9.13 (main, Aug 25 2022, 23:26:10)  [GCC 11.2.0]`
- espnet version: `espnet 202402`
- pytorch version: `pytorch 2.1.0+cu121`
- Git hash: `dd643549fb1865232569cae406bbf5e106e105de`
  - Commit date: `Fri Mar 8 13:14:52 2024 -0600`

## Data Download
Download data from https://huggingface.co/datasets/asapp/slue-phase-2/blob/main/data/slue-ted_train.zip, https://huggingface.co/datasets/asapp/slue-phase-2/blob/main/data/slue-ted_dev.zip, https://huggingface.co/datasets/asapp/slue-phase-2/blob/main/data/slue-ted_test.zip to the shared folder and set SLUE_TED in db.sh to the shared folder.

## ASR Pre-training
Training is done in two stages: (a) ASR Pre-training, and (b) Summarization fine-tuning

First, run ASR pre-training as follows: Go to tedlium3/asr1 and run with the exact same config and token list as used in SUMM fine-tuning except with CTC weight 0.3 and only for 15 epochs.

Then, run the fine-tuning on summarization using the previously trained model as the initialization.

```bash
./run.sh --pretrained_model "../../tedlium3/asr1/exp/<asr_model>/valid.acc.ave_10best.pth:::ctc "
```

## General Information
- token_type: bpe
- SUMM scoring function: local/score.sh

## Uploaded Models
- WavLM : https://huggingface.co/espnet/slueted_wavlm_summ/
- OWSM : https://huggingface.co/espnet/slueted_owsm_summ
- Whisper : https://huggingface.co/espnet/slueted_whisper_summ

## Complex prediction head with SFM feature extractor
### Hubert
- SLU config: [conf/tuning/hubert_complex.yaml](conf/tuning/hubert_complex.yaml)
- Inference config: [conf/decode_asr.yaml](conf/decode_asr.yaml)

|dataset|Snt|ROUGE-L|BERTScore|
|---|---|---|---|
|decode_asr_slu_model_valid.acc.ave/devel|425|16.1|83.4|
|decode_asr_slu_model_valid.acc.ave/test|423|16.0|83.4|

### Wav2vec2
- SLU config: [conf/tuning/w2v2_complex.yaml](conf/tuning/w2v2_complex.yaml)
- Inference config: [conf/decode_asr.yaml](conf/decode_asr.yaml)

|dataset|Snt|ROUGE-L|BERTScore|
|---|---|---|---|
|decode_asr_slu_model_valid.acc.ave/devel|425|16.3|83.3|
|decode_asr_slu_model_valid.acc.ave/test|423|16.2|83.0|

### WavLM
- SLU config: [conf/tuning/wavlm_complex.yaml](conf/tuning/wavlm_complex.yaml)
- Inference config: [conf/decode_asr.yaml](conf/decode_asr.yaml)

|dataset|Snt|ROUGE-L|BERTScore|
|---|---|---|---|
|decode_asr_slu_model_valid.acc.ave/devel|425|16.7|83.4|
|decode_asr_slu_model_valid.acc.ave/test|423|16.4|83.0|

### Whisper
- SLU config: [conf/tuning/whisper_complex.yaml](conf/tuning/whisper_complex.yaml)
- Inference config: [conf/decode_asr.yaml](conf/decode_asr.yaml)

|dataset|Snt|ROUGE-L|BERTScore|
|---|---|---|---|
|decode_asr_slu_model_valid.acc.ave/devel|425|16.3|83.7|
|decode_asr_slu_model_valid.acc.ave/test|423|16.0|83.8|

### OWSM
- Pretrained model: https://huggingface.co/espnet/owsm_v3.1_ebf
- SLU config: [conf/tuning/owsm_complex.yaml](conf/tuning/owsm_complex.yaml)
- Inference config: [conf/decode_asr.yaml](conf/decode_asr.yaml)

|dataset|Snt|ROUGE-L|BERTScore|
|---|---|---|---|
|decode_asr_slu_model_valid.acc.ave/devel|425|16.6|83.7|
|decode_asr_slu_model_valid.acc.ave/test|423|16.5|83.6|

### SLURP
- Pretrained model: https://huggingface.co/pyf98/slurp_entity_conformer
- SLU config: [conf/tuning/slurp_complex.yaml](conf/tuning/slurp_complex.yaml)
- Inference config: [conf/decode_asr.yaml](conf/decode_asr.yaml)

|dataset|Snt|ROUGE-L|BERTScore|
|---|---|---|---|
|decode_asr_slu_model_valid.acc.ave/devel|425|15.8|83.1|
|decode_asr_slu_model_valid.acc.ave/test|423|15.4|82.9|
