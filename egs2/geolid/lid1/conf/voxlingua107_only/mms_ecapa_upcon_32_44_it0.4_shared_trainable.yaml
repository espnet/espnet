# This configuration uses independent intermediate language embedding extractors
# (AttnStatPooling + Projector) and geolocation vector predictors (GeoPred).
# The conditioning projection modules are shared across selected
# intermediate layers, and are trainable.

# Model
model: upstream_condition
model_conf:
  lang2vec_conditioning_layers: [32, 36, 40, 44]
  apply_intermediate_lang2vec_loss: true
  apply_intermediate_lang2vec_condition: true
  inter_lang2vec_loss_weight: 0.4
  # If cutoff_gradient_from_backbone is true, the CondProj is frozen, otherwise,
  # the CondProj is trainable.
  cutoff_gradient_from_backbone: false
  cutoff_gradient_before_condproj: true
  # If true, the conditioning layer will shared across layers
  shared_conditioning_proj: true

# Frontend
frontend: s3prl_condition
frontend_conf:
    frontend_conf:
        # The condition upstream support both lid and lang2vec condition
        upstream: hf_wav2vec2_condition
        path_or_url: facebook/mms-1b
    download_dir: ./hub
    multilayer_feature: true

# Normalizer
normalize: utterance_mvn
normalize_conf:
    norm_vars: false

# Encoder
encoder: ecapa_tdnn
encoder_conf:
  model_scale: 8 # The conv scale for res2net blocks
  ndim: 512
  output_size: 1536 # 512 * 3

# Pooling
pooling: chn_attn_stat

# Projector
projector: rawnet3
projector_conf:
  output_size: 192

# Upstream conditioning modules
encoder_condition: identity

pooling_condition: chn_attn_stat

projector_condition: rawnet3
projector_condition_conf:
  output_size: 192

# Preprocessor
preprocessor: lid
preprocessor_conf:
  fix_duration: false
  sample_rate: 16000
  noise_apply_prob: 0.0
  noise_info:
  # prob, noise_scp, num_to_mix, db_range
  - [1.0, 'dump/raw/musan_speech.scp', [4, 7], [13, 20]]
  - [1.0, 'dump/raw/musan_noise.scp', [1, 1], [0, 15]]
  - [1.0, 'dump/raw/musan_music.scp', [1, 1], [5, 15]]
  rir_apply_prob: 0.0
  rir_scp: dump/raw/rirs.scp
  use_lang2vec: true
  lang2vec_type: geo # ⚠️ If change the lang2vec_type, change three ⚠️ places

# Loss
loss: aamsoftmax_sc_topk_lang2vec
loss_conf:
  margin: 0.5
  scale: 30
  K: 3
  mp: 0.06
  k_top: 5
  # geo: 299, phonology_knn: 28, syntax_knn: 103, inventory_knn: 158
  lang2vec_dim: 299 # ⚠️
  lang2vec_type: geo # ⚠️
  lang2vec_weight: 0.2

# Training related
num_att_plot: 0
num_workers: 8
cudnn_deterministic: false
cudnn_benchmark: true

log_interval: 100
unused_parameters: true
use_amp: true
keep_nbest_models: 2
grad_clip: 9999 # Equals to no clip
best_model_criterion:
- - valid
  - accuracy
  - max

# Data iterator
iterator_type: category
valid_iterator_type: category
seed: 3702

# Total training steps: (10k, 20k, 30k, 40k, 50k)
max_epoch: 30 # total training steps = max_epoch * num_iters_per_epoch / accum_grad
accum_grad: 2
num_iters_per_epoch: 1000

# Batch sampler
batch_type: catpow # CategoryPowerSampler, with an upsampling factor used in MMS
batch_bins: 2880000 # 1440000: 1.5min, 2880000: 3min, 5760000: 6min
max_batch_size: 16
upsampling_factor: 0.5
dataset_scaling_factor: 1.2
drop_last_iter: false

# Optimizer
optim: adam
optim_conf:
  lr: 0.000005 # (1e−5, 3e−5, 3e−6, 5e−6, 7e−6)
  betas: [0.9, 0.98]

# Scheduler
scheduler: tristagelr
scheduler_conf:
  max_steps: 30000 # Must equal to max_epoch * num_iters_per_epoch / accum_grad
  warmup_ratio: 0.3
  hold_ratio: 0.2
  decay_ratio: 0.5
  init_lr_scale: 0.6 # Start from 3e-6
  final_lr_scale: 0.1 # End with 5e-7
