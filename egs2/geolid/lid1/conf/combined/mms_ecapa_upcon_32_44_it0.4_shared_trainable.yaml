# This config use independent module for each intermediate layer. 

# Model
model: upstream_condition
model_conf:
  lang2vec_conditioning_layers: [32, 36, 40, 44]
  apply_intermediate_lang2vec_loss: true # ‚öôÔ∏è
  apply_intermediate_lang2vec_condition: true
  inter_lang2vec_loss_weight: 0.4 # ‚öôÔ∏è
  cutoff_gradient_from_backbone: false
  cutoff_gradient_before_condproj: true
  shared_conditioning_proj: true # if true, the conditioning layer will shared across layers

# Frontend
frontend: s3prl_condition
frontend_conf:
    frontend_conf:
        upstream: hf_wav2vec2_condition # üöÄ the condition upstream support both lid and lang2vec condition
        path_or_url: facebook/mms-1b
    download_dir: ./hub
    multilayer_feature: true

# Normalizer
normalize: utterance_mvn
normalize_conf:
    norm_vars: false

# Encoder
encoder: ecapa_tdnn
encoder_conf:
  model_scale: 8 # the conv scale for res2net blocks
  ndim: 512
  output_size: 1536 # 512 * 3

# Pooling
pooling: chn_attn_stat

# Projector
projector: rawnet3
projector_conf:
  output_size: 192

# Upstream Conditioning Modules
encoder_condition: identity

projector_condition: chn_attn_stat

projector_condition: rawnet3
projector_conf:
  output_size: 192

# Preprocessor
preprocessor: lid
preprocessor_conf:
  fix_duration: false
  sample_rate: 16000
  noise_apply_prob: 0.0
  noise_info:
  - [1.0, 'dump/raw/musan_speech.scp', [4, 7], [13, 20]]
  - [1.0, 'dump/raw/musan_noise.scp', [1, 1], [0, 15]] # prob, noise_scp, num_to_mix, db_range
  - [1.0, 'dump/raw/musan_music.scp', [1, 1], [5, 15]]
  rir_apply_prob: 0.0
  rir_scp: dump/raw/rirs.scp
  use_lang2vec: true
  lang2vec_type: geo # ‚ö†Ô∏è If change the lang2vec_type, change three ‚ö†Ô∏è places

# Loss
loss: aamsoftmax_sc_topk_lang2vec
loss_conf:
  margin: 0.5
  scale: 30
  K: 3
  mp: 0.06
  k_top: 5
  lang2vec_dim: 299 # ‚ö†Ô∏è geo: 299, phonology_knn: 28, syntax_knn: 103, inventory_knn: 158
  lang2vec_type: geo # ‚ö†Ô∏è
  lang2vec_weight: 0.2

# Training related
num_att_plot: 0
num_workers: 8
cudnn_deterministic: false
cudnn_benchmark: true

log_interval: 100
unused_parameters: true
use_amp: true
keep_nbest_models: 2
grad_clip: 9999 # equals to no clip
best_model_criterion:
- - valid
  - accuracy
  - max

# data iterator
iterator_type: category
valid_iterator_type: category
seed: 3702

# total training steps: (10k, 20k, 30k, 40k, 50k)
# NOTE: ‰∏∫‰∫ÜËÉΩÁî®avergage checkpoint inference, change from 50 to 33‰∏ì‰∏∫Ëøô‰∫ã
max_epoch: 33 # total training steps = max_epoch * num_iters_per_epoch / accum_grad
accum_grad: 4
num_iters_per_epoch: 2000 # evaluate evrery 2000 steps, to reduce training time

# batch sampler
batch_type: catpow_balance_dataset
batch_bins: 1440000 # 1440000: 1.5min(90s), 2880000: 16kHz * 3min (180s), 5760000: 6min (1.5min, 3min, 6min), not exactly 3 min, but over 3 min then stop add more utterances.
max_batch_size: 6
language_upsampling_factor: 0.5
dataset_upsampling_factor: 0.3
dataset_scaling_factor: 1.2
drop_last_iter: false

# Optimizer
optim: adam
optim_conf:
  lr: 0.00001 # (1e‚àí5, 3e‚àí5, 3e‚àí6, 5e‚àí6, 7e‚àí6)
  betas: [0.9, 0.98]

# Scheduler
scheduler: tristagelr
scheduler_conf:
  max_steps: 12500 # must be equal to max_epoch * num_iters_per_epoch / accum_grad
  warmup_ratio: 0.1
  hold_ratio: 0.4
  decay_ratio: 0.5
  init_lr_scale: 0.6 # start from 3e-6
  final_lr_scale: 0.1 # end with 5e-7
