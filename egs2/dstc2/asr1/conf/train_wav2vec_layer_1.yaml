# network architecture
# encoder related
encoder: conformer
encoder_conf:
  output_size: 512
  attention_heads: 8
  linear_units: 2048
  num_blocks: 12
  dropout_rate: 0.1
  positional_dropout_rate: 0.1
  attention_dropout_rate: 0.1
  input_layer: conv2d
  normalize_before: true
  macaron_style: true
  pos_enc_layer_type: "rel_pos"
  selfattention_layer_type: "rel_selfattn"
  activation_type: "swish"
  use_cnn_module: true
  cnn_module_kernel: 31

decoder: transformer
decoder_conf:
  attention_heads: 8
  linear_units: 2048
  num_blocks: 6
  dropout_rate: 0.1
  positional_dropout_rate: 0.1
  self_attention_dropout_rate: 0.1
  src_attention_dropout_rate: 0.1

optim: adam
optim_conf:
  lr: 0.0002
scheduler: warmuplr   # pytorch v1.1.0+ required #Tune warmup steps
scheduler_conf:
  warmup_steps: 25000
max_epoch: 50

freeze_param: [
    "frontend.upstream.model.mask_emb", "frontend.upstream.model.feature_extractor",
    "frontend.upstream.model.post_extract_proj", "frontend.upstream.model.quantizer",
    "frontend.upstream.model.project_q", "frontend.upstream.model.encoder.pos_conv",
    "frontend.upstream.model.encoder.layers.0", "frontend.upstream.model.encoder.layers.1",
    "frontend.upstream.model.encoder.layers.2", "frontend.upstream.model.encoder.layers.3",
    "frontend.upstream.model.encoder.layers.4", "frontend.upstream.model.encoder.layers.5",
    "frontend.upstream.model.encoder.layers.6", "frontend.upstream.model.encoder.layers.7",
    "frontend.upstream.model.encoder.layers.8", "frontend.upstream.model.encoder.layers.9",
    "frontend.upstream.model.encoder.layers.10", "frontend.upstream.model.encoder.layers.11",
    "frontend.upstream.model.encoder.layers.12", "frontend.upstream.model.encoder.layers.13",
    "frontend.upstream.model.encoder.layers.14", "frontend.upstream.model.encoder.layers.15",
    "frontend.upstream.model.encoder.layers.16", "frontend.upstream.model.encoder.layers.17",
    "frontend.upstream.model.encoder.layers.18", "frontend.upstream.model.encoder.layers.19",
    "frontend.upstream.model.encoder.layers.20", "frontend.upstream.model.encoder.layers.21",
    "frontend.upstream.model.encoder.layers.22", "frontend.upstream.model.encoder.layer_norm",
    "frontend.upstream.model.layer_norm", "frontend.upstream.model.final_proj",
]


frontend_conf:
 n_fft: 512
 hop_length: 256

frontend: s3prl
frontend_conf:
  frontend_conf:
    upstream: wav2vec2_large_ll60k # Note: If the upstream is changed, please change the input_size in the preencoder.
  download_dir: ./hub

preencoder: linear
preencoder_conf:
  input_size: 1024 # Note: If the upstream is changed, please change this value accordingly.
  output_size: 80

model_conf:
  ctc_weight: 0.3
  lsm_weight: 0.1
  length_normalized_loss: false
  extract_feats_in_collect_stats: false  # Note: "False" means during collect stats (stage 10), generating dummy stats files rather than extract_feats by forward frontend.

specaug: specaug
specaug_conf:
  apply_time_warp: true
  time_warp_window: 5
  time_warp_mode: bicubic
  apply_freq_mask: true
  freq_mask_width_range:
  - 0
  - 30
  num_freq_mask: 2
  apply_time_mask: true
  time_mask_width_range:
  - 0
  - 40
  num_time_mask: 2

best_model_criterion:
-   - valid
    - acc
    - max
keep_nbest_models: 10
