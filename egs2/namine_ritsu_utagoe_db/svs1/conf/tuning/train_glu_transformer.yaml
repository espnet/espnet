

##########################################################
#                  SVS MODEL SETTING                     #
##########################################################
svs: glu_transformer             # model architecture
svs_conf:                        # keyword arguments for the selected model
    midi_dim: 129                # midi dimension (note number + silence)
    tempo_dim: 300
    embed_dim: 256 # embed_size  # char or phn embedding dimension
    elayers: 3                   # number of glu_transformer layers in encoder
    eunits: 256                  # number of glu_transformer units hidden_size
    glu_num_layers: 3
    glu_kernel: 3
    edropout_rate: 0.1
    ddropout_rate: 0.1
    dlayers: 6
    dhead: 4
    postnet_layers: 5            # number of layers in postnet
    postnet_chans: 256           # number of channels in postnet
    postnet_filts: 5             # filter size of postnet layer    n_mels: -1
    local_gaussian: true
    use_batch_norm: true         # whether to use batch normalization in postnet
    reduction_factor: 1          # reduction factor
    edropout_rate: 0.1           # encoder dropout rate
    ddropout_rate: 0.1           # decoder dropout rate
    postnet_dropout_rate: 0.5    # postnet dropout_rate
    init_type: pytorch           # parameter initialization
    use_masking: true            # whether to apply masking for padded part in loss calculation
    embed_integration_type: add
    use_duration: true          # whether to use duration model
    loss_type: L1

##########################################################
#                  OPTIMIZER SETTING                     #
##########################################################
optim: adam           # optimizer type
optim_conf:           # keyword arguments for selected optimizer
    lr: 1.0       # learning rate
scheduler: noamlr
scheduler_conf:
    warmup_steps: 4000

##########################################################
#                OTHER TRAINING SETTING                  #
##########################################################
# num_iters_per_epoch: 200    # number of iterations per epoch
max_epoch: 1500              # number of epochs
grad_clip: 5.0              # gradient clipping norm
grad_noise: false           # whether to use gradient noise injection
accum_grad: 1               # gradient accumulation
batch_size: 5
batch_type: sorted           # how to make batch
batch_type: numel           # how to make batch
sort_in_batch: descending   # how to sort data in making batch
sort_batch: descending      # how to sort created batches
num_workers: 10             # number of workers of data loader
train_dtype: float32        # dtype in training
log_interval: null          # log interval in iterations
keep_nbest_models: 5        # number of models to keep
num_att_plot: 3             # number of attention figures to be saved in every check
seed: 0                     # random seed number
best_model_criterion:
-   - valid
    - loss
    - min
-   - train
    - loss
    - min
