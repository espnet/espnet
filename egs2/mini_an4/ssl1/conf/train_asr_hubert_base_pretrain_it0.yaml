grad_clip: 5.0
batch_type: numel
batch_bins: 1500000
accum_grad: 1
max_epoch: 100
patience: none
# Use self-defined function for initialization
init: xavier_uniform 
best_model_criterion:
-   - valid
    - acc
    - max
keep_nbest_models: 10

input_size: 100
encoder: hubert_pretrain
encoder_conf:
    output_size: 32
    linear_units: 256
    attention_heads: 8
    num_blocks: 2
    dropout_rate: 0.1
    attention_dropout_rate: 0.0
    dropout_input: 0.1
    dropout_features: 0.1
    # TODO(jzmo): add comments here
    skip_masked: false
    skip_nomask: false
    mask_prob: 0.80
    extractor_mode: default
    conv_feature_layers: '[(64,10,5)] + [(64,3,2)] * 4 + [(64,2,2)] * 2'
    final_dim: 256
    encoder_layerdrop: 0.05
    feature_grad_mult: 0.1
    untie_final_proj: true
    label_rate: 100
    sample_rate: 16000

model_conf:
    lsm_weight: 0.1
    length_normalized_loss: false
    pred_masked_weight: 1.0
    pred_nomask_weight: 0.0
    loss_weights: 10.0

optim: adam
optim_conf:
    lr: 0.0005
scheduler: warmuplr
scheduler_conf:
    warmup_steps: 25000

unused_parameters: true

frontend: null

normalize: null

specaug: null
