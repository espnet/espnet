# This is a debug config for CI
batch_type: folded
batch_size: 2
accum_grad: 1
max_epoch: 1
num_iters_per_epoch: 1
patience: none
# The initialization method for model parameters
init: xavier_uniform
best_model_criterion:
-   - valid
    - acc
    - max
keep_nbest_models: 10

# BPE-Dropout (https://github.com/google/sentencepiece#subword-regularization-and-bpe-dropout)
src_tokenizer_encode_conf:
    enable_sampling: true    # If set to true, bpe-dropout is used.
    alpha: 0.4
    nbest_size: -1

frontend: embed     # embedding + positional encoding
frontend_conf:
    embed_dim: 16
    positional_dropout_rate: 0.1

encoder: transformer
encoder_conf:
    output_size: 2
    attention_heads: 2
    linear_units: 2
    num_blocks: 2
    dropout_rate: 0.1
    positional_dropout_rate: 0.1
    attention_dropout_rate: 0.0
    input_layer: conv1d2
    normalize_before: true

decoder: transformer
decoder_conf:
    attention_heads: 2
    linear_units: 2
    num_blocks: 2
    dropout_rate: 0.1
    positional_dropout_rate: 0.1
    self_attention_dropout_rate: 0.0
    src_attention_dropout_rate: 0.0

model: discrete_asr
model_conf:
    ctc_weight: 0.3
    lsm_weight: 0.1
    length_normalized_loss: false

optim: adam
optim_conf:
    lr: 0.005
scheduler: warmuplr
scheduler_conf:
    warmup_steps: 4
