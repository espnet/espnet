##########################################################
#                  TTS MODEL SETTING                     #
##########################################################
tts: tacotron2                   # model architecture
tts_conf:                        # keyword arguments for the selected model
    embed_dim: 2                 # char or phn embedding dimension
    elayers: 1                   # number of blstm layers in encoder
    eunits: 2                    # number of blstm units
    econv_layers: 1              # number of convolutional layers in encoder
    econv_chans: 2               # number of channels in convolutional layer
    econv_filts: 3               # filter size of convolutional layer
    atype: location              # attention function type
    adim: 2                      # attention dimension
    aconv_chans: 2               # number of channels in convolutional layer of attention
    aconv_filts: 3               # filter size of convolutional layer of attention
    cumulate_att_w: true         # whether to cumulate attention weight
    dlayers: 1                   # number of lstm layers in decoder
    dunits: 2                    # number of lstm units in decoder
    prenet_layers: 2             # number of layers in prenet
    prenet_units: 2              # number of units in prenet
    postnet_layers: 2            # number of layers in postnet
    postnet_chans: 2             # number of channels in postnet
    postnet_filts: 3             # filter size of postnet layer
    output_activation: null      # activation function for the final output
    use_batch_norm: true         # whether to use batch normalization in encoder
    use_concate: true            # whether to concatenate encoder embedding with decoder outputs
    use_residual: false          # whether to use residual connection in encoder
    dropout_rate: 0.5            # dropout rate
    zoneout_rate: 0.1            # zoneout rate
    reduction_factor: 1          # reduction factor
    spk_embed_dim: null          # speaker embedding dimension
    use_masking: true            # whether to apply masking for padded part in loss calculation
    bce_pos_weight: 5.0          # weight of positive sample in binary cross entropy calculation
    use_guided_attn_loss: true   # whether to use guided attention loss
    guided_attn_loss_sigma: 0.4  # sigma of guided attention loss
    guided_attn_loss_lambda: 1.0 # strength of guided attention loss

##########################################################
#                OTHER TRAINING SETTING                  #
##########################################################
num_iters_per_epoch: 1
max_epoch: 1
batch_type: folded
batch_size: 2
