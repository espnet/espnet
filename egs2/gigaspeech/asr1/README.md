# Notes
In the data preparation stage, we will clone the [official repo](https://github.com/SpeechColab/GigaSpeech) of GigaSpeech, which provides standard scripts for data preparation, post processing and scoring. For fair comparison across toolkits, here we report the results generated by the official scoring script.


# E-Branchformer

## Environments
- date: `Sat Jan 21 17:54:14 EST 2023`
- python version: `3.9.15 (main, Nov 24 2022, 14:31:59)  [GCC 11.2.0]`
- espnet version: `espnet 202211`
- pytorch version: `pytorch 1.12.1`
- Git hash: `197dc412eab82e9bab008f00fbcb922c824d8cf2`
  - Commit date: `Sat Jan 21 13:59:20 2023 -0500`

## asr_train_asr_e_branchformer_e17_size512_mlp3072_linear1024_layerdrop_raw_en_bpe5000

- ASR config: [conf/tuning/train_asr_e_branchformer_e17_size512_mlp3072_linear1024_layerdrop.yaml](conf/tuning/train_asr_e_branchformer_e17_size512_mlp3072_linear1024_layerdrop.yaml)
- Model link: [https://huggingface.co/pyf98/gigaspeech_e_branchformer](https://huggingface.co/pyf98/gigaspeech_e_branchformer)

### WER

|dataset|Snt|Wrd|Corr|Sub|Del|Ins|Err|S.Err|
|---|---|---|---|---|---|---|---|---|
|decode_asr_asr_model_valid.acc.ave/dev|5715|127790|92.2|5.7|2.0|2.8|10.6|69.9|
|decode_asr_asr_model_valid.acc.ave/test|19930|390744|91.5|6.4|2.1|2.0|10.5|63.3| 


# Conformer

## Environments
- date: `Tue Mar 23 10:03:49 EDT 2021`
- python version: `3.8.5 (default, Sep  4 2020, 07:30:14)  [GCC 7.3.0]`
- espnet version: `espnet 0.9.8`
- pytorch version: `pytorch 1.7.1`
- Git hash: `dcb5bdb2ffa34a9f44255c0b073759c5b9b3f86e`
  - Commit date: `Sat Mar 13 10:16:16 2021 -0500`

## asr_train_asr_raw_en_bpe5000
- https://zenodo.org/record/4630406
### WER

|dataset|Snt|Wrd|Corr|Sub|Del|Ins|Err|S.Err|
|---|---|---|---|---|---|---|---|---|
|decode_asr_asr_model_valid.acc.ave/dev|5715|127790|92.0|6.0|2.1|2.9|10.9|70.9|
|decode_asr_asr_model_valid.acc.ave/test|19930|390744|91.2|6.7|2.1|2.0|10.8|64.2|
