# This configuration requires 4 GPUs with 32GB memory
batch_type: numel
batch_bins: 30000000
accum_grad: 3
max_epoch: 60
patience: none
init: xavier_uniform
best_model_criterion:
  - - valid
    - acc
    - max
keep_nbest_models: 10

encoder: rnn
encoder_conf:
  rnn_type: gru
  bidirectional: true
  use_projection: true
  num_layers: 4
  hidden_size: 320
  output_size: 320
  dropout: 0.2

# # decoder is not used
# decoder: transformer
# decoder_conf:
#   attention_heads: 8
#   linear_units: 2048
#   num_blocks: 6
#   dropout_rate: 0.1
#   positional_dropout_rate: 0.1
#   self_attention_dropout_rate: 0.1
#   src_attention_dropout_rate: 0.1

model_conf:
  ctc_weight: 1.0  # full CTC
  lsm_weight: 0.0  # no label smoothing
  length_normalized_loss: false

optim: adam
optim_conf:
  lr: 0.001
scheduler: warmuplr
scheduler_conf:
  warmup_steps: 25000

specaug: specaug
specaug_conf:
  apply_time_warp: true
  time_warp_window: 5
  time_warp_mode: bicubic
  apply_freq_mask: true
  freq_mask_width_range:
    - 0
    - 30
  num_freq_mask: 2
  apply_time_mask: true
  time_mask_width_range:
    - 0
    - 40
  num_time_mask: 2
