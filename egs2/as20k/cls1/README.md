# AudioSet-20K Audio Classification Recipe

This recipe implements the audio classification task with a BEATs encoder and linear layer decoder model on the [AudioSet-20K](https://research.google.com/audioset/)(AS-20K) dataset, very close to what is described in [this paper](https://arxiv.org/abs/2212.09058).
More specifically, we provide the fine-tuning config and results for the last row in Table 1 (BEATS-iter3+) from the paper.
We reuse part of the code from the [BEATs repository](https://github.com/microsoft/unilm/tree/master/beats) for this implementation.

# Training Details and Requirements
AS-20K is a balanced multi-label classification dataset with 20k training samples.
Fine-tuning needs 1 GPU with ~40 GB memory and runs for ~15 hours on L40.

# Steps to run
1. Download AudioSet YouTube ids and get corresponding audio. Set the path to its root directory in db.sh (`AUDIOSET`). Please look at `local/data.sh` to understand the procedure for pre-processing data.
2. Download the BEATs checkpoint: [BEATs_iter3+ (AS20K)](https://github.com/microsoft/unilm/tree/master/beats) and change the `beats_ckpt_path` path in `conf/beats_cls.yaml`
3. Launch with `run.sh`.

# Trained checkpoints
Fine-tuned checkpoint is available at:
* https://huggingface.co/espnet/BEATs-AS20K , mAP: 37.5

<!-- Generated by scripts/utils/show_cls_result.sh -->
# RESULTS
## Environments
- date: `Wed Jan 29 16:45:24 EST 2025`
- python version: `3.9.20 (main, Oct  3 2024, 07:27:41)  [GCC 11.2.0]`
- espnet version: `espnet 202412`
- pytorch version: `pytorch 2.5.1`
- Git hash: `913ecfb1263f67fdf9084f902f1931a1794144bc`
  - Commit date: `Wed Jan 29 16:44:19 2025 -0500`

## cls_beats_iter3p20k.allroll.Bp8p8.20250103.020644
|Split|mean_acc|mAP|mean_auc|n_labels|n_instances|
|---|---|---|---|---|---|
cls_eval|47.73|37.46|96.58|527.00|20123.00
cls_val|46.62|43.01|96.23|527.00|2014.00
