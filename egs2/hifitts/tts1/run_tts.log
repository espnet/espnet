2025-06-25T13:39:52 (tts.sh:225:main) ./tts.sh --use_sid true --fs 22050 --n_fft 1024 --n_shift 256 --win_length null --dumpdir dump/22k --expdir exp/22k --tts_task gan_tts --feats_extract linear_spectrogram --feats_normalize none --train_config conf/tuning/train_multi_spk_vits.yaml --inference_config conf/tuning/decode_vits.yaml --train_set tr_no_dev --valid_set dev --test_sets test --srctexts data/tr_no_dev/text data/dev/text data/test/text --audio_format flac --stage 6 --stop-stage 10
2025-06-25T13:39:53 (tts.sh:592:main) Stage 6: TTS collect stats: train_set=dump/22k/raw/tr_no_dev, valid_set=dump/22k/raw/dev
2025-06-25T13:39:56 (tts.sh:679:main) Generate 'exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/run.sh'. You can resume the process from stage 6 using this script
2025-06-25T13:39:56 (tts.sh:683:main) TTS collect_stats started... log: 'exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.*.log'
/ocean/projects/cis210027p/ttao3/espnet/egs2/hifitts/tts1/utils/slurm.pl: 32 / 32 failed, log is in exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.*.log
# Running on r027.ib.bridges2.psc.edu
# Started at Wed Jun 25 13:40:56 EDT 2025
# SLURMD_NODENAME=r027
# SLURM_ARRAY_JOB_ID=32990217
# SLURM_ARRAY_TASK_COUNT=32
# SLURM_ARRAY_TASK_ID=1
# SLURM_ARRAY_TASK_MAX=32
# SLURM_ARRAY_TASK_MIN=1
# SLURM_ARRAY_TASK_STEP=1
# SLURM_CLUSTER_NAME=bridges2
# SLURM_CONF=/var/spool/slurm/d/conf-cache/slurm.conf
# SLURM_CPUS_ON_NODE=1
# SLURM_CPU_BIND=quiet,mask_cpu:0x07C0000000
# SLURM_CPU_BIND_LIST=0x07C0000000
# SLURM_CPU_BIND_TYPE=mask_cpu:
# SLURM_CPU_BIND_VERBOSE=quiet
# SLURM_EXPORT_ENV=ALL
# SLURM_GET_USER_ENV=1
# SLURM_GTIDS=0
# SLURM_JOBID=32990219
# SLURM_JOB_ACCOUNT=cis210027p
# SLURM_JOB_CPUS_PER_NODE=1
# SLURM_JOB_GID=24886
# SLURM_JOB_ID=32990219
# SLURM_JOB_NAME=stats.sh
# SLURM_JOB_NODELIST=r027
# SLURM_JOB_NUM_NODES=1
# SLURM_JOB_PARTITION=RM-shared
# SLURM_JOB_QOS=rm
# SLURM_JOB_UID=97947
# SLURM_JOB_USER=ttao3
# SLURM_LAUNCH_NODE_IPADDR=10.8.11.29
# SLURM_LOCALID=0
# SLURM_MEM_PER_CPU=1900
# SLURM_NNODES=1
# SLURM_NODEID=0
# SLURM_NODELIST=r027
# SLURM_NODE_ALIASES='(null)'
# SLURM_NPROCS=1
# SLURM_NTASKS=1
# SLURM_OPEN_MODE=a
# SLURM_PRIO_PROCESS=0
# SLURM_PROCID=0
# SLURM_PTY_PORT=33025
# SLURM_PTY_WIN_COL=126
# SLURM_PTY_WIN_ROW=21
# SLURM_SCRIPT_CONTEXT=prolog_task
# SLURM_SRUN_COMM_HOST=10.8.11.29
# SLURM_SRUN_COMM_PORT=35045
# SLURM_STEPID=0
# SLURM_STEP_GPUS=6
# SLURM_STEP_ID=0
# SLURM_STEP_LAUNCHER_PORT=35045
# SLURM_STEP_NODELIST=v029
# SLURM_STEP_NUM_NODES=1
# SLURM_STEP_NUM_TASKS=1
# SLURM_STEP_TASKS_PER_NODE=1
# SLURM_SUBMIT_DIR=/ocean/projects/cis210027p/ttao3/espnet/egs2/hifitts/tts1
# SLURM_SUBMIT_HOST=v029.ib.bridges2.psc.edu
# SLURM_TASKS_PER_NODE=1
# SLURM_TASK_PID=6981
# SLURM_TOPOLOGY_ADDR=r027
# SLURM_TOPOLOGY_ADDR_PATTERN=node
# SLURM_WORKING_CLUSTER=bridges2:br003:6810:9728:109
# python3 -m espnet2.bin.gan_tts_train --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.1.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.1.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.1 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int 
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/librosa/util/files.py:10: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_filename
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/bin/python3 /ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.1.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.1.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.1 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int
Failed to import Flash Attention, using ESPnet default: No module named 'flash_attn_2_cuda'
Vocabulary size: 74
encoder self-attention layer type = relative self-attention
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/ocean/projects/cis210027p/ttao3/espnet/espnet2/gan_tts/vits/monotonic_align/__init__.py:19: UserWarning: Cython version is not available. Fallback to 'EXPERIMETAL' numba version. If you want to use the cython version, please build it as follows: `cd espnet2/gan_tts/vits/monotonic_align; python setup.py build_ext --inplace`
  warnings.warn(
pytorch.version=2.7.1+cu126, cuda.available=False, cudnn.version=90501, cudnn.benchmark=False, cudnn.deterministic=False
Model structure:
ESPnetGANTTSModel(
  (feats_extract): LinearSpectrogram(
    (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
  )
  (tts): VITS(
    (generator): VITSGenerator(
      (text_encoder): TextEncoder(
        (emb): Embedding(74, 192)
        (encoder): Encoder(
          (embed): Sequential(
            (0): RelPositionalEncoding(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (encoders): MultiSequential(
            (0): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (2): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (3): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (4): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (5): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (after_norm): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (decoder): HiFiGANGenerator(
        (input_conv): Conv1d(192, 512, kernel_size=(7,), stride=(1,), padding=(3,))
        (upsamples): ModuleList(
          (0): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (1): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(256, 128, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (2): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,))
          )
          (3): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,))
          )
        )
        (blocks): ModuleList(
          (0): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (1): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (2): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (3): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (4): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (5): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (6): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (7): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (8): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (9): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (10): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (11): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
        )
        (output_conv): Sequential(
          (0): LeakyReLU(negative_slope=0.01)
          (1): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,))
          (2): Tanh()
        )
        (global_conv): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
      )
      (posterior_encoder): PosteriorEncoder(
        (input_conv): Conv1d(513, 192, kernel_size=(1,), stride=(1,))
        (encoder): WaveNet(
          (conv_layers): ModuleList(
            (0-15): 16 x ResidualBlock(
              (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
              (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
              (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
            )
          )
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (flow): ResidualAffineCouplingBlock(
        (flows): ModuleList(
          (0): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (1): FlipFlow()
          (2): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (3): FlipFlow()
          (4): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (5): FlipFlow()
          (6): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (7): FlipFlow()
        )
      )
      (duration_predictor): StochasticDurationPredictor(
        (pre): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (log_flow): LogFlow()
        (flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (post_pre): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
        (post_dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (post_proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (post_flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (global_conv): Conv1d(256, 192, kernel_size=(1,), stride=(1,))
      )
      (global_emb): Embedding(128, 256)
    )
    (discriminator): HiFiGANMultiScaleMultiPeriodDiscriminator(
      (msd): HiFiGANMultiScaleDiscriminator(
        (discriminators): ModuleList(
          (0): HiFiGANScaleDiscriminator(
            (layers): ModuleList(
              (0): Sequential(
                (0): Conv1d(1, 128, kernel_size=(15,), stride=(1,), padding=(7,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv1d(128, 128, kernel_size=(41,), stride=(2,), padding=(20,), groups=4)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv1d(128, 256, kernel_size=(41,), stride=(2,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv1d(256, 512, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv1d(512, 1024, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (5): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(41,), stride=(1,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (6): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (7): Conv1d(1024, 1, kernel_size=(3,), stride=(1,), padding=(1,))
            )
          )
        )
      )
      (mpd): HiFiGANMultiPeriodDiscriminator(
        (discriminators): ModuleList(
          (0-4): 5 x HiFiGANPeriodDiscriminator(
            (convs): ModuleList(
              (0): Sequential(
                (0): Conv2d(1, 32, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv2d(32, 128, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv2d(128, 512, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv2d(512, 1024, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv2d(1024, 1024, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
            )
            (output_conv): Conv2d(1024, 1, kernel_size=(2, 1), stride=(1, 1), padding=(1, 0))
          )
        )
      )
    )
    (generator_adv_loss): GeneratorAdversarialLoss()
    (discriminator_adv_loss): DiscriminatorAdversarialLoss()
    (feat_match_loss): FeatureMatchLoss()
    (mel_loss): MelSpectrogramLoss(
      (wav_to_mel): LogMelFbank(
        (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
        (logmel): LogMel(sr=22050, n_fft=1024, n_mels=80, fmin=0, fmax=11025.0, htk=False)
      )
    )
    (kl_loss): KLDivergenceLoss()
  )
)

Model summary:
    Class Name: ESPnetGANTTSModel
    Total Number of model parameters: 96.37 M
    Number of trainable parameters: 96.37 M (100.0%)
    Size: 385.46 MB
    Type: torch.float32
Optimizer:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler: <torch.optim.lr_scheduler.ExponentialLR object at 0x1498d6656c40>
Optimizer2:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler2: <torch.optim.lr_scheduler.ExponentialLR object at 0x1498d6656c10>
Saving the configuration in exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.1/config.yaml
Namespace(config='conf/tuning/train_multi_spk_vits.yaml', print_config=False, log_level='INFO', drop_last_iter=False, dry_run=False, iterator_type='sequence', valid_iterator_type=None, output_dir='exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.1', ngpu=0, seed=777, num_workers=4, num_att_plot=3, dist_backend='nccl', dist_init_method='env://', dist_world_size=None, dist_rank=None, local_rank=None, dist_master_addr=None, dist_master_port=None, dist_launcher=None, multiprocessing_distributed=False, unused_parameters=True, sharded_ddp=False, use_deepspeed=False, deepspeed_config=None, gradient_as_bucket_view=True, ddp_comm_hook=None, cudnn_enabled=True, cudnn_benchmark=False, cudnn_deterministic=False, use_tf32=False, collect_stats=True, write_collected_feats=False, max_epoch=1000, patience=None, val_scheduler_criterion=('valid', 'loss'), early_stopping_criterion=('valid', 'loss', 'min'), best_model_criterion=[['train', 'total_count', 'max']], keep_nbest_models=10, nbest_averaging_interval=0, grad_clip=-1, grad_clip_type=2.0, grad_noise=False, accum_grad=1, no_forward_run=False, resume=False, train_dtype='float32', use_amp=False, log_interval=50, use_matplotlib=True, use_tensorboard=True, create_graph_in_tensorboard=False, use_wandb=False, wandb_project=None, wandb_id=None, wandb_entity=None, wandb_name=None, wandb_model_log_interval=-1, detect_anomaly=False, use_adapter=False, adapter='lora', save_strategy='all', adapter_conf={}, pretrain_path=None, init_param=[], ignore_init_mismatch=False, freeze_param=[], num_iters_per_epoch=1000, batch_size=20, valid_batch_size=None, batch_bins=3000000, valid_batch_bins=None, category_sample_size=10, train_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.1.scp'], valid_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.1.scp'], batch_type='numel', valid_batch_type=None, fold_length=[], sort_in_batch='descending', shuffle_within_batch=False, sort_batch='descending', multiple_iterator=False, chunk_length=500, chunk_shift_ratio=0.5, num_cache_chunks=1024, chunk_excluded_key_prefixes=[], chunk_default_fs=None, chunk_max_abs_length=None, chunk_discard_short_samples=True, train_data_path_and_name_and_type=[('dump/22k/raw/tr_no_dev/text', 'text', 'text'), ('dump/22k/raw/tr_no_dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/tr_no_dev/utt2sid', 'sids', 'text_int')], valid_data_path_and_name_and_type=[('dump/22k/raw/dev/text', 'text', 'text'), ('dump/22k/raw/dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/dev/utt2sid', 'sids', 'text_int')], multi_task_dataset=False, allow_variable_data_keys=False, max_cache_size=0.0, max_cache_fd=32, allow_multi_rates=False, valid_max_cache_size=None, exclude_weight_decay=False, exclude_weight_decay_conf={}, optim='adamw', optim_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler='exponentiallr', scheduler_conf={'gamma': 0.999875}, optim2='adamw', optim2_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler2='exponentiallr', scheduler2_conf={'gamma': 0.999875}, generator_first=False, skip_discriminator_prob=0.0, token_list=['<blank>', '<unk>', ' ', 'AH0', 'N', 'T', 'D', 'S', 'R', 'L', 'IH1', 'DH', 'M', 'EH1', 'Z', 'AE1', 'K', 'IH0', 'AH1', 'HH', 'W', 'ER0', 'V', 'IY1', 'F', 'UW1', 'P', 'AY1', 'B', 'AA1', 'AO1', 'EY1', 'IY0', 'OW1', 'NG', 'SH', 'G', 'Y', 'AW1', 'CH', 'ER1', 'UH1', 'TH', 'JH', 'OW0', 'EH2', 'IH2', 'OY1', 'EY2', 'AY2', 'EH0', 'UW0', 'AA2', 'AE2', 'OW2', 'AH2', 'AA0', 'ZH', 'AE0', 'AO2', 'UW2', 'AO0', 'AY0', 'IY2', 'AW2', 'UH2', 'EY0', 'ER2', 'AW0', 'UH0', 'OY2', 'OY0', "'", '<sos/eos>'], odim=None, model_conf={}, use_preprocessor=True, token_type='phn', bpemodel=None, non_linguistic_symbols=None, cleaner='tacotron', g2p='g2p_en', feats_extract='linear_spectrogram', feats_extract_conf={'n_fft': 1024, 'hop_length': 256, 'win_length': None}, normalize=None, normalize_conf={}, tts='vits', tts_conf={'generator_type': 'vits_generator', 'generator_params': {'hidden_channels': 192, 'spks': 128, 'global_channels': 256, 'segment_size': 32, 'text_encoder_attention_heads': 2, 'text_encoder_ffn_expand': 4, 'text_encoder_blocks': 6, 'text_encoder_positionwise_layer_type': 'conv1d', 'text_encoder_positionwise_conv_kernel_size': 3, 'text_encoder_positional_encoding_layer_type': 'rel_pos', 'text_encoder_self_attention_layer_type': 'rel_selfattn', 'text_encoder_activation_type': 'swish', 'text_encoder_normalize_before': True, 'text_encoder_dropout_rate': 0.1, 'text_encoder_positional_dropout_rate': 0.0, 'text_encoder_attention_dropout_rate': 0.1, 'use_macaron_style_in_text_encoder': True, 'use_conformer_conv_in_text_encoder': False, 'text_encoder_conformer_kernel_size': -1, 'decoder_kernel_size': 7, 'decoder_channels': 512, 'decoder_upsample_scales': [8, 8, 2, 2], 'decoder_upsample_kernel_sizes': [16, 16, 4, 4], 'decoder_resblock_kernel_sizes': [3, 7, 11], 'decoder_resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'use_weight_norm_in_decoder': True, 'posterior_encoder_kernel_size': 5, 'posterior_encoder_layers': 16, 'posterior_encoder_stacks': 1, 'posterior_encoder_base_dilation': 1, 'posterior_encoder_dropout_rate': 0.0, 'use_weight_norm_in_posterior_encoder': True, 'flow_flows': 4, 'flow_kernel_size': 5, 'flow_base_dilation': 1, 'flow_layers': 4, 'flow_dropout_rate': 0.0, 'use_weight_norm_in_flow': True, 'use_only_mean_in_flow': True, 'stochastic_duration_predictor_kernel_size': 3, 'stochastic_duration_predictor_dropout_rate': 0.5, 'stochastic_duration_predictor_flows': 4, 'stochastic_duration_predictor_dds_conv_layers': 3, 'vocabs': 74, 'aux_channels': 513}, 'discriminator_type': 'hifigan_multi_scale_multi_period_discriminator', 'discriminator_params': {'scales': 1, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'stride': 2, 'padding': 2}, 'scale_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'channels': 128, 'max_downsample_channels': 1024, 'max_groups': 16, 'bias': True, 'downsample_scales': [2, 2, 4, 4, 1], 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}, 'follow_official_norm': False, 'periods': [2, 3, 5, 7, 11], 'period_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [5, 3], 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'max_downsample_channels': 1024, 'bias': True, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}}, 'generator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'discriminator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'feat_match_loss_params': {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, 'mel_loss_params': {'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None, 'window': 'hann', 'n_mels': 80, 'fmin': 0, 'fmax': None, 'log_base': None}, 'lambda_adv': 1.0, 'lambda_mel': 45.0, 'lambda_feat_match': 2.0, 'lambda_dur': 1.0, 'lambda_kl': 1.0, 'sampling_rate': 22050, 'cache_generator_outputs': True, 'plot_pred_mos': False, 'mos_pred_tool': 'utmos'}, pitch_extract=None, pitch_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'f0max': 400, 'f0min': 80}, pitch_normalize=None, pitch_normalize_conf={}, energy_extract=None, energy_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None}, energy_normalize=None, energy_normalize_conf={}, required=['output_dir', 'token_list'], version='202503', distributed=False)
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1284, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 35542) is killed by signal: Killed. 

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 22, in <module>
    main()
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 18, in main
    GANTTSTask.main(cmd=cmd)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1225, in main
    cls.main_worker(args)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1441, in main_worker
    collect_stats(
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/main_funcs/collect_stats.py", line 51, in collect_stats
    for iiter, (keys, batch) in enumerate(itr, 1):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 733, in __next__
    data = self._next_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1491, in _next_data
    idx, data = self._get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1453, in _get_data
    success, data = self._try_get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1297, in _try_get_data
    raise RuntimeError(
RuntimeError: DataLoader worker (pid(s) 35542) exited unexpectedly
# Accounting: begin_time=1750873256
# Accounting: end_time=1750873472
# Accounting: time=216 threads=1
# Finished at Wed Jun 25 13:44:32 EDT 2025 with status 1
# Running on r217.ib.bridges2.psc.edu
# Started at Wed Jun 25 13:40:56 EDT 2025
# SLURMD_NODENAME=r217
# SLURM_ARRAY_JOB_ID=32990217
# SLURM_ARRAY_TASK_COUNT=32
# SLURM_ARRAY_TASK_ID=10
# SLURM_ARRAY_TASK_MAX=32
# SLURM_ARRAY_TASK_MIN=1
# SLURM_ARRAY_TASK_STEP=1
# SLURM_CLUSTER_NAME=bridges2
# SLURM_CONF=/var/spool/slurm/d/conf-cache/slurm.conf
# SLURM_CPUS_ON_NODE=1
# SLURM_CPU_BIND=quiet,mask_cpu:0x07C0000000
# SLURM_CPU_BIND_LIST=0x07C0000000
# SLURM_CPU_BIND_TYPE=mask_cpu:
# SLURM_CPU_BIND_VERBOSE=quiet
# SLURM_EXPORT_ENV=ALL
# SLURM_GET_USER_ENV=1
# SLURM_GTIDS=0
# SLURM_JOBID=32990228
# SLURM_JOB_ACCOUNT=cis210027p
# SLURM_JOB_CPUS_PER_NODE=1
# SLURM_JOB_GID=24886
# SLURM_JOB_ID=32990228
# SLURM_JOB_NAME=stats.sh
# SLURM_JOB_NODELIST=r217
# SLURM_JOB_NUM_NODES=1
# SLURM_JOB_PARTITION=RM-shared
# SLURM_JOB_QOS=rm
# SLURM_JOB_UID=97947
# SLURM_JOB_USER=ttao3
# SLURM_LAUNCH_NODE_IPADDR=10.8.11.29
# SLURM_LOCALID=0
# SLURM_MEM_PER_CPU=1900
# SLURM_NNODES=1
# SLURM_NODEID=0
# SLURM_NODELIST=r217
# SLURM_NODE_ALIASES='(null)'
# SLURM_NPROCS=1
# SLURM_NTASKS=1
# SLURM_OPEN_MODE=a
# SLURM_PRIO_PROCESS=0
# SLURM_PROCID=0
# SLURM_PTY_PORT=33025
# SLURM_PTY_WIN_COL=126
# SLURM_PTY_WIN_ROW=21
# SLURM_SCRIPT_CONTEXT=prolog_task
# SLURM_SRUN_COMM_HOST=10.8.11.29
# SLURM_SRUN_COMM_PORT=35045
# SLURM_STEPID=0
# SLURM_STEP_GPUS=6
# SLURM_STEP_ID=0
# SLURM_STEP_LAUNCHER_PORT=35045
# SLURM_STEP_NODELIST=v029
# SLURM_STEP_NUM_NODES=1
# SLURM_STEP_NUM_TASKS=1
# SLURM_STEP_TASKS_PER_NODE=1
# SLURM_SUBMIT_DIR=/ocean/projects/cis210027p/ttao3/espnet/egs2/hifitts/tts1
# SLURM_SUBMIT_HOST=v029.ib.bridges2.psc.edu
# SLURM_TASKS_PER_NODE=1
# SLURM_TASK_PID=34605
# SLURM_TOPOLOGY_ADDR=r217
# SLURM_TOPOLOGY_ADDR_PATTERN=node
# SLURM_WORKING_CLUSTER=bridges2:br003:6810:9728:109
# python3 -m espnet2.bin.gan_tts_train --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.10.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.10.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.10 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int 
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/librosa/util/files.py:10: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_filename
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/bin/python3 /ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.10.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.10.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.10 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int
Failed to import Flash Attention, using ESPnet default: No module named 'flash_attn_2_cuda'
Vocabulary size: 74
encoder self-attention layer type = relative self-attention
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/ocean/projects/cis210027p/ttao3/espnet/espnet2/gan_tts/vits/monotonic_align/__init__.py:19: UserWarning: Cython version is not available. Fallback to 'EXPERIMETAL' numba version. If you want to use the cython version, please build it as follows: `cd espnet2/gan_tts/vits/monotonic_align; python setup.py build_ext --inplace`
  warnings.warn(
pytorch.version=2.7.1+cu126, cuda.available=False, cudnn.version=90501, cudnn.benchmark=False, cudnn.deterministic=False
Model structure:
ESPnetGANTTSModel(
  (feats_extract): LinearSpectrogram(
    (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
  )
  (tts): VITS(
    (generator): VITSGenerator(
      (text_encoder): TextEncoder(
        (emb): Embedding(74, 192)
        (encoder): Encoder(
          (embed): Sequential(
            (0): RelPositionalEncoding(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (encoders): MultiSequential(
            (0): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (2): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (3): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (4): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (5): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (after_norm): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (decoder): HiFiGANGenerator(
        (input_conv): Conv1d(192, 512, kernel_size=(7,), stride=(1,), padding=(3,))
        (upsamples): ModuleList(
          (0): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (1): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(256, 128, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (2): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,))
          )
          (3): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,))
          )
        )
        (blocks): ModuleList(
          (0): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (1): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (2): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (3): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (4): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (5): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (6): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (7): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (8): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (9): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (10): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (11): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
        )
        (output_conv): Sequential(
          (0): LeakyReLU(negative_slope=0.01)
          (1): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,))
          (2): Tanh()
        )
        (global_conv): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
      )
      (posterior_encoder): PosteriorEncoder(
        (input_conv): Conv1d(513, 192, kernel_size=(1,), stride=(1,))
        (encoder): WaveNet(
          (conv_layers): ModuleList(
            (0-15): 16 x ResidualBlock(
              (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
              (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
              (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
            )
          )
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (flow): ResidualAffineCouplingBlock(
        (flows): ModuleList(
          (0): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (1): FlipFlow()
          (2): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (3): FlipFlow()
          (4): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (5): FlipFlow()
          (6): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (7): FlipFlow()
        )
      )
      (duration_predictor): StochasticDurationPredictor(
        (pre): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (log_flow): LogFlow()
        (flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (post_pre): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
        (post_dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (post_proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (post_flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (global_conv): Conv1d(256, 192, kernel_size=(1,), stride=(1,))
      )
      (global_emb): Embedding(128, 256)
    )
    (discriminator): HiFiGANMultiScaleMultiPeriodDiscriminator(
      (msd): HiFiGANMultiScaleDiscriminator(
        (discriminators): ModuleList(
          (0): HiFiGANScaleDiscriminator(
            (layers): ModuleList(
              (0): Sequential(
                (0): Conv1d(1, 128, kernel_size=(15,), stride=(1,), padding=(7,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv1d(128, 128, kernel_size=(41,), stride=(2,), padding=(20,), groups=4)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv1d(128, 256, kernel_size=(41,), stride=(2,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv1d(256, 512, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv1d(512, 1024, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (5): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(41,), stride=(1,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (6): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (7): Conv1d(1024, 1, kernel_size=(3,), stride=(1,), padding=(1,))
            )
          )
        )
      )
      (mpd): HiFiGANMultiPeriodDiscriminator(
        (discriminators): ModuleList(
          (0-4): 5 x HiFiGANPeriodDiscriminator(
            (convs): ModuleList(
              (0): Sequential(
                (0): Conv2d(1, 32, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv2d(32, 128, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv2d(128, 512, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv2d(512, 1024, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv2d(1024, 1024, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
            )
            (output_conv): Conv2d(1024, 1, kernel_size=(2, 1), stride=(1, 1), padding=(1, 0))
          )
        )
      )
    )
    (generator_adv_loss): GeneratorAdversarialLoss()
    (discriminator_adv_loss): DiscriminatorAdversarialLoss()
    (feat_match_loss): FeatureMatchLoss()
    (mel_loss): MelSpectrogramLoss(
      (wav_to_mel): LogMelFbank(
        (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
        (logmel): LogMel(sr=22050, n_fft=1024, n_mels=80, fmin=0, fmax=11025.0, htk=False)
      )
    )
    (kl_loss): KLDivergenceLoss()
  )
)

Model summary:
    Class Name: ESPnetGANTTSModel
    Total Number of model parameters: 96.37 M
    Number of trainable parameters: 96.37 M (100.0%)
    Size: 385.46 MB
    Type: torch.float32
Optimizer:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler: <torch.optim.lr_scheduler.ExponentialLR object at 0x14fcda63f640>
Optimizer2:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler2: <torch.optim.lr_scheduler.ExponentialLR object at 0x14fcda63fa30>
Saving the configuration in exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.10/config.yaml
Namespace(config='conf/tuning/train_multi_spk_vits.yaml', print_config=False, log_level='INFO', drop_last_iter=False, dry_run=False, iterator_type='sequence', valid_iterator_type=None, output_dir='exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.10', ngpu=0, seed=777, num_workers=4, num_att_plot=3, dist_backend='nccl', dist_init_method='env://', dist_world_size=None, dist_rank=None, local_rank=None, dist_master_addr=None, dist_master_port=None, dist_launcher=None, multiprocessing_distributed=False, unused_parameters=True, sharded_ddp=False, use_deepspeed=False, deepspeed_config=None, gradient_as_bucket_view=True, ddp_comm_hook=None, cudnn_enabled=True, cudnn_benchmark=False, cudnn_deterministic=False, use_tf32=False, collect_stats=True, write_collected_feats=False, max_epoch=1000, patience=None, val_scheduler_criterion=('valid', 'loss'), early_stopping_criterion=('valid', 'loss', 'min'), best_model_criterion=[['train', 'total_count', 'max']], keep_nbest_models=10, nbest_averaging_interval=0, grad_clip=-1, grad_clip_type=2.0, grad_noise=False, accum_grad=1, no_forward_run=False, resume=False, train_dtype='float32', use_amp=False, log_interval=50, use_matplotlib=True, use_tensorboard=True, create_graph_in_tensorboard=False, use_wandb=False, wandb_project=None, wandb_id=None, wandb_entity=None, wandb_name=None, wandb_model_log_interval=-1, detect_anomaly=False, use_adapter=False, adapter='lora', save_strategy='all', adapter_conf={}, pretrain_path=None, init_param=[], ignore_init_mismatch=False, freeze_param=[], num_iters_per_epoch=1000, batch_size=20, valid_batch_size=None, batch_bins=3000000, valid_batch_bins=None, category_sample_size=10, train_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.10.scp'], valid_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.10.scp'], batch_type='numel', valid_batch_type=None, fold_length=[], sort_in_batch='descending', shuffle_within_batch=False, sort_batch='descending', multiple_iterator=False, chunk_length=500, chunk_shift_ratio=0.5, num_cache_chunks=1024, chunk_excluded_key_prefixes=[], chunk_default_fs=None, chunk_max_abs_length=None, chunk_discard_short_samples=True, train_data_path_and_name_and_type=[('dump/22k/raw/tr_no_dev/text', 'text', 'text'), ('dump/22k/raw/tr_no_dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/tr_no_dev/utt2sid', 'sids', 'text_int')], valid_data_path_and_name_and_type=[('dump/22k/raw/dev/text', 'text', 'text'), ('dump/22k/raw/dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/dev/utt2sid', 'sids', 'text_int')], multi_task_dataset=False, allow_variable_data_keys=False, max_cache_size=0.0, max_cache_fd=32, allow_multi_rates=False, valid_max_cache_size=None, exclude_weight_decay=False, exclude_weight_decay_conf={}, optim='adamw', optim_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler='exponentiallr', scheduler_conf={'gamma': 0.999875}, optim2='adamw', optim2_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler2='exponentiallr', scheduler2_conf={'gamma': 0.999875}, generator_first=False, skip_discriminator_prob=0.0, token_list=['<blank>', '<unk>', ' ', 'AH0', 'N', 'T', 'D', 'S', 'R', 'L', 'IH1', 'DH', 'M', 'EH1', 'Z', 'AE1', 'K', 'IH0', 'AH1', 'HH', 'W', 'ER0', 'V', 'IY1', 'F', 'UW1', 'P', 'AY1', 'B', 'AA1', 'AO1', 'EY1', 'IY0', 'OW1', 'NG', 'SH', 'G', 'Y', 'AW1', 'CH', 'ER1', 'UH1', 'TH', 'JH', 'OW0', 'EH2', 'IH2', 'OY1', 'EY2', 'AY2', 'EH0', 'UW0', 'AA2', 'AE2', 'OW2', 'AH2', 'AA0', 'ZH', 'AE0', 'AO2', 'UW2', 'AO0', 'AY0', 'IY2', 'AW2', 'UH2', 'EY0', 'ER2', 'AW0', 'UH0', 'OY2', 'OY0', "'", '<sos/eos>'], odim=None, model_conf={}, use_preprocessor=True, token_type='phn', bpemodel=None, non_linguistic_symbols=None, cleaner='tacotron', g2p='g2p_en', feats_extract='linear_spectrogram', feats_extract_conf={'n_fft': 1024, 'hop_length': 256, 'win_length': None}, normalize=None, normalize_conf={}, tts='vits', tts_conf={'generator_type': 'vits_generator', 'generator_params': {'hidden_channels': 192, 'spks': 128, 'global_channels': 256, 'segment_size': 32, 'text_encoder_attention_heads': 2, 'text_encoder_ffn_expand': 4, 'text_encoder_blocks': 6, 'text_encoder_positionwise_layer_type': 'conv1d', 'text_encoder_positionwise_conv_kernel_size': 3, 'text_encoder_positional_encoding_layer_type': 'rel_pos', 'text_encoder_self_attention_layer_type': 'rel_selfattn', 'text_encoder_activation_type': 'swish', 'text_encoder_normalize_before': True, 'text_encoder_dropout_rate': 0.1, 'text_encoder_positional_dropout_rate': 0.0, 'text_encoder_attention_dropout_rate': 0.1, 'use_macaron_style_in_text_encoder': True, 'use_conformer_conv_in_text_encoder': False, 'text_encoder_conformer_kernel_size': -1, 'decoder_kernel_size': 7, 'decoder_channels': 512, 'decoder_upsample_scales': [8, 8, 2, 2], 'decoder_upsample_kernel_sizes': [16, 16, 4, 4], 'decoder_resblock_kernel_sizes': [3, 7, 11], 'decoder_resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'use_weight_norm_in_decoder': True, 'posterior_encoder_kernel_size': 5, 'posterior_encoder_layers': 16, 'posterior_encoder_stacks': 1, 'posterior_encoder_base_dilation': 1, 'posterior_encoder_dropout_rate': 0.0, 'use_weight_norm_in_posterior_encoder': True, 'flow_flows': 4, 'flow_kernel_size': 5, 'flow_base_dilation': 1, 'flow_layers': 4, 'flow_dropout_rate': 0.0, 'use_weight_norm_in_flow': True, 'use_only_mean_in_flow': True, 'stochastic_duration_predictor_kernel_size': 3, 'stochastic_duration_predictor_dropout_rate': 0.5, 'stochastic_duration_predictor_flows': 4, 'stochastic_duration_predictor_dds_conv_layers': 3, 'vocabs': 74, 'aux_channels': 513}, 'discriminator_type': 'hifigan_multi_scale_multi_period_discriminator', 'discriminator_params': {'scales': 1, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'stride': 2, 'padding': 2}, 'scale_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'channels': 128, 'max_downsample_channels': 1024, 'max_groups': 16, 'bias': True, 'downsample_scales': [2, 2, 4, 4, 1], 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}, 'follow_official_norm': False, 'periods': [2, 3, 5, 7, 11], 'period_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [5, 3], 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'max_downsample_channels': 1024, 'bias': True, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}}, 'generator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'discriminator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'feat_match_loss_params': {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, 'mel_loss_params': {'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None, 'window': 'hann', 'n_mels': 80, 'fmin': 0, 'fmax': None, 'log_base': None}, 'lambda_adv': 1.0, 'lambda_mel': 45.0, 'lambda_feat_match': 2.0, 'lambda_dur': 1.0, 'lambda_kl': 1.0, 'sampling_rate': 22050, 'cache_generator_outputs': True, 'plot_pred_mos': False, 'mos_pred_tool': 'utmos'}, pitch_extract=None, pitch_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'f0max': 400, 'f0min': 80}, pitch_normalize=None, pitch_normalize_conf={}, energy_extract=None, energy_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None}, energy_normalize=None, energy_normalize_conf={}, required=['output_dir', 'token_list'], version='202503', distributed=False)
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1284, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 34886) is killed by signal: Killed. 

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 22, in <module>
    main()
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 18, in main
    GANTTSTask.main(cmd=cmd)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1225, in main
    cls.main_worker(args)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1441, in main_worker
    collect_stats(
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/main_funcs/collect_stats.py", line 51, in collect_stats
    for iiter, (keys, batch) in enumerate(itr, 1):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 733, in __next__
    data = self._next_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1491, in _next_data
    idx, data = self._get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1453, in _get_data
    success, data = self._try_get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1297, in _try_get_data
    raise RuntimeError(
RuntimeError: DataLoader worker (pid(s) 34886) exited unexpectedly
# Accounting: begin_time=1750873256
# Accounting: end_time=1750873472
# Accounting: time=216 threads=1
# Finished at Wed Jun 25 13:44:32 EDT 2025 with status 1
# Running on r217.ib.bridges2.psc.edu
# Started at Wed Jun 25 13:40:56 EDT 2025
# SLURMD_NODENAME=r217
# SLURM_ARRAY_JOB_ID=32990217
# SLURM_ARRAY_TASK_COUNT=32
# SLURM_ARRAY_TASK_ID=11
# SLURM_ARRAY_TASK_MAX=32
# SLURM_ARRAY_TASK_MIN=1
# SLURM_ARRAY_TASK_STEP=1
# SLURM_CLUSTER_NAME=bridges2
# SLURM_CONF=/var/spool/slurm/d/conf-cache/slurm.conf
# SLURM_CPUS_ON_NODE=1
# SLURM_CPU_BIND=quiet,mask_cpu:0x07C0000000
# SLURM_CPU_BIND_LIST=0x07C0000000
# SLURM_CPU_BIND_TYPE=mask_cpu:
# SLURM_CPU_BIND_VERBOSE=quiet
# SLURM_EXPORT_ENV=ALL
# SLURM_GET_USER_ENV=1
# SLURM_GTIDS=0
# SLURM_JOBID=32990229
# SLURM_JOB_ACCOUNT=cis210027p
# SLURM_JOB_CPUS_PER_NODE=1
# SLURM_JOB_GID=24886
# SLURM_JOB_ID=32990229
# SLURM_JOB_NAME=stats.sh
# SLURM_JOB_NODELIST=r217
# SLURM_JOB_NUM_NODES=1
# SLURM_JOB_PARTITION=RM-shared
# SLURM_JOB_QOS=rm
# SLURM_JOB_UID=97947
# SLURM_JOB_USER=ttao3
# SLURM_LAUNCH_NODE_IPADDR=10.8.11.29
# SLURM_LOCALID=0
# SLURM_MEM_PER_CPU=1900
# SLURM_NNODES=1
# SLURM_NODEID=0
# SLURM_NODELIST=r217
# SLURM_NODE_ALIASES='(null)'
# SLURM_NPROCS=1
# SLURM_NTASKS=1
# SLURM_OPEN_MODE=a
# SLURM_PRIO_PROCESS=0
# SLURM_PROCID=0
# SLURM_PTY_PORT=33025
# SLURM_PTY_WIN_COL=126
# SLURM_PTY_WIN_ROW=21
# SLURM_SCRIPT_CONTEXT=prolog_task
# SLURM_SRUN_COMM_HOST=10.8.11.29
# SLURM_SRUN_COMM_PORT=35045
# SLURM_STEPID=0
# SLURM_STEP_GPUS=6
# SLURM_STEP_ID=0
# SLURM_STEP_LAUNCHER_PORT=35045
# SLURM_STEP_NODELIST=v029
# SLURM_STEP_NUM_NODES=1
# SLURM_STEP_NUM_TASKS=1
# SLURM_STEP_TASKS_PER_NODE=1
# SLURM_SUBMIT_DIR=/ocean/projects/cis210027p/ttao3/espnet/egs2/hifitts/tts1
# SLURM_SUBMIT_HOST=v029.ib.bridges2.psc.edu
# SLURM_TASKS_PER_NODE=1
# SLURM_TASK_PID=34606
# SLURM_TOPOLOGY_ADDR=r217
# SLURM_TOPOLOGY_ADDR_PATTERN=node
# SLURM_WORKING_CLUSTER=bridges2:br003:6810:9728:109
# python3 -m espnet2.bin.gan_tts_train --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.11.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.11.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.11 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int 
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/librosa/util/files.py:10: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_filename
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/bin/python3 /ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.11.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.11.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.11 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int
Failed to import Flash Attention, using ESPnet default: No module named 'flash_attn_2_cuda'
Vocabulary size: 74
encoder self-attention layer type = relative self-attention
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/ocean/projects/cis210027p/ttao3/espnet/espnet2/gan_tts/vits/monotonic_align/__init__.py:19: UserWarning: Cython version is not available. Fallback to 'EXPERIMETAL' numba version. If you want to use the cython version, please build it as follows: `cd espnet2/gan_tts/vits/monotonic_align; python setup.py build_ext --inplace`
  warnings.warn(
pytorch.version=2.7.1+cu126, cuda.available=False, cudnn.version=90501, cudnn.benchmark=False, cudnn.deterministic=False
Model structure:
ESPnetGANTTSModel(
  (feats_extract): LinearSpectrogram(
    (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
  )
  (tts): VITS(
    (generator): VITSGenerator(
      (text_encoder): TextEncoder(
        (emb): Embedding(74, 192)
        (encoder): Encoder(
          (embed): Sequential(
            (0): RelPositionalEncoding(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (encoders): MultiSequential(
            (0): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (2): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (3): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (4): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (5): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (after_norm): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (decoder): HiFiGANGenerator(
        (input_conv): Conv1d(192, 512, kernel_size=(7,), stride=(1,), padding=(3,))
        (upsamples): ModuleList(
          (0): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (1): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(256, 128, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (2): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,))
          )
          (3): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,))
          )
        )
        (blocks): ModuleList(
          (0): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (1): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (2): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (3): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (4): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (5): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (6): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (7): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (8): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (9): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (10): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (11): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
        )
        (output_conv): Sequential(
          (0): LeakyReLU(negative_slope=0.01)
          (1): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,))
          (2): Tanh()
        )
        (global_conv): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
      )
      (posterior_encoder): PosteriorEncoder(
        (input_conv): Conv1d(513, 192, kernel_size=(1,), stride=(1,))
        (encoder): WaveNet(
          (conv_layers): ModuleList(
            (0-15): 16 x ResidualBlock(
              (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
              (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
              (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
            )
          )
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (flow): ResidualAffineCouplingBlock(
        (flows): ModuleList(
          (0): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (1): FlipFlow()
          (2): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (3): FlipFlow()
          (4): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (5): FlipFlow()
          (6): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (7): FlipFlow()
        )
      )
      (duration_predictor): StochasticDurationPredictor(
        (pre): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (log_flow): LogFlow()
        (flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (post_pre): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
        (post_dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (post_proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (post_flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (global_conv): Conv1d(256, 192, kernel_size=(1,), stride=(1,))
      )
      (global_emb): Embedding(128, 256)
    )
    (discriminator): HiFiGANMultiScaleMultiPeriodDiscriminator(
      (msd): HiFiGANMultiScaleDiscriminator(
        (discriminators): ModuleList(
          (0): HiFiGANScaleDiscriminator(
            (layers): ModuleList(
              (0): Sequential(
                (0): Conv1d(1, 128, kernel_size=(15,), stride=(1,), padding=(7,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv1d(128, 128, kernel_size=(41,), stride=(2,), padding=(20,), groups=4)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv1d(128, 256, kernel_size=(41,), stride=(2,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv1d(256, 512, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv1d(512, 1024, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (5): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(41,), stride=(1,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (6): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (7): Conv1d(1024, 1, kernel_size=(3,), stride=(1,), padding=(1,))
            )
          )
        )
      )
      (mpd): HiFiGANMultiPeriodDiscriminator(
        (discriminators): ModuleList(
          (0-4): 5 x HiFiGANPeriodDiscriminator(
            (convs): ModuleList(
              (0): Sequential(
                (0): Conv2d(1, 32, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv2d(32, 128, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv2d(128, 512, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv2d(512, 1024, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv2d(1024, 1024, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
            )
            (output_conv): Conv2d(1024, 1, kernel_size=(2, 1), stride=(1, 1), padding=(1, 0))
          )
        )
      )
    )
    (generator_adv_loss): GeneratorAdversarialLoss()
    (discriminator_adv_loss): DiscriminatorAdversarialLoss()
    (feat_match_loss): FeatureMatchLoss()
    (mel_loss): MelSpectrogramLoss(
      (wav_to_mel): LogMelFbank(
        (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
        (logmel): LogMel(sr=22050, n_fft=1024, n_mels=80, fmin=0, fmax=11025.0, htk=False)
      )
    )
    (kl_loss): KLDivergenceLoss()
  )
)

Model summary:
    Class Name: ESPnetGANTTSModel
    Total Number of model parameters: 96.37 M
    Number of trainable parameters: 96.37 M (100.0%)
    Size: 385.46 MB
    Type: torch.float32
Optimizer:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler: <torch.optim.lr_scheduler.ExponentialLR object at 0x1491beb91640>
Optimizer2:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler2: <torch.optim.lr_scheduler.ExponentialLR object at 0x1491beb91a30>
Saving the configuration in exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.11/config.yaml
Namespace(config='conf/tuning/train_multi_spk_vits.yaml', print_config=False, log_level='INFO', drop_last_iter=False, dry_run=False, iterator_type='sequence', valid_iterator_type=None, output_dir='exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.11', ngpu=0, seed=777, num_workers=4, num_att_plot=3, dist_backend='nccl', dist_init_method='env://', dist_world_size=None, dist_rank=None, local_rank=None, dist_master_addr=None, dist_master_port=None, dist_launcher=None, multiprocessing_distributed=False, unused_parameters=True, sharded_ddp=False, use_deepspeed=False, deepspeed_config=None, gradient_as_bucket_view=True, ddp_comm_hook=None, cudnn_enabled=True, cudnn_benchmark=False, cudnn_deterministic=False, use_tf32=False, collect_stats=True, write_collected_feats=False, max_epoch=1000, patience=None, val_scheduler_criterion=('valid', 'loss'), early_stopping_criterion=('valid', 'loss', 'min'), best_model_criterion=[['train', 'total_count', 'max']], keep_nbest_models=10, nbest_averaging_interval=0, grad_clip=-1, grad_clip_type=2.0, grad_noise=False, accum_grad=1, no_forward_run=False, resume=False, train_dtype='float32', use_amp=False, log_interval=50, use_matplotlib=True, use_tensorboard=True, create_graph_in_tensorboard=False, use_wandb=False, wandb_project=None, wandb_id=None, wandb_entity=None, wandb_name=None, wandb_model_log_interval=-1, detect_anomaly=False, use_adapter=False, adapter='lora', save_strategy='all', adapter_conf={}, pretrain_path=None, init_param=[], ignore_init_mismatch=False, freeze_param=[], num_iters_per_epoch=1000, batch_size=20, valid_batch_size=None, batch_bins=3000000, valid_batch_bins=None, category_sample_size=10, train_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.11.scp'], valid_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.11.scp'], batch_type='numel', valid_batch_type=None, fold_length=[], sort_in_batch='descending', shuffle_within_batch=False, sort_batch='descending', multiple_iterator=False, chunk_length=500, chunk_shift_ratio=0.5, num_cache_chunks=1024, chunk_excluded_key_prefixes=[], chunk_default_fs=None, chunk_max_abs_length=None, chunk_discard_short_samples=True, train_data_path_and_name_and_type=[('dump/22k/raw/tr_no_dev/text', 'text', 'text'), ('dump/22k/raw/tr_no_dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/tr_no_dev/utt2sid', 'sids', 'text_int')], valid_data_path_and_name_and_type=[('dump/22k/raw/dev/text', 'text', 'text'), ('dump/22k/raw/dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/dev/utt2sid', 'sids', 'text_int')], multi_task_dataset=False, allow_variable_data_keys=False, max_cache_size=0.0, max_cache_fd=32, allow_multi_rates=False, valid_max_cache_size=None, exclude_weight_decay=False, exclude_weight_decay_conf={}, optim='adamw', optim_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler='exponentiallr', scheduler_conf={'gamma': 0.999875}, optim2='adamw', optim2_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler2='exponentiallr', scheduler2_conf={'gamma': 0.999875}, generator_first=False, skip_discriminator_prob=0.0, token_list=['<blank>', '<unk>', ' ', 'AH0', 'N', 'T', 'D', 'S', 'R', 'L', 'IH1', 'DH', 'M', 'EH1', 'Z', 'AE1', 'K', 'IH0', 'AH1', 'HH', 'W', 'ER0', 'V', 'IY1', 'F', 'UW1', 'P', 'AY1', 'B', 'AA1', 'AO1', 'EY1', 'IY0', 'OW1', 'NG', 'SH', 'G', 'Y', 'AW1', 'CH', 'ER1', 'UH1', 'TH', 'JH', 'OW0', 'EH2', 'IH2', 'OY1', 'EY2', 'AY2', 'EH0', 'UW0', 'AA2', 'AE2', 'OW2', 'AH2', 'AA0', 'ZH', 'AE0', 'AO2', 'UW2', 'AO0', 'AY0', 'IY2', 'AW2', 'UH2', 'EY0', 'ER2', 'AW0', 'UH0', 'OY2', 'OY0', "'", '<sos/eos>'], odim=None, model_conf={}, use_preprocessor=True, token_type='phn', bpemodel=None, non_linguistic_symbols=None, cleaner='tacotron', g2p='g2p_en', feats_extract='linear_spectrogram', feats_extract_conf={'n_fft': 1024, 'hop_length': 256, 'win_length': None}, normalize=None, normalize_conf={}, tts='vits', tts_conf={'generator_type': 'vits_generator', 'generator_params': {'hidden_channels': 192, 'spks': 128, 'global_channels': 256, 'segment_size': 32, 'text_encoder_attention_heads': 2, 'text_encoder_ffn_expand': 4, 'text_encoder_blocks': 6, 'text_encoder_positionwise_layer_type': 'conv1d', 'text_encoder_positionwise_conv_kernel_size': 3, 'text_encoder_positional_encoding_layer_type': 'rel_pos', 'text_encoder_self_attention_layer_type': 'rel_selfattn', 'text_encoder_activation_type': 'swish', 'text_encoder_normalize_before': True, 'text_encoder_dropout_rate': 0.1, 'text_encoder_positional_dropout_rate': 0.0, 'text_encoder_attention_dropout_rate': 0.1, 'use_macaron_style_in_text_encoder': True, 'use_conformer_conv_in_text_encoder': False, 'text_encoder_conformer_kernel_size': -1, 'decoder_kernel_size': 7, 'decoder_channels': 512, 'decoder_upsample_scales': [8, 8, 2, 2], 'decoder_upsample_kernel_sizes': [16, 16, 4, 4], 'decoder_resblock_kernel_sizes': [3, 7, 11], 'decoder_resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'use_weight_norm_in_decoder': True, 'posterior_encoder_kernel_size': 5, 'posterior_encoder_layers': 16, 'posterior_encoder_stacks': 1, 'posterior_encoder_base_dilation': 1, 'posterior_encoder_dropout_rate': 0.0, 'use_weight_norm_in_posterior_encoder': True, 'flow_flows': 4, 'flow_kernel_size': 5, 'flow_base_dilation': 1, 'flow_layers': 4, 'flow_dropout_rate': 0.0, 'use_weight_norm_in_flow': True, 'use_only_mean_in_flow': True, 'stochastic_duration_predictor_kernel_size': 3, 'stochastic_duration_predictor_dropout_rate': 0.5, 'stochastic_duration_predictor_flows': 4, 'stochastic_duration_predictor_dds_conv_layers': 3, 'vocabs': 74, 'aux_channels': 513}, 'discriminator_type': 'hifigan_multi_scale_multi_period_discriminator', 'discriminator_params': {'scales': 1, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'stride': 2, 'padding': 2}, 'scale_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'channels': 128, 'max_downsample_channels': 1024, 'max_groups': 16, 'bias': True, 'downsample_scales': [2, 2, 4, 4, 1], 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}, 'follow_official_norm': False, 'periods': [2, 3, 5, 7, 11], 'period_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [5, 3], 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'max_downsample_channels': 1024, 'bias': True, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}}, 'generator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'discriminator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'feat_match_loss_params': {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, 'mel_loss_params': {'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None, 'window': 'hann', 'n_mels': 80, 'fmin': 0, 'fmax': None, 'log_base': None}, 'lambda_adv': 1.0, 'lambda_mel': 45.0, 'lambda_feat_match': 2.0, 'lambda_dur': 1.0, 'lambda_kl': 1.0, 'sampling_rate': 22050, 'cache_generator_outputs': True, 'plot_pred_mos': False, 'mos_pred_tool': 'utmos'}, pitch_extract=None, pitch_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'f0max': 400, 'f0min': 80}, pitch_normalize=None, pitch_normalize_conf={}, energy_extract=None, energy_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None}, energy_normalize=None, energy_normalize_conf={}, required=['output_dir', 'token_list'], version='202503', distributed=False)
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1284, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 34885) is killed by signal: Killed. 

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 22, in <module>
    main()
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 18, in main
    GANTTSTask.main(cmd=cmd)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1225, in main
    cls.main_worker(args)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1441, in main_worker
    collect_stats(
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/main_funcs/collect_stats.py", line 51, in collect_stats
    for iiter, (keys, batch) in enumerate(itr, 1):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 733, in __next__
    data = self._next_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1491, in _next_data
    idx, data = self._get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1453, in _get_data
    success, data = self._try_get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1297, in _try_get_data
    raise RuntimeError(
RuntimeError: DataLoader worker (pid(s) 34885) exited unexpectedly
# Accounting: begin_time=1750873256
# Accounting: end_time=1750873472
# Accounting: time=216 threads=1
# Finished at Wed Jun 25 13:44:32 EDT 2025 with status 1
# Running on r248.ib.bridges2.psc.edu
# Started at Wed Jun 25 13:40:56 EDT 2025
# SLURMD_NODENAME=r248
# SLURM_ARRAY_JOB_ID=32990217
# SLURM_ARRAY_TASK_COUNT=32
# SLURM_ARRAY_TASK_ID=12
# SLURM_ARRAY_TASK_MAX=32
# SLURM_ARRAY_TASK_MIN=1
# SLURM_ARRAY_TASK_STEP=1
# SLURM_CLUSTER_NAME=bridges2
# SLURM_CONF=/var/spool/slurm/d/conf-cache/slurm.conf
# SLURM_CPUS_ON_NODE=1
# SLURM_CPU_BIND=quiet,mask_cpu:0x07C0000000
# SLURM_CPU_BIND_LIST=0x07C0000000
# SLURM_CPU_BIND_TYPE=mask_cpu:
# SLURM_CPU_BIND_VERBOSE=quiet
# SLURM_EXPORT_ENV=ALL
# SLURM_GET_USER_ENV=1
# SLURM_GTIDS=0
# SLURM_JOBID=32990230
# SLURM_JOB_ACCOUNT=cis210027p
# SLURM_JOB_CPUS_PER_NODE=1
# SLURM_JOB_GID=24886
# SLURM_JOB_ID=32990230
# SLURM_JOB_NAME=stats.sh
# SLURM_JOB_NODELIST=r248
# SLURM_JOB_NUM_NODES=1
# SLURM_JOB_PARTITION=RM-shared
# SLURM_JOB_QOS=rm
# SLURM_JOB_UID=97947
# SLURM_JOB_USER=ttao3
# SLURM_LAUNCH_NODE_IPADDR=10.8.11.29
# SLURM_LOCALID=0
# SLURM_MEM_PER_CPU=1900
# SLURM_NNODES=1
# SLURM_NODEID=0
# SLURM_NODELIST=r248
# SLURM_NODE_ALIASES='(null)'
# SLURM_NPROCS=1
# SLURM_NTASKS=1
# SLURM_OPEN_MODE=a
# SLURM_PRIO_PROCESS=0
# SLURM_PROCID=0
# SLURM_PTY_PORT=33025
# SLURM_PTY_WIN_COL=126
# SLURM_PTY_WIN_ROW=21
# SLURM_SCRIPT_CONTEXT=prolog_task
# SLURM_SRUN_COMM_HOST=10.8.11.29
# SLURM_SRUN_COMM_PORT=35045
# SLURM_STEPID=0
# SLURM_STEP_GPUS=6
# SLURM_STEP_ID=0
# SLURM_STEP_LAUNCHER_PORT=35045
# SLURM_STEP_NODELIST=v029
# SLURM_STEP_NUM_NODES=1
# SLURM_STEP_NUM_TASKS=1
# SLURM_STEP_TASKS_PER_NODE=1
# SLURM_SUBMIT_DIR=/ocean/projects/cis210027p/ttao3/espnet/egs2/hifitts/tts1
# SLURM_SUBMIT_HOST=v029.ib.bridges2.psc.edu
# SLURM_TASKS_PER_NODE=1
# SLURM_TASK_PID=70656
# SLURM_TOPOLOGY_ADDR=r248
# SLURM_TOPOLOGY_ADDR_PATTERN=node
# SLURM_WORKING_CLUSTER=bridges2:br003:6810:9728:109
# python3 -m espnet2.bin.gan_tts_train --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.12.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.12.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.12 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int 
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/librosa/util/files.py:10: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_filename
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/bin/python3 /ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.12.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.12.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.12 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int
Failed to import Flash Attention, using ESPnet default: No module named 'flash_attn_2_cuda'
Vocabulary size: 74
encoder self-attention layer type = relative self-attention
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/ocean/projects/cis210027p/ttao3/espnet/espnet2/gan_tts/vits/monotonic_align/__init__.py:19: UserWarning: Cython version is not available. Fallback to 'EXPERIMETAL' numba version. If you want to use the cython version, please build it as follows: `cd espnet2/gan_tts/vits/monotonic_align; python setup.py build_ext --inplace`
  warnings.warn(
pytorch.version=2.7.1+cu126, cuda.available=False, cudnn.version=90501, cudnn.benchmark=False, cudnn.deterministic=False
Model structure:
ESPnetGANTTSModel(
  (feats_extract): LinearSpectrogram(
    (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
  )
  (tts): VITS(
    (generator): VITSGenerator(
      (text_encoder): TextEncoder(
        (emb): Embedding(74, 192)
        (encoder): Encoder(
          (embed): Sequential(
            (0): RelPositionalEncoding(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (encoders): MultiSequential(
            (0): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (2): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (3): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (4): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (5): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (after_norm): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (decoder): HiFiGANGenerator(
        (input_conv): Conv1d(192, 512, kernel_size=(7,), stride=(1,), padding=(3,))
        (upsamples): ModuleList(
          (0): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (1): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(256, 128, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (2): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,))
          )
          (3): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,))
          )
        )
        (blocks): ModuleList(
          (0): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (1): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (2): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (3): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (4): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (5): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (6): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (7): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (8): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (9): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (10): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (11): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
        )
        (output_conv): Sequential(
          (0): LeakyReLU(negative_slope=0.01)
          (1): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,))
          (2): Tanh()
        )
        (global_conv): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
      )
      (posterior_encoder): PosteriorEncoder(
        (input_conv): Conv1d(513, 192, kernel_size=(1,), stride=(1,))
        (encoder): WaveNet(
          (conv_layers): ModuleList(
            (0-15): 16 x ResidualBlock(
              (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
              (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
              (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
            )
          )
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (flow): ResidualAffineCouplingBlock(
        (flows): ModuleList(
          (0): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (1): FlipFlow()
          (2): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (3): FlipFlow()
          (4): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (5): FlipFlow()
          (6): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (7): FlipFlow()
        )
      )
      (duration_predictor): StochasticDurationPredictor(
        (pre): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (log_flow): LogFlow()
        (flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (post_pre): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
        (post_dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (post_proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (post_flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (global_conv): Conv1d(256, 192, kernel_size=(1,), stride=(1,))
      )
      (global_emb): Embedding(128, 256)
    )
    (discriminator): HiFiGANMultiScaleMultiPeriodDiscriminator(
      (msd): HiFiGANMultiScaleDiscriminator(
        (discriminators): ModuleList(
          (0): HiFiGANScaleDiscriminator(
            (layers): ModuleList(
              (0): Sequential(
                (0): Conv1d(1, 128, kernel_size=(15,), stride=(1,), padding=(7,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv1d(128, 128, kernel_size=(41,), stride=(2,), padding=(20,), groups=4)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv1d(128, 256, kernel_size=(41,), stride=(2,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv1d(256, 512, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv1d(512, 1024, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (5): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(41,), stride=(1,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (6): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (7): Conv1d(1024, 1, kernel_size=(3,), stride=(1,), padding=(1,))
            )
          )
        )
      )
      (mpd): HiFiGANMultiPeriodDiscriminator(
        (discriminators): ModuleList(
          (0-4): 5 x HiFiGANPeriodDiscriminator(
            (convs): ModuleList(
              (0): Sequential(
                (0): Conv2d(1, 32, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv2d(32, 128, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv2d(128, 512, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv2d(512, 1024, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv2d(1024, 1024, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
            )
            (output_conv): Conv2d(1024, 1, kernel_size=(2, 1), stride=(1, 1), padding=(1, 0))
          )
        )
      )
    )
    (generator_adv_loss): GeneratorAdversarialLoss()
    (discriminator_adv_loss): DiscriminatorAdversarialLoss()
    (feat_match_loss): FeatureMatchLoss()
    (mel_loss): MelSpectrogramLoss(
      (wav_to_mel): LogMelFbank(
        (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
        (logmel): LogMel(sr=22050, n_fft=1024, n_mels=80, fmin=0, fmax=11025.0, htk=False)
      )
    )
    (kl_loss): KLDivergenceLoss()
  )
)

Model summary:
    Class Name: ESPnetGANTTSModel
    Total Number of model parameters: 96.37 M
    Number of trainable parameters: 96.37 M (100.0%)
    Size: 385.46 MB
    Type: torch.float32
Optimizer:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler: <torch.optim.lr_scheduler.ExponentialLR object at 0x14a06f28e610>
Optimizer2:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler2: <torch.optim.lr_scheduler.ExponentialLR object at 0x14a06f28ea00>
Saving the configuration in exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.12/config.yaml
Namespace(config='conf/tuning/train_multi_spk_vits.yaml', print_config=False, log_level='INFO', drop_last_iter=False, dry_run=False, iterator_type='sequence', valid_iterator_type=None, output_dir='exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.12', ngpu=0, seed=777, num_workers=4, num_att_plot=3, dist_backend='nccl', dist_init_method='env://', dist_world_size=None, dist_rank=None, local_rank=None, dist_master_addr=None, dist_master_port=None, dist_launcher=None, multiprocessing_distributed=False, unused_parameters=True, sharded_ddp=False, use_deepspeed=False, deepspeed_config=None, gradient_as_bucket_view=True, ddp_comm_hook=None, cudnn_enabled=True, cudnn_benchmark=False, cudnn_deterministic=False, use_tf32=False, collect_stats=True, write_collected_feats=False, max_epoch=1000, patience=None, val_scheduler_criterion=('valid', 'loss'), early_stopping_criterion=('valid', 'loss', 'min'), best_model_criterion=[['train', 'total_count', 'max']], keep_nbest_models=10, nbest_averaging_interval=0, grad_clip=-1, grad_clip_type=2.0, grad_noise=False, accum_grad=1, no_forward_run=False, resume=False, train_dtype='float32', use_amp=False, log_interval=50, use_matplotlib=True, use_tensorboard=True, create_graph_in_tensorboard=False, use_wandb=False, wandb_project=None, wandb_id=None, wandb_entity=None, wandb_name=None, wandb_model_log_interval=-1, detect_anomaly=False, use_adapter=False, adapter='lora', save_strategy='all', adapter_conf={}, pretrain_path=None, init_param=[], ignore_init_mismatch=False, freeze_param=[], num_iters_per_epoch=1000, batch_size=20, valid_batch_size=None, batch_bins=3000000, valid_batch_bins=None, category_sample_size=10, train_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.12.scp'], valid_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.12.scp'], batch_type='numel', valid_batch_type=None, fold_length=[], sort_in_batch='descending', shuffle_within_batch=False, sort_batch='descending', multiple_iterator=False, chunk_length=500, chunk_shift_ratio=0.5, num_cache_chunks=1024, chunk_excluded_key_prefixes=[], chunk_default_fs=None, chunk_max_abs_length=None, chunk_discard_short_samples=True, train_data_path_and_name_and_type=[('dump/22k/raw/tr_no_dev/text', 'text', 'text'), ('dump/22k/raw/tr_no_dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/tr_no_dev/utt2sid', 'sids', 'text_int')], valid_data_path_and_name_and_type=[('dump/22k/raw/dev/text', 'text', 'text'), ('dump/22k/raw/dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/dev/utt2sid', 'sids', 'text_int')], multi_task_dataset=False, allow_variable_data_keys=False, max_cache_size=0.0, max_cache_fd=32, allow_multi_rates=False, valid_max_cache_size=None, exclude_weight_decay=False, exclude_weight_decay_conf={}, optim='adamw', optim_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler='exponentiallr', scheduler_conf={'gamma': 0.999875}, optim2='adamw', optim2_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler2='exponentiallr', scheduler2_conf={'gamma': 0.999875}, generator_first=False, skip_discriminator_prob=0.0, token_list=['<blank>', '<unk>', ' ', 'AH0', 'N', 'T', 'D', 'S', 'R', 'L', 'IH1', 'DH', 'M', 'EH1', 'Z', 'AE1', 'K', 'IH0', 'AH1', 'HH', 'W', 'ER0', 'V', 'IY1', 'F', 'UW1', 'P', 'AY1', 'B', 'AA1', 'AO1', 'EY1', 'IY0', 'OW1', 'NG', 'SH', 'G', 'Y', 'AW1', 'CH', 'ER1', 'UH1', 'TH', 'JH', 'OW0', 'EH2', 'IH2', 'OY1', 'EY2', 'AY2', 'EH0', 'UW0', 'AA2', 'AE2', 'OW2', 'AH2', 'AA0', 'ZH', 'AE0', 'AO2', 'UW2', 'AO0', 'AY0', 'IY2', 'AW2', 'UH2', 'EY0', 'ER2', 'AW0', 'UH0', 'OY2', 'OY0', "'", '<sos/eos>'], odim=None, model_conf={}, use_preprocessor=True, token_type='phn', bpemodel=None, non_linguistic_symbols=None, cleaner='tacotron', g2p='g2p_en', feats_extract='linear_spectrogram', feats_extract_conf={'n_fft': 1024, 'hop_length': 256, 'win_length': None}, normalize=None, normalize_conf={}, tts='vits', tts_conf={'generator_type': 'vits_generator', 'generator_params': {'hidden_channels': 192, 'spks': 128, 'global_channels': 256, 'segment_size': 32, 'text_encoder_attention_heads': 2, 'text_encoder_ffn_expand': 4, 'text_encoder_blocks': 6, 'text_encoder_positionwise_layer_type': 'conv1d', 'text_encoder_positionwise_conv_kernel_size': 3, 'text_encoder_positional_encoding_layer_type': 'rel_pos', 'text_encoder_self_attention_layer_type': 'rel_selfattn', 'text_encoder_activation_type': 'swish', 'text_encoder_normalize_before': True, 'text_encoder_dropout_rate': 0.1, 'text_encoder_positional_dropout_rate': 0.0, 'text_encoder_attention_dropout_rate': 0.1, 'use_macaron_style_in_text_encoder': True, 'use_conformer_conv_in_text_encoder': False, 'text_encoder_conformer_kernel_size': -1, 'decoder_kernel_size': 7, 'decoder_channels': 512, 'decoder_upsample_scales': [8, 8, 2, 2], 'decoder_upsample_kernel_sizes': [16, 16, 4, 4], 'decoder_resblock_kernel_sizes': [3, 7, 11], 'decoder_resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'use_weight_norm_in_decoder': True, 'posterior_encoder_kernel_size': 5, 'posterior_encoder_layers': 16, 'posterior_encoder_stacks': 1, 'posterior_encoder_base_dilation': 1, 'posterior_encoder_dropout_rate': 0.0, 'use_weight_norm_in_posterior_encoder': True, 'flow_flows': 4, 'flow_kernel_size': 5, 'flow_base_dilation': 1, 'flow_layers': 4, 'flow_dropout_rate': 0.0, 'use_weight_norm_in_flow': True, 'use_only_mean_in_flow': True, 'stochastic_duration_predictor_kernel_size': 3, 'stochastic_duration_predictor_dropout_rate': 0.5, 'stochastic_duration_predictor_flows': 4, 'stochastic_duration_predictor_dds_conv_layers': 3, 'vocabs': 74, 'aux_channels': 513}, 'discriminator_type': 'hifigan_multi_scale_multi_period_discriminator', 'discriminator_params': {'scales': 1, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'stride': 2, 'padding': 2}, 'scale_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'channels': 128, 'max_downsample_channels': 1024, 'max_groups': 16, 'bias': True, 'downsample_scales': [2, 2, 4, 4, 1], 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}, 'follow_official_norm': False, 'periods': [2, 3, 5, 7, 11], 'period_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [5, 3], 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'max_downsample_channels': 1024, 'bias': True, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}}, 'generator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'discriminator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'feat_match_loss_params': {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, 'mel_loss_params': {'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None, 'window': 'hann', 'n_mels': 80, 'fmin': 0, 'fmax': None, 'log_base': None}, 'lambda_adv': 1.0, 'lambda_mel': 45.0, 'lambda_feat_match': 2.0, 'lambda_dur': 1.0, 'lambda_kl': 1.0, 'sampling_rate': 22050, 'cache_generator_outputs': True, 'plot_pred_mos': False, 'mos_pred_tool': 'utmos'}, pitch_extract=None, pitch_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'f0max': 400, 'f0min': 80}, pitch_normalize=None, pitch_normalize_conf={}, energy_extract=None, energy_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None}, energy_normalize=None, energy_normalize_conf={}, required=['output_dir', 'token_list'], version='202503', distributed=False)
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1284, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 71282) is killed by signal: Killed. 

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 22, in <module>
    main()
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 18, in main
    GANTTSTask.main(cmd=cmd)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1225, in main
    cls.main_worker(args)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1441, in main_worker
    collect_stats(
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/main_funcs/collect_stats.py", line 51, in collect_stats
    for iiter, (keys, batch) in enumerate(itr, 1):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 733, in __next__
    data = self._next_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1491, in _next_data
    idx, data = self._get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1453, in _get_data
    success, data = self._try_get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1297, in _try_get_data
    raise RuntimeError(
RuntimeError: DataLoader worker (pid(s) 71282) exited unexpectedly
# Accounting: begin_time=1750873256
# Accounting: end_time=1750873472
# Accounting: time=216 threads=1
# Finished at Wed Jun 25 13:44:32 EDT 2025 with status 1
# Running on r248.ib.bridges2.psc.edu
# Started at Wed Jun 25 13:40:56 EDT 2025
# SLURMD_NODENAME=r248
# SLURM_ARRAY_JOB_ID=32990217
# SLURM_ARRAY_TASK_COUNT=32
# SLURM_ARRAY_TASK_ID=13
# SLURM_ARRAY_TASK_MAX=32
# SLURM_ARRAY_TASK_MIN=1
# SLURM_ARRAY_TASK_STEP=1
# SLURM_CLUSTER_NAME=bridges2
# SLURM_CONF=/var/spool/slurm/d/conf-cache/slurm.conf
# SLURM_CPUS_ON_NODE=1
# SLURM_CPU_BIND=quiet,mask_cpu:0x07C0000000
# SLURM_CPU_BIND_LIST=0x07C0000000
# SLURM_CPU_BIND_TYPE=mask_cpu:
# SLURM_CPU_BIND_VERBOSE=quiet
# SLURM_EXPORT_ENV=ALL
# SLURM_GET_USER_ENV=1
# SLURM_GTIDS=0
# SLURM_JOBID=32990231
# SLURM_JOB_ACCOUNT=cis210027p
# SLURM_JOB_CPUS_PER_NODE=1
# SLURM_JOB_GID=24886
# SLURM_JOB_ID=32990231
# SLURM_JOB_NAME=stats.sh
# SLURM_JOB_NODELIST=r248
# SLURM_JOB_NUM_NODES=1
# SLURM_JOB_PARTITION=RM-shared
# SLURM_JOB_QOS=rm
# SLURM_JOB_UID=97947
# SLURM_JOB_USER=ttao3
# SLURM_LAUNCH_NODE_IPADDR=10.8.11.29
# SLURM_LOCALID=0
# SLURM_MEM_PER_CPU=1900
# SLURM_NNODES=1
# SLURM_NODEID=0
# SLURM_NODELIST=r248
# SLURM_NODE_ALIASES='(null)'
# SLURM_NPROCS=1
# SLURM_NTASKS=1
# SLURM_OPEN_MODE=a
# SLURM_PRIO_PROCESS=0
# SLURM_PROCID=0
# SLURM_PTY_PORT=33025
# SLURM_PTY_WIN_COL=126
# SLURM_PTY_WIN_ROW=21
# SLURM_SCRIPT_CONTEXT=prolog_task
# SLURM_SRUN_COMM_HOST=10.8.11.29
# SLURM_SRUN_COMM_PORT=35045
# SLURM_STEPID=0
# SLURM_STEP_GPUS=6
# SLURM_STEP_ID=0
# SLURM_STEP_LAUNCHER_PORT=35045
# SLURM_STEP_NODELIST=v029
# SLURM_STEP_NUM_NODES=1
# SLURM_STEP_NUM_TASKS=1
# SLURM_STEP_TASKS_PER_NODE=1
# SLURM_SUBMIT_DIR=/ocean/projects/cis210027p/ttao3/espnet/egs2/hifitts/tts1
# SLURM_SUBMIT_HOST=v029.ib.bridges2.psc.edu
# SLURM_TASKS_PER_NODE=1
# SLURM_TASK_PID=70655
# SLURM_TOPOLOGY_ADDR=r248
# SLURM_TOPOLOGY_ADDR_PATTERN=node
# SLURM_WORKING_CLUSTER=bridges2:br003:6810:9728:109
# python3 -m espnet2.bin.gan_tts_train --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.13.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.13.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.13 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int 
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/librosa/util/files.py:10: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_filename
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/bin/python3 /ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.13.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.13.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.13 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int
Failed to import Flash Attention, using ESPnet default: No module named 'flash_attn_2_cuda'
Vocabulary size: 74
encoder self-attention layer type = relative self-attention
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/ocean/projects/cis210027p/ttao3/espnet/espnet2/gan_tts/vits/monotonic_align/__init__.py:19: UserWarning: Cython version is not available. Fallback to 'EXPERIMETAL' numba version. If you want to use the cython version, please build it as follows: `cd espnet2/gan_tts/vits/monotonic_align; python setup.py build_ext --inplace`
  warnings.warn(
pytorch.version=2.7.1+cu126, cuda.available=False, cudnn.version=90501, cudnn.benchmark=False, cudnn.deterministic=False
Model structure:
ESPnetGANTTSModel(
  (feats_extract): LinearSpectrogram(
    (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
  )
  (tts): VITS(
    (generator): VITSGenerator(
      (text_encoder): TextEncoder(
        (emb): Embedding(74, 192)
        (encoder): Encoder(
          (embed): Sequential(
            (0): RelPositionalEncoding(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (encoders): MultiSequential(
            (0): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (2): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (3): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (4): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (5): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (after_norm): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (decoder): HiFiGANGenerator(
        (input_conv): Conv1d(192, 512, kernel_size=(7,), stride=(1,), padding=(3,))
        (upsamples): ModuleList(
          (0): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (1): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(256, 128, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (2): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,))
          )
          (3): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,))
          )
        )
        (blocks): ModuleList(
          (0): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (1): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (2): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (3): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (4): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (5): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (6): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (7): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (8): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (9): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (10): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (11): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
        )
        (output_conv): Sequential(
          (0): LeakyReLU(negative_slope=0.01)
          (1): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,))
          (2): Tanh()
        )
        (global_conv): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
      )
      (posterior_encoder): PosteriorEncoder(
        (input_conv): Conv1d(513, 192, kernel_size=(1,), stride=(1,))
        (encoder): WaveNet(
          (conv_layers): ModuleList(
            (0-15): 16 x ResidualBlock(
              (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
              (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
              (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
            )
          )
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (flow): ResidualAffineCouplingBlock(
        (flows): ModuleList(
          (0): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (1): FlipFlow()
          (2): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (3): FlipFlow()
          (4): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (5): FlipFlow()
          (6): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (7): FlipFlow()
        )
      )
      (duration_predictor): StochasticDurationPredictor(
        (pre): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (log_flow): LogFlow()
        (flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (post_pre): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
        (post_dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (post_proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (post_flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (global_conv): Conv1d(256, 192, kernel_size=(1,), stride=(1,))
      )
      (global_emb): Embedding(128, 256)
    )
    (discriminator): HiFiGANMultiScaleMultiPeriodDiscriminator(
      (msd): HiFiGANMultiScaleDiscriminator(
        (discriminators): ModuleList(
          (0): HiFiGANScaleDiscriminator(
            (layers): ModuleList(
              (0): Sequential(
                (0): Conv1d(1, 128, kernel_size=(15,), stride=(1,), padding=(7,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv1d(128, 128, kernel_size=(41,), stride=(2,), padding=(20,), groups=4)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv1d(128, 256, kernel_size=(41,), stride=(2,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv1d(256, 512, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv1d(512, 1024, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (5): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(41,), stride=(1,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (6): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (7): Conv1d(1024, 1, kernel_size=(3,), stride=(1,), padding=(1,))
            )
          )
        )
      )
      (mpd): HiFiGANMultiPeriodDiscriminator(
        (discriminators): ModuleList(
          (0-4): 5 x HiFiGANPeriodDiscriminator(
            (convs): ModuleList(
              (0): Sequential(
                (0): Conv2d(1, 32, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv2d(32, 128, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv2d(128, 512, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv2d(512, 1024, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv2d(1024, 1024, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
            )
            (output_conv): Conv2d(1024, 1, kernel_size=(2, 1), stride=(1, 1), padding=(1, 0))
          )
        )
      )
    )
    (generator_adv_loss): GeneratorAdversarialLoss()
    (discriminator_adv_loss): DiscriminatorAdversarialLoss()
    (feat_match_loss): FeatureMatchLoss()
    (mel_loss): MelSpectrogramLoss(
      (wav_to_mel): LogMelFbank(
        (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
        (logmel): LogMel(sr=22050, n_fft=1024, n_mels=80, fmin=0, fmax=11025.0, htk=False)
      )
    )
    (kl_loss): KLDivergenceLoss()
  )
)

Model summary:
    Class Name: ESPnetGANTTSModel
    Total Number of model parameters: 96.37 M
    Number of trainable parameters: 96.37 M (100.0%)
    Size: 385.46 MB
    Type: torch.float32
Optimizer:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler: <torch.optim.lr_scheduler.ExponentialLR object at 0x1531626ce610>
Optimizer2:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler2: <torch.optim.lr_scheduler.ExponentialLR object at 0x1531626cea00>
Saving the configuration in exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.13/config.yaml
Namespace(config='conf/tuning/train_multi_spk_vits.yaml', print_config=False, log_level='INFO', drop_last_iter=False, dry_run=False, iterator_type='sequence', valid_iterator_type=None, output_dir='exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.13', ngpu=0, seed=777, num_workers=4, num_att_plot=3, dist_backend='nccl', dist_init_method='env://', dist_world_size=None, dist_rank=None, local_rank=None, dist_master_addr=None, dist_master_port=None, dist_launcher=None, multiprocessing_distributed=False, unused_parameters=True, sharded_ddp=False, use_deepspeed=False, deepspeed_config=None, gradient_as_bucket_view=True, ddp_comm_hook=None, cudnn_enabled=True, cudnn_benchmark=False, cudnn_deterministic=False, use_tf32=False, collect_stats=True, write_collected_feats=False, max_epoch=1000, patience=None, val_scheduler_criterion=('valid', 'loss'), early_stopping_criterion=('valid', 'loss', 'min'), best_model_criterion=[['train', 'total_count', 'max']], keep_nbest_models=10, nbest_averaging_interval=0, grad_clip=-1, grad_clip_type=2.0, grad_noise=False, accum_grad=1, no_forward_run=False, resume=False, train_dtype='float32', use_amp=False, log_interval=50, use_matplotlib=True, use_tensorboard=True, create_graph_in_tensorboard=False, use_wandb=False, wandb_project=None, wandb_id=None, wandb_entity=None, wandb_name=None, wandb_model_log_interval=-1, detect_anomaly=False, use_adapter=False, adapter='lora', save_strategy='all', adapter_conf={}, pretrain_path=None, init_param=[], ignore_init_mismatch=False, freeze_param=[], num_iters_per_epoch=1000, batch_size=20, valid_batch_size=None, batch_bins=3000000, valid_batch_bins=None, category_sample_size=10, train_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.13.scp'], valid_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.13.scp'], batch_type='numel', valid_batch_type=None, fold_length=[], sort_in_batch='descending', shuffle_within_batch=False, sort_batch='descending', multiple_iterator=False, chunk_length=500, chunk_shift_ratio=0.5, num_cache_chunks=1024, chunk_excluded_key_prefixes=[], chunk_default_fs=None, chunk_max_abs_length=None, chunk_discard_short_samples=True, train_data_path_and_name_and_type=[('dump/22k/raw/tr_no_dev/text', 'text', 'text'), ('dump/22k/raw/tr_no_dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/tr_no_dev/utt2sid', 'sids', 'text_int')], valid_data_path_and_name_and_type=[('dump/22k/raw/dev/text', 'text', 'text'), ('dump/22k/raw/dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/dev/utt2sid', 'sids', 'text_int')], multi_task_dataset=False, allow_variable_data_keys=False, max_cache_size=0.0, max_cache_fd=32, allow_multi_rates=False, valid_max_cache_size=None, exclude_weight_decay=False, exclude_weight_decay_conf={}, optim='adamw', optim_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler='exponentiallr', scheduler_conf={'gamma': 0.999875}, optim2='adamw', optim2_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler2='exponentiallr', scheduler2_conf={'gamma': 0.999875}, generator_first=False, skip_discriminator_prob=0.0, token_list=['<blank>', '<unk>', ' ', 'AH0', 'N', 'T', 'D', 'S', 'R', 'L', 'IH1', 'DH', 'M', 'EH1', 'Z', 'AE1', 'K', 'IH0', 'AH1', 'HH', 'W', 'ER0', 'V', 'IY1', 'F', 'UW1', 'P', 'AY1', 'B', 'AA1', 'AO1', 'EY1', 'IY0', 'OW1', 'NG', 'SH', 'G', 'Y', 'AW1', 'CH', 'ER1', 'UH1', 'TH', 'JH', 'OW0', 'EH2', 'IH2', 'OY1', 'EY2', 'AY2', 'EH0', 'UW0', 'AA2', 'AE2', 'OW2', 'AH2', 'AA0', 'ZH', 'AE0', 'AO2', 'UW2', 'AO0', 'AY0', 'IY2', 'AW2', 'UH2', 'EY0', 'ER2', 'AW0', 'UH0', 'OY2', 'OY0', "'", '<sos/eos>'], odim=None, model_conf={}, use_preprocessor=True, token_type='phn', bpemodel=None, non_linguistic_symbols=None, cleaner='tacotron', g2p='g2p_en', feats_extract='linear_spectrogram', feats_extract_conf={'n_fft': 1024, 'hop_length': 256, 'win_length': None}, normalize=None, normalize_conf={}, tts='vits', tts_conf={'generator_type': 'vits_generator', 'generator_params': {'hidden_channels': 192, 'spks': 128, 'global_channels': 256, 'segment_size': 32, 'text_encoder_attention_heads': 2, 'text_encoder_ffn_expand': 4, 'text_encoder_blocks': 6, 'text_encoder_positionwise_layer_type': 'conv1d', 'text_encoder_positionwise_conv_kernel_size': 3, 'text_encoder_positional_encoding_layer_type': 'rel_pos', 'text_encoder_self_attention_layer_type': 'rel_selfattn', 'text_encoder_activation_type': 'swish', 'text_encoder_normalize_before': True, 'text_encoder_dropout_rate': 0.1, 'text_encoder_positional_dropout_rate': 0.0, 'text_encoder_attention_dropout_rate': 0.1, 'use_macaron_style_in_text_encoder': True, 'use_conformer_conv_in_text_encoder': False, 'text_encoder_conformer_kernel_size': -1, 'decoder_kernel_size': 7, 'decoder_channels': 512, 'decoder_upsample_scales': [8, 8, 2, 2], 'decoder_upsample_kernel_sizes': [16, 16, 4, 4], 'decoder_resblock_kernel_sizes': [3, 7, 11], 'decoder_resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'use_weight_norm_in_decoder': True, 'posterior_encoder_kernel_size': 5, 'posterior_encoder_layers': 16, 'posterior_encoder_stacks': 1, 'posterior_encoder_base_dilation': 1, 'posterior_encoder_dropout_rate': 0.0, 'use_weight_norm_in_posterior_encoder': True, 'flow_flows': 4, 'flow_kernel_size': 5, 'flow_base_dilation': 1, 'flow_layers': 4, 'flow_dropout_rate': 0.0, 'use_weight_norm_in_flow': True, 'use_only_mean_in_flow': True, 'stochastic_duration_predictor_kernel_size': 3, 'stochastic_duration_predictor_dropout_rate': 0.5, 'stochastic_duration_predictor_flows': 4, 'stochastic_duration_predictor_dds_conv_layers': 3, 'vocabs': 74, 'aux_channels': 513}, 'discriminator_type': 'hifigan_multi_scale_multi_period_discriminator', 'discriminator_params': {'scales': 1, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'stride': 2, 'padding': 2}, 'scale_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'channels': 128, 'max_downsample_channels': 1024, 'max_groups': 16, 'bias': True, 'downsample_scales': [2, 2, 4, 4, 1], 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}, 'follow_official_norm': False, 'periods': [2, 3, 5, 7, 11], 'period_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [5, 3], 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'max_downsample_channels': 1024, 'bias': True, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}}, 'generator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'discriminator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'feat_match_loss_params': {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, 'mel_loss_params': {'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None, 'window': 'hann', 'n_mels': 80, 'fmin': 0, 'fmax': None, 'log_base': None}, 'lambda_adv': 1.0, 'lambda_mel': 45.0, 'lambda_feat_match': 2.0, 'lambda_dur': 1.0, 'lambda_kl': 1.0, 'sampling_rate': 22050, 'cache_generator_outputs': True, 'plot_pred_mos': False, 'mos_pred_tool': 'utmos'}, pitch_extract=None, pitch_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'f0max': 400, 'f0min': 80}, pitch_normalize=None, pitch_normalize_conf={}, energy_extract=None, energy_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None}, energy_normalize=None, energy_normalize_conf={}, required=['output_dir', 'token_list'], version='202503', distributed=False)
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1284, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 71281) is killed by signal: Killed. 

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 22, in <module>
    main()
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 18, in main
    GANTTSTask.main(cmd=cmd)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1225, in main
    cls.main_worker(args)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1441, in main_worker
    collect_stats(
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/main_funcs/collect_stats.py", line 51, in collect_stats
    for iiter, (keys, batch) in enumerate(itr, 1):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 733, in __next__
    data = self._next_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1491, in _next_data
    idx, data = self._get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1453, in _get_data
    success, data = self._try_get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1297, in _try_get_data
    raise RuntimeError(
RuntimeError: DataLoader worker (pid(s) 71281) exited unexpectedly
# Accounting: begin_time=1750873256
# Accounting: end_time=1750873472
# Accounting: time=216 threads=1
# Finished at Wed Jun 25 13:44:32 EDT 2025 with status 1
# Running on r278.ib.bridges2.psc.edu
# Started at Wed Jun 25 13:42:12 EDT 2025
# SLURMD_NODENAME=r278
# SLURM_ARRAY_JOB_ID=32990217
# SLURM_ARRAY_TASK_COUNT=32
# SLURM_ARRAY_TASK_ID=14
# SLURM_ARRAY_TASK_MAX=32
# SLURM_ARRAY_TASK_MIN=1
# SLURM_ARRAY_TASK_STEP=1
# SLURM_CLUSTER_NAME=bridges2
# SLURM_CONF=/var/spool/slurm/d/conf-cache/slurm.conf
# SLURM_CPUS_ON_NODE=1
# SLURM_CPU_BIND=quiet,mask_cpu:0x07C0000000
# SLURM_CPU_BIND_LIST=0x07C0000000
# SLURM_CPU_BIND_TYPE=mask_cpu:
# SLURM_CPU_BIND_VERBOSE=quiet
# SLURM_EXPORT_ENV=ALL
# SLURM_GET_USER_ENV=1
# SLURM_GTIDS=0
# SLURM_JOBID=32990232
# SLURM_JOB_ACCOUNT=cis210027p
# SLURM_JOB_CPUS_PER_NODE=1
# SLURM_JOB_GID=24886
# SLURM_JOB_ID=32990232
# SLURM_JOB_NAME=stats.sh
# SLURM_JOB_NODELIST=r278
# SLURM_JOB_NUM_NODES=1
# SLURM_JOB_PARTITION=RM-shared
# SLURM_JOB_QOS=rm
# SLURM_JOB_UID=97947
# SLURM_JOB_USER=ttao3
# SLURM_LAUNCH_NODE_IPADDR=10.8.11.29
# SLURM_LOCALID=0
# SLURM_MEM_PER_CPU=1900
# SLURM_NNODES=1
# SLURM_NODEID=0
# SLURM_NODELIST=r278
# SLURM_NODE_ALIASES='(null)'
# SLURM_NPROCS=1
# SLURM_NTASKS=1
# SLURM_OPEN_MODE=a
# SLURM_PRIO_PROCESS=0
# SLURM_PROCID=0
# SLURM_PTY_PORT=33025
# SLURM_PTY_WIN_COL=126
# SLURM_PTY_WIN_ROW=21
# SLURM_SCRIPT_CONTEXT=prolog_task
# SLURM_SRUN_COMM_HOST=10.8.11.29
# SLURM_SRUN_COMM_PORT=35045
# SLURM_STEPID=0
# SLURM_STEP_GPUS=6
# SLURM_STEP_ID=0
# SLURM_STEP_LAUNCHER_PORT=35045
# SLURM_STEP_NODELIST=v029
# SLURM_STEP_NUM_NODES=1
# SLURM_STEP_NUM_TASKS=1
# SLURM_STEP_TASKS_PER_NODE=1
# SLURM_SUBMIT_DIR=/ocean/projects/cis210027p/ttao3/espnet/egs2/hifitts/tts1
# SLURM_SUBMIT_HOST=v029.ib.bridges2.psc.edu
# SLURM_TASKS_PER_NODE=1
# SLURM_TASK_PID=72654
# SLURM_TOPOLOGY_ADDR=r278
# SLURM_TOPOLOGY_ADDR_PATTERN=node
# SLURM_WORKING_CLUSTER=bridges2:br003:6810:9728:109
# python3 -m espnet2.bin.gan_tts_train --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.14.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.14.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.14 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int 
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/librosa/util/files.py:10: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_filename
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/bin/python3 /ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.14.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.14.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.14 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int
Failed to import Flash Attention, using ESPnet default: No module named 'flash_attn_2_cuda'
Vocabulary size: 74
encoder self-attention layer type = relative self-attention
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/ocean/projects/cis210027p/ttao3/espnet/espnet2/gan_tts/vits/monotonic_align/__init__.py:19: UserWarning: Cython version is not available. Fallback to 'EXPERIMETAL' numba version. If you want to use the cython version, please build it as follows: `cd espnet2/gan_tts/vits/monotonic_align; python setup.py build_ext --inplace`
  warnings.warn(
pytorch.version=2.7.1+cu126, cuda.available=False, cudnn.version=90501, cudnn.benchmark=False, cudnn.deterministic=False
Model structure:
ESPnetGANTTSModel(
  (feats_extract): LinearSpectrogram(
    (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
  )
  (tts): VITS(
    (generator): VITSGenerator(
      (text_encoder): TextEncoder(
        (emb): Embedding(74, 192)
        (encoder): Encoder(
          (embed): Sequential(
            (0): RelPositionalEncoding(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (encoders): MultiSequential(
            (0): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (2): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (3): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (4): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (5): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (after_norm): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (decoder): HiFiGANGenerator(
        (input_conv): Conv1d(192, 512, kernel_size=(7,), stride=(1,), padding=(3,))
        (upsamples): ModuleList(
          (0): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (1): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(256, 128, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (2): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,))
          )
          (3): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,))
          )
        )
        (blocks): ModuleList(
          (0): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (1): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (2): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (3): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (4): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (5): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (6): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (7): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (8): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (9): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (10): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (11): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
        )
        (output_conv): Sequential(
          (0): LeakyReLU(negative_slope=0.01)
          (1): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,))
          (2): Tanh()
        )
        (global_conv): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
      )
      (posterior_encoder): PosteriorEncoder(
        (input_conv): Conv1d(513, 192, kernel_size=(1,), stride=(1,))
        (encoder): WaveNet(
          (conv_layers): ModuleList(
            (0-15): 16 x ResidualBlock(
              (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
              (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
              (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
            )
          )
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (flow): ResidualAffineCouplingBlock(
        (flows): ModuleList(
          (0): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (1): FlipFlow()
          (2): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (3): FlipFlow()
          (4): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (5): FlipFlow()
          (6): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (7): FlipFlow()
        )
      )
      (duration_predictor): StochasticDurationPredictor(
        (pre): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (log_flow): LogFlow()
        (flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (post_pre): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
        (post_dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (post_proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (post_flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (global_conv): Conv1d(256, 192, kernel_size=(1,), stride=(1,))
      )
      (global_emb): Embedding(128, 256)
    )
    (discriminator): HiFiGANMultiScaleMultiPeriodDiscriminator(
      (msd): HiFiGANMultiScaleDiscriminator(
        (discriminators): ModuleList(
          (0): HiFiGANScaleDiscriminator(
            (layers): ModuleList(
              (0): Sequential(
                (0): Conv1d(1, 128, kernel_size=(15,), stride=(1,), padding=(7,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv1d(128, 128, kernel_size=(41,), stride=(2,), padding=(20,), groups=4)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv1d(128, 256, kernel_size=(41,), stride=(2,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv1d(256, 512, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv1d(512, 1024, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (5): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(41,), stride=(1,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (6): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (7): Conv1d(1024, 1, kernel_size=(3,), stride=(1,), padding=(1,))
            )
          )
        )
      )
      (mpd): HiFiGANMultiPeriodDiscriminator(
        (discriminators): ModuleList(
          (0-4): 5 x HiFiGANPeriodDiscriminator(
            (convs): ModuleList(
              (0): Sequential(
                (0): Conv2d(1, 32, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv2d(32, 128, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv2d(128, 512, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv2d(512, 1024, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv2d(1024, 1024, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
            )
            (output_conv): Conv2d(1024, 1, kernel_size=(2, 1), stride=(1, 1), padding=(1, 0))
          )
        )
      )
    )
    (generator_adv_loss): GeneratorAdversarialLoss()
    (discriminator_adv_loss): DiscriminatorAdversarialLoss()
    (feat_match_loss): FeatureMatchLoss()
    (mel_loss): MelSpectrogramLoss(
      (wav_to_mel): LogMelFbank(
        (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
        (logmel): LogMel(sr=22050, n_fft=1024, n_mels=80, fmin=0, fmax=11025.0, htk=False)
      )
    )
    (kl_loss): KLDivergenceLoss()
  )
)

Model summary:
    Class Name: ESPnetGANTTSModel
    Total Number of model parameters: 96.37 M
    Number of trainable parameters: 96.37 M (100.0%)
    Size: 385.46 MB
    Type: torch.float32
Optimizer:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler: <torch.optim.lr_scheduler.ExponentialLR object at 0x1508725c5640>
Optimizer2:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler2: <torch.optim.lr_scheduler.ExponentialLR object at 0x1508725c5a30>
Saving the configuration in exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.14/config.yaml
Namespace(config='conf/tuning/train_multi_spk_vits.yaml', print_config=False, log_level='INFO', drop_last_iter=False, dry_run=False, iterator_type='sequence', valid_iterator_type=None, output_dir='exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.14', ngpu=0, seed=777, num_workers=4, num_att_plot=3, dist_backend='nccl', dist_init_method='env://', dist_world_size=None, dist_rank=None, local_rank=None, dist_master_addr=None, dist_master_port=None, dist_launcher=None, multiprocessing_distributed=False, unused_parameters=True, sharded_ddp=False, use_deepspeed=False, deepspeed_config=None, gradient_as_bucket_view=True, ddp_comm_hook=None, cudnn_enabled=True, cudnn_benchmark=False, cudnn_deterministic=False, use_tf32=False, collect_stats=True, write_collected_feats=False, max_epoch=1000, patience=None, val_scheduler_criterion=('valid', 'loss'), early_stopping_criterion=('valid', 'loss', 'min'), best_model_criterion=[['train', 'total_count', 'max']], keep_nbest_models=10, nbest_averaging_interval=0, grad_clip=-1, grad_clip_type=2.0, grad_noise=False, accum_grad=1, no_forward_run=False, resume=False, train_dtype='float32', use_amp=False, log_interval=50, use_matplotlib=True, use_tensorboard=True, create_graph_in_tensorboard=False, use_wandb=False, wandb_project=None, wandb_id=None, wandb_entity=None, wandb_name=None, wandb_model_log_interval=-1, detect_anomaly=False, use_adapter=False, adapter='lora', save_strategy='all', adapter_conf={}, pretrain_path=None, init_param=[], ignore_init_mismatch=False, freeze_param=[], num_iters_per_epoch=1000, batch_size=20, valid_batch_size=None, batch_bins=3000000, valid_batch_bins=None, category_sample_size=10, train_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.14.scp'], valid_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.14.scp'], batch_type='numel', valid_batch_type=None, fold_length=[], sort_in_batch='descending', shuffle_within_batch=False, sort_batch='descending', multiple_iterator=False, chunk_length=500, chunk_shift_ratio=0.5, num_cache_chunks=1024, chunk_excluded_key_prefixes=[], chunk_default_fs=None, chunk_max_abs_length=None, chunk_discard_short_samples=True, train_data_path_and_name_and_type=[('dump/22k/raw/tr_no_dev/text', 'text', 'text'), ('dump/22k/raw/tr_no_dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/tr_no_dev/utt2sid', 'sids', 'text_int')], valid_data_path_and_name_and_type=[('dump/22k/raw/dev/text', 'text', 'text'), ('dump/22k/raw/dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/dev/utt2sid', 'sids', 'text_int')], multi_task_dataset=False, allow_variable_data_keys=False, max_cache_size=0.0, max_cache_fd=32, allow_multi_rates=False, valid_max_cache_size=None, exclude_weight_decay=False, exclude_weight_decay_conf={}, optim='adamw', optim_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler='exponentiallr', scheduler_conf={'gamma': 0.999875}, optim2='adamw', optim2_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler2='exponentiallr', scheduler2_conf={'gamma': 0.999875}, generator_first=False, skip_discriminator_prob=0.0, token_list=['<blank>', '<unk>', ' ', 'AH0', 'N', 'T', 'D', 'S', 'R', 'L', 'IH1', 'DH', 'M', 'EH1', 'Z', 'AE1', 'K', 'IH0', 'AH1', 'HH', 'W', 'ER0', 'V', 'IY1', 'F', 'UW1', 'P', 'AY1', 'B', 'AA1', 'AO1', 'EY1', 'IY0', 'OW1', 'NG', 'SH', 'G', 'Y', 'AW1', 'CH', 'ER1', 'UH1', 'TH', 'JH', 'OW0', 'EH2', 'IH2', 'OY1', 'EY2', 'AY2', 'EH0', 'UW0', 'AA2', 'AE2', 'OW2', 'AH2', 'AA0', 'ZH', 'AE0', 'AO2', 'UW2', 'AO0', 'AY0', 'IY2', 'AW2', 'UH2', 'EY0', 'ER2', 'AW0', 'UH0', 'OY2', 'OY0', "'", '<sos/eos>'], odim=None, model_conf={}, use_preprocessor=True, token_type='phn', bpemodel=None, non_linguistic_symbols=None, cleaner='tacotron', g2p='g2p_en', feats_extract='linear_spectrogram', feats_extract_conf={'n_fft': 1024, 'hop_length': 256, 'win_length': None}, normalize=None, normalize_conf={}, tts='vits', tts_conf={'generator_type': 'vits_generator', 'generator_params': {'hidden_channels': 192, 'spks': 128, 'global_channels': 256, 'segment_size': 32, 'text_encoder_attention_heads': 2, 'text_encoder_ffn_expand': 4, 'text_encoder_blocks': 6, 'text_encoder_positionwise_layer_type': 'conv1d', 'text_encoder_positionwise_conv_kernel_size': 3, 'text_encoder_positional_encoding_layer_type': 'rel_pos', 'text_encoder_self_attention_layer_type': 'rel_selfattn', 'text_encoder_activation_type': 'swish', 'text_encoder_normalize_before': True, 'text_encoder_dropout_rate': 0.1, 'text_encoder_positional_dropout_rate': 0.0, 'text_encoder_attention_dropout_rate': 0.1, 'use_macaron_style_in_text_encoder': True, 'use_conformer_conv_in_text_encoder': False, 'text_encoder_conformer_kernel_size': -1, 'decoder_kernel_size': 7, 'decoder_channels': 512, 'decoder_upsample_scales': [8, 8, 2, 2], 'decoder_upsample_kernel_sizes': [16, 16, 4, 4], 'decoder_resblock_kernel_sizes': [3, 7, 11], 'decoder_resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'use_weight_norm_in_decoder': True, 'posterior_encoder_kernel_size': 5, 'posterior_encoder_layers': 16, 'posterior_encoder_stacks': 1, 'posterior_encoder_base_dilation': 1, 'posterior_encoder_dropout_rate': 0.0, 'use_weight_norm_in_posterior_encoder': True, 'flow_flows': 4, 'flow_kernel_size': 5, 'flow_base_dilation': 1, 'flow_layers': 4, 'flow_dropout_rate': 0.0, 'use_weight_norm_in_flow': True, 'use_only_mean_in_flow': True, 'stochastic_duration_predictor_kernel_size': 3, 'stochastic_duration_predictor_dropout_rate': 0.5, 'stochastic_duration_predictor_flows': 4, 'stochastic_duration_predictor_dds_conv_layers': 3, 'vocabs': 74, 'aux_channels': 513}, 'discriminator_type': 'hifigan_multi_scale_multi_period_discriminator', 'discriminator_params': {'scales': 1, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'stride': 2, 'padding': 2}, 'scale_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'channels': 128, 'max_downsample_channels': 1024, 'max_groups': 16, 'bias': True, 'downsample_scales': [2, 2, 4, 4, 1], 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}, 'follow_official_norm': False, 'periods': [2, 3, 5, 7, 11], 'period_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [5, 3], 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'max_downsample_channels': 1024, 'bias': True, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}}, 'generator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'discriminator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'feat_match_loss_params': {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, 'mel_loss_params': {'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None, 'window': 'hann', 'n_mels': 80, 'fmin': 0, 'fmax': None, 'log_base': None}, 'lambda_adv': 1.0, 'lambda_mel': 45.0, 'lambda_feat_match': 2.0, 'lambda_dur': 1.0, 'lambda_kl': 1.0, 'sampling_rate': 22050, 'cache_generator_outputs': True, 'plot_pred_mos': False, 'mos_pred_tool': 'utmos'}, pitch_extract=None, pitch_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'f0max': 400, 'f0min': 80}, pitch_normalize=None, pitch_normalize_conf={}, energy_extract=None, energy_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None}, energy_normalize=None, energy_normalize_conf={}, required=['output_dir', 'token_list'], version='202503', distributed=False)
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1284, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 72722) is killed by signal: Killed. 

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 22, in <module>
    main()
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 18, in main
    GANTTSTask.main(cmd=cmd)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1225, in main
    cls.main_worker(args)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1441, in main_worker
    collect_stats(
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/main_funcs/collect_stats.py", line 51, in collect_stats
    for iiter, (keys, batch) in enumerate(itr, 1):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 733, in __next__
    data = self._next_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1491, in _next_data
    idx, data = self._get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1453, in _get_data
    success, data = self._try_get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1297, in _try_get_data
    raise RuntimeError(
RuntimeError: DataLoader worker (pid(s) 72722) exited unexpectedly
# Accounting: begin_time=1750873332
# Accounting: end_time=1750873472
# Accounting: time=140 threads=1
# Finished at Wed Jun 25 13:44:32 EDT 2025 with status 1
# Running on r278.ib.bridges2.psc.edu
# Started at Wed Jun 25 13:42:12 EDT 2025
# SLURMD_NODENAME=r278
# SLURM_ARRAY_JOB_ID=32990217
# SLURM_ARRAY_TASK_COUNT=32
# SLURM_ARRAY_TASK_ID=15
# SLURM_ARRAY_TASK_MAX=32
# SLURM_ARRAY_TASK_MIN=1
# SLURM_ARRAY_TASK_STEP=1
# SLURM_CLUSTER_NAME=bridges2
# SLURM_CONF=/var/spool/slurm/d/conf-cache/slurm.conf
# SLURM_CPUS_ON_NODE=1
# SLURM_CPU_BIND=quiet,mask_cpu:0x07C0000000
# SLURM_CPU_BIND_LIST=0x07C0000000
# SLURM_CPU_BIND_TYPE=mask_cpu:
# SLURM_CPU_BIND_VERBOSE=quiet
# SLURM_EXPORT_ENV=ALL
# SLURM_GET_USER_ENV=1
# SLURM_GTIDS=0
# SLURM_JOBID=32990233
# SLURM_JOB_ACCOUNT=cis210027p
# SLURM_JOB_CPUS_PER_NODE=1
# SLURM_JOB_GID=24886
# SLURM_JOB_ID=32990233
# SLURM_JOB_NAME=stats.sh
# SLURM_JOB_NODELIST=r278
# SLURM_JOB_NUM_NODES=1
# SLURM_JOB_PARTITION=RM-shared
# SLURM_JOB_QOS=rm
# SLURM_JOB_UID=97947
# SLURM_JOB_USER=ttao3
# SLURM_LAUNCH_NODE_IPADDR=10.8.11.29
# SLURM_LOCALID=0
# SLURM_MEM_PER_CPU=1900
# SLURM_NNODES=1
# SLURM_NODEID=0
# SLURM_NODELIST=r278
# SLURM_NODE_ALIASES='(null)'
# SLURM_NPROCS=1
# SLURM_NTASKS=1
# SLURM_OPEN_MODE=a
# SLURM_PRIO_PROCESS=0
# SLURM_PROCID=0
# SLURM_PTY_PORT=33025
# SLURM_PTY_WIN_COL=126
# SLURM_PTY_WIN_ROW=21
# SLURM_SCRIPT_CONTEXT=prolog_task
# SLURM_SRUN_COMM_HOST=10.8.11.29
# SLURM_SRUN_COMM_PORT=35045
# SLURM_STEPID=0
# SLURM_STEP_GPUS=6
# SLURM_STEP_ID=0
# SLURM_STEP_LAUNCHER_PORT=35045
# SLURM_STEP_NODELIST=v029
# SLURM_STEP_NUM_NODES=1
# SLURM_STEP_NUM_TASKS=1
# SLURM_STEP_TASKS_PER_NODE=1
# SLURM_SUBMIT_DIR=/ocean/projects/cis210027p/ttao3/espnet/egs2/hifitts/tts1
# SLURM_SUBMIT_HOST=v029.ib.bridges2.psc.edu
# SLURM_TASKS_PER_NODE=1
# SLURM_TASK_PID=72653
# SLURM_TOPOLOGY_ADDR=r278
# SLURM_TOPOLOGY_ADDR_PATTERN=node
# SLURM_WORKING_CLUSTER=bridges2:br003:6810:9728:109
# python3 -m espnet2.bin.gan_tts_train --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.15.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.15.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.15 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int 
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/librosa/util/files.py:10: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_filename
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/bin/python3 /ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.15.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.15.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.15 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int
Failed to import Flash Attention, using ESPnet default: No module named 'flash_attn_2_cuda'
Vocabulary size: 74
encoder self-attention layer type = relative self-attention
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/ocean/projects/cis210027p/ttao3/espnet/espnet2/gan_tts/vits/monotonic_align/__init__.py:19: UserWarning: Cython version is not available. Fallback to 'EXPERIMETAL' numba version. If you want to use the cython version, please build it as follows: `cd espnet2/gan_tts/vits/monotonic_align; python setup.py build_ext --inplace`
  warnings.warn(
pytorch.version=2.7.1+cu126, cuda.available=False, cudnn.version=90501, cudnn.benchmark=False, cudnn.deterministic=False
Model structure:
ESPnetGANTTSModel(
  (feats_extract): LinearSpectrogram(
    (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
  )
  (tts): VITS(
    (generator): VITSGenerator(
      (text_encoder): TextEncoder(
        (emb): Embedding(74, 192)
        (encoder): Encoder(
          (embed): Sequential(
            (0): RelPositionalEncoding(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (encoders): MultiSequential(
            (0): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (2): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (3): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (4): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (5): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (after_norm): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (decoder): HiFiGANGenerator(
        (input_conv): Conv1d(192, 512, kernel_size=(7,), stride=(1,), padding=(3,))
        (upsamples): ModuleList(
          (0): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (1): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(256, 128, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (2): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,))
          )
          (3): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,))
          )
        )
        (blocks): ModuleList(
          (0): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (1): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (2): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (3): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (4): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (5): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (6): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (7): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (8): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (9): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (10): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (11): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
        )
        (output_conv): Sequential(
          (0): LeakyReLU(negative_slope=0.01)
          (1): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,))
          (2): Tanh()
        )
        (global_conv): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
      )
      (posterior_encoder): PosteriorEncoder(
        (input_conv): Conv1d(513, 192, kernel_size=(1,), stride=(1,))
        (encoder): WaveNet(
          (conv_layers): ModuleList(
            (0-15): 16 x ResidualBlock(
              (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
              (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
              (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
            )
          )
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (flow): ResidualAffineCouplingBlock(
        (flows): ModuleList(
          (0): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (1): FlipFlow()
          (2): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (3): FlipFlow()
          (4): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (5): FlipFlow()
          (6): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (7): FlipFlow()
        )
      )
      (duration_predictor): StochasticDurationPredictor(
        (pre): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (log_flow): LogFlow()
        (flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (post_pre): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
        (post_dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (post_proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (post_flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (global_conv): Conv1d(256, 192, kernel_size=(1,), stride=(1,))
      )
      (global_emb): Embedding(128, 256)
    )
    (discriminator): HiFiGANMultiScaleMultiPeriodDiscriminator(
      (msd): HiFiGANMultiScaleDiscriminator(
        (discriminators): ModuleList(
          (0): HiFiGANScaleDiscriminator(
            (layers): ModuleList(
              (0): Sequential(
                (0): Conv1d(1, 128, kernel_size=(15,), stride=(1,), padding=(7,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv1d(128, 128, kernel_size=(41,), stride=(2,), padding=(20,), groups=4)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv1d(128, 256, kernel_size=(41,), stride=(2,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv1d(256, 512, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv1d(512, 1024, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (5): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(41,), stride=(1,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (6): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (7): Conv1d(1024, 1, kernel_size=(3,), stride=(1,), padding=(1,))
            )
          )
        )
      )
      (mpd): HiFiGANMultiPeriodDiscriminator(
        (discriminators): ModuleList(
          (0-4): 5 x HiFiGANPeriodDiscriminator(
            (convs): ModuleList(
              (0): Sequential(
                (0): Conv2d(1, 32, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv2d(32, 128, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv2d(128, 512, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv2d(512, 1024, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv2d(1024, 1024, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
            )
            (output_conv): Conv2d(1024, 1, kernel_size=(2, 1), stride=(1, 1), padding=(1, 0))
          )
        )
      )
    )
    (generator_adv_loss): GeneratorAdversarialLoss()
    (discriminator_adv_loss): DiscriminatorAdversarialLoss()
    (feat_match_loss): FeatureMatchLoss()
    (mel_loss): MelSpectrogramLoss(
      (wav_to_mel): LogMelFbank(
        (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
        (logmel): LogMel(sr=22050, n_fft=1024, n_mels=80, fmin=0, fmax=11025.0, htk=False)
      )
    )
    (kl_loss): KLDivergenceLoss()
  )
)

Model summary:
    Class Name: ESPnetGANTTSModel
    Total Number of model parameters: 96.37 M
    Number of trainable parameters: 96.37 M (100.0%)
    Size: 385.46 MB
    Type: torch.float32
Optimizer:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler: <torch.optim.lr_scheduler.ExponentialLR object at 0x1529f97a8640>
Optimizer2:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler2: <torch.optim.lr_scheduler.ExponentialLR object at 0x1529f97a8a30>
Saving the configuration in exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.15/config.yaml
Namespace(config='conf/tuning/train_multi_spk_vits.yaml', print_config=False, log_level='INFO', drop_last_iter=False, dry_run=False, iterator_type='sequence', valid_iterator_type=None, output_dir='exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.15', ngpu=0, seed=777, num_workers=4, num_att_plot=3, dist_backend='nccl', dist_init_method='env://', dist_world_size=None, dist_rank=None, local_rank=None, dist_master_addr=None, dist_master_port=None, dist_launcher=None, multiprocessing_distributed=False, unused_parameters=True, sharded_ddp=False, use_deepspeed=False, deepspeed_config=None, gradient_as_bucket_view=True, ddp_comm_hook=None, cudnn_enabled=True, cudnn_benchmark=False, cudnn_deterministic=False, use_tf32=False, collect_stats=True, write_collected_feats=False, max_epoch=1000, patience=None, val_scheduler_criterion=('valid', 'loss'), early_stopping_criterion=('valid', 'loss', 'min'), best_model_criterion=[['train', 'total_count', 'max']], keep_nbest_models=10, nbest_averaging_interval=0, grad_clip=-1, grad_clip_type=2.0, grad_noise=False, accum_grad=1, no_forward_run=False, resume=False, train_dtype='float32', use_amp=False, log_interval=50, use_matplotlib=True, use_tensorboard=True, create_graph_in_tensorboard=False, use_wandb=False, wandb_project=None, wandb_id=None, wandb_entity=None, wandb_name=None, wandb_model_log_interval=-1, detect_anomaly=False, use_adapter=False, adapter='lora', save_strategy='all', adapter_conf={}, pretrain_path=None, init_param=[], ignore_init_mismatch=False, freeze_param=[], num_iters_per_epoch=1000, batch_size=20, valid_batch_size=None, batch_bins=3000000, valid_batch_bins=None, category_sample_size=10, train_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.15.scp'], valid_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.15.scp'], batch_type='numel', valid_batch_type=None, fold_length=[], sort_in_batch='descending', shuffle_within_batch=False, sort_batch='descending', multiple_iterator=False, chunk_length=500, chunk_shift_ratio=0.5, num_cache_chunks=1024, chunk_excluded_key_prefixes=[], chunk_default_fs=None, chunk_max_abs_length=None, chunk_discard_short_samples=True, train_data_path_and_name_and_type=[('dump/22k/raw/tr_no_dev/text', 'text', 'text'), ('dump/22k/raw/tr_no_dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/tr_no_dev/utt2sid', 'sids', 'text_int')], valid_data_path_and_name_and_type=[('dump/22k/raw/dev/text', 'text', 'text'), ('dump/22k/raw/dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/dev/utt2sid', 'sids', 'text_int')], multi_task_dataset=False, allow_variable_data_keys=False, max_cache_size=0.0, max_cache_fd=32, allow_multi_rates=False, valid_max_cache_size=None, exclude_weight_decay=False, exclude_weight_decay_conf={}, optim='adamw', optim_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler='exponentiallr', scheduler_conf={'gamma': 0.999875}, optim2='adamw', optim2_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler2='exponentiallr', scheduler2_conf={'gamma': 0.999875}, generator_first=False, skip_discriminator_prob=0.0, token_list=['<blank>', '<unk>', ' ', 'AH0', 'N', 'T', 'D', 'S', 'R', 'L', 'IH1', 'DH', 'M', 'EH1', 'Z', 'AE1', 'K', 'IH0', 'AH1', 'HH', 'W', 'ER0', 'V', 'IY1', 'F', 'UW1', 'P', 'AY1', 'B', 'AA1', 'AO1', 'EY1', 'IY0', 'OW1', 'NG', 'SH', 'G', 'Y', 'AW1', 'CH', 'ER1', 'UH1', 'TH', 'JH', 'OW0', 'EH2', 'IH2', 'OY1', 'EY2', 'AY2', 'EH0', 'UW0', 'AA2', 'AE2', 'OW2', 'AH2', 'AA0', 'ZH', 'AE0', 'AO2', 'UW2', 'AO0', 'AY0', 'IY2', 'AW2', 'UH2', 'EY0', 'ER2', 'AW0', 'UH0', 'OY2', 'OY0', "'", '<sos/eos>'], odim=None, model_conf={}, use_preprocessor=True, token_type='phn', bpemodel=None, non_linguistic_symbols=None, cleaner='tacotron', g2p='g2p_en', feats_extract='linear_spectrogram', feats_extract_conf={'n_fft': 1024, 'hop_length': 256, 'win_length': None}, normalize=None, normalize_conf={}, tts='vits', tts_conf={'generator_type': 'vits_generator', 'generator_params': {'hidden_channels': 192, 'spks': 128, 'global_channels': 256, 'segment_size': 32, 'text_encoder_attention_heads': 2, 'text_encoder_ffn_expand': 4, 'text_encoder_blocks': 6, 'text_encoder_positionwise_layer_type': 'conv1d', 'text_encoder_positionwise_conv_kernel_size': 3, 'text_encoder_positional_encoding_layer_type': 'rel_pos', 'text_encoder_self_attention_layer_type': 'rel_selfattn', 'text_encoder_activation_type': 'swish', 'text_encoder_normalize_before': True, 'text_encoder_dropout_rate': 0.1, 'text_encoder_positional_dropout_rate': 0.0, 'text_encoder_attention_dropout_rate': 0.1, 'use_macaron_style_in_text_encoder': True, 'use_conformer_conv_in_text_encoder': False, 'text_encoder_conformer_kernel_size': -1, 'decoder_kernel_size': 7, 'decoder_channels': 512, 'decoder_upsample_scales': [8, 8, 2, 2], 'decoder_upsample_kernel_sizes': [16, 16, 4, 4], 'decoder_resblock_kernel_sizes': [3, 7, 11], 'decoder_resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'use_weight_norm_in_decoder': True, 'posterior_encoder_kernel_size': 5, 'posterior_encoder_layers': 16, 'posterior_encoder_stacks': 1, 'posterior_encoder_base_dilation': 1, 'posterior_encoder_dropout_rate': 0.0, 'use_weight_norm_in_posterior_encoder': True, 'flow_flows': 4, 'flow_kernel_size': 5, 'flow_base_dilation': 1, 'flow_layers': 4, 'flow_dropout_rate': 0.0, 'use_weight_norm_in_flow': True, 'use_only_mean_in_flow': True, 'stochastic_duration_predictor_kernel_size': 3, 'stochastic_duration_predictor_dropout_rate': 0.5, 'stochastic_duration_predictor_flows': 4, 'stochastic_duration_predictor_dds_conv_layers': 3, 'vocabs': 74, 'aux_channels': 513}, 'discriminator_type': 'hifigan_multi_scale_multi_period_discriminator', 'discriminator_params': {'scales': 1, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'stride': 2, 'padding': 2}, 'scale_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'channels': 128, 'max_downsample_channels': 1024, 'max_groups': 16, 'bias': True, 'downsample_scales': [2, 2, 4, 4, 1], 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}, 'follow_official_norm': False, 'periods': [2, 3, 5, 7, 11], 'period_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [5, 3], 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'max_downsample_channels': 1024, 'bias': True, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}}, 'generator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'discriminator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'feat_match_loss_params': {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, 'mel_loss_params': {'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None, 'window': 'hann', 'n_mels': 80, 'fmin': 0, 'fmax': None, 'log_base': None}, 'lambda_adv': 1.0, 'lambda_mel': 45.0, 'lambda_feat_match': 2.0, 'lambda_dur': 1.0, 'lambda_kl': 1.0, 'sampling_rate': 22050, 'cache_generator_outputs': True, 'plot_pred_mos': False, 'mos_pred_tool': 'utmos'}, pitch_extract=None, pitch_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'f0max': 400, 'f0min': 80}, pitch_normalize=None, pitch_normalize_conf={}, energy_extract=None, energy_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None}, energy_normalize=None, energy_normalize_conf={}, required=['output_dir', 'token_list'], version='202503', distributed=False)
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1284, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 72721) is killed by signal: Killed. 

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 22, in <module>
    main()
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 18, in main
    GANTTSTask.main(cmd=cmd)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1225, in main
    cls.main_worker(args)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1441, in main_worker
    collect_stats(
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/main_funcs/collect_stats.py", line 51, in collect_stats
    for iiter, (keys, batch) in enumerate(itr, 1):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 733, in __next__
    data = self._next_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1491, in _next_data
    idx, data = self._get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1453, in _get_data
    success, data = self._try_get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1297, in _try_get_data
    raise RuntimeError(
RuntimeError: DataLoader worker (pid(s) 72721) exited unexpectedly
# Accounting: begin_time=1750873332
# Accounting: end_time=1750873472
# Accounting: time=140 threads=1
# Finished at Wed Jun 25 13:44:32 EDT 2025 with status 1
# Running on r205.ib.bridges2.psc.edu
# Started at Wed Jun 25 13:40:56 EDT 2025
# SLURMD_NODENAME=r205
# SLURM_ARRAY_JOB_ID=32990217
# SLURM_ARRAY_TASK_COUNT=32
# SLURM_ARRAY_TASK_ID=16
# SLURM_ARRAY_TASK_MAX=32
# SLURM_ARRAY_TASK_MIN=1
# SLURM_ARRAY_TASK_STEP=1
# SLURM_CLUSTER_NAME=bridges2
# SLURM_CONF=/var/spool/slurm/d/conf-cache/slurm.conf
# SLURM_CPUS_ON_NODE=1
# SLURM_CPU_BIND=quiet,mask_cpu:0x07C0000000
# SLURM_CPU_BIND_LIST=0x07C0000000
# SLURM_CPU_BIND_TYPE=mask_cpu:
# SLURM_CPU_BIND_VERBOSE=quiet
# SLURM_EXPORT_ENV=ALL
# SLURM_GET_USER_ENV=1
# SLURM_GTIDS=0
# SLURM_JOBID=32990234
# SLURM_JOB_ACCOUNT=cis210027p
# SLURM_JOB_CPUS_PER_NODE=1
# SLURM_JOB_GID=24886
# SLURM_JOB_ID=32990234
# SLURM_JOB_NAME=stats.sh
# SLURM_JOB_NODELIST=r205
# SLURM_JOB_NUM_NODES=1
# SLURM_JOB_PARTITION=RM-shared
# SLURM_JOB_QOS=rm
# SLURM_JOB_UID=97947
# SLURM_JOB_USER=ttao3
# SLURM_LAUNCH_NODE_IPADDR=10.8.11.29
# SLURM_LOCALID=0
# SLURM_MEM_PER_CPU=1900
# SLURM_NNODES=1
# SLURM_NODEID=0
# SLURM_NODELIST=r205
# SLURM_NODE_ALIASES='(null)'
# SLURM_NPROCS=1
# SLURM_NTASKS=1
# SLURM_OPEN_MODE=a
# SLURM_PRIO_PROCESS=0
# SLURM_PROCID=0
# SLURM_PTY_PORT=33025
# SLURM_PTY_WIN_COL=126
# SLURM_PTY_WIN_ROW=21
# SLURM_SCRIPT_CONTEXT=prolog_task
# SLURM_SRUN_COMM_HOST=10.8.11.29
# SLURM_SRUN_COMM_PORT=35045
# SLURM_STEPID=0
# SLURM_STEP_GPUS=6
# SLURM_STEP_ID=0
# SLURM_STEP_LAUNCHER_PORT=35045
# SLURM_STEP_NODELIST=v029
# SLURM_STEP_NUM_NODES=1
# SLURM_STEP_NUM_TASKS=1
# SLURM_STEP_TASKS_PER_NODE=1
# SLURM_SUBMIT_DIR=/ocean/projects/cis210027p/ttao3/espnet/egs2/hifitts/tts1
# SLURM_SUBMIT_HOST=v029.ib.bridges2.psc.edu
# SLURM_TASKS_PER_NODE=1
# SLURM_TASK_PID=63801
# SLURM_TOPOLOGY_ADDR=r205
# SLURM_TOPOLOGY_ADDR_PATTERN=node
# SLURM_WORKING_CLUSTER=bridges2:br003:6810:9728:109
# python3 -m espnet2.bin.gan_tts_train --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.16.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.16.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.16 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int 
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/librosa/util/files.py:10: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_filename
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/bin/python3 /ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.16.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.16.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.16 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int
Failed to import Flash Attention, using ESPnet default: No module named 'flash_attn_2_cuda'
Vocabulary size: 74
encoder self-attention layer type = relative self-attention
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/ocean/projects/cis210027p/ttao3/espnet/espnet2/gan_tts/vits/monotonic_align/__init__.py:19: UserWarning: Cython version is not available. Fallback to 'EXPERIMETAL' numba version. If you want to use the cython version, please build it as follows: `cd espnet2/gan_tts/vits/monotonic_align; python setup.py build_ext --inplace`
  warnings.warn(
pytorch.version=2.7.1+cu126, cuda.available=False, cudnn.version=90501, cudnn.benchmark=False, cudnn.deterministic=False
Model structure:
ESPnetGANTTSModel(
  (feats_extract): LinearSpectrogram(
    (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
  )
  (tts): VITS(
    (generator): VITSGenerator(
      (text_encoder): TextEncoder(
        (emb): Embedding(74, 192)
        (encoder): Encoder(
          (embed): Sequential(
            (0): RelPositionalEncoding(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (encoders): MultiSequential(
            (0): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (2): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (3): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (4): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (5): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (after_norm): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (decoder): HiFiGANGenerator(
        (input_conv): Conv1d(192, 512, kernel_size=(7,), stride=(1,), padding=(3,))
        (upsamples): ModuleList(
          (0): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (1): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(256, 128, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (2): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,))
          )
          (3): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,))
          )
        )
        (blocks): ModuleList(
          (0): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (1): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (2): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (3): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (4): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (5): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (6): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (7): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (8): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (9): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (10): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (11): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
        )
        (output_conv): Sequential(
          (0): LeakyReLU(negative_slope=0.01)
          (1): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,))
          (2): Tanh()
        )
        (global_conv): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
      )
      (posterior_encoder): PosteriorEncoder(
        (input_conv): Conv1d(513, 192, kernel_size=(1,), stride=(1,))
        (encoder): WaveNet(
          (conv_layers): ModuleList(
            (0-15): 16 x ResidualBlock(
              (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
              (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
              (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
            )
          )
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (flow): ResidualAffineCouplingBlock(
        (flows): ModuleList(
          (0): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (1): FlipFlow()
          (2): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (3): FlipFlow()
          (4): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (5): FlipFlow()
          (6): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (7): FlipFlow()
        )
      )
      (duration_predictor): StochasticDurationPredictor(
        (pre): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (log_flow): LogFlow()
        (flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (post_pre): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
        (post_dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (post_proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (post_flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (global_conv): Conv1d(256, 192, kernel_size=(1,), stride=(1,))
      )
      (global_emb): Embedding(128, 256)
    )
    (discriminator): HiFiGANMultiScaleMultiPeriodDiscriminator(
      (msd): HiFiGANMultiScaleDiscriminator(
        (discriminators): ModuleList(
          (0): HiFiGANScaleDiscriminator(
            (layers): ModuleList(
              (0): Sequential(
                (0): Conv1d(1, 128, kernel_size=(15,), stride=(1,), padding=(7,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv1d(128, 128, kernel_size=(41,), stride=(2,), padding=(20,), groups=4)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv1d(128, 256, kernel_size=(41,), stride=(2,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv1d(256, 512, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv1d(512, 1024, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (5): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(41,), stride=(1,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (6): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (7): Conv1d(1024, 1, kernel_size=(3,), stride=(1,), padding=(1,))
            )
          )
        )
      )
      (mpd): HiFiGANMultiPeriodDiscriminator(
        (discriminators): ModuleList(
          (0-4): 5 x HiFiGANPeriodDiscriminator(
            (convs): ModuleList(
              (0): Sequential(
                (0): Conv2d(1, 32, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv2d(32, 128, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv2d(128, 512, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv2d(512, 1024, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv2d(1024, 1024, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
            )
            (output_conv): Conv2d(1024, 1, kernel_size=(2, 1), stride=(1, 1), padding=(1, 0))
          )
        )
      )
    )
    (generator_adv_loss): GeneratorAdversarialLoss()
    (discriminator_adv_loss): DiscriminatorAdversarialLoss()
    (feat_match_loss): FeatureMatchLoss()
    (mel_loss): MelSpectrogramLoss(
      (wav_to_mel): LogMelFbank(
        (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
        (logmel): LogMel(sr=22050, n_fft=1024, n_mels=80, fmin=0, fmax=11025.0, htk=False)
      )
    )
    (kl_loss): KLDivergenceLoss()
  )
)

Model summary:
    Class Name: ESPnetGANTTSModel
    Total Number of model parameters: 96.37 M
    Number of trainable parameters: 96.37 M (100.0%)
    Size: 385.46 MB
    Type: torch.float32
Optimizer:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler: <torch.optim.lr_scheduler.ExponentialLR object at 0x14ec0f09c5e0>
Optimizer2:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler2: <torch.optim.lr_scheduler.ExponentialLR object at 0x14ec0f09c9d0>
Saving the configuration in exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.16/config.yaml
Namespace(config='conf/tuning/train_multi_spk_vits.yaml', print_config=False, log_level='INFO', drop_last_iter=False, dry_run=False, iterator_type='sequence', valid_iterator_type=None, output_dir='exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.16', ngpu=0, seed=777, num_workers=4, num_att_plot=3, dist_backend='nccl', dist_init_method='env://', dist_world_size=None, dist_rank=None, local_rank=None, dist_master_addr=None, dist_master_port=None, dist_launcher=None, multiprocessing_distributed=False, unused_parameters=True, sharded_ddp=False, use_deepspeed=False, deepspeed_config=None, gradient_as_bucket_view=True, ddp_comm_hook=None, cudnn_enabled=True, cudnn_benchmark=False, cudnn_deterministic=False, use_tf32=False, collect_stats=True, write_collected_feats=False, max_epoch=1000, patience=None, val_scheduler_criterion=('valid', 'loss'), early_stopping_criterion=('valid', 'loss', 'min'), best_model_criterion=[['train', 'total_count', 'max']], keep_nbest_models=10, nbest_averaging_interval=0, grad_clip=-1, grad_clip_type=2.0, grad_noise=False, accum_grad=1, no_forward_run=False, resume=False, train_dtype='float32', use_amp=False, log_interval=50, use_matplotlib=True, use_tensorboard=True, create_graph_in_tensorboard=False, use_wandb=False, wandb_project=None, wandb_id=None, wandb_entity=None, wandb_name=None, wandb_model_log_interval=-1, detect_anomaly=False, use_adapter=False, adapter='lora', save_strategy='all', adapter_conf={}, pretrain_path=None, init_param=[], ignore_init_mismatch=False, freeze_param=[], num_iters_per_epoch=1000, batch_size=20, valid_batch_size=None, batch_bins=3000000, valid_batch_bins=None, category_sample_size=10, train_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.16.scp'], valid_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.16.scp'], batch_type='numel', valid_batch_type=None, fold_length=[], sort_in_batch='descending', shuffle_within_batch=False, sort_batch='descending', multiple_iterator=False, chunk_length=500, chunk_shift_ratio=0.5, num_cache_chunks=1024, chunk_excluded_key_prefixes=[], chunk_default_fs=None, chunk_max_abs_length=None, chunk_discard_short_samples=True, train_data_path_and_name_and_type=[('dump/22k/raw/tr_no_dev/text', 'text', 'text'), ('dump/22k/raw/tr_no_dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/tr_no_dev/utt2sid', 'sids', 'text_int')], valid_data_path_and_name_and_type=[('dump/22k/raw/dev/text', 'text', 'text'), ('dump/22k/raw/dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/dev/utt2sid', 'sids', 'text_int')], multi_task_dataset=False, allow_variable_data_keys=False, max_cache_size=0.0, max_cache_fd=32, allow_multi_rates=False, valid_max_cache_size=None, exclude_weight_decay=False, exclude_weight_decay_conf={}, optim='adamw', optim_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler='exponentiallr', scheduler_conf={'gamma': 0.999875}, optim2='adamw', optim2_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler2='exponentiallr', scheduler2_conf={'gamma': 0.999875}, generator_first=False, skip_discriminator_prob=0.0, token_list=['<blank>', '<unk>', ' ', 'AH0', 'N', 'T', 'D', 'S', 'R', 'L', 'IH1', 'DH', 'M', 'EH1', 'Z', 'AE1', 'K', 'IH0', 'AH1', 'HH', 'W', 'ER0', 'V', 'IY1', 'F', 'UW1', 'P', 'AY1', 'B', 'AA1', 'AO1', 'EY1', 'IY0', 'OW1', 'NG', 'SH', 'G', 'Y', 'AW1', 'CH', 'ER1', 'UH1', 'TH', 'JH', 'OW0', 'EH2', 'IH2', 'OY1', 'EY2', 'AY2', 'EH0', 'UW0', 'AA2', 'AE2', 'OW2', 'AH2', 'AA0', 'ZH', 'AE0', 'AO2', 'UW2', 'AO0', 'AY0', 'IY2', 'AW2', 'UH2', 'EY0', 'ER2', 'AW0', 'UH0', 'OY2', 'OY0', "'", '<sos/eos>'], odim=None, model_conf={}, use_preprocessor=True, token_type='phn', bpemodel=None, non_linguistic_symbols=None, cleaner='tacotron', g2p='g2p_en', feats_extract='linear_spectrogram', feats_extract_conf={'n_fft': 1024, 'hop_length': 256, 'win_length': None}, normalize=None, normalize_conf={}, tts='vits', tts_conf={'generator_type': 'vits_generator', 'generator_params': {'hidden_channels': 192, 'spks': 128, 'global_channels': 256, 'segment_size': 32, 'text_encoder_attention_heads': 2, 'text_encoder_ffn_expand': 4, 'text_encoder_blocks': 6, 'text_encoder_positionwise_layer_type': 'conv1d', 'text_encoder_positionwise_conv_kernel_size': 3, 'text_encoder_positional_encoding_layer_type': 'rel_pos', 'text_encoder_self_attention_layer_type': 'rel_selfattn', 'text_encoder_activation_type': 'swish', 'text_encoder_normalize_before': True, 'text_encoder_dropout_rate': 0.1, 'text_encoder_positional_dropout_rate': 0.0, 'text_encoder_attention_dropout_rate': 0.1, 'use_macaron_style_in_text_encoder': True, 'use_conformer_conv_in_text_encoder': False, 'text_encoder_conformer_kernel_size': -1, 'decoder_kernel_size': 7, 'decoder_channels': 512, 'decoder_upsample_scales': [8, 8, 2, 2], 'decoder_upsample_kernel_sizes': [16, 16, 4, 4], 'decoder_resblock_kernel_sizes': [3, 7, 11], 'decoder_resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'use_weight_norm_in_decoder': True, 'posterior_encoder_kernel_size': 5, 'posterior_encoder_layers': 16, 'posterior_encoder_stacks': 1, 'posterior_encoder_base_dilation': 1, 'posterior_encoder_dropout_rate': 0.0, 'use_weight_norm_in_posterior_encoder': True, 'flow_flows': 4, 'flow_kernel_size': 5, 'flow_base_dilation': 1, 'flow_layers': 4, 'flow_dropout_rate': 0.0, 'use_weight_norm_in_flow': True, 'use_only_mean_in_flow': True, 'stochastic_duration_predictor_kernel_size': 3, 'stochastic_duration_predictor_dropout_rate': 0.5, 'stochastic_duration_predictor_flows': 4, 'stochastic_duration_predictor_dds_conv_layers': 3, 'vocabs': 74, 'aux_channels': 513}, 'discriminator_type': 'hifigan_multi_scale_multi_period_discriminator', 'discriminator_params': {'scales': 1, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'stride': 2, 'padding': 2}, 'scale_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'channels': 128, 'max_downsample_channels': 1024, 'max_groups': 16, 'bias': True, 'downsample_scales': [2, 2, 4, 4, 1], 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}, 'follow_official_norm': False, 'periods': [2, 3, 5, 7, 11], 'period_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [5, 3], 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'max_downsample_channels': 1024, 'bias': True, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}}, 'generator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'discriminator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'feat_match_loss_params': {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, 'mel_loss_params': {'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None, 'window': 'hann', 'n_mels': 80, 'fmin': 0, 'fmax': None, 'log_base': None}, 'lambda_adv': 1.0, 'lambda_mel': 45.0, 'lambda_feat_match': 2.0, 'lambda_dur': 1.0, 'lambda_kl': 1.0, 'sampling_rate': 22050, 'cache_generator_outputs': True, 'plot_pred_mos': False, 'mos_pred_tool': 'utmos'}, pitch_extract=None, pitch_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'f0max': 400, 'f0min': 80}, pitch_normalize=None, pitch_normalize_conf={}, energy_extract=None, energy_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None}, energy_normalize=None, energy_normalize_conf={}, required=['output_dir', 'token_list'], version='202503', distributed=False)
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1284, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 63898) is killed by signal: Killed. 

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 22, in <module>
    main()
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 18, in main
    GANTTSTask.main(cmd=cmd)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1225, in main
    cls.main_worker(args)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1441, in main_worker
    collect_stats(
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/main_funcs/collect_stats.py", line 51, in collect_stats
    for iiter, (keys, batch) in enumerate(itr, 1):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 733, in __next__
    data = self._next_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1491, in _next_data
    idx, data = self._get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1453, in _get_data
    success, data = self._try_get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1297, in _try_get_data
    raise RuntimeError(
RuntimeError: DataLoader worker (pid(s) 63898) exited unexpectedly
# Accounting: begin_time=1750873256
# Accounting: end_time=1750873472
# Accounting: time=216 threads=1
# Finished at Wed Jun 25 13:44:32 EDT 2025 with status 1
# Running on r205.ib.bridges2.psc.edu
# Started at Wed Jun 25 13:40:56 EDT 2025
# SLURMD_NODENAME=r205
# SLURM_ARRAY_JOB_ID=32990217
# SLURM_ARRAY_TASK_COUNT=32
# SLURM_ARRAY_TASK_ID=17
# SLURM_ARRAY_TASK_MAX=32
# SLURM_ARRAY_TASK_MIN=1
# SLURM_ARRAY_TASK_STEP=1
# SLURM_CLUSTER_NAME=bridges2
# SLURM_CONF=/var/spool/slurm/d/conf-cache/slurm.conf
# SLURM_CPUS_ON_NODE=1
# SLURM_CPU_BIND=quiet,mask_cpu:0x07C0000000
# SLURM_CPU_BIND_LIST=0x07C0000000
# SLURM_CPU_BIND_TYPE=mask_cpu:
# SLURM_CPU_BIND_VERBOSE=quiet
# SLURM_EXPORT_ENV=ALL
# SLURM_GET_USER_ENV=1
# SLURM_GTIDS=0
# SLURM_JOBID=32990235
# SLURM_JOB_ACCOUNT=cis210027p
# SLURM_JOB_CPUS_PER_NODE=1
# SLURM_JOB_GID=24886
# SLURM_JOB_ID=32990235
# SLURM_JOB_NAME=stats.sh
# SLURM_JOB_NODELIST=r205
# SLURM_JOB_NUM_NODES=1
# SLURM_JOB_PARTITION=RM-shared
# SLURM_JOB_QOS=rm
# SLURM_JOB_UID=97947
# SLURM_JOB_USER=ttao3
# SLURM_LAUNCH_NODE_IPADDR=10.8.11.29
# SLURM_LOCALID=0
# SLURM_MEM_PER_CPU=1900
# SLURM_NNODES=1
# SLURM_NODEID=0
# SLURM_NODELIST=r205
# SLURM_NODE_ALIASES='(null)'
# SLURM_NPROCS=1
# SLURM_NTASKS=1
# SLURM_OPEN_MODE=a
# SLURM_PRIO_PROCESS=0
# SLURM_PROCID=0
# SLURM_PTY_PORT=33025
# SLURM_PTY_WIN_COL=126
# SLURM_PTY_WIN_ROW=21
# SLURM_SCRIPT_CONTEXT=prolog_task
# SLURM_SRUN_COMM_HOST=10.8.11.29
# SLURM_SRUN_COMM_PORT=35045
# SLURM_STEPID=0
# SLURM_STEP_GPUS=6
# SLURM_STEP_ID=0
# SLURM_STEP_LAUNCHER_PORT=35045
# SLURM_STEP_NODELIST=v029
# SLURM_STEP_NUM_NODES=1
# SLURM_STEP_NUM_TASKS=1
# SLURM_STEP_TASKS_PER_NODE=1
# SLURM_SUBMIT_DIR=/ocean/projects/cis210027p/ttao3/espnet/egs2/hifitts/tts1
# SLURM_SUBMIT_HOST=v029.ib.bridges2.psc.edu
# SLURM_TASKS_PER_NODE=1
# SLURM_TASK_PID=63800
# SLURM_TOPOLOGY_ADDR=r205
# SLURM_TOPOLOGY_ADDR_PATTERN=node
# SLURM_WORKING_CLUSTER=bridges2:br003:6810:9728:109
# python3 -m espnet2.bin.gan_tts_train --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.17.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.17.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.17 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int 
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/librosa/util/files.py:10: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_filename
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/bin/python3 /ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.17.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.17.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.17 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int
Failed to import Flash Attention, using ESPnet default: No module named 'flash_attn_2_cuda'
Vocabulary size: 74
encoder self-attention layer type = relative self-attention
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/ocean/projects/cis210027p/ttao3/espnet/espnet2/gan_tts/vits/monotonic_align/__init__.py:19: UserWarning: Cython version is not available. Fallback to 'EXPERIMETAL' numba version. If you want to use the cython version, please build it as follows: `cd espnet2/gan_tts/vits/monotonic_align; python setup.py build_ext --inplace`
  warnings.warn(
pytorch.version=2.7.1+cu126, cuda.available=False, cudnn.version=90501, cudnn.benchmark=False, cudnn.deterministic=False
Model structure:
ESPnetGANTTSModel(
  (feats_extract): LinearSpectrogram(
    (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
  )
  (tts): VITS(
    (generator): VITSGenerator(
      (text_encoder): TextEncoder(
        (emb): Embedding(74, 192)
        (encoder): Encoder(
          (embed): Sequential(
            (0): RelPositionalEncoding(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (encoders): MultiSequential(
            (0): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (2): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (3): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (4): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (5): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (after_norm): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (decoder): HiFiGANGenerator(
        (input_conv): Conv1d(192, 512, kernel_size=(7,), stride=(1,), padding=(3,))
        (upsamples): ModuleList(
          (0): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (1): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(256, 128, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (2): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,))
          )
          (3): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,))
          )
        )
        (blocks): ModuleList(
          (0): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (1): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (2): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (3): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (4): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (5): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (6): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (7): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (8): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (9): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (10): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (11): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
        )
        (output_conv): Sequential(
          (0): LeakyReLU(negative_slope=0.01)
          (1): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,))
          (2): Tanh()
        )
        (global_conv): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
      )
      (posterior_encoder): PosteriorEncoder(
        (input_conv): Conv1d(513, 192, kernel_size=(1,), stride=(1,))
        (encoder): WaveNet(
          (conv_layers): ModuleList(
            (0-15): 16 x ResidualBlock(
              (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
              (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
              (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
            )
          )
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (flow): ResidualAffineCouplingBlock(
        (flows): ModuleList(
          (0): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (1): FlipFlow()
          (2): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (3): FlipFlow()
          (4): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (5): FlipFlow()
          (6): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (7): FlipFlow()
        )
      )
      (duration_predictor): StochasticDurationPredictor(
        (pre): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (log_flow): LogFlow()
        (flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (post_pre): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
        (post_dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (post_proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (post_flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (global_conv): Conv1d(256, 192, kernel_size=(1,), stride=(1,))
      )
      (global_emb): Embedding(128, 256)
    )
    (discriminator): HiFiGANMultiScaleMultiPeriodDiscriminator(
      (msd): HiFiGANMultiScaleDiscriminator(
        (discriminators): ModuleList(
          (0): HiFiGANScaleDiscriminator(
            (layers): ModuleList(
              (0): Sequential(
                (0): Conv1d(1, 128, kernel_size=(15,), stride=(1,), padding=(7,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv1d(128, 128, kernel_size=(41,), stride=(2,), padding=(20,), groups=4)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv1d(128, 256, kernel_size=(41,), stride=(2,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv1d(256, 512, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv1d(512, 1024, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (5): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(41,), stride=(1,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (6): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (7): Conv1d(1024, 1, kernel_size=(3,), stride=(1,), padding=(1,))
            )
          )
        )
      )
      (mpd): HiFiGANMultiPeriodDiscriminator(
        (discriminators): ModuleList(
          (0-4): 5 x HiFiGANPeriodDiscriminator(
            (convs): ModuleList(
              (0): Sequential(
                (0): Conv2d(1, 32, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv2d(32, 128, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv2d(128, 512, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv2d(512, 1024, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv2d(1024, 1024, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
            )
            (output_conv): Conv2d(1024, 1, kernel_size=(2, 1), stride=(1, 1), padding=(1, 0))
          )
        )
      )
    )
    (generator_adv_loss): GeneratorAdversarialLoss()
    (discriminator_adv_loss): DiscriminatorAdversarialLoss()
    (feat_match_loss): FeatureMatchLoss()
    (mel_loss): MelSpectrogramLoss(
      (wav_to_mel): LogMelFbank(
        (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
        (logmel): LogMel(sr=22050, n_fft=1024, n_mels=80, fmin=0, fmax=11025.0, htk=False)
      )
    )
    (kl_loss): KLDivergenceLoss()
  )
)

Model summary:
    Class Name: ESPnetGANTTSModel
    Total Number of model parameters: 96.37 M
    Number of trainable parameters: 96.37 M (100.0%)
    Size: 385.46 MB
    Type: torch.float32
Optimizer:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler: <torch.optim.lr_scheduler.ExponentialLR object at 0x14e5842d21c0>
Optimizer2:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler2: <torch.optim.lr_scheduler.ExponentialLR object at 0x14e5842d25b0>
Saving the configuration in exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.17/config.yaml
Namespace(config='conf/tuning/train_multi_spk_vits.yaml', print_config=False, log_level='INFO', drop_last_iter=False, dry_run=False, iterator_type='sequence', valid_iterator_type=None, output_dir='exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.17', ngpu=0, seed=777, num_workers=4, num_att_plot=3, dist_backend='nccl', dist_init_method='env://', dist_world_size=None, dist_rank=None, local_rank=None, dist_master_addr=None, dist_master_port=None, dist_launcher=None, multiprocessing_distributed=False, unused_parameters=True, sharded_ddp=False, use_deepspeed=False, deepspeed_config=None, gradient_as_bucket_view=True, ddp_comm_hook=None, cudnn_enabled=True, cudnn_benchmark=False, cudnn_deterministic=False, use_tf32=False, collect_stats=True, write_collected_feats=False, max_epoch=1000, patience=None, val_scheduler_criterion=('valid', 'loss'), early_stopping_criterion=('valid', 'loss', 'min'), best_model_criterion=[['train', 'total_count', 'max']], keep_nbest_models=10, nbest_averaging_interval=0, grad_clip=-1, grad_clip_type=2.0, grad_noise=False, accum_grad=1, no_forward_run=False, resume=False, train_dtype='float32', use_amp=False, log_interval=50, use_matplotlib=True, use_tensorboard=True, create_graph_in_tensorboard=False, use_wandb=False, wandb_project=None, wandb_id=None, wandb_entity=None, wandb_name=None, wandb_model_log_interval=-1, detect_anomaly=False, use_adapter=False, adapter='lora', save_strategy='all', adapter_conf={}, pretrain_path=None, init_param=[], ignore_init_mismatch=False, freeze_param=[], num_iters_per_epoch=1000, batch_size=20, valid_batch_size=None, batch_bins=3000000, valid_batch_bins=None, category_sample_size=10, train_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.17.scp'], valid_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.17.scp'], batch_type='numel', valid_batch_type=None, fold_length=[], sort_in_batch='descending', shuffle_within_batch=False, sort_batch='descending', multiple_iterator=False, chunk_length=500, chunk_shift_ratio=0.5, num_cache_chunks=1024, chunk_excluded_key_prefixes=[], chunk_default_fs=None, chunk_max_abs_length=None, chunk_discard_short_samples=True, train_data_path_and_name_and_type=[('dump/22k/raw/tr_no_dev/text', 'text', 'text'), ('dump/22k/raw/tr_no_dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/tr_no_dev/utt2sid', 'sids', 'text_int')], valid_data_path_and_name_and_type=[('dump/22k/raw/dev/text', 'text', 'text'), ('dump/22k/raw/dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/dev/utt2sid', 'sids', 'text_int')], multi_task_dataset=False, allow_variable_data_keys=False, max_cache_size=0.0, max_cache_fd=32, allow_multi_rates=False, valid_max_cache_size=None, exclude_weight_decay=False, exclude_weight_decay_conf={}, optim='adamw', optim_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler='exponentiallr', scheduler_conf={'gamma': 0.999875}, optim2='adamw', optim2_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler2='exponentiallr', scheduler2_conf={'gamma': 0.999875}, generator_first=False, skip_discriminator_prob=0.0, token_list=['<blank>', '<unk>', ' ', 'AH0', 'N', 'T', 'D', 'S', 'R', 'L', 'IH1', 'DH', 'M', 'EH1', 'Z', 'AE1', 'K', 'IH0', 'AH1', 'HH', 'W', 'ER0', 'V', 'IY1', 'F', 'UW1', 'P', 'AY1', 'B', 'AA1', 'AO1', 'EY1', 'IY0', 'OW1', 'NG', 'SH', 'G', 'Y', 'AW1', 'CH', 'ER1', 'UH1', 'TH', 'JH', 'OW0', 'EH2', 'IH2', 'OY1', 'EY2', 'AY2', 'EH0', 'UW0', 'AA2', 'AE2', 'OW2', 'AH2', 'AA0', 'ZH', 'AE0', 'AO2', 'UW2', 'AO0', 'AY0', 'IY2', 'AW2', 'UH2', 'EY0', 'ER2', 'AW0', 'UH0', 'OY2', 'OY0', "'", '<sos/eos>'], odim=None, model_conf={}, use_preprocessor=True, token_type='phn', bpemodel=None, non_linguistic_symbols=None, cleaner='tacotron', g2p='g2p_en', feats_extract='linear_spectrogram', feats_extract_conf={'n_fft': 1024, 'hop_length': 256, 'win_length': None}, normalize=None, normalize_conf={}, tts='vits', tts_conf={'generator_type': 'vits_generator', 'generator_params': {'hidden_channels': 192, 'spks': 128, 'global_channels': 256, 'segment_size': 32, 'text_encoder_attention_heads': 2, 'text_encoder_ffn_expand': 4, 'text_encoder_blocks': 6, 'text_encoder_positionwise_layer_type': 'conv1d', 'text_encoder_positionwise_conv_kernel_size': 3, 'text_encoder_positional_encoding_layer_type': 'rel_pos', 'text_encoder_self_attention_layer_type': 'rel_selfattn', 'text_encoder_activation_type': 'swish', 'text_encoder_normalize_before': True, 'text_encoder_dropout_rate': 0.1, 'text_encoder_positional_dropout_rate': 0.0, 'text_encoder_attention_dropout_rate': 0.1, 'use_macaron_style_in_text_encoder': True, 'use_conformer_conv_in_text_encoder': False, 'text_encoder_conformer_kernel_size': -1, 'decoder_kernel_size': 7, 'decoder_channels': 512, 'decoder_upsample_scales': [8, 8, 2, 2], 'decoder_upsample_kernel_sizes': [16, 16, 4, 4], 'decoder_resblock_kernel_sizes': [3, 7, 11], 'decoder_resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'use_weight_norm_in_decoder': True, 'posterior_encoder_kernel_size': 5, 'posterior_encoder_layers': 16, 'posterior_encoder_stacks': 1, 'posterior_encoder_base_dilation': 1, 'posterior_encoder_dropout_rate': 0.0, 'use_weight_norm_in_posterior_encoder': True, 'flow_flows': 4, 'flow_kernel_size': 5, 'flow_base_dilation': 1, 'flow_layers': 4, 'flow_dropout_rate': 0.0, 'use_weight_norm_in_flow': True, 'use_only_mean_in_flow': True, 'stochastic_duration_predictor_kernel_size': 3, 'stochastic_duration_predictor_dropout_rate': 0.5, 'stochastic_duration_predictor_flows': 4, 'stochastic_duration_predictor_dds_conv_layers': 3, 'vocabs': 74, 'aux_channels': 513}, 'discriminator_type': 'hifigan_multi_scale_multi_period_discriminator', 'discriminator_params': {'scales': 1, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'stride': 2, 'padding': 2}, 'scale_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'channels': 128, 'max_downsample_channels': 1024, 'max_groups': 16, 'bias': True, 'downsample_scales': [2, 2, 4, 4, 1], 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}, 'follow_official_norm': False, 'periods': [2, 3, 5, 7, 11], 'period_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [5, 3], 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'max_downsample_channels': 1024, 'bias': True, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}}, 'generator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'discriminator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'feat_match_loss_params': {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, 'mel_loss_params': {'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None, 'window': 'hann', 'n_mels': 80, 'fmin': 0, 'fmax': None, 'log_base': None}, 'lambda_adv': 1.0, 'lambda_mel': 45.0, 'lambda_feat_match': 2.0, 'lambda_dur': 1.0, 'lambda_kl': 1.0, 'sampling_rate': 22050, 'cache_generator_outputs': True, 'plot_pred_mos': False, 'mos_pred_tool': 'utmos'}, pitch_extract=None, pitch_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'f0max': 400, 'f0min': 80}, pitch_normalize=None, pitch_normalize_conf={}, energy_extract=None, energy_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None}, energy_normalize=None, energy_normalize_conf={}, required=['output_dir', 'token_list'], version='202503', distributed=False)
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1284, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 63900) is killed by signal: Killed. 

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 22, in <module>
    main()
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 18, in main
    GANTTSTask.main(cmd=cmd)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1225, in main
    cls.main_worker(args)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1441, in main_worker
    collect_stats(
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/main_funcs/collect_stats.py", line 51, in collect_stats
    for iiter, (keys, batch) in enumerate(itr, 1):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 733, in __next__
    data = self._next_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1491, in _next_data
    idx, data = self._get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1453, in _get_data
    success, data = self._try_get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1297, in _try_get_data
    raise RuntimeError(
RuntimeError: DataLoader worker (pid(s) 63900) exited unexpectedly
# Accounting: begin_time=1750873256
# Accounting: end_time=1750873472
# Accounting: time=216 threads=1
# Finished at Wed Jun 25 13:44:32 EDT 2025 with status 1
# Running on r205.ib.bridges2.psc.edu
# Started at Wed Jun 25 13:40:56 EDT 2025
# SLURMD_NODENAME=r205
# SLURM_ARRAY_JOB_ID=32990217
# SLURM_ARRAY_TASK_COUNT=32
# SLURM_ARRAY_TASK_ID=18
# SLURM_ARRAY_TASK_MAX=32
# SLURM_ARRAY_TASK_MIN=1
# SLURM_ARRAY_TASK_STEP=1
# SLURM_CLUSTER_NAME=bridges2
# SLURM_CONF=/var/spool/slurm/d/conf-cache/slurm.conf
# SLURM_CPUS_ON_NODE=1
# SLURM_CPU_BIND=quiet,mask_cpu:0x07C0000000
# SLURM_CPU_BIND_LIST=0x07C0000000
# SLURM_CPU_BIND_TYPE=mask_cpu:
# SLURM_CPU_BIND_VERBOSE=quiet
# SLURM_EXPORT_ENV=ALL
# SLURM_GET_USER_ENV=1
# SLURM_GTIDS=0
# SLURM_JOBID=32990236
# SLURM_JOB_ACCOUNT=cis210027p
# SLURM_JOB_CPUS_PER_NODE=1
# SLURM_JOB_GID=24886
# SLURM_JOB_ID=32990236
# SLURM_JOB_NAME=stats.sh
# SLURM_JOB_NODELIST=r205
# SLURM_JOB_NUM_NODES=1
# SLURM_JOB_PARTITION=RM-shared
# SLURM_JOB_QOS=rm
# SLURM_JOB_UID=97947
# SLURM_JOB_USER=ttao3
# SLURM_LAUNCH_NODE_IPADDR=10.8.11.29
# SLURM_LOCALID=0
# SLURM_MEM_PER_CPU=1900
# SLURM_NNODES=1
# SLURM_NODEID=0
# SLURM_NODELIST=r205
# SLURM_NODE_ALIASES='(null)'
# SLURM_NPROCS=1
# SLURM_NTASKS=1
# SLURM_OPEN_MODE=a
# SLURM_PRIO_PROCESS=0
# SLURM_PROCID=0
# SLURM_PTY_PORT=33025
# SLURM_PTY_WIN_COL=126
# SLURM_PTY_WIN_ROW=21
# SLURM_SCRIPT_CONTEXT=prolog_task
# SLURM_SRUN_COMM_HOST=10.8.11.29
# SLURM_SRUN_COMM_PORT=35045
# SLURM_STEPID=0
# SLURM_STEP_GPUS=6
# SLURM_STEP_ID=0
# SLURM_STEP_LAUNCHER_PORT=35045
# SLURM_STEP_NODELIST=v029
# SLURM_STEP_NUM_NODES=1
# SLURM_STEP_NUM_TASKS=1
# SLURM_STEP_TASKS_PER_NODE=1
# SLURM_SUBMIT_DIR=/ocean/projects/cis210027p/ttao3/espnet/egs2/hifitts/tts1
# SLURM_SUBMIT_HOST=v029.ib.bridges2.psc.edu
# SLURM_TASKS_PER_NODE=1
# SLURM_TASK_PID=63802
# SLURM_TOPOLOGY_ADDR=r205
# SLURM_TOPOLOGY_ADDR_PATTERN=node
# SLURM_WORKING_CLUSTER=bridges2:br003:6810:9728:109
# python3 -m espnet2.bin.gan_tts_train --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.18.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.18.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.18 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int 
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/librosa/util/files.py:10: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_filename
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/bin/python3 /ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.18.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.18.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.18 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int
Failed to import Flash Attention, using ESPnet default: No module named 'flash_attn_2_cuda'
Vocabulary size: 74
encoder self-attention layer type = relative self-attention
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/ocean/projects/cis210027p/ttao3/espnet/espnet2/gan_tts/vits/monotonic_align/__init__.py:19: UserWarning: Cython version is not available. Fallback to 'EXPERIMETAL' numba version. If you want to use the cython version, please build it as follows: `cd espnet2/gan_tts/vits/monotonic_align; python setup.py build_ext --inplace`
  warnings.warn(
pytorch.version=2.7.1+cu126, cuda.available=False, cudnn.version=90501, cudnn.benchmark=False, cudnn.deterministic=False
Model structure:
ESPnetGANTTSModel(
  (feats_extract): LinearSpectrogram(
    (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
  )
  (tts): VITS(
    (generator): VITSGenerator(
      (text_encoder): TextEncoder(
        (emb): Embedding(74, 192)
        (encoder): Encoder(
          (embed): Sequential(
            (0): RelPositionalEncoding(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (encoders): MultiSequential(
            (0): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (2): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (3): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (4): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (5): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (after_norm): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (decoder): HiFiGANGenerator(
        (input_conv): Conv1d(192, 512, kernel_size=(7,), stride=(1,), padding=(3,))
        (upsamples): ModuleList(
          (0): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (1): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(256, 128, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (2): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,))
          )
          (3): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,))
          )
        )
        (blocks): ModuleList(
          (0): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (1): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (2): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (3): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (4): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (5): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (6): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (7): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (8): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (9): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (10): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (11): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
        )
        (output_conv): Sequential(
          (0): LeakyReLU(negative_slope=0.01)
          (1): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,))
          (2): Tanh()
        )
        (global_conv): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
      )
      (posterior_encoder): PosteriorEncoder(
        (input_conv): Conv1d(513, 192, kernel_size=(1,), stride=(1,))
        (encoder): WaveNet(
          (conv_layers): ModuleList(
            (0-15): 16 x ResidualBlock(
              (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
              (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
              (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
            )
          )
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (flow): ResidualAffineCouplingBlock(
        (flows): ModuleList(
          (0): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (1): FlipFlow()
          (2): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (3): FlipFlow()
          (4): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (5): FlipFlow()
          (6): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (7): FlipFlow()
        )
      )
      (duration_predictor): StochasticDurationPredictor(
        (pre): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (log_flow): LogFlow()
        (flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (post_pre): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
        (post_dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (post_proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (post_flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (global_conv): Conv1d(256, 192, kernel_size=(1,), stride=(1,))
      )
      (global_emb): Embedding(128, 256)
    )
    (discriminator): HiFiGANMultiScaleMultiPeriodDiscriminator(
      (msd): HiFiGANMultiScaleDiscriminator(
        (discriminators): ModuleList(
          (0): HiFiGANScaleDiscriminator(
            (layers): ModuleList(
              (0): Sequential(
                (0): Conv1d(1, 128, kernel_size=(15,), stride=(1,), padding=(7,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv1d(128, 128, kernel_size=(41,), stride=(2,), padding=(20,), groups=4)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv1d(128, 256, kernel_size=(41,), stride=(2,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv1d(256, 512, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv1d(512, 1024, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (5): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(41,), stride=(1,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (6): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (7): Conv1d(1024, 1, kernel_size=(3,), stride=(1,), padding=(1,))
            )
          )
        )
      )
      (mpd): HiFiGANMultiPeriodDiscriminator(
        (discriminators): ModuleList(
          (0-4): 5 x HiFiGANPeriodDiscriminator(
            (convs): ModuleList(
              (0): Sequential(
                (0): Conv2d(1, 32, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv2d(32, 128, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv2d(128, 512, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv2d(512, 1024, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv2d(1024, 1024, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
            )
            (output_conv): Conv2d(1024, 1, kernel_size=(2, 1), stride=(1, 1), padding=(1, 0))
          )
        )
      )
    )
    (generator_adv_loss): GeneratorAdversarialLoss()
    (discriminator_adv_loss): DiscriminatorAdversarialLoss()
    (feat_match_loss): FeatureMatchLoss()
    (mel_loss): MelSpectrogramLoss(
      (wav_to_mel): LogMelFbank(
        (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
        (logmel): LogMel(sr=22050, n_fft=1024, n_mels=80, fmin=0, fmax=11025.0, htk=False)
      )
    )
    (kl_loss): KLDivergenceLoss()
  )
)

Model summary:
    Class Name: ESPnetGANTTSModel
    Total Number of model parameters: 96.37 M
    Number of trainable parameters: 96.37 M (100.0%)
    Size: 385.46 MB
    Type: torch.float32
Optimizer:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler: <torch.optim.lr_scheduler.ExponentialLR object at 0x150897e465e0>
Optimizer2:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler2: <torch.optim.lr_scheduler.ExponentialLR object at 0x150897e469d0>
Saving the configuration in exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.18/config.yaml
Namespace(config='conf/tuning/train_multi_spk_vits.yaml', print_config=False, log_level='INFO', drop_last_iter=False, dry_run=False, iterator_type='sequence', valid_iterator_type=None, output_dir='exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.18', ngpu=0, seed=777, num_workers=4, num_att_plot=3, dist_backend='nccl', dist_init_method='env://', dist_world_size=None, dist_rank=None, local_rank=None, dist_master_addr=None, dist_master_port=None, dist_launcher=None, multiprocessing_distributed=False, unused_parameters=True, sharded_ddp=False, use_deepspeed=False, deepspeed_config=None, gradient_as_bucket_view=True, ddp_comm_hook=None, cudnn_enabled=True, cudnn_benchmark=False, cudnn_deterministic=False, use_tf32=False, collect_stats=True, write_collected_feats=False, max_epoch=1000, patience=None, val_scheduler_criterion=('valid', 'loss'), early_stopping_criterion=('valid', 'loss', 'min'), best_model_criterion=[['train', 'total_count', 'max']], keep_nbest_models=10, nbest_averaging_interval=0, grad_clip=-1, grad_clip_type=2.0, grad_noise=False, accum_grad=1, no_forward_run=False, resume=False, train_dtype='float32', use_amp=False, log_interval=50, use_matplotlib=True, use_tensorboard=True, create_graph_in_tensorboard=False, use_wandb=False, wandb_project=None, wandb_id=None, wandb_entity=None, wandb_name=None, wandb_model_log_interval=-1, detect_anomaly=False, use_adapter=False, adapter='lora', save_strategy='all', adapter_conf={}, pretrain_path=None, init_param=[], ignore_init_mismatch=False, freeze_param=[], num_iters_per_epoch=1000, batch_size=20, valid_batch_size=None, batch_bins=3000000, valid_batch_bins=None, category_sample_size=10, train_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.18.scp'], valid_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.18.scp'], batch_type='numel', valid_batch_type=None, fold_length=[], sort_in_batch='descending', shuffle_within_batch=False, sort_batch='descending', multiple_iterator=False, chunk_length=500, chunk_shift_ratio=0.5, num_cache_chunks=1024, chunk_excluded_key_prefixes=[], chunk_default_fs=None, chunk_max_abs_length=None, chunk_discard_short_samples=True, train_data_path_and_name_and_type=[('dump/22k/raw/tr_no_dev/text', 'text', 'text'), ('dump/22k/raw/tr_no_dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/tr_no_dev/utt2sid', 'sids', 'text_int')], valid_data_path_and_name_and_type=[('dump/22k/raw/dev/text', 'text', 'text'), ('dump/22k/raw/dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/dev/utt2sid', 'sids', 'text_int')], multi_task_dataset=False, allow_variable_data_keys=False, max_cache_size=0.0, max_cache_fd=32, allow_multi_rates=False, valid_max_cache_size=None, exclude_weight_decay=False, exclude_weight_decay_conf={}, optim='adamw', optim_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler='exponentiallr', scheduler_conf={'gamma': 0.999875}, optim2='adamw', optim2_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler2='exponentiallr', scheduler2_conf={'gamma': 0.999875}, generator_first=False, skip_discriminator_prob=0.0, token_list=['<blank>', '<unk>', ' ', 'AH0', 'N', 'T', 'D', 'S', 'R', 'L', 'IH1', 'DH', 'M', 'EH1', 'Z', 'AE1', 'K', 'IH0', 'AH1', 'HH', 'W', 'ER0', 'V', 'IY1', 'F', 'UW1', 'P', 'AY1', 'B', 'AA1', 'AO1', 'EY1', 'IY0', 'OW1', 'NG', 'SH', 'G', 'Y', 'AW1', 'CH', 'ER1', 'UH1', 'TH', 'JH', 'OW0', 'EH2', 'IH2', 'OY1', 'EY2', 'AY2', 'EH0', 'UW0', 'AA2', 'AE2', 'OW2', 'AH2', 'AA0', 'ZH', 'AE0', 'AO2', 'UW2', 'AO0', 'AY0', 'IY2', 'AW2', 'UH2', 'EY0', 'ER2', 'AW0', 'UH0', 'OY2', 'OY0', "'", '<sos/eos>'], odim=None, model_conf={}, use_preprocessor=True, token_type='phn', bpemodel=None, non_linguistic_symbols=None, cleaner='tacotron', g2p='g2p_en', feats_extract='linear_spectrogram', feats_extract_conf={'n_fft': 1024, 'hop_length': 256, 'win_length': None}, normalize=None, normalize_conf={}, tts='vits', tts_conf={'generator_type': 'vits_generator', 'generator_params': {'hidden_channels': 192, 'spks': 128, 'global_channels': 256, 'segment_size': 32, 'text_encoder_attention_heads': 2, 'text_encoder_ffn_expand': 4, 'text_encoder_blocks': 6, 'text_encoder_positionwise_layer_type': 'conv1d', 'text_encoder_positionwise_conv_kernel_size': 3, 'text_encoder_positional_encoding_layer_type': 'rel_pos', 'text_encoder_self_attention_layer_type': 'rel_selfattn', 'text_encoder_activation_type': 'swish', 'text_encoder_normalize_before': True, 'text_encoder_dropout_rate': 0.1, 'text_encoder_positional_dropout_rate': 0.0, 'text_encoder_attention_dropout_rate': 0.1, 'use_macaron_style_in_text_encoder': True, 'use_conformer_conv_in_text_encoder': False, 'text_encoder_conformer_kernel_size': -1, 'decoder_kernel_size': 7, 'decoder_channels': 512, 'decoder_upsample_scales': [8, 8, 2, 2], 'decoder_upsample_kernel_sizes': [16, 16, 4, 4], 'decoder_resblock_kernel_sizes': [3, 7, 11], 'decoder_resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'use_weight_norm_in_decoder': True, 'posterior_encoder_kernel_size': 5, 'posterior_encoder_layers': 16, 'posterior_encoder_stacks': 1, 'posterior_encoder_base_dilation': 1, 'posterior_encoder_dropout_rate': 0.0, 'use_weight_norm_in_posterior_encoder': True, 'flow_flows': 4, 'flow_kernel_size': 5, 'flow_base_dilation': 1, 'flow_layers': 4, 'flow_dropout_rate': 0.0, 'use_weight_norm_in_flow': True, 'use_only_mean_in_flow': True, 'stochastic_duration_predictor_kernel_size': 3, 'stochastic_duration_predictor_dropout_rate': 0.5, 'stochastic_duration_predictor_flows': 4, 'stochastic_duration_predictor_dds_conv_layers': 3, 'vocabs': 74, 'aux_channels': 513}, 'discriminator_type': 'hifigan_multi_scale_multi_period_discriminator', 'discriminator_params': {'scales': 1, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'stride': 2, 'padding': 2}, 'scale_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'channels': 128, 'max_downsample_channels': 1024, 'max_groups': 16, 'bias': True, 'downsample_scales': [2, 2, 4, 4, 1], 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}, 'follow_official_norm': False, 'periods': [2, 3, 5, 7, 11], 'period_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [5, 3], 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'max_downsample_channels': 1024, 'bias': True, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}}, 'generator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'discriminator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'feat_match_loss_params': {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, 'mel_loss_params': {'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None, 'window': 'hann', 'n_mels': 80, 'fmin': 0, 'fmax': None, 'log_base': None}, 'lambda_adv': 1.0, 'lambda_mel': 45.0, 'lambda_feat_match': 2.0, 'lambda_dur': 1.0, 'lambda_kl': 1.0, 'sampling_rate': 22050, 'cache_generator_outputs': True, 'plot_pred_mos': False, 'mos_pred_tool': 'utmos'}, pitch_extract=None, pitch_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'f0max': 400, 'f0min': 80}, pitch_normalize=None, pitch_normalize_conf={}, energy_extract=None, energy_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None}, energy_normalize=None, energy_normalize_conf={}, required=['output_dir', 'token_list'], version='202503', distributed=False)
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1284, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 63906) is killed by signal: Killed. 

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 22, in <module>
    main()
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 18, in main
    GANTTSTask.main(cmd=cmd)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1225, in main
    cls.main_worker(args)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1441, in main_worker
    collect_stats(
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/main_funcs/collect_stats.py", line 51, in collect_stats
    for iiter, (keys, batch) in enumerate(itr, 1):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 733, in __next__
    data = self._next_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1491, in _next_data
    idx, data = self._get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1453, in _get_data
    success, data = self._try_get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1297, in _try_get_data
    raise RuntimeError(
RuntimeError: DataLoader worker (pid(s) 63906) exited unexpectedly
# Accounting: begin_time=1750873256
# Accounting: end_time=1750873472
# Accounting: time=216 threads=1
# Finished at Wed Jun 25 13:44:32 EDT 2025 with status 1
# Running on r313.ib.bridges2.psc.edu
# Started at Wed Jun 25 13:41:01 EDT 2025
# SLURMD_NODENAME=r313
# SLURM_ARRAY_JOB_ID=32990217
# SLURM_ARRAY_TASK_COUNT=32
# SLURM_ARRAY_TASK_ID=19
# SLURM_ARRAY_TASK_MAX=32
# SLURM_ARRAY_TASK_MIN=1
# SLURM_ARRAY_TASK_STEP=1
# SLURM_CLUSTER_NAME=bridges2
# SLURM_CONF=/var/spool/slurm/d/conf-cache/slurm.conf
# SLURM_CPUS_ON_NODE=1
# SLURM_CPU_BIND=quiet,mask_cpu:0x07C0000000
# SLURM_CPU_BIND_LIST=0x07C0000000
# SLURM_CPU_BIND_TYPE=mask_cpu:
# SLURM_CPU_BIND_VERBOSE=quiet
# SLURM_EXPORT_ENV=ALL
# SLURM_GET_USER_ENV=1
# SLURM_GTIDS=0
# SLURM_JOBID=32990237
# SLURM_JOB_ACCOUNT=cis210027p
# SLURM_JOB_CPUS_PER_NODE=1
# SLURM_JOB_GID=24886
# SLURM_JOB_ID=32990237
# SLURM_JOB_NAME=stats.sh
# SLURM_JOB_NODELIST=r313
# SLURM_JOB_NUM_NODES=1
# SLURM_JOB_PARTITION=RM-shared
# SLURM_JOB_QOS=rm
# SLURM_JOB_UID=97947
# SLURM_JOB_USER=ttao3
# SLURM_LAUNCH_NODE_IPADDR=10.8.11.29
# SLURM_LOCALID=0
# SLURM_MEM_PER_CPU=1900
# SLURM_NNODES=1
# SLURM_NODEID=0
# SLURM_NODELIST=r313
# SLURM_NODE_ALIASES='(null)'
# SLURM_NPROCS=1
# SLURM_NTASKS=1
# SLURM_OPEN_MODE=a
# SLURM_PRIO_PROCESS=0
# SLURM_PROCID=0
# SLURM_PTY_PORT=33025
# SLURM_PTY_WIN_COL=126
# SLURM_PTY_WIN_ROW=21
# SLURM_SCRIPT_CONTEXT=prolog_task
# SLURM_SRUN_COMM_HOST=10.8.11.29
# SLURM_SRUN_COMM_PORT=35045
# SLURM_STEPID=0
# SLURM_STEP_GPUS=6
# SLURM_STEP_ID=0
# SLURM_STEP_LAUNCHER_PORT=35045
# SLURM_STEP_NODELIST=v029
# SLURM_STEP_NUM_NODES=1
# SLURM_STEP_NUM_TASKS=1
# SLURM_STEP_TASKS_PER_NODE=1
# SLURM_SUBMIT_DIR=/ocean/projects/cis210027p/ttao3/espnet/egs2/hifitts/tts1
# SLURM_SUBMIT_HOST=v029.ib.bridges2.psc.edu
# SLURM_TASKS_PER_NODE=1
# SLURM_TASK_PID=87279
# SLURM_TOPOLOGY_ADDR=r313
# SLURM_TOPOLOGY_ADDR_PATTERN=node
# SLURM_WORKING_CLUSTER=bridges2:br003:6810:9728:109
# python3 -m espnet2.bin.gan_tts_train --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.19.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.19.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.19 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int 
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/librosa/util/files.py:10: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_filename
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/bin/python3 /ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.19.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.19.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.19 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int
Failed to import Flash Attention, using ESPnet default: No module named 'flash_attn_2_cuda'
Vocabulary size: 74
encoder self-attention layer type = relative self-attention
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/ocean/projects/cis210027p/ttao3/espnet/espnet2/gan_tts/vits/monotonic_align/__init__.py:19: UserWarning: Cython version is not available. Fallback to 'EXPERIMETAL' numba version. If you want to use the cython version, please build it as follows: `cd espnet2/gan_tts/vits/monotonic_align; python setup.py build_ext --inplace`
  warnings.warn(
pytorch.version=2.7.1+cu126, cuda.available=False, cudnn.version=90501, cudnn.benchmark=False, cudnn.deterministic=False
Model structure:
ESPnetGANTTSModel(
  (feats_extract): LinearSpectrogram(
    (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
  )
  (tts): VITS(
    (generator): VITSGenerator(
      (text_encoder): TextEncoder(
        (emb): Embedding(74, 192)
        (encoder): Encoder(
          (embed): Sequential(
            (0): RelPositionalEncoding(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (encoders): MultiSequential(
            (0): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (2): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (3): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (4): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (5): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (after_norm): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (decoder): HiFiGANGenerator(
        (input_conv): Conv1d(192, 512, kernel_size=(7,), stride=(1,), padding=(3,))
        (upsamples): ModuleList(
          (0): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (1): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(256, 128, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (2): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,))
          )
          (3): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,))
          )
        )
        (blocks): ModuleList(
          (0): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (1): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (2): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (3): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (4): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (5): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (6): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (7): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (8): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (9): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (10): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (11): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
        )
        (output_conv): Sequential(
          (0): LeakyReLU(negative_slope=0.01)
          (1): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,))
          (2): Tanh()
        )
        (global_conv): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
      )
      (posterior_encoder): PosteriorEncoder(
        (input_conv): Conv1d(513, 192, kernel_size=(1,), stride=(1,))
        (encoder): WaveNet(
          (conv_layers): ModuleList(
            (0-15): 16 x ResidualBlock(
              (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
              (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
              (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
            )
          )
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (flow): ResidualAffineCouplingBlock(
        (flows): ModuleList(
          (0): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (1): FlipFlow()
          (2): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (3): FlipFlow()
          (4): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (5): FlipFlow()
          (6): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (7): FlipFlow()
        )
      )
      (duration_predictor): StochasticDurationPredictor(
        (pre): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (log_flow): LogFlow()
        (flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (post_pre): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
        (post_dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (post_proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (post_flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (global_conv): Conv1d(256, 192, kernel_size=(1,), stride=(1,))
      )
      (global_emb): Embedding(128, 256)
    )
    (discriminator): HiFiGANMultiScaleMultiPeriodDiscriminator(
      (msd): HiFiGANMultiScaleDiscriminator(
        (discriminators): ModuleList(
          (0): HiFiGANScaleDiscriminator(
            (layers): ModuleList(
              (0): Sequential(
                (0): Conv1d(1, 128, kernel_size=(15,), stride=(1,), padding=(7,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv1d(128, 128, kernel_size=(41,), stride=(2,), padding=(20,), groups=4)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv1d(128, 256, kernel_size=(41,), stride=(2,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv1d(256, 512, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv1d(512, 1024, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (5): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(41,), stride=(1,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (6): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (7): Conv1d(1024, 1, kernel_size=(3,), stride=(1,), padding=(1,))
            )
          )
        )
      )
      (mpd): HiFiGANMultiPeriodDiscriminator(
        (discriminators): ModuleList(
          (0-4): 5 x HiFiGANPeriodDiscriminator(
            (convs): ModuleList(
              (0): Sequential(
                (0): Conv2d(1, 32, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv2d(32, 128, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv2d(128, 512, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv2d(512, 1024, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv2d(1024, 1024, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
            )
            (output_conv): Conv2d(1024, 1, kernel_size=(2, 1), stride=(1, 1), padding=(1, 0))
          )
        )
      )
    )
    (generator_adv_loss): GeneratorAdversarialLoss()
    (discriminator_adv_loss): DiscriminatorAdversarialLoss()
    (feat_match_loss): FeatureMatchLoss()
    (mel_loss): MelSpectrogramLoss(
      (wav_to_mel): LogMelFbank(
        (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
        (logmel): LogMel(sr=22050, n_fft=1024, n_mels=80, fmin=0, fmax=11025.0, htk=False)
      )
    )
    (kl_loss): KLDivergenceLoss()
  )
)

Model summary:
    Class Name: ESPnetGANTTSModel
    Total Number of model parameters: 96.37 M
    Number of trainable parameters: 96.37 M (100.0%)
    Size: 385.46 MB
    Type: torch.float32
Optimizer:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler: <torch.optim.lr_scheduler.ExponentialLR object at 0x14ec7c6935b0>
Optimizer2:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler2: <torch.optim.lr_scheduler.ExponentialLR object at 0x14ec7c693970>
Saving the configuration in exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.19/config.yaml
Namespace(config='conf/tuning/train_multi_spk_vits.yaml', print_config=False, log_level='INFO', drop_last_iter=False, dry_run=False, iterator_type='sequence', valid_iterator_type=None, output_dir='exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.19', ngpu=0, seed=777, num_workers=4, num_att_plot=3, dist_backend='nccl', dist_init_method='env://', dist_world_size=None, dist_rank=None, local_rank=None, dist_master_addr=None, dist_master_port=None, dist_launcher=None, multiprocessing_distributed=False, unused_parameters=True, sharded_ddp=False, use_deepspeed=False, deepspeed_config=None, gradient_as_bucket_view=True, ddp_comm_hook=None, cudnn_enabled=True, cudnn_benchmark=False, cudnn_deterministic=False, use_tf32=False, collect_stats=True, write_collected_feats=False, max_epoch=1000, patience=None, val_scheduler_criterion=('valid', 'loss'), early_stopping_criterion=('valid', 'loss', 'min'), best_model_criterion=[['train', 'total_count', 'max']], keep_nbest_models=10, nbest_averaging_interval=0, grad_clip=-1, grad_clip_type=2.0, grad_noise=False, accum_grad=1, no_forward_run=False, resume=False, train_dtype='float32', use_amp=False, log_interval=50, use_matplotlib=True, use_tensorboard=True, create_graph_in_tensorboard=False, use_wandb=False, wandb_project=None, wandb_id=None, wandb_entity=None, wandb_name=None, wandb_model_log_interval=-1, detect_anomaly=False, use_adapter=False, adapter='lora', save_strategy='all', adapter_conf={}, pretrain_path=None, init_param=[], ignore_init_mismatch=False, freeze_param=[], num_iters_per_epoch=1000, batch_size=20, valid_batch_size=None, batch_bins=3000000, valid_batch_bins=None, category_sample_size=10, train_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.19.scp'], valid_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.19.scp'], batch_type='numel', valid_batch_type=None, fold_length=[], sort_in_batch='descending', shuffle_within_batch=False, sort_batch='descending', multiple_iterator=False, chunk_length=500, chunk_shift_ratio=0.5, num_cache_chunks=1024, chunk_excluded_key_prefixes=[], chunk_default_fs=None, chunk_max_abs_length=None, chunk_discard_short_samples=True, train_data_path_and_name_and_type=[('dump/22k/raw/tr_no_dev/text', 'text', 'text'), ('dump/22k/raw/tr_no_dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/tr_no_dev/utt2sid', 'sids', 'text_int')], valid_data_path_and_name_and_type=[('dump/22k/raw/dev/text', 'text', 'text'), ('dump/22k/raw/dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/dev/utt2sid', 'sids', 'text_int')], multi_task_dataset=False, allow_variable_data_keys=False, max_cache_size=0.0, max_cache_fd=32, allow_multi_rates=False, valid_max_cache_size=None, exclude_weight_decay=False, exclude_weight_decay_conf={}, optim='adamw', optim_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler='exponentiallr', scheduler_conf={'gamma': 0.999875}, optim2='adamw', optim2_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler2='exponentiallr', scheduler2_conf={'gamma': 0.999875}, generator_first=False, skip_discriminator_prob=0.0, token_list=['<blank>', '<unk>', ' ', 'AH0', 'N', 'T', 'D', 'S', 'R', 'L', 'IH1', 'DH', 'M', 'EH1', 'Z', 'AE1', 'K', 'IH0', 'AH1', 'HH', 'W', 'ER0', 'V', 'IY1', 'F', 'UW1', 'P', 'AY1', 'B', 'AA1', 'AO1', 'EY1', 'IY0', 'OW1', 'NG', 'SH', 'G', 'Y', 'AW1', 'CH', 'ER1', 'UH1', 'TH', 'JH', 'OW0', 'EH2', 'IH2', 'OY1', 'EY2', 'AY2', 'EH0', 'UW0', 'AA2', 'AE2', 'OW2', 'AH2', 'AA0', 'ZH', 'AE0', 'AO2', 'UW2', 'AO0', 'AY0', 'IY2', 'AW2', 'UH2', 'EY0', 'ER2', 'AW0', 'UH0', 'OY2', 'OY0', "'", '<sos/eos>'], odim=None, model_conf={}, use_preprocessor=True, token_type='phn', bpemodel=None, non_linguistic_symbols=None, cleaner='tacotron', g2p='g2p_en', feats_extract='linear_spectrogram', feats_extract_conf={'n_fft': 1024, 'hop_length': 256, 'win_length': None}, normalize=None, normalize_conf={}, tts='vits', tts_conf={'generator_type': 'vits_generator', 'generator_params': {'hidden_channels': 192, 'spks': 128, 'global_channels': 256, 'segment_size': 32, 'text_encoder_attention_heads': 2, 'text_encoder_ffn_expand': 4, 'text_encoder_blocks': 6, 'text_encoder_positionwise_layer_type': 'conv1d', 'text_encoder_positionwise_conv_kernel_size': 3, 'text_encoder_positional_encoding_layer_type': 'rel_pos', 'text_encoder_self_attention_layer_type': 'rel_selfattn', 'text_encoder_activation_type': 'swish', 'text_encoder_normalize_before': True, 'text_encoder_dropout_rate': 0.1, 'text_encoder_positional_dropout_rate': 0.0, 'text_encoder_attention_dropout_rate': 0.1, 'use_macaron_style_in_text_encoder': True, 'use_conformer_conv_in_text_encoder': False, 'text_encoder_conformer_kernel_size': -1, 'decoder_kernel_size': 7, 'decoder_channels': 512, 'decoder_upsample_scales': [8, 8, 2, 2], 'decoder_upsample_kernel_sizes': [16, 16, 4, 4], 'decoder_resblock_kernel_sizes': [3, 7, 11], 'decoder_resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'use_weight_norm_in_decoder': True, 'posterior_encoder_kernel_size': 5, 'posterior_encoder_layers': 16, 'posterior_encoder_stacks': 1, 'posterior_encoder_base_dilation': 1, 'posterior_encoder_dropout_rate': 0.0, 'use_weight_norm_in_posterior_encoder': True, 'flow_flows': 4, 'flow_kernel_size': 5, 'flow_base_dilation': 1, 'flow_layers': 4, 'flow_dropout_rate': 0.0, 'use_weight_norm_in_flow': True, 'use_only_mean_in_flow': True, 'stochastic_duration_predictor_kernel_size': 3, 'stochastic_duration_predictor_dropout_rate': 0.5, 'stochastic_duration_predictor_flows': 4, 'stochastic_duration_predictor_dds_conv_layers': 3, 'vocabs': 74, 'aux_channels': 513}, 'discriminator_type': 'hifigan_multi_scale_multi_period_discriminator', 'discriminator_params': {'scales': 1, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'stride': 2, 'padding': 2}, 'scale_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'channels': 128, 'max_downsample_channels': 1024, 'max_groups': 16, 'bias': True, 'downsample_scales': [2, 2, 4, 4, 1], 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}, 'follow_official_norm': False, 'periods': [2, 3, 5, 7, 11], 'period_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [5, 3], 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'max_downsample_channels': 1024, 'bias': True, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}}, 'generator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'discriminator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'feat_match_loss_params': {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, 'mel_loss_params': {'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None, 'window': 'hann', 'n_mels': 80, 'fmin': 0, 'fmax': None, 'log_base': None}, 'lambda_adv': 1.0, 'lambda_mel': 45.0, 'lambda_feat_match': 2.0, 'lambda_dur': 1.0, 'lambda_kl': 1.0, 'sampling_rate': 22050, 'cache_generator_outputs': True, 'plot_pred_mos': False, 'mos_pred_tool': 'utmos'}, pitch_extract=None, pitch_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'f0max': 400, 'f0min': 80}, pitch_normalize=None, pitch_normalize_conf={}, energy_extract=None, energy_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None}, energy_normalize=None, energy_normalize_conf={}, required=['output_dir', 'token_list'], version='202503', distributed=False)
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1284, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 87367) is killed by signal: Killed. 

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 22, in <module>
    main()
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 18, in main
    GANTTSTask.main(cmd=cmd)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1225, in main
    cls.main_worker(args)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1441, in main_worker
    collect_stats(
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/main_funcs/collect_stats.py", line 51, in collect_stats
    for iiter, (keys, batch) in enumerate(itr, 1):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 733, in __next__
    data = self._next_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1491, in _next_data
    idx, data = self._get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1453, in _get_data
    success, data = self._try_get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1297, in _try_get_data
    raise RuntimeError(
RuntimeError: DataLoader worker (pid(s) 87367) exited unexpectedly
# Accounting: begin_time=1750873261
# Accounting: end_time=1750873472
# Accounting: time=211 threads=1
# Finished at Wed Jun 25 13:44:32 EDT 2025 with status 1
# Running on r037.ib.bridges2.psc.edu
# Started at Wed Jun 25 13:40:56 EDT 2025
# SLURMD_NODENAME=r037
# SLURM_ARRAY_JOB_ID=32990217
# SLURM_ARRAY_TASK_COUNT=32
# SLURM_ARRAY_TASK_ID=2
# SLURM_ARRAY_TASK_MAX=32
# SLURM_ARRAY_TASK_MIN=1
# SLURM_ARRAY_TASK_STEP=1
# SLURM_CLUSTER_NAME=bridges2
# SLURM_CONF=/var/spool/slurm/d/conf-cache/slurm.conf
# SLURM_CPUS_ON_NODE=1
# SLURM_CPU_BIND=quiet,mask_cpu:0x07C0000000
# SLURM_CPU_BIND_LIST=0x07C0000000
# SLURM_CPU_BIND_TYPE=mask_cpu:
# SLURM_CPU_BIND_VERBOSE=quiet
# SLURM_EXPORT_ENV=ALL
# SLURM_GET_USER_ENV=1
# SLURM_GTIDS=0
# SLURM_JOBID=32990220
# SLURM_JOB_ACCOUNT=cis210027p
# SLURM_JOB_CPUS_PER_NODE=1
# SLURM_JOB_GID=24886
# SLURM_JOB_ID=32990220
# SLURM_JOB_NAME=stats.sh
# SLURM_JOB_NODELIST=r037
# SLURM_JOB_NUM_NODES=1
# SLURM_JOB_PARTITION=RM-shared
# SLURM_JOB_QOS=rm
# SLURM_JOB_UID=97947
# SLURM_JOB_USER=ttao3
# SLURM_LAUNCH_NODE_IPADDR=10.8.11.29
# SLURM_LOCALID=0
# SLURM_MEM_PER_CPU=1900
# SLURM_NNODES=1
# SLURM_NODEID=0
# SLURM_NODELIST=r037
# SLURM_NODE_ALIASES='(null)'
# SLURM_NPROCS=1
# SLURM_NTASKS=1
# SLURM_OPEN_MODE=a
# SLURM_PRIO_PROCESS=0
# SLURM_PROCID=0
# SLURM_PTY_PORT=33025
# SLURM_PTY_WIN_COL=126
# SLURM_PTY_WIN_ROW=21
# SLURM_SCRIPT_CONTEXT=prolog_task
# SLURM_SRUN_COMM_HOST=10.8.11.29
# SLURM_SRUN_COMM_PORT=35045
# SLURM_STEPID=0
# SLURM_STEP_GPUS=6
# SLURM_STEP_ID=0
# SLURM_STEP_LAUNCHER_PORT=35045
# SLURM_STEP_NODELIST=v029
# SLURM_STEP_NUM_NODES=1
# SLURM_STEP_NUM_TASKS=1
# SLURM_STEP_TASKS_PER_NODE=1
# SLURM_SUBMIT_DIR=/ocean/projects/cis210027p/ttao3/espnet/egs2/hifitts/tts1
# SLURM_SUBMIT_HOST=v029.ib.bridges2.psc.edu
# SLURM_TASKS_PER_NODE=1
# SLURM_TASK_PID=66033
# SLURM_TOPOLOGY_ADDR=r037
# SLURM_TOPOLOGY_ADDR_PATTERN=node
# SLURM_WORKING_CLUSTER=bridges2:br003:6810:9728:109
# python3 -m espnet2.bin.gan_tts_train --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.2.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.2.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.2 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int 
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/librosa/util/files.py:10: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_filename
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/bin/python3 /ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.2.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.2.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.2 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int
Failed to import Flash Attention, using ESPnet default: No module named 'flash_attn_2_cuda'
Vocabulary size: 74
encoder self-attention layer type = relative self-attention
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/ocean/projects/cis210027p/ttao3/espnet/espnet2/gan_tts/vits/monotonic_align/__init__.py:19: UserWarning: Cython version is not available. Fallback to 'EXPERIMETAL' numba version. If you want to use the cython version, please build it as follows: `cd espnet2/gan_tts/vits/monotonic_align; python setup.py build_ext --inplace`
  warnings.warn(
pytorch.version=2.7.1+cu126, cuda.available=False, cudnn.version=90501, cudnn.benchmark=False, cudnn.deterministic=False
Model structure:
ESPnetGANTTSModel(
  (feats_extract): LinearSpectrogram(
    (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
  )
  (tts): VITS(
    (generator): VITSGenerator(
      (text_encoder): TextEncoder(
        (emb): Embedding(74, 192)
        (encoder): Encoder(
          (embed): Sequential(
            (0): RelPositionalEncoding(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (encoders): MultiSequential(
            (0): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (2): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (3): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (4): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (5): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (after_norm): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (decoder): HiFiGANGenerator(
        (input_conv): Conv1d(192, 512, kernel_size=(7,), stride=(1,), padding=(3,))
        (upsamples): ModuleList(
          (0): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (1): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(256, 128, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (2): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,))
          )
          (3): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,))
          )
        )
        (blocks): ModuleList(
          (0): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (1): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (2): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (3): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (4): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (5): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (6): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (7): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (8): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (9): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (10): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (11): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
        )
        (output_conv): Sequential(
          (0): LeakyReLU(negative_slope=0.01)
          (1): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,))
          (2): Tanh()
        )
        (global_conv): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
      )
      (posterior_encoder): PosteriorEncoder(
        (input_conv): Conv1d(513, 192, kernel_size=(1,), stride=(1,))
        (encoder): WaveNet(
          (conv_layers): ModuleList(
            (0-15): 16 x ResidualBlock(
              (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
              (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
              (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
            )
          )
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (flow): ResidualAffineCouplingBlock(
        (flows): ModuleList(
          (0): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (1): FlipFlow()
          (2): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (3): FlipFlow()
          (4): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (5): FlipFlow()
          (6): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (7): FlipFlow()
        )
      )
      (duration_predictor): StochasticDurationPredictor(
        (pre): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (log_flow): LogFlow()
        (flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (post_pre): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
        (post_dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (post_proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (post_flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (global_conv): Conv1d(256, 192, kernel_size=(1,), stride=(1,))
      )
      (global_emb): Embedding(128, 256)
    )
    (discriminator): HiFiGANMultiScaleMultiPeriodDiscriminator(
      (msd): HiFiGANMultiScaleDiscriminator(
        (discriminators): ModuleList(
          (0): HiFiGANScaleDiscriminator(
            (layers): ModuleList(
              (0): Sequential(
                (0): Conv1d(1, 128, kernel_size=(15,), stride=(1,), padding=(7,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv1d(128, 128, kernel_size=(41,), stride=(2,), padding=(20,), groups=4)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv1d(128, 256, kernel_size=(41,), stride=(2,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv1d(256, 512, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv1d(512, 1024, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (5): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(41,), stride=(1,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (6): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (7): Conv1d(1024, 1, kernel_size=(3,), stride=(1,), padding=(1,))
            )
          )
        )
      )
      (mpd): HiFiGANMultiPeriodDiscriminator(
        (discriminators): ModuleList(
          (0-4): 5 x HiFiGANPeriodDiscriminator(
            (convs): ModuleList(
              (0): Sequential(
                (0): Conv2d(1, 32, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv2d(32, 128, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv2d(128, 512, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv2d(512, 1024, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv2d(1024, 1024, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
            )
            (output_conv): Conv2d(1024, 1, kernel_size=(2, 1), stride=(1, 1), padding=(1, 0))
          )
        )
      )
    )
    (generator_adv_loss): GeneratorAdversarialLoss()
    (discriminator_adv_loss): DiscriminatorAdversarialLoss()
    (feat_match_loss): FeatureMatchLoss()
    (mel_loss): MelSpectrogramLoss(
      (wav_to_mel): LogMelFbank(
        (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
        (logmel): LogMel(sr=22050, n_fft=1024, n_mels=80, fmin=0, fmax=11025.0, htk=False)
      )
    )
    (kl_loss): KLDivergenceLoss()
  )
)

Model summary:
    Class Name: ESPnetGANTTSModel
    Total Number of model parameters: 96.37 M
    Number of trainable parameters: 96.37 M (100.0%)
    Size: 385.46 MB
    Type: torch.float32
Optimizer:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler: <torch.optim.lr_scheduler.ExponentialLR object at 0x1459c883c5b0>
Optimizer2:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler2: <torch.optim.lr_scheduler.ExponentialLR object at 0x1459c883c970>
Saving the configuration in exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.2/config.yaml
Namespace(config='conf/tuning/train_multi_spk_vits.yaml', print_config=False, log_level='INFO', drop_last_iter=False, dry_run=False, iterator_type='sequence', valid_iterator_type=None, output_dir='exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.2', ngpu=0, seed=777, num_workers=4, num_att_plot=3, dist_backend='nccl', dist_init_method='env://', dist_world_size=None, dist_rank=None, local_rank=None, dist_master_addr=None, dist_master_port=None, dist_launcher=None, multiprocessing_distributed=False, unused_parameters=True, sharded_ddp=False, use_deepspeed=False, deepspeed_config=None, gradient_as_bucket_view=True, ddp_comm_hook=None, cudnn_enabled=True, cudnn_benchmark=False, cudnn_deterministic=False, use_tf32=False, collect_stats=True, write_collected_feats=False, max_epoch=1000, patience=None, val_scheduler_criterion=('valid', 'loss'), early_stopping_criterion=('valid', 'loss', 'min'), best_model_criterion=[['train', 'total_count', 'max']], keep_nbest_models=10, nbest_averaging_interval=0, grad_clip=-1, grad_clip_type=2.0, grad_noise=False, accum_grad=1, no_forward_run=False, resume=False, train_dtype='float32', use_amp=False, log_interval=50, use_matplotlib=True, use_tensorboard=True, create_graph_in_tensorboard=False, use_wandb=False, wandb_project=None, wandb_id=None, wandb_entity=None, wandb_name=None, wandb_model_log_interval=-1, detect_anomaly=False, use_adapter=False, adapter='lora', save_strategy='all', adapter_conf={}, pretrain_path=None, init_param=[], ignore_init_mismatch=False, freeze_param=[], num_iters_per_epoch=1000, batch_size=20, valid_batch_size=None, batch_bins=3000000, valid_batch_bins=None, category_sample_size=10, train_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.2.scp'], valid_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.2.scp'], batch_type='numel', valid_batch_type=None, fold_length=[], sort_in_batch='descending', shuffle_within_batch=False, sort_batch='descending', multiple_iterator=False, chunk_length=500, chunk_shift_ratio=0.5, num_cache_chunks=1024, chunk_excluded_key_prefixes=[], chunk_default_fs=None, chunk_max_abs_length=None, chunk_discard_short_samples=True, train_data_path_and_name_and_type=[('dump/22k/raw/tr_no_dev/text', 'text', 'text'), ('dump/22k/raw/tr_no_dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/tr_no_dev/utt2sid', 'sids', 'text_int')], valid_data_path_and_name_and_type=[('dump/22k/raw/dev/text', 'text', 'text'), ('dump/22k/raw/dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/dev/utt2sid', 'sids', 'text_int')], multi_task_dataset=False, allow_variable_data_keys=False, max_cache_size=0.0, max_cache_fd=32, allow_multi_rates=False, valid_max_cache_size=None, exclude_weight_decay=False, exclude_weight_decay_conf={}, optim='adamw', optim_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler='exponentiallr', scheduler_conf={'gamma': 0.999875}, optim2='adamw', optim2_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler2='exponentiallr', scheduler2_conf={'gamma': 0.999875}, generator_first=False, skip_discriminator_prob=0.0, token_list=['<blank>', '<unk>', ' ', 'AH0', 'N', 'T', 'D', 'S', 'R', 'L', 'IH1', 'DH', 'M', 'EH1', 'Z', 'AE1', 'K', 'IH0', 'AH1', 'HH', 'W', 'ER0', 'V', 'IY1', 'F', 'UW1', 'P', 'AY1', 'B', 'AA1', 'AO1', 'EY1', 'IY0', 'OW1', 'NG', 'SH', 'G', 'Y', 'AW1', 'CH', 'ER1', 'UH1', 'TH', 'JH', 'OW0', 'EH2', 'IH2', 'OY1', 'EY2', 'AY2', 'EH0', 'UW0', 'AA2', 'AE2', 'OW2', 'AH2', 'AA0', 'ZH', 'AE0', 'AO2', 'UW2', 'AO0', 'AY0', 'IY2', 'AW2', 'UH2', 'EY0', 'ER2', 'AW0', 'UH0', 'OY2', 'OY0', "'", '<sos/eos>'], odim=None, model_conf={}, use_preprocessor=True, token_type='phn', bpemodel=None, non_linguistic_symbols=None, cleaner='tacotron', g2p='g2p_en', feats_extract='linear_spectrogram', feats_extract_conf={'n_fft': 1024, 'hop_length': 256, 'win_length': None}, normalize=None, normalize_conf={}, tts='vits', tts_conf={'generator_type': 'vits_generator', 'generator_params': {'hidden_channels': 192, 'spks': 128, 'global_channels': 256, 'segment_size': 32, 'text_encoder_attention_heads': 2, 'text_encoder_ffn_expand': 4, 'text_encoder_blocks': 6, 'text_encoder_positionwise_layer_type': 'conv1d', 'text_encoder_positionwise_conv_kernel_size': 3, 'text_encoder_positional_encoding_layer_type': 'rel_pos', 'text_encoder_self_attention_layer_type': 'rel_selfattn', 'text_encoder_activation_type': 'swish', 'text_encoder_normalize_before': True, 'text_encoder_dropout_rate': 0.1, 'text_encoder_positional_dropout_rate': 0.0, 'text_encoder_attention_dropout_rate': 0.1, 'use_macaron_style_in_text_encoder': True, 'use_conformer_conv_in_text_encoder': False, 'text_encoder_conformer_kernel_size': -1, 'decoder_kernel_size': 7, 'decoder_channels': 512, 'decoder_upsample_scales': [8, 8, 2, 2], 'decoder_upsample_kernel_sizes': [16, 16, 4, 4], 'decoder_resblock_kernel_sizes': [3, 7, 11], 'decoder_resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'use_weight_norm_in_decoder': True, 'posterior_encoder_kernel_size': 5, 'posterior_encoder_layers': 16, 'posterior_encoder_stacks': 1, 'posterior_encoder_base_dilation': 1, 'posterior_encoder_dropout_rate': 0.0, 'use_weight_norm_in_posterior_encoder': True, 'flow_flows': 4, 'flow_kernel_size': 5, 'flow_base_dilation': 1, 'flow_layers': 4, 'flow_dropout_rate': 0.0, 'use_weight_norm_in_flow': True, 'use_only_mean_in_flow': True, 'stochastic_duration_predictor_kernel_size': 3, 'stochastic_duration_predictor_dropout_rate': 0.5, 'stochastic_duration_predictor_flows': 4, 'stochastic_duration_predictor_dds_conv_layers': 3, 'vocabs': 74, 'aux_channels': 513}, 'discriminator_type': 'hifigan_multi_scale_multi_period_discriminator', 'discriminator_params': {'scales': 1, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'stride': 2, 'padding': 2}, 'scale_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'channels': 128, 'max_downsample_channels': 1024, 'max_groups': 16, 'bias': True, 'downsample_scales': [2, 2, 4, 4, 1], 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}, 'follow_official_norm': False, 'periods': [2, 3, 5, 7, 11], 'period_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [5, 3], 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'max_downsample_channels': 1024, 'bias': True, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}}, 'generator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'discriminator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'feat_match_loss_params': {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, 'mel_loss_params': {'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None, 'window': 'hann', 'n_mels': 80, 'fmin': 0, 'fmax': None, 'log_base': None}, 'lambda_adv': 1.0, 'lambda_mel': 45.0, 'lambda_feat_match': 2.0, 'lambda_dur': 1.0, 'lambda_kl': 1.0, 'sampling_rate': 22050, 'cache_generator_outputs': True, 'plot_pred_mos': False, 'mos_pred_tool': 'utmos'}, pitch_extract=None, pitch_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'f0max': 400, 'f0min': 80}, pitch_normalize=None, pitch_normalize_conf={}, energy_extract=None, energy_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None}, energy_normalize=None, energy_normalize_conf={}, required=['output_dir', 'token_list'], version='202503', distributed=False)
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1284, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/queues.py", line 114, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 22, in <module>
    main()
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 18, in main
    GANTTSTask.main(cmd=cmd)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1225, in main
    cls.main_worker(args)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1441, in main_worker
    collect_stats(
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/main_funcs/collect_stats.py", line 51, in collect_stats
    for iiter, (keys, batch) in enumerate(itr, 1):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 733, in __next__
    data = self._next_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1491, in _next_data
    idx, data = self._get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1453, in _get_data
    success, data = self._try_get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1292, in _try_get_data
    if self._workers_status[worker_id] and not w.is_alive():
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/process.py", line 165, in is_alive
    returncode = self._popen.poll()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/popen_fork.py", line 27, in poll
    pid, sts = os.waitpid(self.pid, flag)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 66079) is killed by signal: Killed. 
# Accounting: begin_time=1750873256
# Accounting: end_time=1750873472
# Accounting: time=216 threads=1
# Finished at Wed Jun 25 13:44:32 EDT 2025 with status 1
# Running on r313.ib.bridges2.psc.edu
# Started at Wed Jun 25 13:41:01 EDT 2025
# SLURMD_NODENAME=r313
# SLURM_ARRAY_JOB_ID=32990217
# SLURM_ARRAY_TASK_COUNT=32
# SLURM_ARRAY_TASK_ID=20
# SLURM_ARRAY_TASK_MAX=32
# SLURM_ARRAY_TASK_MIN=1
# SLURM_ARRAY_TASK_STEP=1
# SLURM_CLUSTER_NAME=bridges2
# SLURM_CONF=/var/spool/slurm/d/conf-cache/slurm.conf
# SLURM_CPUS_ON_NODE=1
# SLURM_CPU_BIND=quiet,mask_cpu:0x07C0000000
# SLURM_CPU_BIND_LIST=0x07C0000000
# SLURM_CPU_BIND_TYPE=mask_cpu:
# SLURM_CPU_BIND_VERBOSE=quiet
# SLURM_EXPORT_ENV=ALL
# SLURM_GET_USER_ENV=1
# SLURM_GTIDS=0
# SLURM_JOBID=32990238
# SLURM_JOB_ACCOUNT=cis210027p
# SLURM_JOB_CPUS_PER_NODE=1
# SLURM_JOB_GID=24886
# SLURM_JOB_ID=32990238
# SLURM_JOB_NAME=stats.sh
# SLURM_JOB_NODELIST=r313
# SLURM_JOB_NUM_NODES=1
# SLURM_JOB_PARTITION=RM-shared
# SLURM_JOB_QOS=rm
# SLURM_JOB_UID=97947
# SLURM_JOB_USER=ttao3
# SLURM_LAUNCH_NODE_IPADDR=10.8.11.29
# SLURM_LOCALID=0
# SLURM_MEM_PER_CPU=1900
# SLURM_NNODES=1
# SLURM_NODEID=0
# SLURM_NODELIST=r313
# SLURM_NODE_ALIASES='(null)'
# SLURM_NPROCS=1
# SLURM_NTASKS=1
# SLURM_OPEN_MODE=a
# SLURM_PRIO_PROCESS=0
# SLURM_PROCID=0
# SLURM_PTY_PORT=33025
# SLURM_PTY_WIN_COL=126
# SLURM_PTY_WIN_ROW=21
# SLURM_SCRIPT_CONTEXT=prolog_task
# SLURM_SRUN_COMM_HOST=10.8.11.29
# SLURM_SRUN_COMM_PORT=35045
# SLURM_STEPID=0
# SLURM_STEP_GPUS=6
# SLURM_STEP_ID=0
# SLURM_STEP_LAUNCHER_PORT=35045
# SLURM_STEP_NODELIST=v029
# SLURM_STEP_NUM_NODES=1
# SLURM_STEP_NUM_TASKS=1
# SLURM_STEP_TASKS_PER_NODE=1
# SLURM_SUBMIT_DIR=/ocean/projects/cis210027p/ttao3/espnet/egs2/hifitts/tts1
# SLURM_SUBMIT_HOST=v029.ib.bridges2.psc.edu
# SLURM_TASKS_PER_NODE=1
# SLURM_TASK_PID=87280
# SLURM_TOPOLOGY_ADDR=r313
# SLURM_TOPOLOGY_ADDR_PATTERN=node
# SLURM_WORKING_CLUSTER=bridges2:br003:6810:9728:109
# python3 -m espnet2.bin.gan_tts_train --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.20.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.20.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.20 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int 
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/librosa/util/files.py:10: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_filename
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/bin/python3 /ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.20.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.20.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.20 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int
Failed to import Flash Attention, using ESPnet default: No module named 'flash_attn_2_cuda'
Vocabulary size: 74
encoder self-attention layer type = relative self-attention
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/ocean/projects/cis210027p/ttao3/espnet/espnet2/gan_tts/vits/monotonic_align/__init__.py:19: UserWarning: Cython version is not available. Fallback to 'EXPERIMETAL' numba version. If you want to use the cython version, please build it as follows: `cd espnet2/gan_tts/vits/monotonic_align; python setup.py build_ext --inplace`
  warnings.warn(
pytorch.version=2.7.1+cu126, cuda.available=False, cudnn.version=90501, cudnn.benchmark=False, cudnn.deterministic=False
Model structure:
ESPnetGANTTSModel(
  (feats_extract): LinearSpectrogram(
    (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
  )
  (tts): VITS(
    (generator): VITSGenerator(
      (text_encoder): TextEncoder(
        (emb): Embedding(74, 192)
        (encoder): Encoder(
          (embed): Sequential(
            (0): RelPositionalEncoding(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (encoders): MultiSequential(
            (0): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (2): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (3): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (4): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (5): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (after_norm): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (decoder): HiFiGANGenerator(
        (input_conv): Conv1d(192, 512, kernel_size=(7,), stride=(1,), padding=(3,))
        (upsamples): ModuleList(
          (0): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (1): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(256, 128, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (2): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,))
          )
          (3): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,))
          )
        )
        (blocks): ModuleList(
          (0): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (1): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (2): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (3): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (4): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (5): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (6): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (7): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (8): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (9): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (10): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (11): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
        )
        (output_conv): Sequential(
          (0): LeakyReLU(negative_slope=0.01)
          (1): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,))
          (2): Tanh()
        )
        (global_conv): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
      )
      (posterior_encoder): PosteriorEncoder(
        (input_conv): Conv1d(513, 192, kernel_size=(1,), stride=(1,))
        (encoder): WaveNet(
          (conv_layers): ModuleList(
            (0-15): 16 x ResidualBlock(
              (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
              (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
              (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
            )
          )
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (flow): ResidualAffineCouplingBlock(
        (flows): ModuleList(
          (0): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (1): FlipFlow()
          (2): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (3): FlipFlow()
          (4): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (5): FlipFlow()
          (6): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (7): FlipFlow()
        )
      )
      (duration_predictor): StochasticDurationPredictor(
        (pre): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (log_flow): LogFlow()
        (flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (post_pre): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
        (post_dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (post_proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (post_flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (global_conv): Conv1d(256, 192, kernel_size=(1,), stride=(1,))
      )
      (global_emb): Embedding(128, 256)
    )
    (discriminator): HiFiGANMultiScaleMultiPeriodDiscriminator(
      (msd): HiFiGANMultiScaleDiscriminator(
        (discriminators): ModuleList(
          (0): HiFiGANScaleDiscriminator(
            (layers): ModuleList(
              (0): Sequential(
                (0): Conv1d(1, 128, kernel_size=(15,), stride=(1,), padding=(7,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv1d(128, 128, kernel_size=(41,), stride=(2,), padding=(20,), groups=4)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv1d(128, 256, kernel_size=(41,), stride=(2,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv1d(256, 512, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv1d(512, 1024, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (5): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(41,), stride=(1,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (6): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (7): Conv1d(1024, 1, kernel_size=(3,), stride=(1,), padding=(1,))
            )
          )
        )
      )
      (mpd): HiFiGANMultiPeriodDiscriminator(
        (discriminators): ModuleList(
          (0-4): 5 x HiFiGANPeriodDiscriminator(
            (convs): ModuleList(
              (0): Sequential(
                (0): Conv2d(1, 32, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv2d(32, 128, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv2d(128, 512, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv2d(512, 1024, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv2d(1024, 1024, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
            )
            (output_conv): Conv2d(1024, 1, kernel_size=(2, 1), stride=(1, 1), padding=(1, 0))
          )
        )
      )
    )
    (generator_adv_loss): GeneratorAdversarialLoss()
    (discriminator_adv_loss): DiscriminatorAdversarialLoss()
    (feat_match_loss): FeatureMatchLoss()
    (mel_loss): MelSpectrogramLoss(
      (wav_to_mel): LogMelFbank(
        (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
        (logmel): LogMel(sr=22050, n_fft=1024, n_mels=80, fmin=0, fmax=11025.0, htk=False)
      )
    )
    (kl_loss): KLDivergenceLoss()
  )
)

Model summary:
    Class Name: ESPnetGANTTSModel
    Total Number of model parameters: 96.37 M
    Number of trainable parameters: 96.37 M (100.0%)
    Size: 385.46 MB
    Type: torch.float32
Optimizer:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler: <torch.optim.lr_scheduler.ExponentialLR object at 0x14d4f15555e0>
Optimizer2:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler2: <torch.optim.lr_scheduler.ExponentialLR object at 0x14d4f15559d0>
Saving the configuration in exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.20/config.yaml
Namespace(config='conf/tuning/train_multi_spk_vits.yaml', print_config=False, log_level='INFO', drop_last_iter=False, dry_run=False, iterator_type='sequence', valid_iterator_type=None, output_dir='exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.20', ngpu=0, seed=777, num_workers=4, num_att_plot=3, dist_backend='nccl', dist_init_method='env://', dist_world_size=None, dist_rank=None, local_rank=None, dist_master_addr=None, dist_master_port=None, dist_launcher=None, multiprocessing_distributed=False, unused_parameters=True, sharded_ddp=False, use_deepspeed=False, deepspeed_config=None, gradient_as_bucket_view=True, ddp_comm_hook=None, cudnn_enabled=True, cudnn_benchmark=False, cudnn_deterministic=False, use_tf32=False, collect_stats=True, write_collected_feats=False, max_epoch=1000, patience=None, val_scheduler_criterion=('valid', 'loss'), early_stopping_criterion=('valid', 'loss', 'min'), best_model_criterion=[['train', 'total_count', 'max']], keep_nbest_models=10, nbest_averaging_interval=0, grad_clip=-1, grad_clip_type=2.0, grad_noise=False, accum_grad=1, no_forward_run=False, resume=False, train_dtype='float32', use_amp=False, log_interval=50, use_matplotlib=True, use_tensorboard=True, create_graph_in_tensorboard=False, use_wandb=False, wandb_project=None, wandb_id=None, wandb_entity=None, wandb_name=None, wandb_model_log_interval=-1, detect_anomaly=False, use_adapter=False, adapter='lora', save_strategy='all', adapter_conf={}, pretrain_path=None, init_param=[], ignore_init_mismatch=False, freeze_param=[], num_iters_per_epoch=1000, batch_size=20, valid_batch_size=None, batch_bins=3000000, valid_batch_bins=None, category_sample_size=10, train_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.20.scp'], valid_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.20.scp'], batch_type='numel', valid_batch_type=None, fold_length=[], sort_in_batch='descending', shuffle_within_batch=False, sort_batch='descending', multiple_iterator=False, chunk_length=500, chunk_shift_ratio=0.5, num_cache_chunks=1024, chunk_excluded_key_prefixes=[], chunk_default_fs=None, chunk_max_abs_length=None, chunk_discard_short_samples=True, train_data_path_and_name_and_type=[('dump/22k/raw/tr_no_dev/text', 'text', 'text'), ('dump/22k/raw/tr_no_dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/tr_no_dev/utt2sid', 'sids', 'text_int')], valid_data_path_and_name_and_type=[('dump/22k/raw/dev/text', 'text', 'text'), ('dump/22k/raw/dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/dev/utt2sid', 'sids', 'text_int')], multi_task_dataset=False, allow_variable_data_keys=False, max_cache_size=0.0, max_cache_fd=32, allow_multi_rates=False, valid_max_cache_size=None, exclude_weight_decay=False, exclude_weight_decay_conf={}, optim='adamw', optim_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler='exponentiallr', scheduler_conf={'gamma': 0.999875}, optim2='adamw', optim2_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler2='exponentiallr', scheduler2_conf={'gamma': 0.999875}, generator_first=False, skip_discriminator_prob=0.0, token_list=['<blank>', '<unk>', ' ', 'AH0', 'N', 'T', 'D', 'S', 'R', 'L', 'IH1', 'DH', 'M', 'EH1', 'Z', 'AE1', 'K', 'IH0', 'AH1', 'HH', 'W', 'ER0', 'V', 'IY1', 'F', 'UW1', 'P', 'AY1', 'B', 'AA1', 'AO1', 'EY1', 'IY0', 'OW1', 'NG', 'SH', 'G', 'Y', 'AW1', 'CH', 'ER1', 'UH1', 'TH', 'JH', 'OW0', 'EH2', 'IH2', 'OY1', 'EY2', 'AY2', 'EH0', 'UW0', 'AA2', 'AE2', 'OW2', 'AH2', 'AA0', 'ZH', 'AE0', 'AO2', 'UW2', 'AO0', 'AY0', 'IY2', 'AW2', 'UH2', 'EY0', 'ER2', 'AW0', 'UH0', 'OY2', 'OY0', "'", '<sos/eos>'], odim=None, model_conf={}, use_preprocessor=True, token_type='phn', bpemodel=None, non_linguistic_symbols=None, cleaner='tacotron', g2p='g2p_en', feats_extract='linear_spectrogram', feats_extract_conf={'n_fft': 1024, 'hop_length': 256, 'win_length': None}, normalize=None, normalize_conf={}, tts='vits', tts_conf={'generator_type': 'vits_generator', 'generator_params': {'hidden_channels': 192, 'spks': 128, 'global_channels': 256, 'segment_size': 32, 'text_encoder_attention_heads': 2, 'text_encoder_ffn_expand': 4, 'text_encoder_blocks': 6, 'text_encoder_positionwise_layer_type': 'conv1d', 'text_encoder_positionwise_conv_kernel_size': 3, 'text_encoder_positional_encoding_layer_type': 'rel_pos', 'text_encoder_self_attention_layer_type': 'rel_selfattn', 'text_encoder_activation_type': 'swish', 'text_encoder_normalize_before': True, 'text_encoder_dropout_rate': 0.1, 'text_encoder_positional_dropout_rate': 0.0, 'text_encoder_attention_dropout_rate': 0.1, 'use_macaron_style_in_text_encoder': True, 'use_conformer_conv_in_text_encoder': False, 'text_encoder_conformer_kernel_size': -1, 'decoder_kernel_size': 7, 'decoder_channels': 512, 'decoder_upsample_scales': [8, 8, 2, 2], 'decoder_upsample_kernel_sizes': [16, 16, 4, 4], 'decoder_resblock_kernel_sizes': [3, 7, 11], 'decoder_resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'use_weight_norm_in_decoder': True, 'posterior_encoder_kernel_size': 5, 'posterior_encoder_layers': 16, 'posterior_encoder_stacks': 1, 'posterior_encoder_base_dilation': 1, 'posterior_encoder_dropout_rate': 0.0, 'use_weight_norm_in_posterior_encoder': True, 'flow_flows': 4, 'flow_kernel_size': 5, 'flow_base_dilation': 1, 'flow_layers': 4, 'flow_dropout_rate': 0.0, 'use_weight_norm_in_flow': True, 'use_only_mean_in_flow': True, 'stochastic_duration_predictor_kernel_size': 3, 'stochastic_duration_predictor_dropout_rate': 0.5, 'stochastic_duration_predictor_flows': 4, 'stochastic_duration_predictor_dds_conv_layers': 3, 'vocabs': 74, 'aux_channels': 513}, 'discriminator_type': 'hifigan_multi_scale_multi_period_discriminator', 'discriminator_params': {'scales': 1, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'stride': 2, 'padding': 2}, 'scale_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'channels': 128, 'max_downsample_channels': 1024, 'max_groups': 16, 'bias': True, 'downsample_scales': [2, 2, 4, 4, 1], 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}, 'follow_official_norm': False, 'periods': [2, 3, 5, 7, 11], 'period_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [5, 3], 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'max_downsample_channels': 1024, 'bias': True, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}}, 'generator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'discriminator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'feat_match_loss_params': {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, 'mel_loss_params': {'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None, 'window': 'hann', 'n_mels': 80, 'fmin': 0, 'fmax': None, 'log_base': None}, 'lambda_adv': 1.0, 'lambda_mel': 45.0, 'lambda_feat_match': 2.0, 'lambda_dur': 1.0, 'lambda_kl': 1.0, 'sampling_rate': 22050, 'cache_generator_outputs': True, 'plot_pred_mos': False, 'mos_pred_tool': 'utmos'}, pitch_extract=None, pitch_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'f0max': 400, 'f0min': 80}, pitch_normalize=None, pitch_normalize_conf={}, energy_extract=None, energy_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None}, energy_normalize=None, energy_normalize_conf={}, required=['output_dir', 'token_list'], version='202503', distributed=False)
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1284, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 87370) is killed by signal: Killed. 

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 22, in <module>
    main()
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 18, in main
    GANTTSTask.main(cmd=cmd)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1225, in main
    cls.main_worker(args)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1441, in main_worker
    collect_stats(
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/main_funcs/collect_stats.py", line 51, in collect_stats
    for iiter, (keys, batch) in enumerate(itr, 1):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 733, in __next__
    data = self._next_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1491, in _next_data
    idx, data = self._get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1453, in _get_data
    success, data = self._try_get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1297, in _try_get_data
    raise RuntimeError(
RuntimeError: DataLoader worker (pid(s) 87370) exited unexpectedly
# Accounting: begin_time=1750873261
# Accounting: end_time=1750873472
# Accounting: time=211 threads=1
# Finished at Wed Jun 25 13:44:32 EDT 2025 with status 1
# Running on r027.ib.bridges2.psc.edu
# Started at Wed Jun 25 13:44:43 EDT 2025
# SLURMD_NODENAME=r027
# SLURM_ARRAY_JOB_ID=32990217
# SLURM_ARRAY_TASK_COUNT=32
# SLURM_ARRAY_TASK_ID=21
# SLURM_ARRAY_TASK_MAX=32
# SLURM_ARRAY_TASK_MIN=1
# SLURM_ARRAY_TASK_STEP=1
# SLURM_CLUSTER_NAME=bridges2
# SLURM_CONF=/var/spool/slurm/d/conf-cache/slurm.conf
# SLURM_CPUS_ON_NODE=1
# SLURM_CPU_BIND=quiet,mask_cpu:0x07C0000000
# SLURM_CPU_BIND_LIST=0x07C0000000
# SLURM_CPU_BIND_TYPE=mask_cpu:
# SLURM_CPU_BIND_VERBOSE=quiet
# SLURM_EXPORT_ENV=ALL
# SLURM_GET_USER_ENV=1
# SLURM_GTIDS=0
# SLURM_JOBID=32990265
# SLURM_JOB_ACCOUNT=cis210027p
# SLURM_JOB_CPUS_PER_NODE=1
# SLURM_JOB_GID=24886
# SLURM_JOB_ID=32990265
# SLURM_JOB_NAME=stats.sh
# SLURM_JOB_NODELIST=r027
# SLURM_JOB_NUM_NODES=1
# SLURM_JOB_PARTITION=RM-shared
# SLURM_JOB_QOS=rm
# SLURM_JOB_UID=97947
# SLURM_JOB_USER=ttao3
# SLURM_LAUNCH_NODE_IPADDR=10.8.11.29
# SLURM_LOCALID=0
# SLURM_MEM_PER_CPU=1900
# SLURM_NNODES=1
# SLURM_NODEID=0
# SLURM_NODELIST=r027
# SLURM_NODE_ALIASES='(null)'
# SLURM_NPROCS=1
# SLURM_NTASKS=1
# SLURM_OPEN_MODE=a
# SLURM_PRIO_PROCESS=0
# SLURM_PROCID=0
# SLURM_PTY_PORT=33025
# SLURM_PTY_WIN_COL=126
# SLURM_PTY_WIN_ROW=21
# SLURM_SCRIPT_CONTEXT=prolog_task
# SLURM_SRUN_COMM_HOST=10.8.11.29
# SLURM_SRUN_COMM_PORT=35045
# SLURM_STEPID=0
# SLURM_STEP_GPUS=6
# SLURM_STEP_ID=0
# SLURM_STEP_LAUNCHER_PORT=35045
# SLURM_STEP_NODELIST=v029
# SLURM_STEP_NUM_NODES=1
# SLURM_STEP_NUM_TASKS=1
# SLURM_STEP_TASKS_PER_NODE=1
# SLURM_SUBMIT_DIR=/ocean/projects/cis210027p/ttao3/espnet/egs2/hifitts/tts1
# SLURM_SUBMIT_HOST=v029.ib.bridges2.psc.edu
# SLURM_TASKS_PER_NODE=1
# SLURM_TASK_PID=43030
# SLURM_TOPOLOGY_ADDR=r027
# SLURM_TOPOLOGY_ADDR_PATTERN=node
# SLURM_WORKING_CLUSTER=bridges2:br003:6810:9728:109
# python3 -m espnet2.bin.gan_tts_train --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.21.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.21.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.21 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int 
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/librosa/util/files.py:10: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_filename
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/bin/python3 /ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.21.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.21.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.21 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int
Failed to import Flash Attention, using ESPnet default: No module named 'flash_attn_2_cuda'
Vocabulary size: 74
encoder self-attention layer type = relative self-attention
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/ocean/projects/cis210027p/ttao3/espnet/espnet2/gan_tts/vits/monotonic_align/__init__.py:19: UserWarning: Cython version is not available. Fallback to 'EXPERIMETAL' numba version. If you want to use the cython version, please build it as follows: `cd espnet2/gan_tts/vits/monotonic_align; python setup.py build_ext --inplace`
  warnings.warn(
pytorch.version=2.7.1+cu126, cuda.available=False, cudnn.version=90501, cudnn.benchmark=False, cudnn.deterministic=False
Model structure:
ESPnetGANTTSModel(
  (feats_extract): LinearSpectrogram(
    (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
  )
  (tts): VITS(
    (generator): VITSGenerator(
      (text_encoder): TextEncoder(
        (emb): Embedding(74, 192)
        (encoder): Encoder(
          (embed): Sequential(
            (0): RelPositionalEncoding(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (encoders): MultiSequential(
            (0): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (2): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (3): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (4): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (5): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (after_norm): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (decoder): HiFiGANGenerator(
        (input_conv): Conv1d(192, 512, kernel_size=(7,), stride=(1,), padding=(3,))
        (upsamples): ModuleList(
          (0): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (1): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(256, 128, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (2): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,))
          )
          (3): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,))
          )
        )
        (blocks): ModuleList(
          (0): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (1): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (2): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (3): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (4): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (5): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (6): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (7): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (8): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (9): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (10): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (11): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
        )
        (output_conv): Sequential(
          (0): LeakyReLU(negative_slope=0.01)
          (1): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,))
          (2): Tanh()
        )
        (global_conv): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
      )
      (posterior_encoder): PosteriorEncoder(
        (input_conv): Conv1d(513, 192, kernel_size=(1,), stride=(1,))
        (encoder): WaveNet(
          (conv_layers): ModuleList(
            (0-15): 16 x ResidualBlock(
              (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
              (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
              (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
            )
          )
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (flow): ResidualAffineCouplingBlock(
        (flows): ModuleList(
          (0): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (1): FlipFlow()
          (2): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (3): FlipFlow()
          (4): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (5): FlipFlow()
          (6): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (7): FlipFlow()
        )
      )
      (duration_predictor): StochasticDurationPredictor(
        (pre): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (log_flow): LogFlow()
        (flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (post_pre): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
        (post_dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (post_proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (post_flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (global_conv): Conv1d(256, 192, kernel_size=(1,), stride=(1,))
      )
      (global_emb): Embedding(128, 256)
    )
    (discriminator): HiFiGANMultiScaleMultiPeriodDiscriminator(
      (msd): HiFiGANMultiScaleDiscriminator(
        (discriminators): ModuleList(
          (0): HiFiGANScaleDiscriminator(
            (layers): ModuleList(
              (0): Sequential(
                (0): Conv1d(1, 128, kernel_size=(15,), stride=(1,), padding=(7,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv1d(128, 128, kernel_size=(41,), stride=(2,), padding=(20,), groups=4)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv1d(128, 256, kernel_size=(41,), stride=(2,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv1d(256, 512, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv1d(512, 1024, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (5): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(41,), stride=(1,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (6): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (7): Conv1d(1024, 1, kernel_size=(3,), stride=(1,), padding=(1,))
            )
          )
        )
      )
      (mpd): HiFiGANMultiPeriodDiscriminator(
        (discriminators): ModuleList(
          (0-4): 5 x HiFiGANPeriodDiscriminator(
            (convs): ModuleList(
              (0): Sequential(
                (0): Conv2d(1, 32, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv2d(32, 128, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv2d(128, 512, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv2d(512, 1024, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv2d(1024, 1024, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
            )
            (output_conv): Conv2d(1024, 1, kernel_size=(2, 1), stride=(1, 1), padding=(1, 0))
          )
        )
      )
    )
    (generator_adv_loss): GeneratorAdversarialLoss()
    (discriminator_adv_loss): DiscriminatorAdversarialLoss()
    (feat_match_loss): FeatureMatchLoss()
    (mel_loss): MelSpectrogramLoss(
      (wav_to_mel): LogMelFbank(
        (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
        (logmel): LogMel(sr=22050, n_fft=1024, n_mels=80, fmin=0, fmax=11025.0, htk=False)
      )
    )
    (kl_loss): KLDivergenceLoss()
  )
)

Model summary:
    Class Name: ESPnetGANTTSModel
    Total Number of model parameters: 96.37 M
    Number of trainable parameters: 96.37 M (100.0%)
    Size: 385.46 MB
    Type: torch.float32
Optimizer:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler: <torch.optim.lr_scheduler.ExponentialLR object at 0x14faa7d6f610>
Optimizer2:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler2: <torch.optim.lr_scheduler.ExponentialLR object at 0x14faa7d6fa00>
Saving the configuration in exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.21/config.yaml
Namespace(config='conf/tuning/train_multi_spk_vits.yaml', print_config=False, log_level='INFO', drop_last_iter=False, dry_run=False, iterator_type='sequence', valid_iterator_type=None, output_dir='exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.21', ngpu=0, seed=777, num_workers=4, num_att_plot=3, dist_backend='nccl', dist_init_method='env://', dist_world_size=None, dist_rank=None, local_rank=None, dist_master_addr=None, dist_master_port=None, dist_launcher=None, multiprocessing_distributed=False, unused_parameters=True, sharded_ddp=False, use_deepspeed=False, deepspeed_config=None, gradient_as_bucket_view=True, ddp_comm_hook=None, cudnn_enabled=True, cudnn_benchmark=False, cudnn_deterministic=False, use_tf32=False, collect_stats=True, write_collected_feats=False, max_epoch=1000, patience=None, val_scheduler_criterion=('valid', 'loss'), early_stopping_criterion=('valid', 'loss', 'min'), best_model_criterion=[['train', 'total_count', 'max']], keep_nbest_models=10, nbest_averaging_interval=0, grad_clip=-1, grad_clip_type=2.0, grad_noise=False, accum_grad=1, no_forward_run=False, resume=False, train_dtype='float32', use_amp=False, log_interval=50, use_matplotlib=True, use_tensorboard=True, create_graph_in_tensorboard=False, use_wandb=False, wandb_project=None, wandb_id=None, wandb_entity=None, wandb_name=None, wandb_model_log_interval=-1, detect_anomaly=False, use_adapter=False, adapter='lora', save_strategy='all', adapter_conf={}, pretrain_path=None, init_param=[], ignore_init_mismatch=False, freeze_param=[], num_iters_per_epoch=1000, batch_size=20, valid_batch_size=None, batch_bins=3000000, valid_batch_bins=None, category_sample_size=10, train_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.21.scp'], valid_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.21.scp'], batch_type='numel', valid_batch_type=None, fold_length=[], sort_in_batch='descending', shuffle_within_batch=False, sort_batch='descending', multiple_iterator=False, chunk_length=500, chunk_shift_ratio=0.5, num_cache_chunks=1024, chunk_excluded_key_prefixes=[], chunk_default_fs=None, chunk_max_abs_length=None, chunk_discard_short_samples=True, train_data_path_and_name_and_type=[('dump/22k/raw/tr_no_dev/text', 'text', 'text'), ('dump/22k/raw/tr_no_dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/tr_no_dev/utt2sid', 'sids', 'text_int')], valid_data_path_and_name_and_type=[('dump/22k/raw/dev/text', 'text', 'text'), ('dump/22k/raw/dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/dev/utt2sid', 'sids', 'text_int')], multi_task_dataset=False, allow_variable_data_keys=False, max_cache_size=0.0, max_cache_fd=32, allow_multi_rates=False, valid_max_cache_size=None, exclude_weight_decay=False, exclude_weight_decay_conf={}, optim='adamw', optim_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler='exponentiallr', scheduler_conf={'gamma': 0.999875}, optim2='adamw', optim2_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler2='exponentiallr', scheduler2_conf={'gamma': 0.999875}, generator_first=False, skip_discriminator_prob=0.0, token_list=['<blank>', '<unk>', ' ', 'AH0', 'N', 'T', 'D', 'S', 'R', 'L', 'IH1', 'DH', 'M', 'EH1', 'Z', 'AE1', 'K', 'IH0', 'AH1', 'HH', 'W', 'ER0', 'V', 'IY1', 'F', 'UW1', 'P', 'AY1', 'B', 'AA1', 'AO1', 'EY1', 'IY0', 'OW1', 'NG', 'SH', 'G', 'Y', 'AW1', 'CH', 'ER1', 'UH1', 'TH', 'JH', 'OW0', 'EH2', 'IH2', 'OY1', 'EY2', 'AY2', 'EH0', 'UW0', 'AA2', 'AE2', 'OW2', 'AH2', 'AA0', 'ZH', 'AE0', 'AO2', 'UW2', 'AO0', 'AY0', 'IY2', 'AW2', 'UH2', 'EY0', 'ER2', 'AW0', 'UH0', 'OY2', 'OY0', "'", '<sos/eos>'], odim=None, model_conf={}, use_preprocessor=True, token_type='phn', bpemodel=None, non_linguistic_symbols=None, cleaner='tacotron', g2p='g2p_en', feats_extract='linear_spectrogram', feats_extract_conf={'n_fft': 1024, 'hop_length': 256, 'win_length': None}, normalize=None, normalize_conf={}, tts='vits', tts_conf={'generator_type': 'vits_generator', 'generator_params': {'hidden_channels': 192, 'spks': 128, 'global_channels': 256, 'segment_size': 32, 'text_encoder_attention_heads': 2, 'text_encoder_ffn_expand': 4, 'text_encoder_blocks': 6, 'text_encoder_positionwise_layer_type': 'conv1d', 'text_encoder_positionwise_conv_kernel_size': 3, 'text_encoder_positional_encoding_layer_type': 'rel_pos', 'text_encoder_self_attention_layer_type': 'rel_selfattn', 'text_encoder_activation_type': 'swish', 'text_encoder_normalize_before': True, 'text_encoder_dropout_rate': 0.1, 'text_encoder_positional_dropout_rate': 0.0, 'text_encoder_attention_dropout_rate': 0.1, 'use_macaron_style_in_text_encoder': True, 'use_conformer_conv_in_text_encoder': False, 'text_encoder_conformer_kernel_size': -1, 'decoder_kernel_size': 7, 'decoder_channels': 512, 'decoder_upsample_scales': [8, 8, 2, 2], 'decoder_upsample_kernel_sizes': [16, 16, 4, 4], 'decoder_resblock_kernel_sizes': [3, 7, 11], 'decoder_resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'use_weight_norm_in_decoder': True, 'posterior_encoder_kernel_size': 5, 'posterior_encoder_layers': 16, 'posterior_encoder_stacks': 1, 'posterior_encoder_base_dilation': 1, 'posterior_encoder_dropout_rate': 0.0, 'use_weight_norm_in_posterior_encoder': True, 'flow_flows': 4, 'flow_kernel_size': 5, 'flow_base_dilation': 1, 'flow_layers': 4, 'flow_dropout_rate': 0.0, 'use_weight_norm_in_flow': True, 'use_only_mean_in_flow': True, 'stochastic_duration_predictor_kernel_size': 3, 'stochastic_duration_predictor_dropout_rate': 0.5, 'stochastic_duration_predictor_flows': 4, 'stochastic_duration_predictor_dds_conv_layers': 3, 'vocabs': 74, 'aux_channels': 513}, 'discriminator_type': 'hifigan_multi_scale_multi_period_discriminator', 'discriminator_params': {'scales': 1, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'stride': 2, 'padding': 2}, 'scale_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'channels': 128, 'max_downsample_channels': 1024, 'max_groups': 16, 'bias': True, 'downsample_scales': [2, 2, 4, 4, 1], 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}, 'follow_official_norm': False, 'periods': [2, 3, 5, 7, 11], 'period_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [5, 3], 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'max_downsample_channels': 1024, 'bias': True, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}}, 'generator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'discriminator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'feat_match_loss_params': {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, 'mel_loss_params': {'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None, 'window': 'hann', 'n_mels': 80, 'fmin': 0, 'fmax': None, 'log_base': None}, 'lambda_adv': 1.0, 'lambda_mel': 45.0, 'lambda_feat_match': 2.0, 'lambda_dur': 1.0, 'lambda_kl': 1.0, 'sampling_rate': 22050, 'cache_generator_outputs': True, 'plot_pred_mos': False, 'mos_pred_tool': 'utmos'}, pitch_extract=None, pitch_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'f0max': 400, 'f0min': 80}, pitch_normalize=None, pitch_normalize_conf={}, energy_extract=None, energy_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None}, energy_normalize=None, energy_normalize_conf={}, required=['output_dir', 'token_list'], version='202503', distributed=False)
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1284, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 57106) is killed by signal: Killed. 

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 22, in <module>
    main()
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 18, in main
    GANTTSTask.main(cmd=cmd)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1225, in main
    cls.main_worker(args)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1441, in main_worker
    collect_stats(
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/main_funcs/collect_stats.py", line 51, in collect_stats
    for iiter, (keys, batch) in enumerate(itr, 1):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 733, in __next__
    data = self._next_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1491, in _next_data
    idx, data = self._get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1453, in _get_data
    success, data = self._try_get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1297, in _try_get_data
    raise RuntimeError(
RuntimeError: DataLoader worker (pid(s) 57106) exited unexpectedly
# Accounting: begin_time=1750873483
# Accounting: end_time=1750873629
# Accounting: time=146 threads=1
# Finished at Wed Jun 25 13:47:09 EDT 2025 with status 1
# Running on r037.ib.bridges2.psc.edu
# Started at Wed Jun 25 13:44:42 EDT 2025
# SLURMD_NODENAME=r037
# SLURM_ARRAY_JOB_ID=32990217
# SLURM_ARRAY_TASK_COUNT=32
# SLURM_ARRAY_TASK_ID=22
# SLURM_ARRAY_TASK_MAX=32
# SLURM_ARRAY_TASK_MIN=1
# SLURM_ARRAY_TASK_STEP=1
# SLURM_CLUSTER_NAME=bridges2
# SLURM_CONF=/var/spool/slurm/d/conf-cache/slurm.conf
# SLURM_CPUS_ON_NODE=1
# SLURM_CPU_BIND=quiet,mask_cpu:0x07C0000000
# SLURM_CPU_BIND_LIST=0x07C0000000
# SLURM_CPU_BIND_TYPE=mask_cpu:
# SLURM_CPU_BIND_VERBOSE=quiet
# SLURM_EXPORT_ENV=ALL
# SLURM_GET_USER_ENV=1
# SLURM_GTIDS=0
# SLURM_JOBID=32990266
# SLURM_JOB_ACCOUNT=cis210027p
# SLURM_JOB_CPUS_PER_NODE=1
# SLURM_JOB_GID=24886
# SLURM_JOB_ID=32990266
# SLURM_JOB_NAME=stats.sh
# SLURM_JOB_NODELIST=r037
# SLURM_JOB_NUM_NODES=1
# SLURM_JOB_PARTITION=RM-shared
# SLURM_JOB_QOS=rm
# SLURM_JOB_UID=97947
# SLURM_JOB_USER=ttao3
# SLURM_LAUNCH_NODE_IPADDR=10.8.11.29
# SLURM_LOCALID=0
# SLURM_MEM_PER_CPU=1900
# SLURM_NNODES=1
# SLURM_NODEID=0
# SLURM_NODELIST=r037
# SLURM_NODE_ALIASES='(null)'
# SLURM_NPROCS=1
# SLURM_NTASKS=1
# SLURM_OPEN_MODE=a
# SLURM_PRIO_PROCESS=0
# SLURM_PROCID=0
# SLURM_PTY_PORT=33025
# SLURM_PTY_WIN_COL=126
# SLURM_PTY_WIN_ROW=21
# SLURM_SCRIPT_CONTEXT=prolog_task
# SLURM_SRUN_COMM_HOST=10.8.11.29
# SLURM_SRUN_COMM_PORT=35045
# SLURM_STEPID=0
# SLURM_STEP_GPUS=6
# SLURM_STEP_ID=0
# SLURM_STEP_LAUNCHER_PORT=35045
# SLURM_STEP_NODELIST=v029
# SLURM_STEP_NUM_NODES=1
# SLURM_STEP_NUM_TASKS=1
# SLURM_STEP_TASKS_PER_NODE=1
# SLURM_SUBMIT_DIR=/ocean/projects/cis210027p/ttao3/espnet/egs2/hifitts/tts1
# SLURM_SUBMIT_HOST=v029.ib.bridges2.psc.edu
# SLURM_TASKS_PER_NODE=1
# SLURM_TASK_PID=67102
# SLURM_TOPOLOGY_ADDR=r037
# SLURM_TOPOLOGY_ADDR_PATTERN=node
# SLURM_WORKING_CLUSTER=bridges2:br003:6810:9728:109
# python3 -m espnet2.bin.gan_tts_train --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.22.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.22.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.22 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int 
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/librosa/util/files.py:10: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_filename
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/bin/python3 /ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.22.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.22.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.22 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int
Failed to import Flash Attention, using ESPnet default: No module named 'flash_attn_2_cuda'
Vocabulary size: 74
encoder self-attention layer type = relative self-attention
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/ocean/projects/cis210027p/ttao3/espnet/espnet2/gan_tts/vits/monotonic_align/__init__.py:19: UserWarning: Cython version is not available. Fallback to 'EXPERIMETAL' numba version. If you want to use the cython version, please build it as follows: `cd espnet2/gan_tts/vits/monotonic_align; python setup.py build_ext --inplace`
  warnings.warn(
pytorch.version=2.7.1+cu126, cuda.available=False, cudnn.version=90501, cudnn.benchmark=False, cudnn.deterministic=False
Model structure:
ESPnetGANTTSModel(
  (feats_extract): LinearSpectrogram(
    (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
  )
  (tts): VITS(
    (generator): VITSGenerator(
      (text_encoder): TextEncoder(
        (emb): Embedding(74, 192)
        (encoder): Encoder(
          (embed): Sequential(
            (0): RelPositionalEncoding(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (encoders): MultiSequential(
            (0): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (2): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (3): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (4): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (5): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (after_norm): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (decoder): HiFiGANGenerator(
        (input_conv): Conv1d(192, 512, kernel_size=(7,), stride=(1,), padding=(3,))
        (upsamples): ModuleList(
          (0): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (1): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(256, 128, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (2): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,))
          )
          (3): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,))
          )
        )
        (blocks): ModuleList(
          (0): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (1): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (2): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (3): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (4): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (5): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (6): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (7): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (8): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (9): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (10): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (11): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
        )
        (output_conv): Sequential(
          (0): LeakyReLU(negative_slope=0.01)
          (1): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,))
          (2): Tanh()
        )
        (global_conv): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
      )
      (posterior_encoder): PosteriorEncoder(
        (input_conv): Conv1d(513, 192, kernel_size=(1,), stride=(1,))
        (encoder): WaveNet(
          (conv_layers): ModuleList(
            (0-15): 16 x ResidualBlock(
              (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
              (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
              (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
            )
          )
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (flow): ResidualAffineCouplingBlock(
        (flows): ModuleList(
          (0): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (1): FlipFlow()
          (2): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (3): FlipFlow()
          (4): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (5): FlipFlow()
          (6): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (7): FlipFlow()
        )
      )
      (duration_predictor): StochasticDurationPredictor(
        (pre): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (log_flow): LogFlow()
        (flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (post_pre): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
        (post_dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (post_proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (post_flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (global_conv): Conv1d(256, 192, kernel_size=(1,), stride=(1,))
      )
      (global_emb): Embedding(128, 256)
    )
    (discriminator): HiFiGANMultiScaleMultiPeriodDiscriminator(
      (msd): HiFiGANMultiScaleDiscriminator(
        (discriminators): ModuleList(
          (0): HiFiGANScaleDiscriminator(
            (layers): ModuleList(
              (0): Sequential(
                (0): Conv1d(1, 128, kernel_size=(15,), stride=(1,), padding=(7,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv1d(128, 128, kernel_size=(41,), stride=(2,), padding=(20,), groups=4)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv1d(128, 256, kernel_size=(41,), stride=(2,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv1d(256, 512, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv1d(512, 1024, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (5): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(41,), stride=(1,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (6): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (7): Conv1d(1024, 1, kernel_size=(3,), stride=(1,), padding=(1,))
            )
          )
        )
      )
      (mpd): HiFiGANMultiPeriodDiscriminator(
        (discriminators): ModuleList(
          (0-4): 5 x HiFiGANPeriodDiscriminator(
            (convs): ModuleList(
              (0): Sequential(
                (0): Conv2d(1, 32, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv2d(32, 128, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv2d(128, 512, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv2d(512, 1024, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv2d(1024, 1024, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
            )
            (output_conv): Conv2d(1024, 1, kernel_size=(2, 1), stride=(1, 1), padding=(1, 0))
          )
        )
      )
    )
    (generator_adv_loss): GeneratorAdversarialLoss()
    (discriminator_adv_loss): DiscriminatorAdversarialLoss()
    (feat_match_loss): FeatureMatchLoss()
    (mel_loss): MelSpectrogramLoss(
      (wav_to_mel): LogMelFbank(
        (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
        (logmel): LogMel(sr=22050, n_fft=1024, n_mels=80, fmin=0, fmax=11025.0, htk=False)
      )
    )
    (kl_loss): KLDivergenceLoss()
  )
)

Model summary:
    Class Name: ESPnetGANTTSModel
    Total Number of model parameters: 96.37 M
    Number of trainable parameters: 96.37 M (100.0%)
    Size: 385.46 MB
    Type: torch.float32
Optimizer:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler: <torch.optim.lr_scheduler.ExponentialLR object at 0x1485b476a640>
Optimizer2:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler2: <torch.optim.lr_scheduler.ExponentialLR object at 0x1485b476aa30>
Saving the configuration in exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.22/config.yaml
Namespace(config='conf/tuning/train_multi_spk_vits.yaml', print_config=False, log_level='INFO', drop_last_iter=False, dry_run=False, iterator_type='sequence', valid_iterator_type=None, output_dir='exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.22', ngpu=0, seed=777, num_workers=4, num_att_plot=3, dist_backend='nccl', dist_init_method='env://', dist_world_size=None, dist_rank=None, local_rank=None, dist_master_addr=None, dist_master_port=None, dist_launcher=None, multiprocessing_distributed=False, unused_parameters=True, sharded_ddp=False, use_deepspeed=False, deepspeed_config=None, gradient_as_bucket_view=True, ddp_comm_hook=None, cudnn_enabled=True, cudnn_benchmark=False, cudnn_deterministic=False, use_tf32=False, collect_stats=True, write_collected_feats=False, max_epoch=1000, patience=None, val_scheduler_criterion=('valid', 'loss'), early_stopping_criterion=('valid', 'loss', 'min'), best_model_criterion=[['train', 'total_count', 'max']], keep_nbest_models=10, nbest_averaging_interval=0, grad_clip=-1, grad_clip_type=2.0, grad_noise=False, accum_grad=1, no_forward_run=False, resume=False, train_dtype='float32', use_amp=False, log_interval=50, use_matplotlib=True, use_tensorboard=True, create_graph_in_tensorboard=False, use_wandb=False, wandb_project=None, wandb_id=None, wandb_entity=None, wandb_name=None, wandb_model_log_interval=-1, detect_anomaly=False, use_adapter=False, adapter='lora', save_strategy='all', adapter_conf={}, pretrain_path=None, init_param=[], ignore_init_mismatch=False, freeze_param=[], num_iters_per_epoch=1000, batch_size=20, valid_batch_size=None, batch_bins=3000000, valid_batch_bins=None, category_sample_size=10, train_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.22.scp'], valid_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.22.scp'], batch_type='numel', valid_batch_type=None, fold_length=[], sort_in_batch='descending', shuffle_within_batch=False, sort_batch='descending', multiple_iterator=False, chunk_length=500, chunk_shift_ratio=0.5, num_cache_chunks=1024, chunk_excluded_key_prefixes=[], chunk_default_fs=None, chunk_max_abs_length=None, chunk_discard_short_samples=True, train_data_path_and_name_and_type=[('dump/22k/raw/tr_no_dev/text', 'text', 'text'), ('dump/22k/raw/tr_no_dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/tr_no_dev/utt2sid', 'sids', 'text_int')], valid_data_path_and_name_and_type=[('dump/22k/raw/dev/text', 'text', 'text'), ('dump/22k/raw/dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/dev/utt2sid', 'sids', 'text_int')], multi_task_dataset=False, allow_variable_data_keys=False, max_cache_size=0.0, max_cache_fd=32, allow_multi_rates=False, valid_max_cache_size=None, exclude_weight_decay=False, exclude_weight_decay_conf={}, optim='adamw', optim_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler='exponentiallr', scheduler_conf={'gamma': 0.999875}, optim2='adamw', optim2_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler2='exponentiallr', scheduler2_conf={'gamma': 0.999875}, generator_first=False, skip_discriminator_prob=0.0, token_list=['<blank>', '<unk>', ' ', 'AH0', 'N', 'T', 'D', 'S', 'R', 'L', 'IH1', 'DH', 'M', 'EH1', 'Z', 'AE1', 'K', 'IH0', 'AH1', 'HH', 'W', 'ER0', 'V', 'IY1', 'F', 'UW1', 'P', 'AY1', 'B', 'AA1', 'AO1', 'EY1', 'IY0', 'OW1', 'NG', 'SH', 'G', 'Y', 'AW1', 'CH', 'ER1', 'UH1', 'TH', 'JH', 'OW0', 'EH2', 'IH2', 'OY1', 'EY2', 'AY2', 'EH0', 'UW0', 'AA2', 'AE2', 'OW2', 'AH2', 'AA0', 'ZH', 'AE0', 'AO2', 'UW2', 'AO0', 'AY0', 'IY2', 'AW2', 'UH2', 'EY0', 'ER2', 'AW0', 'UH0', 'OY2', 'OY0', "'", '<sos/eos>'], odim=None, model_conf={}, use_preprocessor=True, token_type='phn', bpemodel=None, non_linguistic_symbols=None, cleaner='tacotron', g2p='g2p_en', feats_extract='linear_spectrogram', feats_extract_conf={'n_fft': 1024, 'hop_length': 256, 'win_length': None}, normalize=None, normalize_conf={}, tts='vits', tts_conf={'generator_type': 'vits_generator', 'generator_params': {'hidden_channels': 192, 'spks': 128, 'global_channels': 256, 'segment_size': 32, 'text_encoder_attention_heads': 2, 'text_encoder_ffn_expand': 4, 'text_encoder_blocks': 6, 'text_encoder_positionwise_layer_type': 'conv1d', 'text_encoder_positionwise_conv_kernel_size': 3, 'text_encoder_positional_encoding_layer_type': 'rel_pos', 'text_encoder_self_attention_layer_type': 'rel_selfattn', 'text_encoder_activation_type': 'swish', 'text_encoder_normalize_before': True, 'text_encoder_dropout_rate': 0.1, 'text_encoder_positional_dropout_rate': 0.0, 'text_encoder_attention_dropout_rate': 0.1, 'use_macaron_style_in_text_encoder': True, 'use_conformer_conv_in_text_encoder': False, 'text_encoder_conformer_kernel_size': -1, 'decoder_kernel_size': 7, 'decoder_channels': 512, 'decoder_upsample_scales': [8, 8, 2, 2], 'decoder_upsample_kernel_sizes': [16, 16, 4, 4], 'decoder_resblock_kernel_sizes': [3, 7, 11], 'decoder_resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'use_weight_norm_in_decoder': True, 'posterior_encoder_kernel_size': 5, 'posterior_encoder_layers': 16, 'posterior_encoder_stacks': 1, 'posterior_encoder_base_dilation': 1, 'posterior_encoder_dropout_rate': 0.0, 'use_weight_norm_in_posterior_encoder': True, 'flow_flows': 4, 'flow_kernel_size': 5, 'flow_base_dilation': 1, 'flow_layers': 4, 'flow_dropout_rate': 0.0, 'use_weight_norm_in_flow': True, 'use_only_mean_in_flow': True, 'stochastic_duration_predictor_kernel_size': 3, 'stochastic_duration_predictor_dropout_rate': 0.5, 'stochastic_duration_predictor_flows': 4, 'stochastic_duration_predictor_dds_conv_layers': 3, 'vocabs': 74, 'aux_channels': 513}, 'discriminator_type': 'hifigan_multi_scale_multi_period_discriminator', 'discriminator_params': {'scales': 1, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'stride': 2, 'padding': 2}, 'scale_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'channels': 128, 'max_downsample_channels': 1024, 'max_groups': 16, 'bias': True, 'downsample_scales': [2, 2, 4, 4, 1], 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}, 'follow_official_norm': False, 'periods': [2, 3, 5, 7, 11], 'period_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [5, 3], 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'max_downsample_channels': 1024, 'bias': True, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}}, 'generator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'discriminator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'feat_match_loss_params': {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, 'mel_loss_params': {'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None, 'window': 'hann', 'n_mels': 80, 'fmin': 0, 'fmax': None, 'log_base': None}, 'lambda_adv': 1.0, 'lambda_mel': 45.0, 'lambda_feat_match': 2.0, 'lambda_dur': 1.0, 'lambda_kl': 1.0, 'sampling_rate': 22050, 'cache_generator_outputs': True, 'plot_pred_mos': False, 'mos_pred_tool': 'utmos'}, pitch_extract=None, pitch_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'f0max': 400, 'f0min': 80}, pitch_normalize=None, pitch_normalize_conf={}, energy_extract=None, energy_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None}, energy_normalize=None, energy_normalize_conf={}, required=['output_dir', 'token_list'], version='202503', distributed=False)
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1284, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 67218) is killed by signal: Killed. 

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 22, in <module>
    main()
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 18, in main
    GANTTSTask.main(cmd=cmd)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1225, in main
    cls.main_worker(args)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1441, in main_worker
    collect_stats(
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/main_funcs/collect_stats.py", line 51, in collect_stats
    for iiter, (keys, batch) in enumerate(itr, 1):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 733, in __next__
    data = self._next_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1491, in _next_data
    idx, data = self._get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1453, in _get_data
    success, data = self._try_get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1297, in _try_get_data
    raise RuntimeError(
RuntimeError: DataLoader worker (pid(s) 67218, 67220) exited unexpectedly
# Accounting: begin_time=1750873482
# Accounting: end_time=1750873631
# Accounting: time=149 threads=1
# Finished at Wed Jun 25 13:47:11 EDT 2025 with status 1
# Running on r225.ib.bridges2.psc.edu
# Started at Wed Jun 25 13:44:43 EDT 2025
# SLURMD_NODENAME=r225
# SLURM_ARRAY_JOB_ID=32990217
# SLURM_ARRAY_TASK_COUNT=32
# SLURM_ARRAY_TASK_ID=23
# SLURM_ARRAY_TASK_MAX=32
# SLURM_ARRAY_TASK_MIN=1
# SLURM_ARRAY_TASK_STEP=1
# SLURM_CLUSTER_NAME=bridges2
# SLURM_CONF=/var/spool/slurm/d/conf-cache/slurm.conf
# SLURM_CPUS_ON_NODE=1
# SLURM_CPU_BIND=quiet,mask_cpu:0x07C0000000
# SLURM_CPU_BIND_LIST=0x07C0000000
# SLURM_CPU_BIND_TYPE=mask_cpu:
# SLURM_CPU_BIND_VERBOSE=quiet
# SLURM_EXPORT_ENV=ALL
# SLURM_GET_USER_ENV=1
# SLURM_GTIDS=0
# SLURM_JOBID=32990267
# SLURM_JOB_ACCOUNT=cis210027p
# SLURM_JOB_CPUS_PER_NODE=1
# SLURM_JOB_GID=24886
# SLURM_JOB_ID=32990267
# SLURM_JOB_NAME=stats.sh
# SLURM_JOB_NODELIST=r225
# SLURM_JOB_NUM_NODES=1
# SLURM_JOB_PARTITION=RM-shared
# SLURM_JOB_QOS=rm
# SLURM_JOB_UID=97947
# SLURM_JOB_USER=ttao3
# SLURM_LAUNCH_NODE_IPADDR=10.8.11.29
# SLURM_LOCALID=0
# SLURM_MEM_PER_CPU=1900
# SLURM_NNODES=1
# SLURM_NODEID=0
# SLURM_NODELIST=r225
# SLURM_NODE_ALIASES='(null)'
# SLURM_NPROCS=1
# SLURM_NTASKS=1
# SLURM_OPEN_MODE=a
# SLURM_PRIO_PROCESS=0
# SLURM_PROCID=0
# SLURM_PTY_PORT=33025
# SLURM_PTY_WIN_COL=126
# SLURM_PTY_WIN_ROW=21
# SLURM_SCRIPT_CONTEXT=prolog_task
# SLURM_SRUN_COMM_HOST=10.8.11.29
# SLURM_SRUN_COMM_PORT=35045
# SLURM_STEPID=0
# SLURM_STEP_GPUS=6
# SLURM_STEP_ID=0
# SLURM_STEP_LAUNCHER_PORT=35045
# SLURM_STEP_NODELIST=v029
# SLURM_STEP_NUM_NODES=1
# SLURM_STEP_NUM_TASKS=1
# SLURM_STEP_TASKS_PER_NODE=1
# SLURM_SUBMIT_DIR=/ocean/projects/cis210027p/ttao3/espnet/egs2/hifitts/tts1
# SLURM_SUBMIT_HOST=v029.ib.bridges2.psc.edu
# SLURM_TASKS_PER_NODE=1
# SLURM_TASK_PID=99297
# SLURM_TOPOLOGY_ADDR=r225
# SLURM_TOPOLOGY_ADDR_PATTERN=node
# SLURM_WORKING_CLUSTER=bridges2:br003:6810:9728:109
# python3 -m espnet2.bin.gan_tts_train --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.23.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.23.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.23 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int 
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/librosa/util/files.py:10: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_filename
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/bin/python3 /ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.23.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.23.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.23 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int
Failed to import Flash Attention, using ESPnet default: No module named 'flash_attn_2_cuda'
Vocabulary size: 74
encoder self-attention layer type = relative self-attention
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/ocean/projects/cis210027p/ttao3/espnet/espnet2/gan_tts/vits/monotonic_align/__init__.py:19: UserWarning: Cython version is not available. Fallback to 'EXPERIMETAL' numba version. If you want to use the cython version, please build it as follows: `cd espnet2/gan_tts/vits/monotonic_align; python setup.py build_ext --inplace`
  warnings.warn(
pytorch.version=2.7.1+cu126, cuda.available=False, cudnn.version=90501, cudnn.benchmark=False, cudnn.deterministic=False
Model structure:
ESPnetGANTTSModel(
  (feats_extract): LinearSpectrogram(
    (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
  )
  (tts): VITS(
    (generator): VITSGenerator(
      (text_encoder): TextEncoder(
        (emb): Embedding(74, 192)
        (encoder): Encoder(
          (embed): Sequential(
            (0): RelPositionalEncoding(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (encoders): MultiSequential(
            (0): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (2): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (3): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (4): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (5): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (after_norm): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (decoder): HiFiGANGenerator(
        (input_conv): Conv1d(192, 512, kernel_size=(7,), stride=(1,), padding=(3,))
        (upsamples): ModuleList(
          (0): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (1): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(256, 128, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (2): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,))
          )
          (3): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,))
          )
        )
        (blocks): ModuleList(
          (0): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (1): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (2): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (3): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (4): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (5): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (6): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (7): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (8): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (9): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (10): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (11): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
        )
        (output_conv): Sequential(
          (0): LeakyReLU(negative_slope=0.01)
          (1): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,))
          (2): Tanh()
        )
        (global_conv): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
      )
      (posterior_encoder): PosteriorEncoder(
        (input_conv): Conv1d(513, 192, kernel_size=(1,), stride=(1,))
        (encoder): WaveNet(
          (conv_layers): ModuleList(
            (0-15): 16 x ResidualBlock(
              (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
              (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
              (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
            )
          )
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (flow): ResidualAffineCouplingBlock(
        (flows): ModuleList(
          (0): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (1): FlipFlow()
          (2): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (3): FlipFlow()
          (4): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (5): FlipFlow()
          (6): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (7): FlipFlow()
        )
      )
      (duration_predictor): StochasticDurationPredictor(
        (pre): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (log_flow): LogFlow()
        (flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (post_pre): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
        (post_dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (post_proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (post_flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (global_conv): Conv1d(256, 192, kernel_size=(1,), stride=(1,))
      )
      (global_emb): Embedding(128, 256)
    )
    (discriminator): HiFiGANMultiScaleMultiPeriodDiscriminator(
      (msd): HiFiGANMultiScaleDiscriminator(
        (discriminators): ModuleList(
          (0): HiFiGANScaleDiscriminator(
            (layers): ModuleList(
              (0): Sequential(
                (0): Conv1d(1, 128, kernel_size=(15,), stride=(1,), padding=(7,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv1d(128, 128, kernel_size=(41,), stride=(2,), padding=(20,), groups=4)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv1d(128, 256, kernel_size=(41,), stride=(2,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv1d(256, 512, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv1d(512, 1024, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (5): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(41,), stride=(1,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (6): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (7): Conv1d(1024, 1, kernel_size=(3,), stride=(1,), padding=(1,))
            )
          )
        )
      )
      (mpd): HiFiGANMultiPeriodDiscriminator(
        (discriminators): ModuleList(
          (0-4): 5 x HiFiGANPeriodDiscriminator(
            (convs): ModuleList(
              (0): Sequential(
                (0): Conv2d(1, 32, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv2d(32, 128, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv2d(128, 512, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv2d(512, 1024, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv2d(1024, 1024, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
            )
            (output_conv): Conv2d(1024, 1, kernel_size=(2, 1), stride=(1, 1), padding=(1, 0))
          )
        )
      )
    )
    (generator_adv_loss): GeneratorAdversarialLoss()
    (discriminator_adv_loss): DiscriminatorAdversarialLoss()
    (feat_match_loss): FeatureMatchLoss()
    (mel_loss): MelSpectrogramLoss(
      (wav_to_mel): LogMelFbank(
        (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
        (logmel): LogMel(sr=22050, n_fft=1024, n_mels=80, fmin=0, fmax=11025.0, htk=False)
      )
    )
    (kl_loss): KLDivergenceLoss()
  )
)

Model summary:
    Class Name: ESPnetGANTTSModel
    Total Number of model parameters: 96.37 M
    Number of trainable parameters: 96.37 M (100.0%)
    Size: 385.46 MB
    Type: torch.float32
Optimizer:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler: <torch.optim.lr_scheduler.ExponentialLR object at 0x14bb747595e0>
Optimizer2:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler2: <torch.optim.lr_scheduler.ExponentialLR object at 0x14bb747599d0>
Saving the configuration in exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.23/config.yaml
Namespace(config='conf/tuning/train_multi_spk_vits.yaml', print_config=False, log_level='INFO', drop_last_iter=False, dry_run=False, iterator_type='sequence', valid_iterator_type=None, output_dir='exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.23', ngpu=0, seed=777, num_workers=4, num_att_plot=3, dist_backend='nccl', dist_init_method='env://', dist_world_size=None, dist_rank=None, local_rank=None, dist_master_addr=None, dist_master_port=None, dist_launcher=None, multiprocessing_distributed=False, unused_parameters=True, sharded_ddp=False, use_deepspeed=False, deepspeed_config=None, gradient_as_bucket_view=True, ddp_comm_hook=None, cudnn_enabled=True, cudnn_benchmark=False, cudnn_deterministic=False, use_tf32=False, collect_stats=True, write_collected_feats=False, max_epoch=1000, patience=None, val_scheduler_criterion=('valid', 'loss'), early_stopping_criterion=('valid', 'loss', 'min'), best_model_criterion=[['train', 'total_count', 'max']], keep_nbest_models=10, nbest_averaging_interval=0, grad_clip=-1, grad_clip_type=2.0, grad_noise=False, accum_grad=1, no_forward_run=False, resume=False, train_dtype='float32', use_amp=False, log_interval=50, use_matplotlib=True, use_tensorboard=True, create_graph_in_tensorboard=False, use_wandb=False, wandb_project=None, wandb_id=None, wandb_entity=None, wandb_name=None, wandb_model_log_interval=-1, detect_anomaly=False, use_adapter=False, adapter='lora', save_strategy='all', adapter_conf={}, pretrain_path=None, init_param=[], ignore_init_mismatch=False, freeze_param=[], num_iters_per_epoch=1000, batch_size=20, valid_batch_size=None, batch_bins=3000000, valid_batch_bins=None, category_sample_size=10, train_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.23.scp'], valid_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.23.scp'], batch_type='numel', valid_batch_type=None, fold_length=[], sort_in_batch='descending', shuffle_within_batch=False, sort_batch='descending', multiple_iterator=False, chunk_length=500, chunk_shift_ratio=0.5, num_cache_chunks=1024, chunk_excluded_key_prefixes=[], chunk_default_fs=None, chunk_max_abs_length=None, chunk_discard_short_samples=True, train_data_path_and_name_and_type=[('dump/22k/raw/tr_no_dev/text', 'text', 'text'), ('dump/22k/raw/tr_no_dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/tr_no_dev/utt2sid', 'sids', 'text_int')], valid_data_path_and_name_and_type=[('dump/22k/raw/dev/text', 'text', 'text'), ('dump/22k/raw/dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/dev/utt2sid', 'sids', 'text_int')], multi_task_dataset=False, allow_variable_data_keys=False, max_cache_size=0.0, max_cache_fd=32, allow_multi_rates=False, valid_max_cache_size=None, exclude_weight_decay=False, exclude_weight_decay_conf={}, optim='adamw', optim_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler='exponentiallr', scheduler_conf={'gamma': 0.999875}, optim2='adamw', optim2_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler2='exponentiallr', scheduler2_conf={'gamma': 0.999875}, generator_first=False, skip_discriminator_prob=0.0, token_list=['<blank>', '<unk>', ' ', 'AH0', 'N', 'T', 'D', 'S', 'R', 'L', 'IH1', 'DH', 'M', 'EH1', 'Z', 'AE1', 'K', 'IH0', 'AH1', 'HH', 'W', 'ER0', 'V', 'IY1', 'F', 'UW1', 'P', 'AY1', 'B', 'AA1', 'AO1', 'EY1', 'IY0', 'OW1', 'NG', 'SH', 'G', 'Y', 'AW1', 'CH', 'ER1', 'UH1', 'TH', 'JH', 'OW0', 'EH2', 'IH2', 'OY1', 'EY2', 'AY2', 'EH0', 'UW0', 'AA2', 'AE2', 'OW2', 'AH2', 'AA0', 'ZH', 'AE0', 'AO2', 'UW2', 'AO0', 'AY0', 'IY2', 'AW2', 'UH2', 'EY0', 'ER2', 'AW0', 'UH0', 'OY2', 'OY0', "'", '<sos/eos>'], odim=None, model_conf={}, use_preprocessor=True, token_type='phn', bpemodel=None, non_linguistic_symbols=None, cleaner='tacotron', g2p='g2p_en', feats_extract='linear_spectrogram', feats_extract_conf={'n_fft': 1024, 'hop_length': 256, 'win_length': None}, normalize=None, normalize_conf={}, tts='vits', tts_conf={'generator_type': 'vits_generator', 'generator_params': {'hidden_channels': 192, 'spks': 128, 'global_channels': 256, 'segment_size': 32, 'text_encoder_attention_heads': 2, 'text_encoder_ffn_expand': 4, 'text_encoder_blocks': 6, 'text_encoder_positionwise_layer_type': 'conv1d', 'text_encoder_positionwise_conv_kernel_size': 3, 'text_encoder_positional_encoding_layer_type': 'rel_pos', 'text_encoder_self_attention_layer_type': 'rel_selfattn', 'text_encoder_activation_type': 'swish', 'text_encoder_normalize_before': True, 'text_encoder_dropout_rate': 0.1, 'text_encoder_positional_dropout_rate': 0.0, 'text_encoder_attention_dropout_rate': 0.1, 'use_macaron_style_in_text_encoder': True, 'use_conformer_conv_in_text_encoder': False, 'text_encoder_conformer_kernel_size': -1, 'decoder_kernel_size': 7, 'decoder_channels': 512, 'decoder_upsample_scales': [8, 8, 2, 2], 'decoder_upsample_kernel_sizes': [16, 16, 4, 4], 'decoder_resblock_kernel_sizes': [3, 7, 11], 'decoder_resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'use_weight_norm_in_decoder': True, 'posterior_encoder_kernel_size': 5, 'posterior_encoder_layers': 16, 'posterior_encoder_stacks': 1, 'posterior_encoder_base_dilation': 1, 'posterior_encoder_dropout_rate': 0.0, 'use_weight_norm_in_posterior_encoder': True, 'flow_flows': 4, 'flow_kernel_size': 5, 'flow_base_dilation': 1, 'flow_layers': 4, 'flow_dropout_rate': 0.0, 'use_weight_norm_in_flow': True, 'use_only_mean_in_flow': True, 'stochastic_duration_predictor_kernel_size': 3, 'stochastic_duration_predictor_dropout_rate': 0.5, 'stochastic_duration_predictor_flows': 4, 'stochastic_duration_predictor_dds_conv_layers': 3, 'vocabs': 74, 'aux_channels': 513}, 'discriminator_type': 'hifigan_multi_scale_multi_period_discriminator', 'discriminator_params': {'scales': 1, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'stride': 2, 'padding': 2}, 'scale_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'channels': 128, 'max_downsample_channels': 1024, 'max_groups': 16, 'bias': True, 'downsample_scales': [2, 2, 4, 4, 1], 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}, 'follow_official_norm': False, 'periods': [2, 3, 5, 7, 11], 'period_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [5, 3], 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'max_downsample_channels': 1024, 'bias': True, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}}, 'generator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'discriminator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'feat_match_loss_params': {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, 'mel_loss_params': {'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None, 'window': 'hann', 'n_mels': 80, 'fmin': 0, 'fmax': None, 'log_base': None}, 'lambda_adv': 1.0, 'lambda_mel': 45.0, 'lambda_feat_match': 2.0, 'lambda_dur': 1.0, 'lambda_kl': 1.0, 'sampling_rate': 22050, 'cache_generator_outputs': True, 'plot_pred_mos': False, 'mos_pred_tool': 'utmos'}, pitch_extract=None, pitch_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'f0max': 400, 'f0min': 80}, pitch_normalize=None, pitch_normalize_conf={}, energy_extract=None, energy_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None}, energy_normalize=None, energy_normalize_conf={}, required=['output_dir', 'token_list'], version='202503', distributed=False)
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1284, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 99419) is killed by signal: Killed. 

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 22, in <module>
    main()
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 18, in main
    GANTTSTask.main(cmd=cmd)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1225, in main
    cls.main_worker(args)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1441, in main_worker
    collect_stats(
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/main_funcs/collect_stats.py", line 51, in collect_stats
    for iiter, (keys, batch) in enumerate(itr, 1):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 733, in __next__
    data = self._next_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1491, in _next_data
    idx, data = self._get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1453, in _get_data
    success, data = self._try_get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1297, in _try_get_data
    raise RuntimeError(
RuntimeError: DataLoader worker (pid(s) 99419) exited unexpectedly
# Accounting: begin_time=1750873483
# Accounting: end_time=1750873627
# Accounting: time=144 threads=1
# Finished at Wed Jun 25 13:47:07 EDT 2025 with status 1
# Running on r023.ib.bridges2.psc.edu
# Started at Wed Jun 25 13:44:42 EDT 2025
# SLURMD_NODENAME=r023
# SLURM_ARRAY_JOB_ID=32990217
# SLURM_ARRAY_TASK_COUNT=32
# SLURM_ARRAY_TASK_ID=24
# SLURM_ARRAY_TASK_MAX=32
# SLURM_ARRAY_TASK_MIN=1
# SLURM_ARRAY_TASK_STEP=1
# SLURM_CLUSTER_NAME=bridges2
# SLURM_CONF=/var/spool/slurm/d/conf-cache/slurm.conf
# SLURM_CPUS_ON_NODE=1
# SLURM_CPU_BIND=quiet,mask_cpu:0x07C0000000
# SLURM_CPU_BIND_LIST=0x07C0000000
# SLURM_CPU_BIND_TYPE=mask_cpu:
# SLURM_CPU_BIND_VERBOSE=quiet
# SLURM_EXPORT_ENV=ALL
# SLURM_GET_USER_ENV=1
# SLURM_GTIDS=0
# SLURM_JOBID=32990268
# SLURM_JOB_ACCOUNT=cis210027p
# SLURM_JOB_CPUS_PER_NODE=1
# SLURM_JOB_GID=24886
# SLURM_JOB_ID=32990268
# SLURM_JOB_NAME=stats.sh
# SLURM_JOB_NODELIST=r023
# SLURM_JOB_NUM_NODES=1
# SLURM_JOB_PARTITION=RM-shared
# SLURM_JOB_QOS=rm
# SLURM_JOB_UID=97947
# SLURM_JOB_USER=ttao3
# SLURM_LAUNCH_NODE_IPADDR=10.8.11.29
# SLURM_LOCALID=0
# SLURM_MEM_PER_CPU=1900
# SLURM_NNODES=1
# SLURM_NODEID=0
# SLURM_NODELIST=r023
# SLURM_NODE_ALIASES='(null)'
# SLURM_NPROCS=1
# SLURM_NTASKS=1
# SLURM_OPEN_MODE=a
# SLURM_PRIO_PROCESS=0
# SLURM_PROCID=0
# SLURM_PTY_PORT=33025
# SLURM_PTY_WIN_COL=126
# SLURM_PTY_WIN_ROW=21
# SLURM_SCRIPT_CONTEXT=prolog_task
# SLURM_SRUN_COMM_HOST=10.8.11.29
# SLURM_SRUN_COMM_PORT=35045
# SLURM_STEPID=0
# SLURM_STEP_GPUS=6
# SLURM_STEP_ID=0
# SLURM_STEP_LAUNCHER_PORT=35045
# SLURM_STEP_NODELIST=v029
# SLURM_STEP_NUM_NODES=1
# SLURM_STEP_NUM_TASKS=1
# SLURM_STEP_TASKS_PER_NODE=1
# SLURM_SUBMIT_DIR=/ocean/projects/cis210027p/ttao3/espnet/egs2/hifitts/tts1
# SLURM_SUBMIT_HOST=v029.ib.bridges2.psc.edu
# SLURM_TASKS_PER_NODE=1
# SLURM_TASK_PID=66409
# SLURM_TOPOLOGY_ADDR=r023
# SLURM_TOPOLOGY_ADDR_PATTERN=node
# SLURM_WORKING_CLUSTER=bridges2:br003:6810:9728:109
# python3 -m espnet2.bin.gan_tts_train --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.24.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.24.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.24 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int 
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/librosa/util/files.py:10: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_filename
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/bin/python3 /ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.24.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.24.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.24 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int
Failed to import Flash Attention, using ESPnet default: No module named 'flash_attn_2_cuda'
Vocabulary size: 74
encoder self-attention layer type = relative self-attention
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/ocean/projects/cis210027p/ttao3/espnet/espnet2/gan_tts/vits/monotonic_align/__init__.py:19: UserWarning: Cython version is not available. Fallback to 'EXPERIMETAL' numba version. If you want to use the cython version, please build it as follows: `cd espnet2/gan_tts/vits/monotonic_align; python setup.py build_ext --inplace`
  warnings.warn(
pytorch.version=2.7.1+cu126, cuda.available=False, cudnn.version=90501, cudnn.benchmark=False, cudnn.deterministic=False
Model structure:
ESPnetGANTTSModel(
  (feats_extract): LinearSpectrogram(
    (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
  )
  (tts): VITS(
    (generator): VITSGenerator(
      (text_encoder): TextEncoder(
        (emb): Embedding(74, 192)
        (encoder): Encoder(
          (embed): Sequential(
            (0): RelPositionalEncoding(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (encoders): MultiSequential(
            (0): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (2): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (3): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (4): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (5): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (after_norm): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (decoder): HiFiGANGenerator(
        (input_conv): Conv1d(192, 512, kernel_size=(7,), stride=(1,), padding=(3,))
        (upsamples): ModuleList(
          (0): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (1): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(256, 128, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (2): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,))
          )
          (3): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,))
          )
        )
        (blocks): ModuleList(
          (0): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (1): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (2): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (3): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (4): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (5): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (6): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (7): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (8): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (9): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (10): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (11): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
        )
        (output_conv): Sequential(
          (0): LeakyReLU(negative_slope=0.01)
          (1): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,))
          (2): Tanh()
        )
        (global_conv): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
      )
      (posterior_encoder): PosteriorEncoder(
        (input_conv): Conv1d(513, 192, kernel_size=(1,), stride=(1,))
        (encoder): WaveNet(
          (conv_layers): ModuleList(
            (0-15): 16 x ResidualBlock(
              (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
              (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
              (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
            )
          )
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (flow): ResidualAffineCouplingBlock(
        (flows): ModuleList(
          (0): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (1): FlipFlow()
          (2): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (3): FlipFlow()
          (4): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (5): FlipFlow()
          (6): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (7): FlipFlow()
        )
      )
      (duration_predictor): StochasticDurationPredictor(
        (pre): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (log_flow): LogFlow()
        (flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (post_pre): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
        (post_dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (post_proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (post_flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (global_conv): Conv1d(256, 192, kernel_size=(1,), stride=(1,))
      )
      (global_emb): Embedding(128, 256)
    )
    (discriminator): HiFiGANMultiScaleMultiPeriodDiscriminator(
      (msd): HiFiGANMultiScaleDiscriminator(
        (discriminators): ModuleList(
          (0): HiFiGANScaleDiscriminator(
            (layers): ModuleList(
              (0): Sequential(
                (0): Conv1d(1, 128, kernel_size=(15,), stride=(1,), padding=(7,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv1d(128, 128, kernel_size=(41,), stride=(2,), padding=(20,), groups=4)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv1d(128, 256, kernel_size=(41,), stride=(2,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv1d(256, 512, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv1d(512, 1024, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (5): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(41,), stride=(1,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (6): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (7): Conv1d(1024, 1, kernel_size=(3,), stride=(1,), padding=(1,))
            )
          )
        )
      )
      (mpd): HiFiGANMultiPeriodDiscriminator(
        (discriminators): ModuleList(
          (0-4): 5 x HiFiGANPeriodDiscriminator(
            (convs): ModuleList(
              (0): Sequential(
                (0): Conv2d(1, 32, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv2d(32, 128, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv2d(128, 512, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv2d(512, 1024, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv2d(1024, 1024, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
            )
            (output_conv): Conv2d(1024, 1, kernel_size=(2, 1), stride=(1, 1), padding=(1, 0))
          )
        )
      )
    )
    (generator_adv_loss): GeneratorAdversarialLoss()
    (discriminator_adv_loss): DiscriminatorAdversarialLoss()
    (feat_match_loss): FeatureMatchLoss()
    (mel_loss): MelSpectrogramLoss(
      (wav_to_mel): LogMelFbank(
        (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
        (logmel): LogMel(sr=22050, n_fft=1024, n_mels=80, fmin=0, fmax=11025.0, htk=False)
      )
    )
    (kl_loss): KLDivergenceLoss()
  )
)

Model summary:
    Class Name: ESPnetGANTTSModel
    Total Number of model parameters: 96.37 M
    Number of trainable parameters: 96.37 M (100.0%)
    Size: 385.46 MB
    Type: torch.float32
Optimizer:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler: <torch.optim.lr_scheduler.ExponentialLR object at 0x147eb00af640>
Optimizer2:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler2: <torch.optim.lr_scheduler.ExponentialLR object at 0x147eb00afa30>
Saving the configuration in exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.24/config.yaml
Namespace(config='conf/tuning/train_multi_spk_vits.yaml', print_config=False, log_level='INFO', drop_last_iter=False, dry_run=False, iterator_type='sequence', valid_iterator_type=None, output_dir='exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.24', ngpu=0, seed=777, num_workers=4, num_att_plot=3, dist_backend='nccl', dist_init_method='env://', dist_world_size=None, dist_rank=None, local_rank=None, dist_master_addr=None, dist_master_port=None, dist_launcher=None, multiprocessing_distributed=False, unused_parameters=True, sharded_ddp=False, use_deepspeed=False, deepspeed_config=None, gradient_as_bucket_view=True, ddp_comm_hook=None, cudnn_enabled=True, cudnn_benchmark=False, cudnn_deterministic=False, use_tf32=False, collect_stats=True, write_collected_feats=False, max_epoch=1000, patience=None, val_scheduler_criterion=('valid', 'loss'), early_stopping_criterion=('valid', 'loss', 'min'), best_model_criterion=[['train', 'total_count', 'max']], keep_nbest_models=10, nbest_averaging_interval=0, grad_clip=-1, grad_clip_type=2.0, grad_noise=False, accum_grad=1, no_forward_run=False, resume=False, train_dtype='float32', use_amp=False, log_interval=50, use_matplotlib=True, use_tensorboard=True, create_graph_in_tensorboard=False, use_wandb=False, wandb_project=None, wandb_id=None, wandb_entity=None, wandb_name=None, wandb_model_log_interval=-1, detect_anomaly=False, use_adapter=False, adapter='lora', save_strategy='all', adapter_conf={}, pretrain_path=None, init_param=[], ignore_init_mismatch=False, freeze_param=[], num_iters_per_epoch=1000, batch_size=20, valid_batch_size=None, batch_bins=3000000, valid_batch_bins=None, category_sample_size=10, train_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.24.scp'], valid_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.24.scp'], batch_type='numel', valid_batch_type=None, fold_length=[], sort_in_batch='descending', shuffle_within_batch=False, sort_batch='descending', multiple_iterator=False, chunk_length=500, chunk_shift_ratio=0.5, num_cache_chunks=1024, chunk_excluded_key_prefixes=[], chunk_default_fs=None, chunk_max_abs_length=None, chunk_discard_short_samples=True, train_data_path_and_name_and_type=[('dump/22k/raw/tr_no_dev/text', 'text', 'text'), ('dump/22k/raw/tr_no_dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/tr_no_dev/utt2sid', 'sids', 'text_int')], valid_data_path_and_name_and_type=[('dump/22k/raw/dev/text', 'text', 'text'), ('dump/22k/raw/dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/dev/utt2sid', 'sids', 'text_int')], multi_task_dataset=False, allow_variable_data_keys=False, max_cache_size=0.0, max_cache_fd=32, allow_multi_rates=False, valid_max_cache_size=None, exclude_weight_decay=False, exclude_weight_decay_conf={}, optim='adamw', optim_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler='exponentiallr', scheduler_conf={'gamma': 0.999875}, optim2='adamw', optim2_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler2='exponentiallr', scheduler2_conf={'gamma': 0.999875}, generator_first=False, skip_discriminator_prob=0.0, token_list=['<blank>', '<unk>', ' ', 'AH0', 'N', 'T', 'D', 'S', 'R', 'L', 'IH1', 'DH', 'M', 'EH1', 'Z', 'AE1', 'K', 'IH0', 'AH1', 'HH', 'W', 'ER0', 'V', 'IY1', 'F', 'UW1', 'P', 'AY1', 'B', 'AA1', 'AO1', 'EY1', 'IY0', 'OW1', 'NG', 'SH', 'G', 'Y', 'AW1', 'CH', 'ER1', 'UH1', 'TH', 'JH', 'OW0', 'EH2', 'IH2', 'OY1', 'EY2', 'AY2', 'EH0', 'UW0', 'AA2', 'AE2', 'OW2', 'AH2', 'AA0', 'ZH', 'AE0', 'AO2', 'UW2', 'AO0', 'AY0', 'IY2', 'AW2', 'UH2', 'EY0', 'ER2', 'AW0', 'UH0', 'OY2', 'OY0', "'", '<sos/eos>'], odim=None, model_conf={}, use_preprocessor=True, token_type='phn', bpemodel=None, non_linguistic_symbols=None, cleaner='tacotron', g2p='g2p_en', feats_extract='linear_spectrogram', feats_extract_conf={'n_fft': 1024, 'hop_length': 256, 'win_length': None}, normalize=None, normalize_conf={}, tts='vits', tts_conf={'generator_type': 'vits_generator', 'generator_params': {'hidden_channels': 192, 'spks': 128, 'global_channels': 256, 'segment_size': 32, 'text_encoder_attention_heads': 2, 'text_encoder_ffn_expand': 4, 'text_encoder_blocks': 6, 'text_encoder_positionwise_layer_type': 'conv1d', 'text_encoder_positionwise_conv_kernel_size': 3, 'text_encoder_positional_encoding_layer_type': 'rel_pos', 'text_encoder_self_attention_layer_type': 'rel_selfattn', 'text_encoder_activation_type': 'swish', 'text_encoder_normalize_before': True, 'text_encoder_dropout_rate': 0.1, 'text_encoder_positional_dropout_rate': 0.0, 'text_encoder_attention_dropout_rate': 0.1, 'use_macaron_style_in_text_encoder': True, 'use_conformer_conv_in_text_encoder': False, 'text_encoder_conformer_kernel_size': -1, 'decoder_kernel_size': 7, 'decoder_channels': 512, 'decoder_upsample_scales': [8, 8, 2, 2], 'decoder_upsample_kernel_sizes': [16, 16, 4, 4], 'decoder_resblock_kernel_sizes': [3, 7, 11], 'decoder_resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'use_weight_norm_in_decoder': True, 'posterior_encoder_kernel_size': 5, 'posterior_encoder_layers': 16, 'posterior_encoder_stacks': 1, 'posterior_encoder_base_dilation': 1, 'posterior_encoder_dropout_rate': 0.0, 'use_weight_norm_in_posterior_encoder': True, 'flow_flows': 4, 'flow_kernel_size': 5, 'flow_base_dilation': 1, 'flow_layers': 4, 'flow_dropout_rate': 0.0, 'use_weight_norm_in_flow': True, 'use_only_mean_in_flow': True, 'stochastic_duration_predictor_kernel_size': 3, 'stochastic_duration_predictor_dropout_rate': 0.5, 'stochastic_duration_predictor_flows': 4, 'stochastic_duration_predictor_dds_conv_layers': 3, 'vocabs': 74, 'aux_channels': 513}, 'discriminator_type': 'hifigan_multi_scale_multi_period_discriminator', 'discriminator_params': {'scales': 1, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'stride': 2, 'padding': 2}, 'scale_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'channels': 128, 'max_downsample_channels': 1024, 'max_groups': 16, 'bias': True, 'downsample_scales': [2, 2, 4, 4, 1], 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}, 'follow_official_norm': False, 'periods': [2, 3, 5, 7, 11], 'period_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [5, 3], 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'max_downsample_channels': 1024, 'bias': True, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}}, 'generator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'discriminator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'feat_match_loss_params': {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, 'mel_loss_params': {'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None, 'window': 'hann', 'n_mels': 80, 'fmin': 0, 'fmax': None, 'log_base': None}, 'lambda_adv': 1.0, 'lambda_mel': 45.0, 'lambda_feat_match': 2.0, 'lambda_dur': 1.0, 'lambda_kl': 1.0, 'sampling_rate': 22050, 'cache_generator_outputs': True, 'plot_pred_mos': False, 'mos_pred_tool': 'utmos'}, pitch_extract=None, pitch_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'f0max': 400, 'f0min': 80}, pitch_normalize=None, pitch_normalize_conf={}, energy_extract=None, energy_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None}, energy_normalize=None, energy_normalize_conf={}, required=['output_dir', 'token_list'], version='202503', distributed=False)
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1284, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 67024) is killed by signal: Killed. 

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 22, in <module>
    main()
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 18, in main
    GANTTSTask.main(cmd=cmd)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1225, in main
    cls.main_worker(args)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1441, in main_worker
    collect_stats(
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/main_funcs/collect_stats.py", line 51, in collect_stats
    for iiter, (keys, batch) in enumerate(itr, 1):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 733, in __next__
    data = self._next_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1491, in _next_data
    idx, data = self._get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1453, in _get_data
    success, data = self._try_get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1297, in _try_get_data
    raise RuntimeError(
RuntimeError: DataLoader worker (pid(s) 67024) exited unexpectedly
# Accounting: begin_time=1750873482
# Accounting: end_time=1750873629
# Accounting: time=147 threads=1
# Finished at Wed Jun 25 13:47:09 EDT 2025 with status 1
# Running on r023.ib.bridges2.psc.edu
# Started at Wed Jun 25 13:44:40 EDT 2025
# SLURMD_NODENAME=r023
# SLURM_ARRAY_JOB_ID=32990217
# SLURM_ARRAY_TASK_COUNT=32
# SLURM_ARRAY_TASK_ID=25
# SLURM_ARRAY_TASK_MAX=32
# SLURM_ARRAY_TASK_MIN=1
# SLURM_ARRAY_TASK_STEP=1
# SLURM_CLUSTER_NAME=bridges2
# SLURM_CONF=/var/spool/slurm/d/conf-cache/slurm.conf
# SLURM_CPUS_ON_NODE=1
# SLURM_CPU_BIND=quiet,mask_cpu:0x07C0000000
# SLURM_CPU_BIND_LIST=0x07C0000000
# SLURM_CPU_BIND_TYPE=mask_cpu:
# SLURM_CPU_BIND_VERBOSE=quiet
# SLURM_EXPORT_ENV=ALL
# SLURM_GET_USER_ENV=1
# SLURM_GTIDS=0
# SLURM_JOBID=32990269
# SLURM_JOB_ACCOUNT=cis210027p
# SLURM_JOB_CPUS_PER_NODE=1
# SLURM_JOB_GID=24886
# SLURM_JOB_ID=32990269
# SLURM_JOB_NAME=stats.sh
# SLURM_JOB_NODELIST=r023
# SLURM_JOB_NUM_NODES=1
# SLURM_JOB_PARTITION=RM-shared
# SLURM_JOB_QOS=rm
# SLURM_JOB_UID=97947
# SLURM_JOB_USER=ttao3
# SLURM_LAUNCH_NODE_IPADDR=10.8.11.29
# SLURM_LOCALID=0
# SLURM_MEM_PER_CPU=1900
# SLURM_NNODES=1
# SLURM_NODEID=0
# SLURM_NODELIST=r023
# SLURM_NODE_ALIASES='(null)'
# SLURM_NPROCS=1
# SLURM_NTASKS=1
# SLURM_OPEN_MODE=a
# SLURM_PRIO_PROCESS=0
# SLURM_PROCID=0
# SLURM_PTY_PORT=33025
# SLURM_PTY_WIN_COL=126
# SLURM_PTY_WIN_ROW=21
# SLURM_SCRIPT_CONTEXT=prolog_task
# SLURM_SRUN_COMM_HOST=10.8.11.29
# SLURM_SRUN_COMM_PORT=35045
# SLURM_STEPID=0
# SLURM_STEP_GPUS=6
# SLURM_STEP_ID=0
# SLURM_STEP_LAUNCHER_PORT=35045
# SLURM_STEP_NODELIST=v029
# SLURM_STEP_NUM_NODES=1
# SLURM_STEP_NUM_TASKS=1
# SLURM_STEP_TASKS_PER_NODE=1
# SLURM_SUBMIT_DIR=/ocean/projects/cis210027p/ttao3/espnet/egs2/hifitts/tts1
# SLURM_SUBMIT_HOST=v029.ib.bridges2.psc.edu
# SLURM_TASKS_PER_NODE=1
# SLURM_TASK_PID=66393
# SLURM_TOPOLOGY_ADDR=r023
# SLURM_TOPOLOGY_ADDR_PATTERN=node
# SLURM_WORKING_CLUSTER=bridges2:br003:6810:9728:109
# python3 -m espnet2.bin.gan_tts_train --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.25.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.25.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.25 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int 
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/librosa/util/files.py:10: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_filename
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/bin/python3 /ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.25.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.25.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.25 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int
Failed to import Flash Attention, using ESPnet default: No module named 'flash_attn_2_cuda'
Vocabulary size: 74
encoder self-attention layer type = relative self-attention
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/ocean/projects/cis210027p/ttao3/espnet/espnet2/gan_tts/vits/monotonic_align/__init__.py:19: UserWarning: Cython version is not available. Fallback to 'EXPERIMETAL' numba version. If you want to use the cython version, please build it as follows: `cd espnet2/gan_tts/vits/monotonic_align; python setup.py build_ext --inplace`
  warnings.warn(
pytorch.version=2.7.1+cu126, cuda.available=False, cudnn.version=90501, cudnn.benchmark=False, cudnn.deterministic=False
Model structure:
ESPnetGANTTSModel(
  (feats_extract): LinearSpectrogram(
    (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
  )
  (tts): VITS(
    (generator): VITSGenerator(
      (text_encoder): TextEncoder(
        (emb): Embedding(74, 192)
        (encoder): Encoder(
          (embed): Sequential(
            (0): RelPositionalEncoding(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (encoders): MultiSequential(
            (0): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (2): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (3): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (4): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (5): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (after_norm): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (decoder): HiFiGANGenerator(
        (input_conv): Conv1d(192, 512, kernel_size=(7,), stride=(1,), padding=(3,))
        (upsamples): ModuleList(
          (0): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (1): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(256, 128, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (2): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,))
          )
          (3): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,))
          )
        )
        (blocks): ModuleList(
          (0): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (1): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (2): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (3): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (4): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (5): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (6): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (7): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (8): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (9): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (10): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (11): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
        )
        (output_conv): Sequential(
          (0): LeakyReLU(negative_slope=0.01)
          (1): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,))
          (2): Tanh()
        )
        (global_conv): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
      )
      (posterior_encoder): PosteriorEncoder(
        (input_conv): Conv1d(513, 192, kernel_size=(1,), stride=(1,))
        (encoder): WaveNet(
          (conv_layers): ModuleList(
            (0-15): 16 x ResidualBlock(
              (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
              (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
              (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
            )
          )
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (flow): ResidualAffineCouplingBlock(
        (flows): ModuleList(
          (0): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (1): FlipFlow()
          (2): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (3): FlipFlow()
          (4): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (5): FlipFlow()
          (6): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (7): FlipFlow()
        )
      )
      (duration_predictor): StochasticDurationPredictor(
        (pre): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (log_flow): LogFlow()
        (flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (post_pre): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
        (post_dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (post_proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (post_flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (global_conv): Conv1d(256, 192, kernel_size=(1,), stride=(1,))
      )
      (global_emb): Embedding(128, 256)
    )
    (discriminator): HiFiGANMultiScaleMultiPeriodDiscriminator(
      (msd): HiFiGANMultiScaleDiscriminator(
        (discriminators): ModuleList(
          (0): HiFiGANScaleDiscriminator(
            (layers): ModuleList(
              (0): Sequential(
                (0): Conv1d(1, 128, kernel_size=(15,), stride=(1,), padding=(7,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv1d(128, 128, kernel_size=(41,), stride=(2,), padding=(20,), groups=4)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv1d(128, 256, kernel_size=(41,), stride=(2,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv1d(256, 512, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv1d(512, 1024, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (5): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(41,), stride=(1,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (6): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (7): Conv1d(1024, 1, kernel_size=(3,), stride=(1,), padding=(1,))
            )
          )
        )
      )
      (mpd): HiFiGANMultiPeriodDiscriminator(
        (discriminators): ModuleList(
          (0-4): 5 x HiFiGANPeriodDiscriminator(
            (convs): ModuleList(
              (0): Sequential(
                (0): Conv2d(1, 32, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv2d(32, 128, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv2d(128, 512, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv2d(512, 1024, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv2d(1024, 1024, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
            )
            (output_conv): Conv2d(1024, 1, kernel_size=(2, 1), stride=(1, 1), padding=(1, 0))
          )
        )
      )
    )
    (generator_adv_loss): GeneratorAdversarialLoss()
    (discriminator_adv_loss): DiscriminatorAdversarialLoss()
    (feat_match_loss): FeatureMatchLoss()
    (mel_loss): MelSpectrogramLoss(
      (wav_to_mel): LogMelFbank(
        (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
        (logmel): LogMel(sr=22050, n_fft=1024, n_mels=80, fmin=0, fmax=11025.0, htk=False)
      )
    )
    (kl_loss): KLDivergenceLoss()
  )
)

Model summary:
    Class Name: ESPnetGANTTSModel
    Total Number of model parameters: 96.37 M
    Number of trainable parameters: 96.37 M (100.0%)
    Size: 385.46 MB
    Type: torch.float32
Optimizer:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler: <torch.optim.lr_scheduler.ExponentialLR object at 0x14b6d882e610>
Optimizer2:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler2: <torch.optim.lr_scheduler.ExponentialLR object at 0x14b6d882ea00>
Saving the configuration in exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.25/config.yaml
Namespace(config='conf/tuning/train_multi_spk_vits.yaml', print_config=False, log_level='INFO', drop_last_iter=False, dry_run=False, iterator_type='sequence', valid_iterator_type=None, output_dir='exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.25', ngpu=0, seed=777, num_workers=4, num_att_plot=3, dist_backend='nccl', dist_init_method='env://', dist_world_size=None, dist_rank=None, local_rank=None, dist_master_addr=None, dist_master_port=None, dist_launcher=None, multiprocessing_distributed=False, unused_parameters=True, sharded_ddp=False, use_deepspeed=False, deepspeed_config=None, gradient_as_bucket_view=True, ddp_comm_hook=None, cudnn_enabled=True, cudnn_benchmark=False, cudnn_deterministic=False, use_tf32=False, collect_stats=True, write_collected_feats=False, max_epoch=1000, patience=None, val_scheduler_criterion=('valid', 'loss'), early_stopping_criterion=('valid', 'loss', 'min'), best_model_criterion=[['train', 'total_count', 'max']], keep_nbest_models=10, nbest_averaging_interval=0, grad_clip=-1, grad_clip_type=2.0, grad_noise=False, accum_grad=1, no_forward_run=False, resume=False, train_dtype='float32', use_amp=False, log_interval=50, use_matplotlib=True, use_tensorboard=True, create_graph_in_tensorboard=False, use_wandb=False, wandb_project=None, wandb_id=None, wandb_entity=None, wandb_name=None, wandb_model_log_interval=-1, detect_anomaly=False, use_adapter=False, adapter='lora', save_strategy='all', adapter_conf={}, pretrain_path=None, init_param=[], ignore_init_mismatch=False, freeze_param=[], num_iters_per_epoch=1000, batch_size=20, valid_batch_size=None, batch_bins=3000000, valid_batch_bins=None, category_sample_size=10, train_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.25.scp'], valid_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.25.scp'], batch_type='numel', valid_batch_type=None, fold_length=[], sort_in_batch='descending', shuffle_within_batch=False, sort_batch='descending', multiple_iterator=False, chunk_length=500, chunk_shift_ratio=0.5, num_cache_chunks=1024, chunk_excluded_key_prefixes=[], chunk_default_fs=None, chunk_max_abs_length=None, chunk_discard_short_samples=True, train_data_path_and_name_and_type=[('dump/22k/raw/tr_no_dev/text', 'text', 'text'), ('dump/22k/raw/tr_no_dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/tr_no_dev/utt2sid', 'sids', 'text_int')], valid_data_path_and_name_and_type=[('dump/22k/raw/dev/text', 'text', 'text'), ('dump/22k/raw/dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/dev/utt2sid', 'sids', 'text_int')], multi_task_dataset=False, allow_variable_data_keys=False, max_cache_size=0.0, max_cache_fd=32, allow_multi_rates=False, valid_max_cache_size=None, exclude_weight_decay=False, exclude_weight_decay_conf={}, optim='adamw', optim_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler='exponentiallr', scheduler_conf={'gamma': 0.999875}, optim2='adamw', optim2_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler2='exponentiallr', scheduler2_conf={'gamma': 0.999875}, generator_first=False, skip_discriminator_prob=0.0, token_list=['<blank>', '<unk>', ' ', 'AH0', 'N', 'T', 'D', 'S', 'R', 'L', 'IH1', 'DH', 'M', 'EH1', 'Z', 'AE1', 'K', 'IH0', 'AH1', 'HH', 'W', 'ER0', 'V', 'IY1', 'F', 'UW1', 'P', 'AY1', 'B', 'AA1', 'AO1', 'EY1', 'IY0', 'OW1', 'NG', 'SH', 'G', 'Y', 'AW1', 'CH', 'ER1', 'UH1', 'TH', 'JH', 'OW0', 'EH2', 'IH2', 'OY1', 'EY2', 'AY2', 'EH0', 'UW0', 'AA2', 'AE2', 'OW2', 'AH2', 'AA0', 'ZH', 'AE0', 'AO2', 'UW2', 'AO0', 'AY0', 'IY2', 'AW2', 'UH2', 'EY0', 'ER2', 'AW0', 'UH0', 'OY2', 'OY0', "'", '<sos/eos>'], odim=None, model_conf={}, use_preprocessor=True, token_type='phn', bpemodel=None, non_linguistic_symbols=None, cleaner='tacotron', g2p='g2p_en', feats_extract='linear_spectrogram', feats_extract_conf={'n_fft': 1024, 'hop_length': 256, 'win_length': None}, normalize=None, normalize_conf={}, tts='vits', tts_conf={'generator_type': 'vits_generator', 'generator_params': {'hidden_channels': 192, 'spks': 128, 'global_channels': 256, 'segment_size': 32, 'text_encoder_attention_heads': 2, 'text_encoder_ffn_expand': 4, 'text_encoder_blocks': 6, 'text_encoder_positionwise_layer_type': 'conv1d', 'text_encoder_positionwise_conv_kernel_size': 3, 'text_encoder_positional_encoding_layer_type': 'rel_pos', 'text_encoder_self_attention_layer_type': 'rel_selfattn', 'text_encoder_activation_type': 'swish', 'text_encoder_normalize_before': True, 'text_encoder_dropout_rate': 0.1, 'text_encoder_positional_dropout_rate': 0.0, 'text_encoder_attention_dropout_rate': 0.1, 'use_macaron_style_in_text_encoder': True, 'use_conformer_conv_in_text_encoder': False, 'text_encoder_conformer_kernel_size': -1, 'decoder_kernel_size': 7, 'decoder_channels': 512, 'decoder_upsample_scales': [8, 8, 2, 2], 'decoder_upsample_kernel_sizes': [16, 16, 4, 4], 'decoder_resblock_kernel_sizes': [3, 7, 11], 'decoder_resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'use_weight_norm_in_decoder': True, 'posterior_encoder_kernel_size': 5, 'posterior_encoder_layers': 16, 'posterior_encoder_stacks': 1, 'posterior_encoder_base_dilation': 1, 'posterior_encoder_dropout_rate': 0.0, 'use_weight_norm_in_posterior_encoder': True, 'flow_flows': 4, 'flow_kernel_size': 5, 'flow_base_dilation': 1, 'flow_layers': 4, 'flow_dropout_rate': 0.0, 'use_weight_norm_in_flow': True, 'use_only_mean_in_flow': True, 'stochastic_duration_predictor_kernel_size': 3, 'stochastic_duration_predictor_dropout_rate': 0.5, 'stochastic_duration_predictor_flows': 4, 'stochastic_duration_predictor_dds_conv_layers': 3, 'vocabs': 74, 'aux_channels': 513}, 'discriminator_type': 'hifigan_multi_scale_multi_period_discriminator', 'discriminator_params': {'scales': 1, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'stride': 2, 'padding': 2}, 'scale_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'channels': 128, 'max_downsample_channels': 1024, 'max_groups': 16, 'bias': True, 'downsample_scales': [2, 2, 4, 4, 1], 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}, 'follow_official_norm': False, 'periods': [2, 3, 5, 7, 11], 'period_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [5, 3], 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'max_downsample_channels': 1024, 'bias': True, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}}, 'generator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'discriminator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'feat_match_loss_params': {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, 'mel_loss_params': {'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None, 'window': 'hann', 'n_mels': 80, 'fmin': 0, 'fmax': None, 'log_base': None}, 'lambda_adv': 1.0, 'lambda_mel': 45.0, 'lambda_feat_match': 2.0, 'lambda_dur': 1.0, 'lambda_kl': 1.0, 'sampling_rate': 22050, 'cache_generator_outputs': True, 'plot_pred_mos': False, 'mos_pred_tool': 'utmos'}, pitch_extract=None, pitch_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'f0max': 400, 'f0min': 80}, pitch_normalize=None, pitch_normalize_conf={}, energy_extract=None, energy_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None}, energy_normalize=None, energy_normalize_conf={}, required=['output_dir', 'token_list'], version='202503', distributed=False)
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1284, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 67023) is killed by signal: Killed. 

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 22, in <module>
    main()
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 18, in main
    GANTTSTask.main(cmd=cmd)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1225, in main
    cls.main_worker(args)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1441, in main_worker
    collect_stats(
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/main_funcs/collect_stats.py", line 51, in collect_stats
    for iiter, (keys, batch) in enumerate(itr, 1):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 733, in __next__
    data = self._next_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1491, in _next_data
    idx, data = self._get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1453, in _get_data
    success, data = self._try_get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1297, in _try_get_data
    raise RuntimeError(
RuntimeError: DataLoader worker (pid(s) 67023) exited unexpectedly
# Accounting: begin_time=1750873480
# Accounting: end_time=1750873629
# Accounting: time=149 threads=1
# Finished at Wed Jun 25 13:47:09 EDT 2025 with status 1
# Running on r196.ib.bridges2.psc.edu
# Started at Wed Jun 25 13:44:40 EDT 2025
# SLURMD_NODENAME=r196
# SLURM_ARRAY_JOB_ID=32990217
# SLURM_ARRAY_TASK_COUNT=32
# SLURM_ARRAY_TASK_ID=26
# SLURM_ARRAY_TASK_MAX=32
# SLURM_ARRAY_TASK_MIN=1
# SLURM_ARRAY_TASK_STEP=1
# SLURM_CLUSTER_NAME=bridges2
# SLURM_CONF=/var/spool/slurm/d/conf-cache/slurm.conf
# SLURM_CPUS_ON_NODE=1
# SLURM_CPU_BIND=quiet,mask_cpu:0x07C0000000
# SLURM_CPU_BIND_LIST=0x07C0000000
# SLURM_CPU_BIND_TYPE=mask_cpu:
# SLURM_CPU_BIND_VERBOSE=quiet
# SLURM_EXPORT_ENV=ALL
# SLURM_GET_USER_ENV=1
# SLURM_GTIDS=0
# SLURM_JOBID=32990270
# SLURM_JOB_ACCOUNT=cis210027p
# SLURM_JOB_CPUS_PER_NODE=1
# SLURM_JOB_GID=24886
# SLURM_JOB_ID=32990270
# SLURM_JOB_NAME=stats.sh
# SLURM_JOB_NODELIST=r196
# SLURM_JOB_NUM_NODES=1
# SLURM_JOB_PARTITION=RM-shared
# SLURM_JOB_QOS=rm
# SLURM_JOB_UID=97947
# SLURM_JOB_USER=ttao3
# SLURM_LAUNCH_NODE_IPADDR=10.8.11.29
# SLURM_LOCALID=0
# SLURM_MEM_PER_CPU=1900
# SLURM_NNODES=1
# SLURM_NODEID=0
# SLURM_NODELIST=r196
# SLURM_NODE_ALIASES='(null)'
# SLURM_NPROCS=1
# SLURM_NTASKS=1
# SLURM_OPEN_MODE=a
# SLURM_PRIO_PROCESS=0
# SLURM_PROCID=0
# SLURM_PTY_PORT=33025
# SLURM_PTY_WIN_COL=126
# SLURM_PTY_WIN_ROW=21
# SLURM_SCRIPT_CONTEXT=prolog_task
# SLURM_SRUN_COMM_HOST=10.8.11.29
# SLURM_SRUN_COMM_PORT=35045
# SLURM_STEPID=0
# SLURM_STEP_GPUS=6
# SLURM_STEP_ID=0
# SLURM_STEP_LAUNCHER_PORT=35045
# SLURM_STEP_NODELIST=v029
# SLURM_STEP_NUM_NODES=1
# SLURM_STEP_NUM_TASKS=1
# SLURM_STEP_TASKS_PER_NODE=1
# SLURM_SUBMIT_DIR=/ocean/projects/cis210027p/ttao3/espnet/egs2/hifitts/tts1
# SLURM_SUBMIT_HOST=v029.ib.bridges2.psc.edu
# SLURM_TASKS_PER_NODE=1
# SLURM_TASK_PID=104098
# SLURM_TOPOLOGY_ADDR=r196
# SLURM_TOPOLOGY_ADDR_PATTERN=node
# SLURM_WORKING_CLUSTER=bridges2:br003:6810:9728:109
# python3 -m espnet2.bin.gan_tts_train --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.26.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.26.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.26 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int 
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/librosa/util/files.py:10: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_filename
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/bin/python3 /ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.26.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.26.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.26 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int
Failed to import Flash Attention, using ESPnet default: No module named 'flash_attn_2_cuda'
Vocabulary size: 74
encoder self-attention layer type = relative self-attention
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/ocean/projects/cis210027p/ttao3/espnet/espnet2/gan_tts/vits/monotonic_align/__init__.py:19: UserWarning: Cython version is not available. Fallback to 'EXPERIMETAL' numba version. If you want to use the cython version, please build it as follows: `cd espnet2/gan_tts/vits/monotonic_align; python setup.py build_ext --inplace`
  warnings.warn(
pytorch.version=2.7.1+cu126, cuda.available=False, cudnn.version=90501, cudnn.benchmark=False, cudnn.deterministic=False
Model structure:
ESPnetGANTTSModel(
  (feats_extract): LinearSpectrogram(
    (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
  )
  (tts): VITS(
    (generator): VITSGenerator(
      (text_encoder): TextEncoder(
        (emb): Embedding(74, 192)
        (encoder): Encoder(
          (embed): Sequential(
            (0): RelPositionalEncoding(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (encoders): MultiSequential(
            (0): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (2): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (3): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (4): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (5): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (after_norm): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (decoder): HiFiGANGenerator(
        (input_conv): Conv1d(192, 512, kernel_size=(7,), stride=(1,), padding=(3,))
        (upsamples): ModuleList(
          (0): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (1): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(256, 128, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (2): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,))
          )
          (3): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,))
          )
        )
        (blocks): ModuleList(
          (0): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (1): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (2): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (3): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (4): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (5): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (6): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (7): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (8): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (9): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (10): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (11): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
        )
        (output_conv): Sequential(
          (0): LeakyReLU(negative_slope=0.01)
          (1): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,))
          (2): Tanh()
        )
        (global_conv): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
      )
      (posterior_encoder): PosteriorEncoder(
        (input_conv): Conv1d(513, 192, kernel_size=(1,), stride=(1,))
        (encoder): WaveNet(
          (conv_layers): ModuleList(
            (0-15): 16 x ResidualBlock(
              (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
              (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
              (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
            )
          )
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (flow): ResidualAffineCouplingBlock(
        (flows): ModuleList(
          (0): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (1): FlipFlow()
          (2): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (3): FlipFlow()
          (4): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (5): FlipFlow()
          (6): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (7): FlipFlow()
        )
      )
      (duration_predictor): StochasticDurationPredictor(
        (pre): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (log_flow): LogFlow()
        (flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (post_pre): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
        (post_dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (post_proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (post_flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (global_conv): Conv1d(256, 192, kernel_size=(1,), stride=(1,))
      )
      (global_emb): Embedding(128, 256)
    )
    (discriminator): HiFiGANMultiScaleMultiPeriodDiscriminator(
      (msd): HiFiGANMultiScaleDiscriminator(
        (discriminators): ModuleList(
          (0): HiFiGANScaleDiscriminator(
            (layers): ModuleList(
              (0): Sequential(
                (0): Conv1d(1, 128, kernel_size=(15,), stride=(1,), padding=(7,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv1d(128, 128, kernel_size=(41,), stride=(2,), padding=(20,), groups=4)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv1d(128, 256, kernel_size=(41,), stride=(2,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv1d(256, 512, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv1d(512, 1024, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (5): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(41,), stride=(1,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (6): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (7): Conv1d(1024, 1, kernel_size=(3,), stride=(1,), padding=(1,))
            )
          )
        )
      )
      (mpd): HiFiGANMultiPeriodDiscriminator(
        (discriminators): ModuleList(
          (0-4): 5 x HiFiGANPeriodDiscriminator(
            (convs): ModuleList(
              (0): Sequential(
                (0): Conv2d(1, 32, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv2d(32, 128, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv2d(128, 512, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv2d(512, 1024, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv2d(1024, 1024, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
            )
            (output_conv): Conv2d(1024, 1, kernel_size=(2, 1), stride=(1, 1), padding=(1, 0))
          )
        )
      )
    )
    (generator_adv_loss): GeneratorAdversarialLoss()
    (discriminator_adv_loss): DiscriminatorAdversarialLoss()
    (feat_match_loss): FeatureMatchLoss()
    (mel_loss): MelSpectrogramLoss(
      (wav_to_mel): LogMelFbank(
        (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
        (logmel): LogMel(sr=22050, n_fft=1024, n_mels=80, fmin=0, fmax=11025.0, htk=False)
      )
    )
    (kl_loss): KLDivergenceLoss()
  )
)

Model summary:
    Class Name: ESPnetGANTTSModel
    Total Number of model parameters: 96.37 M
    Number of trainable parameters: 96.37 M (100.0%)
    Size: 385.46 MB
    Type: torch.float32
Optimizer:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler: <torch.optim.lr_scheduler.ExponentialLR object at 0x146529ede5b0>
Optimizer2:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler2: <torch.optim.lr_scheduler.ExponentialLR object at 0x146529ede970>
Saving the configuration in exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.26/config.yaml
Namespace(config='conf/tuning/train_multi_spk_vits.yaml', print_config=False, log_level='INFO', drop_last_iter=False, dry_run=False, iterator_type='sequence', valid_iterator_type=None, output_dir='exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.26', ngpu=0, seed=777, num_workers=4, num_att_plot=3, dist_backend='nccl', dist_init_method='env://', dist_world_size=None, dist_rank=None, local_rank=None, dist_master_addr=None, dist_master_port=None, dist_launcher=None, multiprocessing_distributed=False, unused_parameters=True, sharded_ddp=False, use_deepspeed=False, deepspeed_config=None, gradient_as_bucket_view=True, ddp_comm_hook=None, cudnn_enabled=True, cudnn_benchmark=False, cudnn_deterministic=False, use_tf32=False, collect_stats=True, write_collected_feats=False, max_epoch=1000, patience=None, val_scheduler_criterion=('valid', 'loss'), early_stopping_criterion=('valid', 'loss', 'min'), best_model_criterion=[['train', 'total_count', 'max']], keep_nbest_models=10, nbest_averaging_interval=0, grad_clip=-1, grad_clip_type=2.0, grad_noise=False, accum_grad=1, no_forward_run=False, resume=False, train_dtype='float32', use_amp=False, log_interval=50, use_matplotlib=True, use_tensorboard=True, create_graph_in_tensorboard=False, use_wandb=False, wandb_project=None, wandb_id=None, wandb_entity=None, wandb_name=None, wandb_model_log_interval=-1, detect_anomaly=False, use_adapter=False, adapter='lora', save_strategy='all', adapter_conf={}, pretrain_path=None, init_param=[], ignore_init_mismatch=False, freeze_param=[], num_iters_per_epoch=1000, batch_size=20, valid_batch_size=None, batch_bins=3000000, valid_batch_bins=None, category_sample_size=10, train_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.26.scp'], valid_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.26.scp'], batch_type='numel', valid_batch_type=None, fold_length=[], sort_in_batch='descending', shuffle_within_batch=False, sort_batch='descending', multiple_iterator=False, chunk_length=500, chunk_shift_ratio=0.5, num_cache_chunks=1024, chunk_excluded_key_prefixes=[], chunk_default_fs=None, chunk_max_abs_length=None, chunk_discard_short_samples=True, train_data_path_and_name_and_type=[('dump/22k/raw/tr_no_dev/text', 'text', 'text'), ('dump/22k/raw/tr_no_dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/tr_no_dev/utt2sid', 'sids', 'text_int')], valid_data_path_and_name_and_type=[('dump/22k/raw/dev/text', 'text', 'text'), ('dump/22k/raw/dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/dev/utt2sid', 'sids', 'text_int')], multi_task_dataset=False, allow_variable_data_keys=False, max_cache_size=0.0, max_cache_fd=32, allow_multi_rates=False, valid_max_cache_size=None, exclude_weight_decay=False, exclude_weight_decay_conf={}, optim='adamw', optim_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler='exponentiallr', scheduler_conf={'gamma': 0.999875}, optim2='adamw', optim2_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler2='exponentiallr', scheduler2_conf={'gamma': 0.999875}, generator_first=False, skip_discriminator_prob=0.0, token_list=['<blank>', '<unk>', ' ', 'AH0', 'N', 'T', 'D', 'S', 'R', 'L', 'IH1', 'DH', 'M', 'EH1', 'Z', 'AE1', 'K', 'IH0', 'AH1', 'HH', 'W', 'ER0', 'V', 'IY1', 'F', 'UW1', 'P', 'AY1', 'B', 'AA1', 'AO1', 'EY1', 'IY0', 'OW1', 'NG', 'SH', 'G', 'Y', 'AW1', 'CH', 'ER1', 'UH1', 'TH', 'JH', 'OW0', 'EH2', 'IH2', 'OY1', 'EY2', 'AY2', 'EH0', 'UW0', 'AA2', 'AE2', 'OW2', 'AH2', 'AA0', 'ZH', 'AE0', 'AO2', 'UW2', 'AO0', 'AY0', 'IY2', 'AW2', 'UH2', 'EY0', 'ER2', 'AW0', 'UH0', 'OY2', 'OY0', "'", '<sos/eos>'], odim=None, model_conf={}, use_preprocessor=True, token_type='phn', bpemodel=None, non_linguistic_symbols=None, cleaner='tacotron', g2p='g2p_en', feats_extract='linear_spectrogram', feats_extract_conf={'n_fft': 1024, 'hop_length': 256, 'win_length': None}, normalize=None, normalize_conf={}, tts='vits', tts_conf={'generator_type': 'vits_generator', 'generator_params': {'hidden_channels': 192, 'spks': 128, 'global_channels': 256, 'segment_size': 32, 'text_encoder_attention_heads': 2, 'text_encoder_ffn_expand': 4, 'text_encoder_blocks': 6, 'text_encoder_positionwise_layer_type': 'conv1d', 'text_encoder_positionwise_conv_kernel_size': 3, 'text_encoder_positional_encoding_layer_type': 'rel_pos', 'text_encoder_self_attention_layer_type': 'rel_selfattn', 'text_encoder_activation_type': 'swish', 'text_encoder_normalize_before': True, 'text_encoder_dropout_rate': 0.1, 'text_encoder_positional_dropout_rate': 0.0, 'text_encoder_attention_dropout_rate': 0.1, 'use_macaron_style_in_text_encoder': True, 'use_conformer_conv_in_text_encoder': False, 'text_encoder_conformer_kernel_size': -1, 'decoder_kernel_size': 7, 'decoder_channels': 512, 'decoder_upsample_scales': [8, 8, 2, 2], 'decoder_upsample_kernel_sizes': [16, 16, 4, 4], 'decoder_resblock_kernel_sizes': [3, 7, 11], 'decoder_resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'use_weight_norm_in_decoder': True, 'posterior_encoder_kernel_size': 5, 'posterior_encoder_layers': 16, 'posterior_encoder_stacks': 1, 'posterior_encoder_base_dilation': 1, 'posterior_encoder_dropout_rate': 0.0, 'use_weight_norm_in_posterior_encoder': True, 'flow_flows': 4, 'flow_kernel_size': 5, 'flow_base_dilation': 1, 'flow_layers': 4, 'flow_dropout_rate': 0.0, 'use_weight_norm_in_flow': True, 'use_only_mean_in_flow': True, 'stochastic_duration_predictor_kernel_size': 3, 'stochastic_duration_predictor_dropout_rate': 0.5, 'stochastic_duration_predictor_flows': 4, 'stochastic_duration_predictor_dds_conv_layers': 3, 'vocabs': 74, 'aux_channels': 513}, 'discriminator_type': 'hifigan_multi_scale_multi_period_discriminator', 'discriminator_params': {'scales': 1, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'stride': 2, 'padding': 2}, 'scale_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'channels': 128, 'max_downsample_channels': 1024, 'max_groups': 16, 'bias': True, 'downsample_scales': [2, 2, 4, 4, 1], 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}, 'follow_official_norm': False, 'periods': [2, 3, 5, 7, 11], 'period_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [5, 3], 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'max_downsample_channels': 1024, 'bias': True, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}}, 'generator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'discriminator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'feat_match_loss_params': {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, 'mel_loss_params': {'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None, 'window': 'hann', 'n_mels': 80, 'fmin': 0, 'fmax': None, 'log_base': None}, 'lambda_adv': 1.0, 'lambda_mel': 45.0, 'lambda_feat_match': 2.0, 'lambda_dur': 1.0, 'lambda_kl': 1.0, 'sampling_rate': 22050, 'cache_generator_outputs': True, 'plot_pred_mos': False, 'mos_pred_tool': 'utmos'}, pitch_extract=None, pitch_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'f0max': 400, 'f0min': 80}, pitch_normalize=None, pitch_normalize_conf={}, energy_extract=None, energy_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None}, energy_normalize=None, energy_normalize_conf={}, required=['output_dir', 'token_list'], version='202503', distributed=False)
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1284, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 104244) is killed by signal: Killed. 

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 22, in <module>
    main()
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 18, in main
    GANTTSTask.main(cmd=cmd)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1225, in main
    cls.main_worker(args)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1441, in main_worker
    collect_stats(
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/main_funcs/collect_stats.py", line 51, in collect_stats
    for iiter, (keys, batch) in enumerate(itr, 1):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 733, in __next__
    data = self._next_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1491, in _next_data
    idx, data = self._get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1453, in _get_data
    success, data = self._try_get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1297, in _try_get_data
    raise RuntimeError(
RuntimeError: DataLoader worker (pid(s) 104244) exited unexpectedly
# Accounting: begin_time=1750873480
# Accounting: end_time=1750873628
# Accounting: time=148 threads=1
# Finished at Wed Jun 25 13:47:08 EDT 2025 with status 1
# Running on r196.ib.bridges2.psc.edu
# Started at Wed Jun 25 13:44:42 EDT 2025
# SLURMD_NODENAME=r196
# SLURM_ARRAY_JOB_ID=32990217
# SLURM_ARRAY_TASK_COUNT=32
# SLURM_ARRAY_TASK_ID=27
# SLURM_ARRAY_TASK_MAX=32
# SLURM_ARRAY_TASK_MIN=1
# SLURM_ARRAY_TASK_STEP=1
# SLURM_CLUSTER_NAME=bridges2
# SLURM_CONF=/var/spool/slurm/d/conf-cache/slurm.conf
# SLURM_CPUS_ON_NODE=1
# SLURM_CPU_BIND=quiet,mask_cpu:0x07C0000000
# SLURM_CPU_BIND_LIST=0x07C0000000
# SLURM_CPU_BIND_TYPE=mask_cpu:
# SLURM_CPU_BIND_VERBOSE=quiet
# SLURM_EXPORT_ENV=ALL
# SLURM_GET_USER_ENV=1
# SLURM_GTIDS=0
# SLURM_JOBID=32990271
# SLURM_JOB_ACCOUNT=cis210027p
# SLURM_JOB_CPUS_PER_NODE=1
# SLURM_JOB_GID=24886
# SLURM_JOB_ID=32990271
# SLURM_JOB_NAME=stats.sh
# SLURM_JOB_NODELIST=r196
# SLURM_JOB_NUM_NODES=1
# SLURM_JOB_PARTITION=RM-shared
# SLURM_JOB_QOS=rm
# SLURM_JOB_UID=97947
# SLURM_JOB_USER=ttao3
# SLURM_LAUNCH_NODE_IPADDR=10.8.11.29
# SLURM_LOCALID=0
# SLURM_MEM_PER_CPU=1900
# SLURM_NNODES=1
# SLURM_NODEID=0
# SLURM_NODELIST=r196
# SLURM_NODE_ALIASES='(null)'
# SLURM_NPROCS=1
# SLURM_NTASKS=1
# SLURM_OPEN_MODE=a
# SLURM_PRIO_PROCESS=0
# SLURM_PROCID=0
# SLURM_PTY_PORT=33025
# SLURM_PTY_WIN_COL=126
# SLURM_PTY_WIN_ROW=21
# SLURM_SCRIPT_CONTEXT=prolog_task
# SLURM_SRUN_COMM_HOST=10.8.11.29
# SLURM_SRUN_COMM_PORT=35045
# SLURM_STEPID=0
# SLURM_STEP_GPUS=6
# SLURM_STEP_ID=0
# SLURM_STEP_LAUNCHER_PORT=35045
# SLURM_STEP_NODELIST=v029
# SLURM_STEP_NUM_NODES=1
# SLURM_STEP_NUM_TASKS=1
# SLURM_STEP_TASKS_PER_NODE=1
# SLURM_SUBMIT_DIR=/ocean/projects/cis210027p/ttao3/espnet/egs2/hifitts/tts1
# SLURM_SUBMIT_HOST=v029.ib.bridges2.psc.edu
# SLURM_TASKS_PER_NODE=1
# SLURM_TASK_PID=104109
# SLURM_TOPOLOGY_ADDR=r196
# SLURM_TOPOLOGY_ADDR_PATTERN=node
# SLURM_WORKING_CLUSTER=bridges2:br003:6810:9728:109
# python3 -m espnet2.bin.gan_tts_train --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.27.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.27.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.27 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int 
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/librosa/util/files.py:10: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_filename
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/bin/python3 /ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.27.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.27.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.27 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int
Failed to import Flash Attention, using ESPnet default: No module named 'flash_attn_2_cuda'
Vocabulary size: 74
encoder self-attention layer type = relative self-attention
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/ocean/projects/cis210027p/ttao3/espnet/espnet2/gan_tts/vits/monotonic_align/__init__.py:19: UserWarning: Cython version is not available. Fallback to 'EXPERIMETAL' numba version. If you want to use the cython version, please build it as follows: `cd espnet2/gan_tts/vits/monotonic_align; python setup.py build_ext --inplace`
  warnings.warn(
pytorch.version=2.7.1+cu126, cuda.available=False, cudnn.version=90501, cudnn.benchmark=False, cudnn.deterministic=False
Model structure:
ESPnetGANTTSModel(
  (feats_extract): LinearSpectrogram(
    (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
  )
  (tts): VITS(
    (generator): VITSGenerator(
      (text_encoder): TextEncoder(
        (emb): Embedding(74, 192)
        (encoder): Encoder(
          (embed): Sequential(
            (0): RelPositionalEncoding(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (encoders): MultiSequential(
            (0): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (2): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (3): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (4): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (5): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (after_norm): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (decoder): HiFiGANGenerator(
        (input_conv): Conv1d(192, 512, kernel_size=(7,), stride=(1,), padding=(3,))
        (upsamples): ModuleList(
          (0): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (1): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(256, 128, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (2): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,))
          )
          (3): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,))
          )
        )
        (blocks): ModuleList(
          (0): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (1): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (2): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (3): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (4): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (5): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (6): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (7): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (8): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (9): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (10): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (11): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
        )
        (output_conv): Sequential(
          (0): LeakyReLU(negative_slope=0.01)
          (1): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,))
          (2): Tanh()
        )
        (global_conv): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
      )
      (posterior_encoder): PosteriorEncoder(
        (input_conv): Conv1d(513, 192, kernel_size=(1,), stride=(1,))
        (encoder): WaveNet(
          (conv_layers): ModuleList(
            (0-15): 16 x ResidualBlock(
              (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
              (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
              (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
            )
          )
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (flow): ResidualAffineCouplingBlock(
        (flows): ModuleList(
          (0): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (1): FlipFlow()
          (2): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (3): FlipFlow()
          (4): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (5): FlipFlow()
          (6): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (7): FlipFlow()
        )
      )
      (duration_predictor): StochasticDurationPredictor(
        (pre): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (log_flow): LogFlow()
        (flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (post_pre): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
        (post_dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (post_proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (post_flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (global_conv): Conv1d(256, 192, kernel_size=(1,), stride=(1,))
      )
      (global_emb): Embedding(128, 256)
    )
    (discriminator): HiFiGANMultiScaleMultiPeriodDiscriminator(
      (msd): HiFiGANMultiScaleDiscriminator(
        (discriminators): ModuleList(
          (0): HiFiGANScaleDiscriminator(
            (layers): ModuleList(
              (0): Sequential(
                (0): Conv1d(1, 128, kernel_size=(15,), stride=(1,), padding=(7,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv1d(128, 128, kernel_size=(41,), stride=(2,), padding=(20,), groups=4)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv1d(128, 256, kernel_size=(41,), stride=(2,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv1d(256, 512, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv1d(512, 1024, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (5): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(41,), stride=(1,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (6): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (7): Conv1d(1024, 1, kernel_size=(3,), stride=(1,), padding=(1,))
            )
          )
        )
      )
      (mpd): HiFiGANMultiPeriodDiscriminator(
        (discriminators): ModuleList(
          (0-4): 5 x HiFiGANPeriodDiscriminator(
            (convs): ModuleList(
              (0): Sequential(
                (0): Conv2d(1, 32, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv2d(32, 128, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv2d(128, 512, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv2d(512, 1024, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv2d(1024, 1024, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
            )
            (output_conv): Conv2d(1024, 1, kernel_size=(2, 1), stride=(1, 1), padding=(1, 0))
          )
        )
      )
    )
    (generator_adv_loss): GeneratorAdversarialLoss()
    (discriminator_adv_loss): DiscriminatorAdversarialLoss()
    (feat_match_loss): FeatureMatchLoss()
    (mel_loss): MelSpectrogramLoss(
      (wav_to_mel): LogMelFbank(
        (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
        (logmel): LogMel(sr=22050, n_fft=1024, n_mels=80, fmin=0, fmax=11025.0, htk=False)
      )
    )
    (kl_loss): KLDivergenceLoss()
  )
)

Model summary:
    Class Name: ESPnetGANTTSModel
    Total Number of model parameters: 96.37 M
    Number of trainable parameters: 96.37 M (100.0%)
    Size: 385.46 MB
    Type: torch.float32
Optimizer:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler: <torch.optim.lr_scheduler.ExponentialLR object at 0x14bb7f3855e0>
Optimizer2:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler2: <torch.optim.lr_scheduler.ExponentialLR object at 0x14bb7f3859d0>
Saving the configuration in exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.27/config.yaml
Namespace(config='conf/tuning/train_multi_spk_vits.yaml', print_config=False, log_level='INFO', drop_last_iter=False, dry_run=False, iterator_type='sequence', valid_iterator_type=None, output_dir='exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.27', ngpu=0, seed=777, num_workers=4, num_att_plot=3, dist_backend='nccl', dist_init_method='env://', dist_world_size=None, dist_rank=None, local_rank=None, dist_master_addr=None, dist_master_port=None, dist_launcher=None, multiprocessing_distributed=False, unused_parameters=True, sharded_ddp=False, use_deepspeed=False, deepspeed_config=None, gradient_as_bucket_view=True, ddp_comm_hook=None, cudnn_enabled=True, cudnn_benchmark=False, cudnn_deterministic=False, use_tf32=False, collect_stats=True, write_collected_feats=False, max_epoch=1000, patience=None, val_scheduler_criterion=('valid', 'loss'), early_stopping_criterion=('valid', 'loss', 'min'), best_model_criterion=[['train', 'total_count', 'max']], keep_nbest_models=10, nbest_averaging_interval=0, grad_clip=-1, grad_clip_type=2.0, grad_noise=False, accum_grad=1, no_forward_run=False, resume=False, train_dtype='float32', use_amp=False, log_interval=50, use_matplotlib=True, use_tensorboard=True, create_graph_in_tensorboard=False, use_wandb=False, wandb_project=None, wandb_id=None, wandb_entity=None, wandb_name=None, wandb_model_log_interval=-1, detect_anomaly=False, use_adapter=False, adapter='lora', save_strategy='all', adapter_conf={}, pretrain_path=None, init_param=[], ignore_init_mismatch=False, freeze_param=[], num_iters_per_epoch=1000, batch_size=20, valid_batch_size=None, batch_bins=3000000, valid_batch_bins=None, category_sample_size=10, train_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.27.scp'], valid_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.27.scp'], batch_type='numel', valid_batch_type=None, fold_length=[], sort_in_batch='descending', shuffle_within_batch=False, sort_batch='descending', multiple_iterator=False, chunk_length=500, chunk_shift_ratio=0.5, num_cache_chunks=1024, chunk_excluded_key_prefixes=[], chunk_default_fs=None, chunk_max_abs_length=None, chunk_discard_short_samples=True, train_data_path_and_name_and_type=[('dump/22k/raw/tr_no_dev/text', 'text', 'text'), ('dump/22k/raw/tr_no_dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/tr_no_dev/utt2sid', 'sids', 'text_int')], valid_data_path_and_name_and_type=[('dump/22k/raw/dev/text', 'text', 'text'), ('dump/22k/raw/dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/dev/utt2sid', 'sids', 'text_int')], multi_task_dataset=False, allow_variable_data_keys=False, max_cache_size=0.0, max_cache_fd=32, allow_multi_rates=False, valid_max_cache_size=None, exclude_weight_decay=False, exclude_weight_decay_conf={}, optim='adamw', optim_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler='exponentiallr', scheduler_conf={'gamma': 0.999875}, optim2='adamw', optim2_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler2='exponentiallr', scheduler2_conf={'gamma': 0.999875}, generator_first=False, skip_discriminator_prob=0.0, token_list=['<blank>', '<unk>', ' ', 'AH0', 'N', 'T', 'D', 'S', 'R', 'L', 'IH1', 'DH', 'M', 'EH1', 'Z', 'AE1', 'K', 'IH0', 'AH1', 'HH', 'W', 'ER0', 'V', 'IY1', 'F', 'UW1', 'P', 'AY1', 'B', 'AA1', 'AO1', 'EY1', 'IY0', 'OW1', 'NG', 'SH', 'G', 'Y', 'AW1', 'CH', 'ER1', 'UH1', 'TH', 'JH', 'OW0', 'EH2', 'IH2', 'OY1', 'EY2', 'AY2', 'EH0', 'UW0', 'AA2', 'AE2', 'OW2', 'AH2', 'AA0', 'ZH', 'AE0', 'AO2', 'UW2', 'AO0', 'AY0', 'IY2', 'AW2', 'UH2', 'EY0', 'ER2', 'AW0', 'UH0', 'OY2', 'OY0', "'", '<sos/eos>'], odim=None, model_conf={}, use_preprocessor=True, token_type='phn', bpemodel=None, non_linguistic_symbols=None, cleaner='tacotron', g2p='g2p_en', feats_extract='linear_spectrogram', feats_extract_conf={'n_fft': 1024, 'hop_length': 256, 'win_length': None}, normalize=None, normalize_conf={}, tts='vits', tts_conf={'generator_type': 'vits_generator', 'generator_params': {'hidden_channels': 192, 'spks': 128, 'global_channels': 256, 'segment_size': 32, 'text_encoder_attention_heads': 2, 'text_encoder_ffn_expand': 4, 'text_encoder_blocks': 6, 'text_encoder_positionwise_layer_type': 'conv1d', 'text_encoder_positionwise_conv_kernel_size': 3, 'text_encoder_positional_encoding_layer_type': 'rel_pos', 'text_encoder_self_attention_layer_type': 'rel_selfattn', 'text_encoder_activation_type': 'swish', 'text_encoder_normalize_before': True, 'text_encoder_dropout_rate': 0.1, 'text_encoder_positional_dropout_rate': 0.0, 'text_encoder_attention_dropout_rate': 0.1, 'use_macaron_style_in_text_encoder': True, 'use_conformer_conv_in_text_encoder': False, 'text_encoder_conformer_kernel_size': -1, 'decoder_kernel_size': 7, 'decoder_channels': 512, 'decoder_upsample_scales': [8, 8, 2, 2], 'decoder_upsample_kernel_sizes': [16, 16, 4, 4], 'decoder_resblock_kernel_sizes': [3, 7, 11], 'decoder_resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'use_weight_norm_in_decoder': True, 'posterior_encoder_kernel_size': 5, 'posterior_encoder_layers': 16, 'posterior_encoder_stacks': 1, 'posterior_encoder_base_dilation': 1, 'posterior_encoder_dropout_rate': 0.0, 'use_weight_norm_in_posterior_encoder': True, 'flow_flows': 4, 'flow_kernel_size': 5, 'flow_base_dilation': 1, 'flow_layers': 4, 'flow_dropout_rate': 0.0, 'use_weight_norm_in_flow': True, 'use_only_mean_in_flow': True, 'stochastic_duration_predictor_kernel_size': 3, 'stochastic_duration_predictor_dropout_rate': 0.5, 'stochastic_duration_predictor_flows': 4, 'stochastic_duration_predictor_dds_conv_layers': 3, 'vocabs': 74, 'aux_channels': 513}, 'discriminator_type': 'hifigan_multi_scale_multi_period_discriminator', 'discriminator_params': {'scales': 1, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'stride': 2, 'padding': 2}, 'scale_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'channels': 128, 'max_downsample_channels': 1024, 'max_groups': 16, 'bias': True, 'downsample_scales': [2, 2, 4, 4, 1], 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}, 'follow_official_norm': False, 'periods': [2, 3, 5, 7, 11], 'period_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [5, 3], 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'max_downsample_channels': 1024, 'bias': True, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}}, 'generator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'discriminator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'feat_match_loss_params': {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, 'mel_loss_params': {'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None, 'window': 'hann', 'n_mels': 80, 'fmin': 0, 'fmax': None, 'log_base': None}, 'lambda_adv': 1.0, 'lambda_mel': 45.0, 'lambda_feat_match': 2.0, 'lambda_dur': 1.0, 'lambda_kl': 1.0, 'sampling_rate': 22050, 'cache_generator_outputs': True, 'plot_pred_mos': False, 'mos_pred_tool': 'utmos'}, pitch_extract=None, pitch_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'f0max': 400, 'f0min': 80}, pitch_normalize=None, pitch_normalize_conf={}, energy_extract=None, energy_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None}, energy_normalize=None, energy_normalize_conf={}, required=['output_dir', 'token_list'], version='202503', distributed=False)
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1284, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 104241) is killed by signal: Killed. 

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 22, in <module>
    main()
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 18, in main
    GANTTSTask.main(cmd=cmd)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1225, in main
    cls.main_worker(args)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1441, in main_worker
    collect_stats(
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/main_funcs/collect_stats.py", line 51, in collect_stats
    for iiter, (keys, batch) in enumerate(itr, 1):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 733, in __next__
    data = self._next_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1491, in _next_data
    idx, data = self._get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1453, in _get_data
    success, data = self._try_get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1297, in _try_get_data
    raise RuntimeError(
RuntimeError: DataLoader worker (pid(s) 104241) exited unexpectedly
# Accounting: begin_time=1750873482
# Accounting: end_time=1750873628
# Accounting: time=146 threads=1
# Finished at Wed Jun 25 13:47:08 EDT 2025 with status 1
# Running on r214.ib.bridges2.psc.edu
# Started at Wed Jun 25 13:44:42 EDT 2025
# SLURMD_NODENAME=r214
# SLURM_ARRAY_JOB_ID=32990217
# SLURM_ARRAY_TASK_COUNT=32
# SLURM_ARRAY_TASK_ID=28
# SLURM_ARRAY_TASK_MAX=32
# SLURM_ARRAY_TASK_MIN=1
# SLURM_ARRAY_TASK_STEP=1
# SLURM_CLUSTER_NAME=bridges2
# SLURM_CONF=/var/spool/slurm/d/conf-cache/slurm.conf
# SLURM_CPUS_ON_NODE=1
# SLURM_CPU_BIND=quiet,mask_cpu:0x07C0000000
# SLURM_CPU_BIND_LIST=0x07C0000000
# SLURM_CPU_BIND_TYPE=mask_cpu:
# SLURM_CPU_BIND_VERBOSE=quiet
# SLURM_EXPORT_ENV=ALL
# SLURM_GET_USER_ENV=1
# SLURM_GTIDS=0
# SLURM_JOBID=32990272
# SLURM_JOB_ACCOUNT=cis210027p
# SLURM_JOB_CPUS_PER_NODE=1
# SLURM_JOB_GID=24886
# SLURM_JOB_ID=32990272
# SLURM_JOB_NAME=stats.sh
# SLURM_JOB_NODELIST=r214
# SLURM_JOB_NUM_NODES=1
# SLURM_JOB_PARTITION=RM-shared
# SLURM_JOB_QOS=rm
# SLURM_JOB_UID=97947
# SLURM_JOB_USER=ttao3
# SLURM_LAUNCH_NODE_IPADDR=10.8.11.29
# SLURM_LOCALID=0
# SLURM_MEM_PER_CPU=1900
# SLURM_NNODES=1
# SLURM_NODEID=0
# SLURM_NODELIST=r214
# SLURM_NODE_ALIASES='(null)'
# SLURM_NPROCS=1
# SLURM_NTASKS=1
# SLURM_OPEN_MODE=a
# SLURM_PRIO_PROCESS=0
# SLURM_PROCID=0
# SLURM_PTY_PORT=33025
# SLURM_PTY_WIN_COL=126
# SLURM_PTY_WIN_ROW=21
# SLURM_SCRIPT_CONTEXT=prolog_task
# SLURM_SRUN_COMM_HOST=10.8.11.29
# SLURM_SRUN_COMM_PORT=35045
# SLURM_STEPID=0
# SLURM_STEP_GPUS=6
# SLURM_STEP_ID=0
# SLURM_STEP_LAUNCHER_PORT=35045
# SLURM_STEP_NODELIST=v029
# SLURM_STEP_NUM_NODES=1
# SLURM_STEP_NUM_TASKS=1
# SLURM_STEP_TASKS_PER_NODE=1
# SLURM_SUBMIT_DIR=/ocean/projects/cis210027p/ttao3/espnet/egs2/hifitts/tts1
# SLURM_SUBMIT_HOST=v029.ib.bridges2.psc.edu
# SLURM_TASKS_PER_NODE=1
# SLURM_TASK_PID=54945
# SLURM_TOPOLOGY_ADDR=r214
# SLURM_TOPOLOGY_ADDR_PATTERN=node
# SLURM_WORKING_CLUSTER=bridges2:br003:6810:9728:109
# python3 -m espnet2.bin.gan_tts_train --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.28.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.28.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.28 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int 
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/librosa/util/files.py:10: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_filename
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/bin/python3 /ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.28.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.28.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.28 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int
Failed to import Flash Attention, using ESPnet default: No module named 'flash_attn_2_cuda'
Vocabulary size: 74
encoder self-attention layer type = relative self-attention
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/ocean/projects/cis210027p/ttao3/espnet/espnet2/gan_tts/vits/monotonic_align/__init__.py:19: UserWarning: Cython version is not available. Fallback to 'EXPERIMETAL' numba version. If you want to use the cython version, please build it as follows: `cd espnet2/gan_tts/vits/monotonic_align; python setup.py build_ext --inplace`
  warnings.warn(
pytorch.version=2.7.1+cu126, cuda.available=False, cudnn.version=90501, cudnn.benchmark=False, cudnn.deterministic=False
Model structure:
ESPnetGANTTSModel(
  (feats_extract): LinearSpectrogram(
    (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
  )
  (tts): VITS(
    (generator): VITSGenerator(
      (text_encoder): TextEncoder(
        (emb): Embedding(74, 192)
        (encoder): Encoder(
          (embed): Sequential(
            (0): RelPositionalEncoding(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (encoders): MultiSequential(
            (0): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (2): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (3): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (4): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (5): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (after_norm): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (decoder): HiFiGANGenerator(
        (input_conv): Conv1d(192, 512, kernel_size=(7,), stride=(1,), padding=(3,))
        (upsamples): ModuleList(
          (0): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (1): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(256, 128, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (2): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,))
          )
          (3): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,))
          )
        )
        (blocks): ModuleList(
          (0): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (1): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (2): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (3): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (4): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (5): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (6): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (7): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (8): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (9): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (10): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (11): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
        )
        (output_conv): Sequential(
          (0): LeakyReLU(negative_slope=0.01)
          (1): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,))
          (2): Tanh()
        )
        (global_conv): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
      )
      (posterior_encoder): PosteriorEncoder(
        (input_conv): Conv1d(513, 192, kernel_size=(1,), stride=(1,))
        (encoder): WaveNet(
          (conv_layers): ModuleList(
            (0-15): 16 x ResidualBlock(
              (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
              (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
              (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
            )
          )
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (flow): ResidualAffineCouplingBlock(
        (flows): ModuleList(
          (0): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (1): FlipFlow()
          (2): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (3): FlipFlow()
          (4): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (5): FlipFlow()
          (6): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (7): FlipFlow()
        )
      )
      (duration_predictor): StochasticDurationPredictor(
        (pre): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (log_flow): LogFlow()
        (flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (post_pre): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
        (post_dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (post_proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (post_flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (global_conv): Conv1d(256, 192, kernel_size=(1,), stride=(1,))
      )
      (global_emb): Embedding(128, 256)
    )
    (discriminator): HiFiGANMultiScaleMultiPeriodDiscriminator(
      (msd): HiFiGANMultiScaleDiscriminator(
        (discriminators): ModuleList(
          (0): HiFiGANScaleDiscriminator(
            (layers): ModuleList(
              (0): Sequential(
                (0): Conv1d(1, 128, kernel_size=(15,), stride=(1,), padding=(7,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv1d(128, 128, kernel_size=(41,), stride=(2,), padding=(20,), groups=4)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv1d(128, 256, kernel_size=(41,), stride=(2,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv1d(256, 512, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv1d(512, 1024, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (5): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(41,), stride=(1,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (6): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (7): Conv1d(1024, 1, kernel_size=(3,), stride=(1,), padding=(1,))
            )
          )
        )
      )
      (mpd): HiFiGANMultiPeriodDiscriminator(
        (discriminators): ModuleList(
          (0-4): 5 x HiFiGANPeriodDiscriminator(
            (convs): ModuleList(
              (0): Sequential(
                (0): Conv2d(1, 32, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv2d(32, 128, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv2d(128, 512, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv2d(512, 1024, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv2d(1024, 1024, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
            )
            (output_conv): Conv2d(1024, 1, kernel_size=(2, 1), stride=(1, 1), padding=(1, 0))
          )
        )
      )
    )
    (generator_adv_loss): GeneratorAdversarialLoss()
    (discriminator_adv_loss): DiscriminatorAdversarialLoss()
    (feat_match_loss): FeatureMatchLoss()
    (mel_loss): MelSpectrogramLoss(
      (wav_to_mel): LogMelFbank(
        (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
        (logmel): LogMel(sr=22050, n_fft=1024, n_mels=80, fmin=0, fmax=11025.0, htk=False)
      )
    )
    (kl_loss): KLDivergenceLoss()
  )
)

Model summary:
    Class Name: ESPnetGANTTSModel
    Total Number of model parameters: 96.37 M
    Number of trainable parameters: 96.37 M (100.0%)
    Size: 385.46 MB
    Type: torch.float32
Optimizer:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler: <torch.optim.lr_scheduler.ExponentialLR object at 0x150f6e88c640>
Optimizer2:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler2: <torch.optim.lr_scheduler.ExponentialLR object at 0x150f6e88ca30>
Saving the configuration in exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.28/config.yaml
Namespace(config='conf/tuning/train_multi_spk_vits.yaml', print_config=False, log_level='INFO', drop_last_iter=False, dry_run=False, iterator_type='sequence', valid_iterator_type=None, output_dir='exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.28', ngpu=0, seed=777, num_workers=4, num_att_plot=3, dist_backend='nccl', dist_init_method='env://', dist_world_size=None, dist_rank=None, local_rank=None, dist_master_addr=None, dist_master_port=None, dist_launcher=None, multiprocessing_distributed=False, unused_parameters=True, sharded_ddp=False, use_deepspeed=False, deepspeed_config=None, gradient_as_bucket_view=True, ddp_comm_hook=None, cudnn_enabled=True, cudnn_benchmark=False, cudnn_deterministic=False, use_tf32=False, collect_stats=True, write_collected_feats=False, max_epoch=1000, patience=None, val_scheduler_criterion=('valid', 'loss'), early_stopping_criterion=('valid', 'loss', 'min'), best_model_criterion=[['train', 'total_count', 'max']], keep_nbest_models=10, nbest_averaging_interval=0, grad_clip=-1, grad_clip_type=2.0, grad_noise=False, accum_grad=1, no_forward_run=False, resume=False, train_dtype='float32', use_amp=False, log_interval=50, use_matplotlib=True, use_tensorboard=True, create_graph_in_tensorboard=False, use_wandb=False, wandb_project=None, wandb_id=None, wandb_entity=None, wandb_name=None, wandb_model_log_interval=-1, detect_anomaly=False, use_adapter=False, adapter='lora', save_strategy='all', adapter_conf={}, pretrain_path=None, init_param=[], ignore_init_mismatch=False, freeze_param=[], num_iters_per_epoch=1000, batch_size=20, valid_batch_size=None, batch_bins=3000000, valid_batch_bins=None, category_sample_size=10, train_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.28.scp'], valid_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.28.scp'], batch_type='numel', valid_batch_type=None, fold_length=[], sort_in_batch='descending', shuffle_within_batch=False, sort_batch='descending', multiple_iterator=False, chunk_length=500, chunk_shift_ratio=0.5, num_cache_chunks=1024, chunk_excluded_key_prefixes=[], chunk_default_fs=None, chunk_max_abs_length=None, chunk_discard_short_samples=True, train_data_path_and_name_and_type=[('dump/22k/raw/tr_no_dev/text', 'text', 'text'), ('dump/22k/raw/tr_no_dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/tr_no_dev/utt2sid', 'sids', 'text_int')], valid_data_path_and_name_and_type=[('dump/22k/raw/dev/text', 'text', 'text'), ('dump/22k/raw/dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/dev/utt2sid', 'sids', 'text_int')], multi_task_dataset=False, allow_variable_data_keys=False, max_cache_size=0.0, max_cache_fd=32, allow_multi_rates=False, valid_max_cache_size=None, exclude_weight_decay=False, exclude_weight_decay_conf={}, optim='adamw', optim_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler='exponentiallr', scheduler_conf={'gamma': 0.999875}, optim2='adamw', optim2_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler2='exponentiallr', scheduler2_conf={'gamma': 0.999875}, generator_first=False, skip_discriminator_prob=0.0, token_list=['<blank>', '<unk>', ' ', 'AH0', 'N', 'T', 'D', 'S', 'R', 'L', 'IH1', 'DH', 'M', 'EH1', 'Z', 'AE1', 'K', 'IH0', 'AH1', 'HH', 'W', 'ER0', 'V', 'IY1', 'F', 'UW1', 'P', 'AY1', 'B', 'AA1', 'AO1', 'EY1', 'IY0', 'OW1', 'NG', 'SH', 'G', 'Y', 'AW1', 'CH', 'ER1', 'UH1', 'TH', 'JH', 'OW0', 'EH2', 'IH2', 'OY1', 'EY2', 'AY2', 'EH0', 'UW0', 'AA2', 'AE2', 'OW2', 'AH2', 'AA0', 'ZH', 'AE0', 'AO2', 'UW2', 'AO0', 'AY0', 'IY2', 'AW2', 'UH2', 'EY0', 'ER2', 'AW0', 'UH0', 'OY2', 'OY0', "'", '<sos/eos>'], odim=None, model_conf={}, use_preprocessor=True, token_type='phn', bpemodel=None, non_linguistic_symbols=None, cleaner='tacotron', g2p='g2p_en', feats_extract='linear_spectrogram', feats_extract_conf={'n_fft': 1024, 'hop_length': 256, 'win_length': None}, normalize=None, normalize_conf={}, tts='vits', tts_conf={'generator_type': 'vits_generator', 'generator_params': {'hidden_channels': 192, 'spks': 128, 'global_channels': 256, 'segment_size': 32, 'text_encoder_attention_heads': 2, 'text_encoder_ffn_expand': 4, 'text_encoder_blocks': 6, 'text_encoder_positionwise_layer_type': 'conv1d', 'text_encoder_positionwise_conv_kernel_size': 3, 'text_encoder_positional_encoding_layer_type': 'rel_pos', 'text_encoder_self_attention_layer_type': 'rel_selfattn', 'text_encoder_activation_type': 'swish', 'text_encoder_normalize_before': True, 'text_encoder_dropout_rate': 0.1, 'text_encoder_positional_dropout_rate': 0.0, 'text_encoder_attention_dropout_rate': 0.1, 'use_macaron_style_in_text_encoder': True, 'use_conformer_conv_in_text_encoder': False, 'text_encoder_conformer_kernel_size': -1, 'decoder_kernel_size': 7, 'decoder_channels': 512, 'decoder_upsample_scales': [8, 8, 2, 2], 'decoder_upsample_kernel_sizes': [16, 16, 4, 4], 'decoder_resblock_kernel_sizes': [3, 7, 11], 'decoder_resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'use_weight_norm_in_decoder': True, 'posterior_encoder_kernel_size': 5, 'posterior_encoder_layers': 16, 'posterior_encoder_stacks': 1, 'posterior_encoder_base_dilation': 1, 'posterior_encoder_dropout_rate': 0.0, 'use_weight_norm_in_posterior_encoder': True, 'flow_flows': 4, 'flow_kernel_size': 5, 'flow_base_dilation': 1, 'flow_layers': 4, 'flow_dropout_rate': 0.0, 'use_weight_norm_in_flow': True, 'use_only_mean_in_flow': True, 'stochastic_duration_predictor_kernel_size': 3, 'stochastic_duration_predictor_dropout_rate': 0.5, 'stochastic_duration_predictor_flows': 4, 'stochastic_duration_predictor_dds_conv_layers': 3, 'vocabs': 74, 'aux_channels': 513}, 'discriminator_type': 'hifigan_multi_scale_multi_period_discriminator', 'discriminator_params': {'scales': 1, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'stride': 2, 'padding': 2}, 'scale_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'channels': 128, 'max_downsample_channels': 1024, 'max_groups': 16, 'bias': True, 'downsample_scales': [2, 2, 4, 4, 1], 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}, 'follow_official_norm': False, 'periods': [2, 3, 5, 7, 11], 'period_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [5, 3], 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'max_downsample_channels': 1024, 'bias': True, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}}, 'generator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'discriminator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'feat_match_loss_params': {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, 'mel_loss_params': {'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None, 'window': 'hann', 'n_mels': 80, 'fmin': 0, 'fmax': None, 'log_base': None}, 'lambda_adv': 1.0, 'lambda_mel': 45.0, 'lambda_feat_match': 2.0, 'lambda_dur': 1.0, 'lambda_kl': 1.0, 'sampling_rate': 22050, 'cache_generator_outputs': True, 'plot_pred_mos': False, 'mos_pred_tool': 'utmos'}, pitch_extract=None, pitch_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'f0max': 400, 'f0min': 80}, pitch_normalize=None, pitch_normalize_conf={}, energy_extract=None, energy_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None}, energy_normalize=None, energy_normalize_conf={}, required=['output_dir', 'token_list'], version='202503', distributed=False)
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1284, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 55087) is killed by signal: Killed. 

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 22, in <module>
    main()
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 18, in main
    GANTTSTask.main(cmd=cmd)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1225, in main
    cls.main_worker(args)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1441, in main_worker
    collect_stats(
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/main_funcs/collect_stats.py", line 51, in collect_stats
    for iiter, (keys, batch) in enumerate(itr, 1):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 733, in __next__
    data = self._next_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1491, in _next_data
    idx, data = self._get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1453, in _get_data
    success, data = self._try_get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1297, in _try_get_data
    raise RuntimeError(
RuntimeError: DataLoader worker (pid(s) 55087) exited unexpectedly
# Accounting: begin_time=1750873482
# Accounting: end_time=1750873630
# Accounting: time=148 threads=1
# Finished at Wed Jun 25 13:47:10 EDT 2025 with status 1
# Running on r214.ib.bridges2.psc.edu
# Started at Wed Jun 25 13:44:42 EDT 2025
# SLURMD_NODENAME=r214
# SLURM_ARRAY_JOB_ID=32990217
# SLURM_ARRAY_TASK_COUNT=32
# SLURM_ARRAY_TASK_ID=29
# SLURM_ARRAY_TASK_MAX=32
# SLURM_ARRAY_TASK_MIN=1
# SLURM_ARRAY_TASK_STEP=1
# SLURM_CLUSTER_NAME=bridges2
# SLURM_CONF=/var/spool/slurm/d/conf-cache/slurm.conf
# SLURM_CPUS_ON_NODE=1
# SLURM_CPU_BIND=quiet,mask_cpu:0x07C0000000
# SLURM_CPU_BIND_LIST=0x07C0000000
# SLURM_CPU_BIND_TYPE=mask_cpu:
# SLURM_CPU_BIND_VERBOSE=quiet
# SLURM_EXPORT_ENV=ALL
# SLURM_GET_USER_ENV=1
# SLURM_GTIDS=0
# SLURM_JOBID=32990273
# SLURM_JOB_ACCOUNT=cis210027p
# SLURM_JOB_CPUS_PER_NODE=1
# SLURM_JOB_GID=24886
# SLURM_JOB_ID=32990273
# SLURM_JOB_NAME=stats.sh
# SLURM_JOB_NODELIST=r214
# SLURM_JOB_NUM_NODES=1
# SLURM_JOB_PARTITION=RM-shared
# SLURM_JOB_QOS=rm
# SLURM_JOB_UID=97947
# SLURM_JOB_USER=ttao3
# SLURM_LAUNCH_NODE_IPADDR=10.8.11.29
# SLURM_LOCALID=0
# SLURM_MEM_PER_CPU=1900
# SLURM_NNODES=1
# SLURM_NODEID=0
# SLURM_NODELIST=r214
# SLURM_NODE_ALIASES='(null)'
# SLURM_NPROCS=1
# SLURM_NTASKS=1
# SLURM_OPEN_MODE=a
# SLURM_PRIO_PROCESS=0
# SLURM_PROCID=0
# SLURM_PTY_PORT=33025
# SLURM_PTY_WIN_COL=126
# SLURM_PTY_WIN_ROW=21
# SLURM_SCRIPT_CONTEXT=prolog_task
# SLURM_SRUN_COMM_HOST=10.8.11.29
# SLURM_SRUN_COMM_PORT=35045
# SLURM_STEPID=0
# SLURM_STEP_GPUS=6
# SLURM_STEP_ID=0
# SLURM_STEP_LAUNCHER_PORT=35045
# SLURM_STEP_NODELIST=v029
# SLURM_STEP_NUM_NODES=1
# SLURM_STEP_NUM_TASKS=1
# SLURM_STEP_TASKS_PER_NODE=1
# SLURM_SUBMIT_DIR=/ocean/projects/cis210027p/ttao3/espnet/egs2/hifitts/tts1
# SLURM_SUBMIT_HOST=v029.ib.bridges2.psc.edu
# SLURM_TASKS_PER_NODE=1
# SLURM_TASK_PID=54946
# SLURM_TOPOLOGY_ADDR=r214
# SLURM_TOPOLOGY_ADDR_PATTERN=node
# SLURM_WORKING_CLUSTER=bridges2:br003:6810:9728:109
# python3 -m espnet2.bin.gan_tts_train --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.29.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.29.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.29 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int 
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/librosa/util/files.py:10: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_filename
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/bin/python3 /ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.29.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.29.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.29 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int
Failed to import Flash Attention, using ESPnet default: No module named 'flash_attn_2_cuda'
Vocabulary size: 74
encoder self-attention layer type = relative self-attention
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/ocean/projects/cis210027p/ttao3/espnet/espnet2/gan_tts/vits/monotonic_align/__init__.py:19: UserWarning: Cython version is not available. Fallback to 'EXPERIMETAL' numba version. If you want to use the cython version, please build it as follows: `cd espnet2/gan_tts/vits/monotonic_align; python setup.py build_ext --inplace`
  warnings.warn(
pytorch.version=2.7.1+cu126, cuda.available=False, cudnn.version=90501, cudnn.benchmark=False, cudnn.deterministic=False
Model structure:
ESPnetGANTTSModel(
  (feats_extract): LinearSpectrogram(
    (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
  )
  (tts): VITS(
    (generator): VITSGenerator(
      (text_encoder): TextEncoder(
        (emb): Embedding(74, 192)
        (encoder): Encoder(
          (embed): Sequential(
            (0): RelPositionalEncoding(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (encoders): MultiSequential(
            (0): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (2): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (3): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (4): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (5): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (after_norm): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (decoder): HiFiGANGenerator(
        (input_conv): Conv1d(192, 512, kernel_size=(7,), stride=(1,), padding=(3,))
        (upsamples): ModuleList(
          (0): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (1): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(256, 128, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (2): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,))
          )
          (3): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,))
          )
        )
        (blocks): ModuleList(
          (0): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (1): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (2): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (3): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (4): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (5): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (6): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (7): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (8): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (9): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (10): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (11): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
        )
        (output_conv): Sequential(
          (0): LeakyReLU(negative_slope=0.01)
          (1): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,))
          (2): Tanh()
        )
        (global_conv): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
      )
      (posterior_encoder): PosteriorEncoder(
        (input_conv): Conv1d(513, 192, kernel_size=(1,), stride=(1,))
        (encoder): WaveNet(
          (conv_layers): ModuleList(
            (0-15): 16 x ResidualBlock(
              (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
              (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
              (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
            )
          )
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (flow): ResidualAffineCouplingBlock(
        (flows): ModuleList(
          (0): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (1): FlipFlow()
          (2): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (3): FlipFlow()
          (4): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (5): FlipFlow()
          (6): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (7): FlipFlow()
        )
      )
      (duration_predictor): StochasticDurationPredictor(
        (pre): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (log_flow): LogFlow()
        (flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (post_pre): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
        (post_dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (post_proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (post_flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (global_conv): Conv1d(256, 192, kernel_size=(1,), stride=(1,))
      )
      (global_emb): Embedding(128, 256)
    )
    (discriminator): HiFiGANMultiScaleMultiPeriodDiscriminator(
      (msd): HiFiGANMultiScaleDiscriminator(
        (discriminators): ModuleList(
          (0): HiFiGANScaleDiscriminator(
            (layers): ModuleList(
              (0): Sequential(
                (0): Conv1d(1, 128, kernel_size=(15,), stride=(1,), padding=(7,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv1d(128, 128, kernel_size=(41,), stride=(2,), padding=(20,), groups=4)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv1d(128, 256, kernel_size=(41,), stride=(2,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv1d(256, 512, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv1d(512, 1024, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (5): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(41,), stride=(1,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (6): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (7): Conv1d(1024, 1, kernel_size=(3,), stride=(1,), padding=(1,))
            )
          )
        )
      )
      (mpd): HiFiGANMultiPeriodDiscriminator(
        (discriminators): ModuleList(
          (0-4): 5 x HiFiGANPeriodDiscriminator(
            (convs): ModuleList(
              (0): Sequential(
                (0): Conv2d(1, 32, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv2d(32, 128, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv2d(128, 512, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv2d(512, 1024, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv2d(1024, 1024, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
            )
            (output_conv): Conv2d(1024, 1, kernel_size=(2, 1), stride=(1, 1), padding=(1, 0))
          )
        )
      )
    )
    (generator_adv_loss): GeneratorAdversarialLoss()
    (discriminator_adv_loss): DiscriminatorAdversarialLoss()
    (feat_match_loss): FeatureMatchLoss()
    (mel_loss): MelSpectrogramLoss(
      (wav_to_mel): LogMelFbank(
        (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
        (logmel): LogMel(sr=22050, n_fft=1024, n_mels=80, fmin=0, fmax=11025.0, htk=False)
      )
    )
    (kl_loss): KLDivergenceLoss()
  )
)

Model summary:
    Class Name: ESPnetGANTTSModel
    Total Number of model parameters: 96.37 M
    Number of trainable parameters: 96.37 M (100.0%)
    Size: 385.46 MB
    Type: torch.float32
Optimizer:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler: <torch.optim.lr_scheduler.ExponentialLR object at 0x1540c91e1640>
Optimizer2:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler2: <torch.optim.lr_scheduler.ExponentialLR object at 0x1540c91e1a30>
Saving the configuration in exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.29/config.yaml
Namespace(config='conf/tuning/train_multi_spk_vits.yaml', print_config=False, log_level='INFO', drop_last_iter=False, dry_run=False, iterator_type='sequence', valid_iterator_type=None, output_dir='exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.29', ngpu=0, seed=777, num_workers=4, num_att_plot=3, dist_backend='nccl', dist_init_method='env://', dist_world_size=None, dist_rank=None, local_rank=None, dist_master_addr=None, dist_master_port=None, dist_launcher=None, multiprocessing_distributed=False, unused_parameters=True, sharded_ddp=False, use_deepspeed=False, deepspeed_config=None, gradient_as_bucket_view=True, ddp_comm_hook=None, cudnn_enabled=True, cudnn_benchmark=False, cudnn_deterministic=False, use_tf32=False, collect_stats=True, write_collected_feats=False, max_epoch=1000, patience=None, val_scheduler_criterion=('valid', 'loss'), early_stopping_criterion=('valid', 'loss', 'min'), best_model_criterion=[['train', 'total_count', 'max']], keep_nbest_models=10, nbest_averaging_interval=0, grad_clip=-1, grad_clip_type=2.0, grad_noise=False, accum_grad=1, no_forward_run=False, resume=False, train_dtype='float32', use_amp=False, log_interval=50, use_matplotlib=True, use_tensorboard=True, create_graph_in_tensorboard=False, use_wandb=False, wandb_project=None, wandb_id=None, wandb_entity=None, wandb_name=None, wandb_model_log_interval=-1, detect_anomaly=False, use_adapter=False, adapter='lora', save_strategy='all', adapter_conf={}, pretrain_path=None, init_param=[], ignore_init_mismatch=False, freeze_param=[], num_iters_per_epoch=1000, batch_size=20, valid_batch_size=None, batch_bins=3000000, valid_batch_bins=None, category_sample_size=10, train_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.29.scp'], valid_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.29.scp'], batch_type='numel', valid_batch_type=None, fold_length=[], sort_in_batch='descending', shuffle_within_batch=False, sort_batch='descending', multiple_iterator=False, chunk_length=500, chunk_shift_ratio=0.5, num_cache_chunks=1024, chunk_excluded_key_prefixes=[], chunk_default_fs=None, chunk_max_abs_length=None, chunk_discard_short_samples=True, train_data_path_and_name_and_type=[('dump/22k/raw/tr_no_dev/text', 'text', 'text'), ('dump/22k/raw/tr_no_dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/tr_no_dev/utt2sid', 'sids', 'text_int')], valid_data_path_and_name_and_type=[('dump/22k/raw/dev/text', 'text', 'text'), ('dump/22k/raw/dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/dev/utt2sid', 'sids', 'text_int')], multi_task_dataset=False, allow_variable_data_keys=False, max_cache_size=0.0, max_cache_fd=32, allow_multi_rates=False, valid_max_cache_size=None, exclude_weight_decay=False, exclude_weight_decay_conf={}, optim='adamw', optim_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler='exponentiallr', scheduler_conf={'gamma': 0.999875}, optim2='adamw', optim2_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler2='exponentiallr', scheduler2_conf={'gamma': 0.999875}, generator_first=False, skip_discriminator_prob=0.0, token_list=['<blank>', '<unk>', ' ', 'AH0', 'N', 'T', 'D', 'S', 'R', 'L', 'IH1', 'DH', 'M', 'EH1', 'Z', 'AE1', 'K', 'IH0', 'AH1', 'HH', 'W', 'ER0', 'V', 'IY1', 'F', 'UW1', 'P', 'AY1', 'B', 'AA1', 'AO1', 'EY1', 'IY0', 'OW1', 'NG', 'SH', 'G', 'Y', 'AW1', 'CH', 'ER1', 'UH1', 'TH', 'JH', 'OW0', 'EH2', 'IH2', 'OY1', 'EY2', 'AY2', 'EH0', 'UW0', 'AA2', 'AE2', 'OW2', 'AH2', 'AA0', 'ZH', 'AE0', 'AO2', 'UW2', 'AO0', 'AY0', 'IY2', 'AW2', 'UH2', 'EY0', 'ER2', 'AW0', 'UH0', 'OY2', 'OY0', "'", '<sos/eos>'], odim=None, model_conf={}, use_preprocessor=True, token_type='phn', bpemodel=None, non_linguistic_symbols=None, cleaner='tacotron', g2p='g2p_en', feats_extract='linear_spectrogram', feats_extract_conf={'n_fft': 1024, 'hop_length': 256, 'win_length': None}, normalize=None, normalize_conf={}, tts='vits', tts_conf={'generator_type': 'vits_generator', 'generator_params': {'hidden_channels': 192, 'spks': 128, 'global_channels': 256, 'segment_size': 32, 'text_encoder_attention_heads': 2, 'text_encoder_ffn_expand': 4, 'text_encoder_blocks': 6, 'text_encoder_positionwise_layer_type': 'conv1d', 'text_encoder_positionwise_conv_kernel_size': 3, 'text_encoder_positional_encoding_layer_type': 'rel_pos', 'text_encoder_self_attention_layer_type': 'rel_selfattn', 'text_encoder_activation_type': 'swish', 'text_encoder_normalize_before': True, 'text_encoder_dropout_rate': 0.1, 'text_encoder_positional_dropout_rate': 0.0, 'text_encoder_attention_dropout_rate': 0.1, 'use_macaron_style_in_text_encoder': True, 'use_conformer_conv_in_text_encoder': False, 'text_encoder_conformer_kernel_size': -1, 'decoder_kernel_size': 7, 'decoder_channels': 512, 'decoder_upsample_scales': [8, 8, 2, 2], 'decoder_upsample_kernel_sizes': [16, 16, 4, 4], 'decoder_resblock_kernel_sizes': [3, 7, 11], 'decoder_resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'use_weight_norm_in_decoder': True, 'posterior_encoder_kernel_size': 5, 'posterior_encoder_layers': 16, 'posterior_encoder_stacks': 1, 'posterior_encoder_base_dilation': 1, 'posterior_encoder_dropout_rate': 0.0, 'use_weight_norm_in_posterior_encoder': True, 'flow_flows': 4, 'flow_kernel_size': 5, 'flow_base_dilation': 1, 'flow_layers': 4, 'flow_dropout_rate': 0.0, 'use_weight_norm_in_flow': True, 'use_only_mean_in_flow': True, 'stochastic_duration_predictor_kernel_size': 3, 'stochastic_duration_predictor_dropout_rate': 0.5, 'stochastic_duration_predictor_flows': 4, 'stochastic_duration_predictor_dds_conv_layers': 3, 'vocabs': 74, 'aux_channels': 513}, 'discriminator_type': 'hifigan_multi_scale_multi_period_discriminator', 'discriminator_params': {'scales': 1, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'stride': 2, 'padding': 2}, 'scale_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'channels': 128, 'max_downsample_channels': 1024, 'max_groups': 16, 'bias': True, 'downsample_scales': [2, 2, 4, 4, 1], 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}, 'follow_official_norm': False, 'periods': [2, 3, 5, 7, 11], 'period_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [5, 3], 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'max_downsample_channels': 1024, 'bias': True, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}}, 'generator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'discriminator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'feat_match_loss_params': {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, 'mel_loss_params': {'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None, 'window': 'hann', 'n_mels': 80, 'fmin': 0, 'fmax': None, 'log_base': None}, 'lambda_adv': 1.0, 'lambda_mel': 45.0, 'lambda_feat_match': 2.0, 'lambda_dur': 1.0, 'lambda_kl': 1.0, 'sampling_rate': 22050, 'cache_generator_outputs': True, 'plot_pred_mos': False, 'mos_pred_tool': 'utmos'}, pitch_extract=None, pitch_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'f0max': 400, 'f0min': 80}, pitch_normalize=None, pitch_normalize_conf={}, energy_extract=None, energy_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None}, energy_normalize=None, energy_normalize_conf={}, required=['output_dir', 'token_list'], version='202503', distributed=False)
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1284, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 55086) is killed by signal: Killed. 

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 22, in <module>
    main()
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 18, in main
    GANTTSTask.main(cmd=cmd)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1225, in main
    cls.main_worker(args)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1441, in main_worker
    collect_stats(
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/main_funcs/collect_stats.py", line 51, in collect_stats
    for iiter, (keys, batch) in enumerate(itr, 1):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 733, in __next__
    data = self._next_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1491, in _next_data
    idx, data = self._get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1453, in _get_data
    success, data = self._try_get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1297, in _try_get_data
    raise RuntimeError(
RuntimeError: DataLoader worker (pid(s) 55086) exited unexpectedly
# Accounting: begin_time=1750873482
# Accounting: end_time=1750873630
# Accounting: time=148 threads=1
# Finished at Wed Jun 25 13:47:10 EDT 2025 with status 1
# Running on r225.ib.bridges2.psc.edu
# Started at Wed Jun 25 13:40:56 EDT 2025
# SLURMD_NODENAME=r225
# SLURM_ARRAY_JOB_ID=32990217
# SLURM_ARRAY_TASK_COUNT=32
# SLURM_ARRAY_TASK_ID=3
# SLURM_ARRAY_TASK_MAX=32
# SLURM_ARRAY_TASK_MIN=1
# SLURM_ARRAY_TASK_STEP=1
# SLURM_CLUSTER_NAME=bridges2
# SLURM_CONF=/var/spool/slurm/d/conf-cache/slurm.conf
# SLURM_CPUS_ON_NODE=1
# SLURM_CPU_BIND=quiet,mask_cpu:0x07C0000000
# SLURM_CPU_BIND_LIST=0x07C0000000
# SLURM_CPU_BIND_TYPE=mask_cpu:
# SLURM_CPU_BIND_VERBOSE=quiet
# SLURM_EXPORT_ENV=ALL
# SLURM_GET_USER_ENV=1
# SLURM_GTIDS=0
# SLURM_JOBID=32990221
# SLURM_JOB_ACCOUNT=cis210027p
# SLURM_JOB_CPUS_PER_NODE=1
# SLURM_JOB_GID=24886
# SLURM_JOB_ID=32990221
# SLURM_JOB_NAME=stats.sh
# SLURM_JOB_NODELIST=r225
# SLURM_JOB_NUM_NODES=1
# SLURM_JOB_PARTITION=RM-shared
# SLURM_JOB_QOS=rm
# SLURM_JOB_UID=97947
# SLURM_JOB_USER=ttao3
# SLURM_LAUNCH_NODE_IPADDR=10.8.11.29
# SLURM_LOCALID=0
# SLURM_MEM_PER_CPU=1900
# SLURM_NNODES=1
# SLURM_NODEID=0
# SLURM_NODELIST=r225
# SLURM_NODE_ALIASES='(null)'
# SLURM_NPROCS=1
# SLURM_NTASKS=1
# SLURM_OPEN_MODE=a
# SLURM_PRIO_PROCESS=0
# SLURM_PROCID=0
# SLURM_PTY_PORT=33025
# SLURM_PTY_WIN_COL=126
# SLURM_PTY_WIN_ROW=21
# SLURM_SCRIPT_CONTEXT=prolog_task
# SLURM_SRUN_COMM_HOST=10.8.11.29
# SLURM_SRUN_COMM_PORT=35045
# SLURM_STEPID=0
# SLURM_STEP_GPUS=6
# SLURM_STEP_ID=0
# SLURM_STEP_LAUNCHER_PORT=35045
# SLURM_STEP_NODELIST=v029
# SLURM_STEP_NUM_NODES=1
# SLURM_STEP_NUM_TASKS=1
# SLURM_STEP_TASKS_PER_NODE=1
# SLURM_SUBMIT_DIR=/ocean/projects/cis210027p/ttao3/espnet/egs2/hifitts/tts1
# SLURM_SUBMIT_HOST=v029.ib.bridges2.psc.edu
# SLURM_TASKS_PER_NODE=1
# SLURM_TASK_PID=98220
# SLURM_TOPOLOGY_ADDR=r225
# SLURM_TOPOLOGY_ADDR_PATTERN=node
# SLURM_WORKING_CLUSTER=bridges2:br003:6810:9728:109
# python3 -m espnet2.bin.gan_tts_train --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.3.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.3.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.3 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int 
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/librosa/util/files.py:10: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_filename
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/bin/python3 /ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.3.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.3.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.3 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int
Failed to import Flash Attention, using ESPnet default: No module named 'flash_attn_2_cuda'
Vocabulary size: 74
encoder self-attention layer type = relative self-attention
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/ocean/projects/cis210027p/ttao3/espnet/espnet2/gan_tts/vits/monotonic_align/__init__.py:19: UserWarning: Cython version is not available. Fallback to 'EXPERIMETAL' numba version. If you want to use the cython version, please build it as follows: `cd espnet2/gan_tts/vits/monotonic_align; python setup.py build_ext --inplace`
  warnings.warn(
pytorch.version=2.7.1+cu126, cuda.available=False, cudnn.version=90501, cudnn.benchmark=False, cudnn.deterministic=False
Model structure:
ESPnetGANTTSModel(
  (feats_extract): LinearSpectrogram(
    (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
  )
  (tts): VITS(
    (generator): VITSGenerator(
      (text_encoder): TextEncoder(
        (emb): Embedding(74, 192)
        (encoder): Encoder(
          (embed): Sequential(
            (0): RelPositionalEncoding(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (encoders): MultiSequential(
            (0): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (2): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (3): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (4): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (5): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (after_norm): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (decoder): HiFiGANGenerator(
        (input_conv): Conv1d(192, 512, kernel_size=(7,), stride=(1,), padding=(3,))
        (upsamples): ModuleList(
          (0): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (1): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(256, 128, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (2): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,))
          )
          (3): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,))
          )
        )
        (blocks): ModuleList(
          (0): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (1): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (2): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (3): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (4): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (5): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (6): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (7): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (8): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (9): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (10): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (11): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
        )
        (output_conv): Sequential(
          (0): LeakyReLU(negative_slope=0.01)
          (1): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,))
          (2): Tanh()
        )
        (global_conv): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
      )
      (posterior_encoder): PosteriorEncoder(
        (input_conv): Conv1d(513, 192, kernel_size=(1,), stride=(1,))
        (encoder): WaveNet(
          (conv_layers): ModuleList(
            (0-15): 16 x ResidualBlock(
              (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
              (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
              (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
            )
          )
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (flow): ResidualAffineCouplingBlock(
        (flows): ModuleList(
          (0): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (1): FlipFlow()
          (2): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (3): FlipFlow()
          (4): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (5): FlipFlow()
          (6): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (7): FlipFlow()
        )
      )
      (duration_predictor): StochasticDurationPredictor(
        (pre): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (log_flow): LogFlow()
        (flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (post_pre): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
        (post_dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (post_proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (post_flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (global_conv): Conv1d(256, 192, kernel_size=(1,), stride=(1,))
      )
      (global_emb): Embedding(128, 256)
    )
    (discriminator): HiFiGANMultiScaleMultiPeriodDiscriminator(
      (msd): HiFiGANMultiScaleDiscriminator(
        (discriminators): ModuleList(
          (0): HiFiGANScaleDiscriminator(
            (layers): ModuleList(
              (0): Sequential(
                (0): Conv1d(1, 128, kernel_size=(15,), stride=(1,), padding=(7,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv1d(128, 128, kernel_size=(41,), stride=(2,), padding=(20,), groups=4)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv1d(128, 256, kernel_size=(41,), stride=(2,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv1d(256, 512, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv1d(512, 1024, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (5): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(41,), stride=(1,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (6): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (7): Conv1d(1024, 1, kernel_size=(3,), stride=(1,), padding=(1,))
            )
          )
        )
      )
      (mpd): HiFiGANMultiPeriodDiscriminator(
        (discriminators): ModuleList(
          (0-4): 5 x HiFiGANPeriodDiscriminator(
            (convs): ModuleList(
              (0): Sequential(
                (0): Conv2d(1, 32, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv2d(32, 128, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv2d(128, 512, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv2d(512, 1024, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv2d(1024, 1024, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
            )
            (output_conv): Conv2d(1024, 1, kernel_size=(2, 1), stride=(1, 1), padding=(1, 0))
          )
        )
      )
    )
    (generator_adv_loss): GeneratorAdversarialLoss()
    (discriminator_adv_loss): DiscriminatorAdversarialLoss()
    (feat_match_loss): FeatureMatchLoss()
    (mel_loss): MelSpectrogramLoss(
      (wav_to_mel): LogMelFbank(
        (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
        (logmel): LogMel(sr=22050, n_fft=1024, n_mels=80, fmin=0, fmax=11025.0, htk=False)
      )
    )
    (kl_loss): KLDivergenceLoss()
  )
)

Model summary:
    Class Name: ESPnetGANTTSModel
    Total Number of model parameters: 96.37 M
    Number of trainable parameters: 96.37 M (100.0%)
    Size: 385.46 MB
    Type: torch.float32
Optimizer:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler: <torch.optim.lr_scheduler.ExponentialLR object at 0x150e439565b0>
Optimizer2:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler2: <torch.optim.lr_scheduler.ExponentialLR object at 0x150e43956970>
Saving the configuration in exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.3/config.yaml
Namespace(config='conf/tuning/train_multi_spk_vits.yaml', print_config=False, log_level='INFO', drop_last_iter=False, dry_run=False, iterator_type='sequence', valid_iterator_type=None, output_dir='exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.3', ngpu=0, seed=777, num_workers=4, num_att_plot=3, dist_backend='nccl', dist_init_method='env://', dist_world_size=None, dist_rank=None, local_rank=None, dist_master_addr=None, dist_master_port=None, dist_launcher=None, multiprocessing_distributed=False, unused_parameters=True, sharded_ddp=False, use_deepspeed=False, deepspeed_config=None, gradient_as_bucket_view=True, ddp_comm_hook=None, cudnn_enabled=True, cudnn_benchmark=False, cudnn_deterministic=False, use_tf32=False, collect_stats=True, write_collected_feats=False, max_epoch=1000, patience=None, val_scheduler_criterion=('valid', 'loss'), early_stopping_criterion=('valid', 'loss', 'min'), best_model_criterion=[['train', 'total_count', 'max']], keep_nbest_models=10, nbest_averaging_interval=0, grad_clip=-1, grad_clip_type=2.0, grad_noise=False, accum_grad=1, no_forward_run=False, resume=False, train_dtype='float32', use_amp=False, log_interval=50, use_matplotlib=True, use_tensorboard=True, create_graph_in_tensorboard=False, use_wandb=False, wandb_project=None, wandb_id=None, wandb_entity=None, wandb_name=None, wandb_model_log_interval=-1, detect_anomaly=False, use_adapter=False, adapter='lora', save_strategy='all', adapter_conf={}, pretrain_path=None, init_param=[], ignore_init_mismatch=False, freeze_param=[], num_iters_per_epoch=1000, batch_size=20, valid_batch_size=None, batch_bins=3000000, valid_batch_bins=None, category_sample_size=10, train_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.3.scp'], valid_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.3.scp'], batch_type='numel', valid_batch_type=None, fold_length=[], sort_in_batch='descending', shuffle_within_batch=False, sort_batch='descending', multiple_iterator=False, chunk_length=500, chunk_shift_ratio=0.5, num_cache_chunks=1024, chunk_excluded_key_prefixes=[], chunk_default_fs=None, chunk_max_abs_length=None, chunk_discard_short_samples=True, train_data_path_and_name_and_type=[('dump/22k/raw/tr_no_dev/text', 'text', 'text'), ('dump/22k/raw/tr_no_dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/tr_no_dev/utt2sid', 'sids', 'text_int')], valid_data_path_and_name_and_type=[('dump/22k/raw/dev/text', 'text', 'text'), ('dump/22k/raw/dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/dev/utt2sid', 'sids', 'text_int')], multi_task_dataset=False, allow_variable_data_keys=False, max_cache_size=0.0, max_cache_fd=32, allow_multi_rates=False, valid_max_cache_size=None, exclude_weight_decay=False, exclude_weight_decay_conf={}, optim='adamw', optim_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler='exponentiallr', scheduler_conf={'gamma': 0.999875}, optim2='adamw', optim2_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler2='exponentiallr', scheduler2_conf={'gamma': 0.999875}, generator_first=False, skip_discriminator_prob=0.0, token_list=['<blank>', '<unk>', ' ', 'AH0', 'N', 'T', 'D', 'S', 'R', 'L', 'IH1', 'DH', 'M', 'EH1', 'Z', 'AE1', 'K', 'IH0', 'AH1', 'HH', 'W', 'ER0', 'V', 'IY1', 'F', 'UW1', 'P', 'AY1', 'B', 'AA1', 'AO1', 'EY1', 'IY0', 'OW1', 'NG', 'SH', 'G', 'Y', 'AW1', 'CH', 'ER1', 'UH1', 'TH', 'JH', 'OW0', 'EH2', 'IH2', 'OY1', 'EY2', 'AY2', 'EH0', 'UW0', 'AA2', 'AE2', 'OW2', 'AH2', 'AA0', 'ZH', 'AE0', 'AO2', 'UW2', 'AO0', 'AY0', 'IY2', 'AW2', 'UH2', 'EY0', 'ER2', 'AW0', 'UH0', 'OY2', 'OY0', "'", '<sos/eos>'], odim=None, model_conf={}, use_preprocessor=True, token_type='phn', bpemodel=None, non_linguistic_symbols=None, cleaner='tacotron', g2p='g2p_en', feats_extract='linear_spectrogram', feats_extract_conf={'n_fft': 1024, 'hop_length': 256, 'win_length': None}, normalize=None, normalize_conf={}, tts='vits', tts_conf={'generator_type': 'vits_generator', 'generator_params': {'hidden_channels': 192, 'spks': 128, 'global_channels': 256, 'segment_size': 32, 'text_encoder_attention_heads': 2, 'text_encoder_ffn_expand': 4, 'text_encoder_blocks': 6, 'text_encoder_positionwise_layer_type': 'conv1d', 'text_encoder_positionwise_conv_kernel_size': 3, 'text_encoder_positional_encoding_layer_type': 'rel_pos', 'text_encoder_self_attention_layer_type': 'rel_selfattn', 'text_encoder_activation_type': 'swish', 'text_encoder_normalize_before': True, 'text_encoder_dropout_rate': 0.1, 'text_encoder_positional_dropout_rate': 0.0, 'text_encoder_attention_dropout_rate': 0.1, 'use_macaron_style_in_text_encoder': True, 'use_conformer_conv_in_text_encoder': False, 'text_encoder_conformer_kernel_size': -1, 'decoder_kernel_size': 7, 'decoder_channels': 512, 'decoder_upsample_scales': [8, 8, 2, 2], 'decoder_upsample_kernel_sizes': [16, 16, 4, 4], 'decoder_resblock_kernel_sizes': [3, 7, 11], 'decoder_resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'use_weight_norm_in_decoder': True, 'posterior_encoder_kernel_size': 5, 'posterior_encoder_layers': 16, 'posterior_encoder_stacks': 1, 'posterior_encoder_base_dilation': 1, 'posterior_encoder_dropout_rate': 0.0, 'use_weight_norm_in_posterior_encoder': True, 'flow_flows': 4, 'flow_kernel_size': 5, 'flow_base_dilation': 1, 'flow_layers': 4, 'flow_dropout_rate': 0.0, 'use_weight_norm_in_flow': True, 'use_only_mean_in_flow': True, 'stochastic_duration_predictor_kernel_size': 3, 'stochastic_duration_predictor_dropout_rate': 0.5, 'stochastic_duration_predictor_flows': 4, 'stochastic_duration_predictor_dds_conv_layers': 3, 'vocabs': 74, 'aux_channels': 513}, 'discriminator_type': 'hifigan_multi_scale_multi_period_discriminator', 'discriminator_params': {'scales': 1, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'stride': 2, 'padding': 2}, 'scale_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'channels': 128, 'max_downsample_channels': 1024, 'max_groups': 16, 'bias': True, 'downsample_scales': [2, 2, 4, 4, 1], 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}, 'follow_official_norm': False, 'periods': [2, 3, 5, 7, 11], 'period_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [5, 3], 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'max_downsample_channels': 1024, 'bias': True, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}}, 'generator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'discriminator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'feat_match_loss_params': {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, 'mel_loss_params': {'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None, 'window': 'hann', 'n_mels': 80, 'fmin': 0, 'fmax': None, 'log_base': None}, 'lambda_adv': 1.0, 'lambda_mel': 45.0, 'lambda_feat_match': 2.0, 'lambda_dur': 1.0, 'lambda_kl': 1.0, 'sampling_rate': 22050, 'cache_generator_outputs': True, 'plot_pred_mos': False, 'mos_pred_tool': 'utmos'}, pitch_extract=None, pitch_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'f0max': 400, 'f0min': 80}, pitch_normalize=None, pitch_normalize_conf={}, energy_extract=None, energy_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None}, energy_normalize=None, energy_normalize_conf={}, required=['output_dir', 'token_list'], version='202503', distributed=False)
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1284, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 98273) is killed by signal: Killed. 

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 22, in <module>
    main()
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 18, in main
    GANTTSTask.main(cmd=cmd)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1225, in main
    cls.main_worker(args)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1441, in main_worker
    collect_stats(
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/main_funcs/collect_stats.py", line 51, in collect_stats
    for iiter, (keys, batch) in enumerate(itr, 1):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 733, in __next__
    data = self._next_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1491, in _next_data
    idx, data = self._get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1453, in _get_data
    success, data = self._try_get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1297, in _try_get_data
    raise RuntimeError(
RuntimeError: DataLoader worker (pid(s) 98273) exited unexpectedly
# Accounting: begin_time=1750873256
# Accounting: end_time=1750873472
# Accounting: time=216 threads=1
# Finished at Wed Jun 25 13:44:32 EDT 2025 with status 1
# Running on r217.ib.bridges2.psc.edu
# Started at Wed Jun 25 13:44:42 EDT 2025
# SLURMD_NODENAME=r217
# SLURM_ARRAY_JOB_ID=32990217
# SLURM_ARRAY_TASK_COUNT=32
# SLURM_ARRAY_TASK_ID=30
# SLURM_ARRAY_TASK_MAX=32
# SLURM_ARRAY_TASK_MIN=1
# SLURM_ARRAY_TASK_STEP=1
# SLURM_CLUSTER_NAME=bridges2
# SLURM_CONF=/var/spool/slurm/d/conf-cache/slurm.conf
# SLURM_CPUS_ON_NODE=1
# SLURM_CPU_BIND=quiet,mask_cpu:0x07C0000000
# SLURM_CPU_BIND_LIST=0x07C0000000
# SLURM_CPU_BIND_TYPE=mask_cpu:
# SLURM_CPU_BIND_VERBOSE=quiet
# SLURM_EXPORT_ENV=ALL
# SLURM_GET_USER_ENV=1
# SLURM_GTIDS=0
# SLURM_JOBID=32990274
# SLURM_JOB_ACCOUNT=cis210027p
# SLURM_JOB_CPUS_PER_NODE=1
# SLURM_JOB_GID=24886
# SLURM_JOB_ID=32990274
# SLURM_JOB_NAME=stats.sh
# SLURM_JOB_NODELIST=r217
# SLURM_JOB_NUM_NODES=1
# SLURM_JOB_PARTITION=RM-shared
# SLURM_JOB_QOS=rm
# SLURM_JOB_UID=97947
# SLURM_JOB_USER=ttao3
# SLURM_LAUNCH_NODE_IPADDR=10.8.11.29
# SLURM_LOCALID=0
# SLURM_MEM_PER_CPU=1900
# SLURM_NNODES=1
# SLURM_NODEID=0
# SLURM_NODELIST=r217
# SLURM_NODE_ALIASES='(null)'
# SLURM_NPROCS=1
# SLURM_NTASKS=1
# SLURM_OPEN_MODE=a
# SLURM_PRIO_PROCESS=0
# SLURM_PROCID=0
# SLURM_PTY_PORT=33025
# SLURM_PTY_WIN_COL=126
# SLURM_PTY_WIN_ROW=21
# SLURM_SCRIPT_CONTEXT=prolog_task
# SLURM_SRUN_COMM_HOST=10.8.11.29
# SLURM_SRUN_COMM_PORT=35045
# SLURM_STEPID=0
# SLURM_STEP_GPUS=6
# SLURM_STEP_ID=0
# SLURM_STEP_LAUNCHER_PORT=35045
# SLURM_STEP_NODELIST=v029
# SLURM_STEP_NUM_NODES=1
# SLURM_STEP_NUM_TASKS=1
# SLURM_STEP_TASKS_PER_NODE=1
# SLURM_SUBMIT_DIR=/ocean/projects/cis210027p/ttao3/espnet/egs2/hifitts/tts1
# SLURM_SUBMIT_HOST=v029.ib.bridges2.psc.edu
# SLURM_TASKS_PER_NODE=1
# SLURM_TASK_PID=36118
# SLURM_TOPOLOGY_ADDR=r217
# SLURM_TOPOLOGY_ADDR_PATTERN=node
# SLURM_WORKING_CLUSTER=bridges2:br003:6810:9728:109
# python3 -m espnet2.bin.gan_tts_train --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.30.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.30.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.30 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int 
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/librosa/util/files.py:10: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_filename
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/bin/python3 /ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.30.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.30.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.30 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int
Failed to import Flash Attention, using ESPnet default: No module named 'flash_attn_2_cuda'
Vocabulary size: 74
encoder self-attention layer type = relative self-attention
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/ocean/projects/cis210027p/ttao3/espnet/espnet2/gan_tts/vits/monotonic_align/__init__.py:19: UserWarning: Cython version is not available. Fallback to 'EXPERIMETAL' numba version. If you want to use the cython version, please build it as follows: `cd espnet2/gan_tts/vits/monotonic_align; python setup.py build_ext --inplace`
  warnings.warn(
pytorch.version=2.7.1+cu126, cuda.available=False, cudnn.version=90501, cudnn.benchmark=False, cudnn.deterministic=False
Model structure:
ESPnetGANTTSModel(
  (feats_extract): LinearSpectrogram(
    (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
  )
  (tts): VITS(
    (generator): VITSGenerator(
      (text_encoder): TextEncoder(
        (emb): Embedding(74, 192)
        (encoder): Encoder(
          (embed): Sequential(
            (0): RelPositionalEncoding(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (encoders): MultiSequential(
            (0): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (2): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (3): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (4): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (5): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (after_norm): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (decoder): HiFiGANGenerator(
        (input_conv): Conv1d(192, 512, kernel_size=(7,), stride=(1,), padding=(3,))
        (upsamples): ModuleList(
          (0): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (1): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(256, 128, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (2): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,))
          )
          (3): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,))
          )
        )
        (blocks): ModuleList(
          (0): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (1): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (2): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (3): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (4): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (5): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (6): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (7): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (8): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (9): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (10): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (11): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
        )
        (output_conv): Sequential(
          (0): LeakyReLU(negative_slope=0.01)
          (1): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,))
          (2): Tanh()
        )
        (global_conv): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
      )
      (posterior_encoder): PosteriorEncoder(
        (input_conv): Conv1d(513, 192, kernel_size=(1,), stride=(1,))
        (encoder): WaveNet(
          (conv_layers): ModuleList(
            (0-15): 16 x ResidualBlock(
              (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
              (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
              (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
            )
          )
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (flow): ResidualAffineCouplingBlock(
        (flows): ModuleList(
          (0): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (1): FlipFlow()
          (2): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (3): FlipFlow()
          (4): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (5): FlipFlow()
          (6): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (7): FlipFlow()
        )
      )
      (duration_predictor): StochasticDurationPredictor(
        (pre): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (log_flow): LogFlow()
        (flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (post_pre): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
        (post_dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (post_proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (post_flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (global_conv): Conv1d(256, 192, kernel_size=(1,), stride=(1,))
      )
      (global_emb): Embedding(128, 256)
    )
    (discriminator): HiFiGANMultiScaleMultiPeriodDiscriminator(
      (msd): HiFiGANMultiScaleDiscriminator(
        (discriminators): ModuleList(
          (0): HiFiGANScaleDiscriminator(
            (layers): ModuleList(
              (0): Sequential(
                (0): Conv1d(1, 128, kernel_size=(15,), stride=(1,), padding=(7,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv1d(128, 128, kernel_size=(41,), stride=(2,), padding=(20,), groups=4)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv1d(128, 256, kernel_size=(41,), stride=(2,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv1d(256, 512, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv1d(512, 1024, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (5): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(41,), stride=(1,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (6): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (7): Conv1d(1024, 1, kernel_size=(3,), stride=(1,), padding=(1,))
            )
          )
        )
      )
      (mpd): HiFiGANMultiPeriodDiscriminator(
        (discriminators): ModuleList(
          (0-4): 5 x HiFiGANPeriodDiscriminator(
            (convs): ModuleList(
              (0): Sequential(
                (0): Conv2d(1, 32, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv2d(32, 128, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv2d(128, 512, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv2d(512, 1024, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv2d(1024, 1024, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
            )
            (output_conv): Conv2d(1024, 1, kernel_size=(2, 1), stride=(1, 1), padding=(1, 0))
          )
        )
      )
    )
    (generator_adv_loss): GeneratorAdversarialLoss()
    (discriminator_adv_loss): DiscriminatorAdversarialLoss()
    (feat_match_loss): FeatureMatchLoss()
    (mel_loss): MelSpectrogramLoss(
      (wav_to_mel): LogMelFbank(
        (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
        (logmel): LogMel(sr=22050, n_fft=1024, n_mels=80, fmin=0, fmax=11025.0, htk=False)
      )
    )
    (kl_loss): KLDivergenceLoss()
  )
)

Model summary:
    Class Name: ESPnetGANTTSModel
    Total Number of model parameters: 96.37 M
    Number of trainable parameters: 96.37 M (100.0%)
    Size: 385.46 MB
    Type: torch.float32
Optimizer:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler: <torch.optim.lr_scheduler.ExponentialLR object at 0x14c0f848e5b0>
Optimizer2:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler2: <torch.optim.lr_scheduler.ExponentialLR object at 0x14c0f848e970>
Saving the configuration in exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.30/config.yaml
Namespace(config='conf/tuning/train_multi_spk_vits.yaml', print_config=False, log_level='INFO', drop_last_iter=False, dry_run=False, iterator_type='sequence', valid_iterator_type=None, output_dir='exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.30', ngpu=0, seed=777, num_workers=4, num_att_plot=3, dist_backend='nccl', dist_init_method='env://', dist_world_size=None, dist_rank=None, local_rank=None, dist_master_addr=None, dist_master_port=None, dist_launcher=None, multiprocessing_distributed=False, unused_parameters=True, sharded_ddp=False, use_deepspeed=False, deepspeed_config=None, gradient_as_bucket_view=True, ddp_comm_hook=None, cudnn_enabled=True, cudnn_benchmark=False, cudnn_deterministic=False, use_tf32=False, collect_stats=True, write_collected_feats=False, max_epoch=1000, patience=None, val_scheduler_criterion=('valid', 'loss'), early_stopping_criterion=('valid', 'loss', 'min'), best_model_criterion=[['train', 'total_count', 'max']], keep_nbest_models=10, nbest_averaging_interval=0, grad_clip=-1, grad_clip_type=2.0, grad_noise=False, accum_grad=1, no_forward_run=False, resume=False, train_dtype='float32', use_amp=False, log_interval=50, use_matplotlib=True, use_tensorboard=True, create_graph_in_tensorboard=False, use_wandb=False, wandb_project=None, wandb_id=None, wandb_entity=None, wandb_name=None, wandb_model_log_interval=-1, detect_anomaly=False, use_adapter=False, adapter='lora', save_strategy='all', adapter_conf={}, pretrain_path=None, init_param=[], ignore_init_mismatch=False, freeze_param=[], num_iters_per_epoch=1000, batch_size=20, valid_batch_size=None, batch_bins=3000000, valid_batch_bins=None, category_sample_size=10, train_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.30.scp'], valid_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.30.scp'], batch_type='numel', valid_batch_type=None, fold_length=[], sort_in_batch='descending', shuffle_within_batch=False, sort_batch='descending', multiple_iterator=False, chunk_length=500, chunk_shift_ratio=0.5, num_cache_chunks=1024, chunk_excluded_key_prefixes=[], chunk_default_fs=None, chunk_max_abs_length=None, chunk_discard_short_samples=True, train_data_path_and_name_and_type=[('dump/22k/raw/tr_no_dev/text', 'text', 'text'), ('dump/22k/raw/tr_no_dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/tr_no_dev/utt2sid', 'sids', 'text_int')], valid_data_path_and_name_and_type=[('dump/22k/raw/dev/text', 'text', 'text'), ('dump/22k/raw/dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/dev/utt2sid', 'sids', 'text_int')], multi_task_dataset=False, allow_variable_data_keys=False, max_cache_size=0.0, max_cache_fd=32, allow_multi_rates=False, valid_max_cache_size=None, exclude_weight_decay=False, exclude_weight_decay_conf={}, optim='adamw', optim_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler='exponentiallr', scheduler_conf={'gamma': 0.999875}, optim2='adamw', optim2_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler2='exponentiallr', scheduler2_conf={'gamma': 0.999875}, generator_first=False, skip_discriminator_prob=0.0, token_list=['<blank>', '<unk>', ' ', 'AH0', 'N', 'T', 'D', 'S', 'R', 'L', 'IH1', 'DH', 'M', 'EH1', 'Z', 'AE1', 'K', 'IH0', 'AH1', 'HH', 'W', 'ER0', 'V', 'IY1', 'F', 'UW1', 'P', 'AY1', 'B', 'AA1', 'AO1', 'EY1', 'IY0', 'OW1', 'NG', 'SH', 'G', 'Y', 'AW1', 'CH', 'ER1', 'UH1', 'TH', 'JH', 'OW0', 'EH2', 'IH2', 'OY1', 'EY2', 'AY2', 'EH0', 'UW0', 'AA2', 'AE2', 'OW2', 'AH2', 'AA0', 'ZH', 'AE0', 'AO2', 'UW2', 'AO0', 'AY0', 'IY2', 'AW2', 'UH2', 'EY0', 'ER2', 'AW0', 'UH0', 'OY2', 'OY0', "'", '<sos/eos>'], odim=None, model_conf={}, use_preprocessor=True, token_type='phn', bpemodel=None, non_linguistic_symbols=None, cleaner='tacotron', g2p='g2p_en', feats_extract='linear_spectrogram', feats_extract_conf={'n_fft': 1024, 'hop_length': 256, 'win_length': None}, normalize=None, normalize_conf={}, tts='vits', tts_conf={'generator_type': 'vits_generator', 'generator_params': {'hidden_channels': 192, 'spks': 128, 'global_channels': 256, 'segment_size': 32, 'text_encoder_attention_heads': 2, 'text_encoder_ffn_expand': 4, 'text_encoder_blocks': 6, 'text_encoder_positionwise_layer_type': 'conv1d', 'text_encoder_positionwise_conv_kernel_size': 3, 'text_encoder_positional_encoding_layer_type': 'rel_pos', 'text_encoder_self_attention_layer_type': 'rel_selfattn', 'text_encoder_activation_type': 'swish', 'text_encoder_normalize_before': True, 'text_encoder_dropout_rate': 0.1, 'text_encoder_positional_dropout_rate': 0.0, 'text_encoder_attention_dropout_rate': 0.1, 'use_macaron_style_in_text_encoder': True, 'use_conformer_conv_in_text_encoder': False, 'text_encoder_conformer_kernel_size': -1, 'decoder_kernel_size': 7, 'decoder_channels': 512, 'decoder_upsample_scales': [8, 8, 2, 2], 'decoder_upsample_kernel_sizes': [16, 16, 4, 4], 'decoder_resblock_kernel_sizes': [3, 7, 11], 'decoder_resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'use_weight_norm_in_decoder': True, 'posterior_encoder_kernel_size': 5, 'posterior_encoder_layers': 16, 'posterior_encoder_stacks': 1, 'posterior_encoder_base_dilation': 1, 'posterior_encoder_dropout_rate': 0.0, 'use_weight_norm_in_posterior_encoder': True, 'flow_flows': 4, 'flow_kernel_size': 5, 'flow_base_dilation': 1, 'flow_layers': 4, 'flow_dropout_rate': 0.0, 'use_weight_norm_in_flow': True, 'use_only_mean_in_flow': True, 'stochastic_duration_predictor_kernel_size': 3, 'stochastic_duration_predictor_dropout_rate': 0.5, 'stochastic_duration_predictor_flows': 4, 'stochastic_duration_predictor_dds_conv_layers': 3, 'vocabs': 74, 'aux_channels': 513}, 'discriminator_type': 'hifigan_multi_scale_multi_period_discriminator', 'discriminator_params': {'scales': 1, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'stride': 2, 'padding': 2}, 'scale_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'channels': 128, 'max_downsample_channels': 1024, 'max_groups': 16, 'bias': True, 'downsample_scales': [2, 2, 4, 4, 1], 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}, 'follow_official_norm': False, 'periods': [2, 3, 5, 7, 11], 'period_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [5, 3], 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'max_downsample_channels': 1024, 'bias': True, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}}, 'generator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'discriminator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'feat_match_loss_params': {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, 'mel_loss_params': {'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None, 'window': 'hann', 'n_mels': 80, 'fmin': 0, 'fmax': None, 'log_base': None}, 'lambda_adv': 1.0, 'lambda_mel': 45.0, 'lambda_feat_match': 2.0, 'lambda_dur': 1.0, 'lambda_kl': 1.0, 'sampling_rate': 22050, 'cache_generator_outputs': True, 'plot_pred_mos': False, 'mos_pred_tool': 'utmos'}, pitch_extract=None, pitch_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'f0max': 400, 'f0min': 80}, pitch_normalize=None, pitch_normalize_conf={}, energy_extract=None, energy_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None}, energy_normalize=None, energy_normalize_conf={}, required=['output_dir', 'token_list'], version='202503', distributed=False)
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1284, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 36260) is killed by signal: Killed. 

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 22, in <module>
    main()
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 18, in main
    GANTTSTask.main(cmd=cmd)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1225, in main
    cls.main_worker(args)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1441, in main_worker
    collect_stats(
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/main_funcs/collect_stats.py", line 51, in collect_stats
    for iiter, (keys, batch) in enumerate(itr, 1):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 733, in __next__
    data = self._next_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1491, in _next_data
    idx, data = self._get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1453, in _get_data
    success, data = self._try_get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1297, in _try_get_data
    raise RuntimeError(
RuntimeError: DataLoader worker (pid(s) 36260) exited unexpectedly
# Accounting: begin_time=1750873482
# Accounting: end_time=1750873628
# Accounting: time=146 threads=1
# Finished at Wed Jun 25 13:47:08 EDT 2025 with status 1
# Running on r217.ib.bridges2.psc.edu
# Started at Wed Jun 25 13:44:42 EDT 2025
# SLURMD_NODENAME=r217
# SLURM_ARRAY_JOB_ID=32990217
# SLURM_ARRAY_TASK_COUNT=32
# SLURM_ARRAY_TASK_ID=31
# SLURM_ARRAY_TASK_MAX=32
# SLURM_ARRAY_TASK_MIN=1
# SLURM_ARRAY_TASK_STEP=1
# SLURM_CLUSTER_NAME=bridges2
# SLURM_CONF=/var/spool/slurm/d/conf-cache/slurm.conf
# SLURM_CPUS_ON_NODE=1
# SLURM_CPU_BIND=quiet,mask_cpu:0x07C0000000
# SLURM_CPU_BIND_LIST=0x07C0000000
# SLURM_CPU_BIND_TYPE=mask_cpu:
# SLURM_CPU_BIND_VERBOSE=quiet
# SLURM_EXPORT_ENV=ALL
# SLURM_GET_USER_ENV=1
# SLURM_GTIDS=0
# SLURM_JOBID=32990275
# SLURM_JOB_ACCOUNT=cis210027p
# SLURM_JOB_CPUS_PER_NODE=1
# SLURM_JOB_GID=24886
# SLURM_JOB_ID=32990275
# SLURM_JOB_NAME=stats.sh
# SLURM_JOB_NODELIST=r217
# SLURM_JOB_NUM_NODES=1
# SLURM_JOB_PARTITION=RM-shared
# SLURM_JOB_QOS=rm
# SLURM_JOB_UID=97947
# SLURM_JOB_USER=ttao3
# SLURM_LAUNCH_NODE_IPADDR=10.8.11.29
# SLURM_LOCALID=0
# SLURM_MEM_PER_CPU=1900
# SLURM_NNODES=1
# SLURM_NODEID=0
# SLURM_NODELIST=r217
# SLURM_NODE_ALIASES='(null)'
# SLURM_NPROCS=1
# SLURM_NTASKS=1
# SLURM_OPEN_MODE=a
# SLURM_PRIO_PROCESS=0
# SLURM_PROCID=0
# SLURM_PTY_PORT=33025
# SLURM_PTY_WIN_COL=126
# SLURM_PTY_WIN_ROW=21
# SLURM_SCRIPT_CONTEXT=prolog_task
# SLURM_SRUN_COMM_HOST=10.8.11.29
# SLURM_SRUN_COMM_PORT=35045
# SLURM_STEPID=0
# SLURM_STEP_GPUS=6
# SLURM_STEP_ID=0
# SLURM_STEP_LAUNCHER_PORT=35045
# SLURM_STEP_NODELIST=v029
# SLURM_STEP_NUM_NODES=1
# SLURM_STEP_NUM_TASKS=1
# SLURM_STEP_TASKS_PER_NODE=1
# SLURM_SUBMIT_DIR=/ocean/projects/cis210027p/ttao3/espnet/egs2/hifitts/tts1
# SLURM_SUBMIT_HOST=v029.ib.bridges2.psc.edu
# SLURM_TASKS_PER_NODE=1
# SLURM_TASK_PID=36120
# SLURM_TOPOLOGY_ADDR=r217
# SLURM_TOPOLOGY_ADDR_PATTERN=node
# SLURM_WORKING_CLUSTER=bridges2:br003:6810:9728:109
# python3 -m espnet2.bin.gan_tts_train --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.31.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.31.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.31 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int 
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/librosa/util/files.py:10: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_filename
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/bin/python3 /ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.31.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.31.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.31 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int
Failed to import Flash Attention, using ESPnet default: No module named 'flash_attn_2_cuda'
Vocabulary size: 74
encoder self-attention layer type = relative self-attention
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/ocean/projects/cis210027p/ttao3/espnet/espnet2/gan_tts/vits/monotonic_align/__init__.py:19: UserWarning: Cython version is not available. Fallback to 'EXPERIMETAL' numba version. If you want to use the cython version, please build it as follows: `cd espnet2/gan_tts/vits/monotonic_align; python setup.py build_ext --inplace`
  warnings.warn(
pytorch.version=2.7.1+cu126, cuda.available=False, cudnn.version=90501, cudnn.benchmark=False, cudnn.deterministic=False
Model structure:
ESPnetGANTTSModel(
  (feats_extract): LinearSpectrogram(
    (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
  )
  (tts): VITS(
    (generator): VITSGenerator(
      (text_encoder): TextEncoder(
        (emb): Embedding(74, 192)
        (encoder): Encoder(
          (embed): Sequential(
            (0): RelPositionalEncoding(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (encoders): MultiSequential(
            (0): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (2): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (3): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (4): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (5): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (after_norm): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (decoder): HiFiGANGenerator(
        (input_conv): Conv1d(192, 512, kernel_size=(7,), stride=(1,), padding=(3,))
        (upsamples): ModuleList(
          (0): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (1): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(256, 128, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (2): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,))
          )
          (3): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,))
          )
        )
        (blocks): ModuleList(
          (0): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (1): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (2): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (3): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (4): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (5): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (6): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (7): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (8): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (9): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (10): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (11): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
        )
        (output_conv): Sequential(
          (0): LeakyReLU(negative_slope=0.01)
          (1): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,))
          (2): Tanh()
        )
        (global_conv): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
      )
      (posterior_encoder): PosteriorEncoder(
        (input_conv): Conv1d(513, 192, kernel_size=(1,), stride=(1,))
        (encoder): WaveNet(
          (conv_layers): ModuleList(
            (0-15): 16 x ResidualBlock(
              (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
              (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
              (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
            )
          )
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (flow): ResidualAffineCouplingBlock(
        (flows): ModuleList(
          (0): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (1): FlipFlow()
          (2): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (3): FlipFlow()
          (4): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (5): FlipFlow()
          (6): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (7): FlipFlow()
        )
      )
      (duration_predictor): StochasticDurationPredictor(
        (pre): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (log_flow): LogFlow()
        (flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (post_pre): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
        (post_dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (post_proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (post_flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (global_conv): Conv1d(256, 192, kernel_size=(1,), stride=(1,))
      )
      (global_emb): Embedding(128, 256)
    )
    (discriminator): HiFiGANMultiScaleMultiPeriodDiscriminator(
      (msd): HiFiGANMultiScaleDiscriminator(
        (discriminators): ModuleList(
          (0): HiFiGANScaleDiscriminator(
            (layers): ModuleList(
              (0): Sequential(
                (0): Conv1d(1, 128, kernel_size=(15,), stride=(1,), padding=(7,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv1d(128, 128, kernel_size=(41,), stride=(2,), padding=(20,), groups=4)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv1d(128, 256, kernel_size=(41,), stride=(2,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv1d(256, 512, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv1d(512, 1024, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (5): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(41,), stride=(1,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (6): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (7): Conv1d(1024, 1, kernel_size=(3,), stride=(1,), padding=(1,))
            )
          )
        )
      )
      (mpd): HiFiGANMultiPeriodDiscriminator(
        (discriminators): ModuleList(
          (0-4): 5 x HiFiGANPeriodDiscriminator(
            (convs): ModuleList(
              (0): Sequential(
                (0): Conv2d(1, 32, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv2d(32, 128, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv2d(128, 512, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv2d(512, 1024, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv2d(1024, 1024, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
            )
            (output_conv): Conv2d(1024, 1, kernel_size=(2, 1), stride=(1, 1), padding=(1, 0))
          )
        )
      )
    )
    (generator_adv_loss): GeneratorAdversarialLoss()
    (discriminator_adv_loss): DiscriminatorAdversarialLoss()
    (feat_match_loss): FeatureMatchLoss()
    (mel_loss): MelSpectrogramLoss(
      (wav_to_mel): LogMelFbank(
        (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
        (logmel): LogMel(sr=22050, n_fft=1024, n_mels=80, fmin=0, fmax=11025.0, htk=False)
      )
    )
    (kl_loss): KLDivergenceLoss()
  )
)

Model summary:
    Class Name: ESPnetGANTTSModel
    Total Number of model parameters: 96.37 M
    Number of trainable parameters: 96.37 M (100.0%)
    Size: 385.46 MB
    Type: torch.float32
Optimizer:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler: <torch.optim.lr_scheduler.ExponentialLR object at 0x150ee3dcb5e0>
Optimizer2:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler2: <torch.optim.lr_scheduler.ExponentialLR object at 0x150ee3dcb9d0>
Saving the configuration in exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.31/config.yaml
Namespace(config='conf/tuning/train_multi_spk_vits.yaml', print_config=False, log_level='INFO', drop_last_iter=False, dry_run=False, iterator_type='sequence', valid_iterator_type=None, output_dir='exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.31', ngpu=0, seed=777, num_workers=4, num_att_plot=3, dist_backend='nccl', dist_init_method='env://', dist_world_size=None, dist_rank=None, local_rank=None, dist_master_addr=None, dist_master_port=None, dist_launcher=None, multiprocessing_distributed=False, unused_parameters=True, sharded_ddp=False, use_deepspeed=False, deepspeed_config=None, gradient_as_bucket_view=True, ddp_comm_hook=None, cudnn_enabled=True, cudnn_benchmark=False, cudnn_deterministic=False, use_tf32=False, collect_stats=True, write_collected_feats=False, max_epoch=1000, patience=None, val_scheduler_criterion=('valid', 'loss'), early_stopping_criterion=('valid', 'loss', 'min'), best_model_criterion=[['train', 'total_count', 'max']], keep_nbest_models=10, nbest_averaging_interval=0, grad_clip=-1, grad_clip_type=2.0, grad_noise=False, accum_grad=1, no_forward_run=False, resume=False, train_dtype='float32', use_amp=False, log_interval=50, use_matplotlib=True, use_tensorboard=True, create_graph_in_tensorboard=False, use_wandb=False, wandb_project=None, wandb_id=None, wandb_entity=None, wandb_name=None, wandb_model_log_interval=-1, detect_anomaly=False, use_adapter=False, adapter='lora', save_strategy='all', adapter_conf={}, pretrain_path=None, init_param=[], ignore_init_mismatch=False, freeze_param=[], num_iters_per_epoch=1000, batch_size=20, valid_batch_size=None, batch_bins=3000000, valid_batch_bins=None, category_sample_size=10, train_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.31.scp'], valid_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.31.scp'], batch_type='numel', valid_batch_type=None, fold_length=[], sort_in_batch='descending', shuffle_within_batch=False, sort_batch='descending', multiple_iterator=False, chunk_length=500, chunk_shift_ratio=0.5, num_cache_chunks=1024, chunk_excluded_key_prefixes=[], chunk_default_fs=None, chunk_max_abs_length=None, chunk_discard_short_samples=True, train_data_path_and_name_and_type=[('dump/22k/raw/tr_no_dev/text', 'text', 'text'), ('dump/22k/raw/tr_no_dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/tr_no_dev/utt2sid', 'sids', 'text_int')], valid_data_path_and_name_and_type=[('dump/22k/raw/dev/text', 'text', 'text'), ('dump/22k/raw/dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/dev/utt2sid', 'sids', 'text_int')], multi_task_dataset=False, allow_variable_data_keys=False, max_cache_size=0.0, max_cache_fd=32, allow_multi_rates=False, valid_max_cache_size=None, exclude_weight_decay=False, exclude_weight_decay_conf={}, optim='adamw', optim_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler='exponentiallr', scheduler_conf={'gamma': 0.999875}, optim2='adamw', optim2_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler2='exponentiallr', scheduler2_conf={'gamma': 0.999875}, generator_first=False, skip_discriminator_prob=0.0, token_list=['<blank>', '<unk>', ' ', 'AH0', 'N', 'T', 'D', 'S', 'R', 'L', 'IH1', 'DH', 'M', 'EH1', 'Z', 'AE1', 'K', 'IH0', 'AH1', 'HH', 'W', 'ER0', 'V', 'IY1', 'F', 'UW1', 'P', 'AY1', 'B', 'AA1', 'AO1', 'EY1', 'IY0', 'OW1', 'NG', 'SH', 'G', 'Y', 'AW1', 'CH', 'ER1', 'UH1', 'TH', 'JH', 'OW0', 'EH2', 'IH2', 'OY1', 'EY2', 'AY2', 'EH0', 'UW0', 'AA2', 'AE2', 'OW2', 'AH2', 'AA0', 'ZH', 'AE0', 'AO2', 'UW2', 'AO0', 'AY0', 'IY2', 'AW2', 'UH2', 'EY0', 'ER2', 'AW0', 'UH0', 'OY2', 'OY0', "'", '<sos/eos>'], odim=None, model_conf={}, use_preprocessor=True, token_type='phn', bpemodel=None, non_linguistic_symbols=None, cleaner='tacotron', g2p='g2p_en', feats_extract='linear_spectrogram', feats_extract_conf={'n_fft': 1024, 'hop_length': 256, 'win_length': None}, normalize=None, normalize_conf={}, tts='vits', tts_conf={'generator_type': 'vits_generator', 'generator_params': {'hidden_channels': 192, 'spks': 128, 'global_channels': 256, 'segment_size': 32, 'text_encoder_attention_heads': 2, 'text_encoder_ffn_expand': 4, 'text_encoder_blocks': 6, 'text_encoder_positionwise_layer_type': 'conv1d', 'text_encoder_positionwise_conv_kernel_size': 3, 'text_encoder_positional_encoding_layer_type': 'rel_pos', 'text_encoder_self_attention_layer_type': 'rel_selfattn', 'text_encoder_activation_type': 'swish', 'text_encoder_normalize_before': True, 'text_encoder_dropout_rate': 0.1, 'text_encoder_positional_dropout_rate': 0.0, 'text_encoder_attention_dropout_rate': 0.1, 'use_macaron_style_in_text_encoder': True, 'use_conformer_conv_in_text_encoder': False, 'text_encoder_conformer_kernel_size': -1, 'decoder_kernel_size': 7, 'decoder_channels': 512, 'decoder_upsample_scales': [8, 8, 2, 2], 'decoder_upsample_kernel_sizes': [16, 16, 4, 4], 'decoder_resblock_kernel_sizes': [3, 7, 11], 'decoder_resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'use_weight_norm_in_decoder': True, 'posterior_encoder_kernel_size': 5, 'posterior_encoder_layers': 16, 'posterior_encoder_stacks': 1, 'posterior_encoder_base_dilation': 1, 'posterior_encoder_dropout_rate': 0.0, 'use_weight_norm_in_posterior_encoder': True, 'flow_flows': 4, 'flow_kernel_size': 5, 'flow_base_dilation': 1, 'flow_layers': 4, 'flow_dropout_rate': 0.0, 'use_weight_norm_in_flow': True, 'use_only_mean_in_flow': True, 'stochastic_duration_predictor_kernel_size': 3, 'stochastic_duration_predictor_dropout_rate': 0.5, 'stochastic_duration_predictor_flows': 4, 'stochastic_duration_predictor_dds_conv_layers': 3, 'vocabs': 74, 'aux_channels': 513}, 'discriminator_type': 'hifigan_multi_scale_multi_period_discriminator', 'discriminator_params': {'scales': 1, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'stride': 2, 'padding': 2}, 'scale_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'channels': 128, 'max_downsample_channels': 1024, 'max_groups': 16, 'bias': True, 'downsample_scales': [2, 2, 4, 4, 1], 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}, 'follow_official_norm': False, 'periods': [2, 3, 5, 7, 11], 'period_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [5, 3], 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'max_downsample_channels': 1024, 'bias': True, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}}, 'generator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'discriminator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'feat_match_loss_params': {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, 'mel_loss_params': {'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None, 'window': 'hann', 'n_mels': 80, 'fmin': 0, 'fmax': None, 'log_base': None}, 'lambda_adv': 1.0, 'lambda_mel': 45.0, 'lambda_feat_match': 2.0, 'lambda_dur': 1.0, 'lambda_kl': 1.0, 'sampling_rate': 22050, 'cache_generator_outputs': True, 'plot_pred_mos': False, 'mos_pred_tool': 'utmos'}, pitch_extract=None, pitch_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'f0max': 400, 'f0min': 80}, pitch_normalize=None, pitch_normalize_conf={}, energy_extract=None, energy_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None}, energy_normalize=None, energy_normalize_conf={}, required=['output_dir', 'token_list'], version='202503', distributed=False)
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1284, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 36259) is killed by signal: Killed. 

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 22, in <module>
    main()
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 18, in main
    GANTTSTask.main(cmd=cmd)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1225, in main
    cls.main_worker(args)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1441, in main_worker
    collect_stats(
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/main_funcs/collect_stats.py", line 51, in collect_stats
    for iiter, (keys, batch) in enumerate(itr, 1):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 733, in __next__
    data = self._next_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1491, in _next_data
    idx, data = self._get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1453, in _get_data
    success, data = self._try_get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1297, in _try_get_data
    raise RuntimeError(
RuntimeError: DataLoader worker (pid(s) 36259) exited unexpectedly
# Accounting: begin_time=1750873482
# Accounting: end_time=1750873628
# Accounting: time=146 threads=1
# Finished at Wed Jun 25 13:47:08 EDT 2025 with status 1
# Running on r248.ib.bridges2.psc.edu
# Started at Wed Jun 25 13:44:42 EDT 2025
# SLURMD_NODENAME=r248
# SLURM_ARRAY_JOB_ID=32990217
# SLURM_ARRAY_TASK_COUNT=32
# SLURM_ARRAY_TASK_ID=32
# SLURM_ARRAY_TASK_MAX=32
# SLURM_ARRAY_TASK_MIN=1
# SLURM_ARRAY_TASK_STEP=1
# SLURM_CLUSTER_NAME=bridges2
# SLURM_CONF=/var/spool/slurm/d/conf-cache/slurm.conf
# SLURM_CPUS_ON_NODE=1
# SLURM_CPU_BIND=quiet,mask_cpu:0x07C0000000
# SLURM_CPU_BIND_LIST=0x07C0000000
# SLURM_CPU_BIND_TYPE=mask_cpu:
# SLURM_CPU_BIND_VERBOSE=quiet
# SLURM_EXPORT_ENV=ALL
# SLURM_GET_USER_ENV=1
# SLURM_GTIDS=0
# SLURM_JOBID=32990217
# SLURM_JOB_ACCOUNT=cis210027p
# SLURM_JOB_CPUS_PER_NODE=1
# SLURM_JOB_GID=24886
# SLURM_JOB_ID=32990217
# SLURM_JOB_NAME=stats.sh
# SLURM_JOB_NODELIST=r248
# SLURM_JOB_NUM_NODES=1
# SLURM_JOB_PARTITION=RM-shared
# SLURM_JOB_QOS=rm
# SLURM_JOB_UID=97947
# SLURM_JOB_USER=ttao3
# SLURM_LAUNCH_NODE_IPADDR=10.8.11.29
# SLURM_LOCALID=0
# SLURM_MEM_PER_CPU=1900
# SLURM_NNODES=1
# SLURM_NODEID=0
# SLURM_NODELIST=r248
# SLURM_NODE_ALIASES='(null)'
# SLURM_NPROCS=1
# SLURM_NTASKS=1
# SLURM_OPEN_MODE=a
# SLURM_PRIO_PROCESS=0
# SLURM_PROCID=0
# SLURM_PTY_PORT=33025
# SLURM_PTY_WIN_COL=126
# SLURM_PTY_WIN_ROW=21
# SLURM_SCRIPT_CONTEXT=prolog_task
# SLURM_SRUN_COMM_HOST=10.8.11.29
# SLURM_SRUN_COMM_PORT=35045
# SLURM_STEPID=0
# SLURM_STEP_GPUS=6
# SLURM_STEP_ID=0
# SLURM_STEP_LAUNCHER_PORT=35045
# SLURM_STEP_NODELIST=v029
# SLURM_STEP_NUM_NODES=1
# SLURM_STEP_NUM_TASKS=1
# SLURM_STEP_TASKS_PER_NODE=1
# SLURM_SUBMIT_DIR=/ocean/projects/cis210027p/ttao3/espnet/egs2/hifitts/tts1
# SLURM_SUBMIT_HOST=v029.ib.bridges2.psc.edu
# SLURM_TASKS_PER_NODE=1
# SLURM_TASK_PID=72483
# SLURM_TOPOLOGY_ADDR=r248
# SLURM_TOPOLOGY_ADDR_PATTERN=node
# SLURM_WORKING_CLUSTER=bridges2:br003:6810:9728:109
# python3 -m espnet2.bin.gan_tts_train --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.32.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.32.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.32 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int 
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/librosa/util/files.py:10: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_filename
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/bin/python3 /ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.32.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.32.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.32 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int
Failed to import Flash Attention, using ESPnet default: No module named 'flash_attn_2_cuda'
Vocabulary size: 74
encoder self-attention layer type = relative self-attention
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/ocean/projects/cis210027p/ttao3/espnet/espnet2/gan_tts/vits/monotonic_align/__init__.py:19: UserWarning: Cython version is not available. Fallback to 'EXPERIMETAL' numba version. If you want to use the cython version, please build it as follows: `cd espnet2/gan_tts/vits/monotonic_align; python setup.py build_ext --inplace`
  warnings.warn(
pytorch.version=2.7.1+cu126, cuda.available=False, cudnn.version=90501, cudnn.benchmark=False, cudnn.deterministic=False
Model structure:
ESPnetGANTTSModel(
  (feats_extract): LinearSpectrogram(
    (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
  )
  (tts): VITS(
    (generator): VITSGenerator(
      (text_encoder): TextEncoder(
        (emb): Embedding(74, 192)
        (encoder): Encoder(
          (embed): Sequential(
            (0): RelPositionalEncoding(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (encoders): MultiSequential(
            (0): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (2): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (3): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (4): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (5): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (after_norm): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (decoder): HiFiGANGenerator(
        (input_conv): Conv1d(192, 512, kernel_size=(7,), stride=(1,), padding=(3,))
        (upsamples): ModuleList(
          (0): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (1): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(256, 128, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (2): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,))
          )
          (3): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,))
          )
        )
        (blocks): ModuleList(
          (0): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (1): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (2): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (3): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (4): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (5): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (6): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (7): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (8): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (9): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (10): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (11): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
        )
        (output_conv): Sequential(
          (0): LeakyReLU(negative_slope=0.01)
          (1): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,))
          (2): Tanh()
        )
        (global_conv): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
      )
      (posterior_encoder): PosteriorEncoder(
        (input_conv): Conv1d(513, 192, kernel_size=(1,), stride=(1,))
        (encoder): WaveNet(
          (conv_layers): ModuleList(
            (0-15): 16 x ResidualBlock(
              (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
              (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
              (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
            )
          )
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (flow): ResidualAffineCouplingBlock(
        (flows): ModuleList(
          (0): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (1): FlipFlow()
          (2): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (3): FlipFlow()
          (4): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (5): FlipFlow()
          (6): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (7): FlipFlow()
        )
      )
      (duration_predictor): StochasticDurationPredictor(
        (pre): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (log_flow): LogFlow()
        (flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (post_pre): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
        (post_dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (post_proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (post_flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (global_conv): Conv1d(256, 192, kernel_size=(1,), stride=(1,))
      )
      (global_emb): Embedding(128, 256)
    )
    (discriminator): HiFiGANMultiScaleMultiPeriodDiscriminator(
      (msd): HiFiGANMultiScaleDiscriminator(
        (discriminators): ModuleList(
          (0): HiFiGANScaleDiscriminator(
            (layers): ModuleList(
              (0): Sequential(
                (0): Conv1d(1, 128, kernel_size=(15,), stride=(1,), padding=(7,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv1d(128, 128, kernel_size=(41,), stride=(2,), padding=(20,), groups=4)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv1d(128, 256, kernel_size=(41,), stride=(2,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv1d(256, 512, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv1d(512, 1024, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (5): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(41,), stride=(1,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (6): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (7): Conv1d(1024, 1, kernel_size=(3,), stride=(1,), padding=(1,))
            )
          )
        )
      )
      (mpd): HiFiGANMultiPeriodDiscriminator(
        (discriminators): ModuleList(
          (0-4): 5 x HiFiGANPeriodDiscriminator(
            (convs): ModuleList(
              (0): Sequential(
                (0): Conv2d(1, 32, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv2d(32, 128, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv2d(128, 512, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv2d(512, 1024, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv2d(1024, 1024, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
            )
            (output_conv): Conv2d(1024, 1, kernel_size=(2, 1), stride=(1, 1), padding=(1, 0))
          )
        )
      )
    )
    (generator_adv_loss): GeneratorAdversarialLoss()
    (discriminator_adv_loss): DiscriminatorAdversarialLoss()
    (feat_match_loss): FeatureMatchLoss()
    (mel_loss): MelSpectrogramLoss(
      (wav_to_mel): LogMelFbank(
        (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
        (logmel): LogMel(sr=22050, n_fft=1024, n_mels=80, fmin=0, fmax=11025.0, htk=False)
      )
    )
    (kl_loss): KLDivergenceLoss()
  )
)

Model summary:
    Class Name: ESPnetGANTTSModel
    Total Number of model parameters: 96.37 M
    Number of trainable parameters: 96.37 M (100.0%)
    Size: 385.46 MB
    Type: torch.float32
Optimizer:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler: <torch.optim.lr_scheduler.ExponentialLR object at 0x15002b224640>
Optimizer2:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler2: <torch.optim.lr_scheduler.ExponentialLR object at 0x15002b224a30>
Saving the configuration in exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.32/config.yaml
Namespace(config='conf/tuning/train_multi_spk_vits.yaml', print_config=False, log_level='INFO', drop_last_iter=False, dry_run=False, iterator_type='sequence', valid_iterator_type=None, output_dir='exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.32', ngpu=0, seed=777, num_workers=4, num_att_plot=3, dist_backend='nccl', dist_init_method='env://', dist_world_size=None, dist_rank=None, local_rank=None, dist_master_addr=None, dist_master_port=None, dist_launcher=None, multiprocessing_distributed=False, unused_parameters=True, sharded_ddp=False, use_deepspeed=False, deepspeed_config=None, gradient_as_bucket_view=True, ddp_comm_hook=None, cudnn_enabled=True, cudnn_benchmark=False, cudnn_deterministic=False, use_tf32=False, collect_stats=True, write_collected_feats=False, max_epoch=1000, patience=None, val_scheduler_criterion=('valid', 'loss'), early_stopping_criterion=('valid', 'loss', 'min'), best_model_criterion=[['train', 'total_count', 'max']], keep_nbest_models=10, nbest_averaging_interval=0, grad_clip=-1, grad_clip_type=2.0, grad_noise=False, accum_grad=1, no_forward_run=False, resume=False, train_dtype='float32', use_amp=False, log_interval=50, use_matplotlib=True, use_tensorboard=True, create_graph_in_tensorboard=False, use_wandb=False, wandb_project=None, wandb_id=None, wandb_entity=None, wandb_name=None, wandb_model_log_interval=-1, detect_anomaly=False, use_adapter=False, adapter='lora', save_strategy='all', adapter_conf={}, pretrain_path=None, init_param=[], ignore_init_mismatch=False, freeze_param=[], num_iters_per_epoch=1000, batch_size=20, valid_batch_size=None, batch_bins=3000000, valid_batch_bins=None, category_sample_size=10, train_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.32.scp'], valid_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.32.scp'], batch_type='numel', valid_batch_type=None, fold_length=[], sort_in_batch='descending', shuffle_within_batch=False, sort_batch='descending', multiple_iterator=False, chunk_length=500, chunk_shift_ratio=0.5, num_cache_chunks=1024, chunk_excluded_key_prefixes=[], chunk_default_fs=None, chunk_max_abs_length=None, chunk_discard_short_samples=True, train_data_path_and_name_and_type=[('dump/22k/raw/tr_no_dev/text', 'text', 'text'), ('dump/22k/raw/tr_no_dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/tr_no_dev/utt2sid', 'sids', 'text_int')], valid_data_path_and_name_and_type=[('dump/22k/raw/dev/text', 'text', 'text'), ('dump/22k/raw/dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/dev/utt2sid', 'sids', 'text_int')], multi_task_dataset=False, allow_variable_data_keys=False, max_cache_size=0.0, max_cache_fd=32, allow_multi_rates=False, valid_max_cache_size=None, exclude_weight_decay=False, exclude_weight_decay_conf={}, optim='adamw', optim_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler='exponentiallr', scheduler_conf={'gamma': 0.999875}, optim2='adamw', optim2_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler2='exponentiallr', scheduler2_conf={'gamma': 0.999875}, generator_first=False, skip_discriminator_prob=0.0, token_list=['<blank>', '<unk>', ' ', 'AH0', 'N', 'T', 'D', 'S', 'R', 'L', 'IH1', 'DH', 'M', 'EH1', 'Z', 'AE1', 'K', 'IH0', 'AH1', 'HH', 'W', 'ER0', 'V', 'IY1', 'F', 'UW1', 'P', 'AY1', 'B', 'AA1', 'AO1', 'EY1', 'IY0', 'OW1', 'NG', 'SH', 'G', 'Y', 'AW1', 'CH', 'ER1', 'UH1', 'TH', 'JH', 'OW0', 'EH2', 'IH2', 'OY1', 'EY2', 'AY2', 'EH0', 'UW0', 'AA2', 'AE2', 'OW2', 'AH2', 'AA0', 'ZH', 'AE0', 'AO2', 'UW2', 'AO0', 'AY0', 'IY2', 'AW2', 'UH2', 'EY0', 'ER2', 'AW0', 'UH0', 'OY2', 'OY0', "'", '<sos/eos>'], odim=None, model_conf={}, use_preprocessor=True, token_type='phn', bpemodel=None, non_linguistic_symbols=None, cleaner='tacotron', g2p='g2p_en', feats_extract='linear_spectrogram', feats_extract_conf={'n_fft': 1024, 'hop_length': 256, 'win_length': None}, normalize=None, normalize_conf={}, tts='vits', tts_conf={'generator_type': 'vits_generator', 'generator_params': {'hidden_channels': 192, 'spks': 128, 'global_channels': 256, 'segment_size': 32, 'text_encoder_attention_heads': 2, 'text_encoder_ffn_expand': 4, 'text_encoder_blocks': 6, 'text_encoder_positionwise_layer_type': 'conv1d', 'text_encoder_positionwise_conv_kernel_size': 3, 'text_encoder_positional_encoding_layer_type': 'rel_pos', 'text_encoder_self_attention_layer_type': 'rel_selfattn', 'text_encoder_activation_type': 'swish', 'text_encoder_normalize_before': True, 'text_encoder_dropout_rate': 0.1, 'text_encoder_positional_dropout_rate': 0.0, 'text_encoder_attention_dropout_rate': 0.1, 'use_macaron_style_in_text_encoder': True, 'use_conformer_conv_in_text_encoder': False, 'text_encoder_conformer_kernel_size': -1, 'decoder_kernel_size': 7, 'decoder_channels': 512, 'decoder_upsample_scales': [8, 8, 2, 2], 'decoder_upsample_kernel_sizes': [16, 16, 4, 4], 'decoder_resblock_kernel_sizes': [3, 7, 11], 'decoder_resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'use_weight_norm_in_decoder': True, 'posterior_encoder_kernel_size': 5, 'posterior_encoder_layers': 16, 'posterior_encoder_stacks': 1, 'posterior_encoder_base_dilation': 1, 'posterior_encoder_dropout_rate': 0.0, 'use_weight_norm_in_posterior_encoder': True, 'flow_flows': 4, 'flow_kernel_size': 5, 'flow_base_dilation': 1, 'flow_layers': 4, 'flow_dropout_rate': 0.0, 'use_weight_norm_in_flow': True, 'use_only_mean_in_flow': True, 'stochastic_duration_predictor_kernel_size': 3, 'stochastic_duration_predictor_dropout_rate': 0.5, 'stochastic_duration_predictor_flows': 4, 'stochastic_duration_predictor_dds_conv_layers': 3, 'vocabs': 74, 'aux_channels': 513}, 'discriminator_type': 'hifigan_multi_scale_multi_period_discriminator', 'discriminator_params': {'scales': 1, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'stride': 2, 'padding': 2}, 'scale_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'channels': 128, 'max_downsample_channels': 1024, 'max_groups': 16, 'bias': True, 'downsample_scales': [2, 2, 4, 4, 1], 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}, 'follow_official_norm': False, 'periods': [2, 3, 5, 7, 11], 'period_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [5, 3], 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'max_downsample_channels': 1024, 'bias': True, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}}, 'generator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'discriminator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'feat_match_loss_params': {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, 'mel_loss_params': {'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None, 'window': 'hann', 'n_mels': 80, 'fmin': 0, 'fmax': None, 'log_base': None}, 'lambda_adv': 1.0, 'lambda_mel': 45.0, 'lambda_feat_match': 2.0, 'lambda_dur': 1.0, 'lambda_kl': 1.0, 'sampling_rate': 22050, 'cache_generator_outputs': True, 'plot_pred_mos': False, 'mos_pred_tool': 'utmos'}, pitch_extract=None, pitch_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'f0max': 400, 'f0min': 80}, pitch_normalize=None, pitch_normalize_conf={}, energy_extract=None, energy_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None}, energy_normalize=None, energy_normalize_conf={}, required=['output_dir', 'token_list'], version='202503', distributed=False)
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1284, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 73129) is killed by signal: Killed. 

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 22, in <module>
    main()
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 18, in main
    GANTTSTask.main(cmd=cmd)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1225, in main
    cls.main_worker(args)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1441, in main_worker
    collect_stats(
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/main_funcs/collect_stats.py", line 51, in collect_stats
    for iiter, (keys, batch) in enumerate(itr, 1):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 733, in __next__
    data = self._next_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1491, in _next_data
    idx, data = self._get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1453, in _get_data
    success, data = self._try_get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1297, in _try_get_data
    raise RuntimeError(
RuntimeError: DataLoader worker (pid(s) 73129) exited unexpectedly
# Accounting: begin_time=1750873482
# Accounting: end_time=1750873631
# Accounting: time=149 threads=1
# Finished at Wed Jun 25 13:47:11 EDT 2025 with status 1
# Running on r023.ib.bridges2.psc.edu
# Started at Wed Jun 25 13:40:56 EDT 2025
# SLURMD_NODENAME=r023
# SLURM_ARRAY_JOB_ID=32990217
# SLURM_ARRAY_TASK_COUNT=32
# SLURM_ARRAY_TASK_ID=4
# SLURM_ARRAY_TASK_MAX=32
# SLURM_ARRAY_TASK_MIN=1
# SLURM_ARRAY_TASK_STEP=1
# SLURM_CLUSTER_NAME=bridges2
# SLURM_CONF=/var/spool/slurm/d/conf-cache/slurm.conf
# SLURM_CPUS_ON_NODE=1
# SLURM_CPU_BIND=quiet,mask_cpu:0x07C0000000
# SLURM_CPU_BIND_LIST=0x07C0000000
# SLURM_CPU_BIND_TYPE=mask_cpu:
# SLURM_CPU_BIND_VERBOSE=quiet
# SLURM_EXPORT_ENV=ALL
# SLURM_GET_USER_ENV=1
# SLURM_GTIDS=0
# SLURM_JOBID=32990222
# SLURM_JOB_ACCOUNT=cis210027p
# SLURM_JOB_CPUS_PER_NODE=1
# SLURM_JOB_GID=24886
# SLURM_JOB_ID=32990222
# SLURM_JOB_NAME=stats.sh
# SLURM_JOB_NODELIST=r023
# SLURM_JOB_NUM_NODES=1
# SLURM_JOB_PARTITION=RM-shared
# SLURM_JOB_QOS=rm
# SLURM_JOB_UID=97947
# SLURM_JOB_USER=ttao3
# SLURM_LAUNCH_NODE_IPADDR=10.8.11.29
# SLURM_LOCALID=0
# SLURM_MEM_PER_CPU=1900
# SLURM_NNODES=1
# SLURM_NODEID=0
# SLURM_NODELIST=r023
# SLURM_NODE_ALIASES='(null)'
# SLURM_NPROCS=1
# SLURM_NTASKS=1
# SLURM_OPEN_MODE=a
# SLURM_PRIO_PROCESS=0
# SLURM_PROCID=0
# SLURM_PTY_PORT=33025
# SLURM_PTY_WIN_COL=126
# SLURM_PTY_WIN_ROW=21
# SLURM_SCRIPT_CONTEXT=prolog_task
# SLURM_SRUN_COMM_HOST=10.8.11.29
# SLURM_SRUN_COMM_PORT=35045
# SLURM_STEPID=0
# SLURM_STEP_GPUS=6
# SLURM_STEP_ID=0
# SLURM_STEP_LAUNCHER_PORT=35045
# SLURM_STEP_NODELIST=v029
# SLURM_STEP_NUM_NODES=1
# SLURM_STEP_NUM_TASKS=1
# SLURM_STEP_TASKS_PER_NODE=1
# SLURM_SUBMIT_DIR=/ocean/projects/cis210027p/ttao3/espnet/egs2/hifitts/tts1
# SLURM_SUBMIT_HOST=v029.ib.bridges2.psc.edu
# SLURM_TASKS_PER_NODE=1
# SLURM_TASK_PID=63746
# SLURM_TOPOLOGY_ADDR=r023
# SLURM_TOPOLOGY_ADDR_PATTERN=node
# SLURM_WORKING_CLUSTER=bridges2:br003:6810:9728:109
# python3 -m espnet2.bin.gan_tts_train --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.4.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.4.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.4 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int 
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/librosa/util/files.py:10: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_filename
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/bin/python3 /ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.4.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.4.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.4 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int
Failed to import Flash Attention, using ESPnet default: No module named 'flash_attn_2_cuda'
Vocabulary size: 74
encoder self-attention layer type = relative self-attention
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/ocean/projects/cis210027p/ttao3/espnet/espnet2/gan_tts/vits/monotonic_align/__init__.py:19: UserWarning: Cython version is not available. Fallback to 'EXPERIMETAL' numba version. If you want to use the cython version, please build it as follows: `cd espnet2/gan_tts/vits/monotonic_align; python setup.py build_ext --inplace`
  warnings.warn(
pytorch.version=2.7.1+cu126, cuda.available=False, cudnn.version=90501, cudnn.benchmark=False, cudnn.deterministic=False
Model structure:
ESPnetGANTTSModel(
  (feats_extract): LinearSpectrogram(
    (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
  )
  (tts): VITS(
    (generator): VITSGenerator(
      (text_encoder): TextEncoder(
        (emb): Embedding(74, 192)
        (encoder): Encoder(
          (embed): Sequential(
            (0): RelPositionalEncoding(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (encoders): MultiSequential(
            (0): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (2): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (3): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (4): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (5): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (after_norm): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (decoder): HiFiGANGenerator(
        (input_conv): Conv1d(192, 512, kernel_size=(7,), stride=(1,), padding=(3,))
        (upsamples): ModuleList(
          (0): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (1): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(256, 128, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (2): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,))
          )
          (3): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,))
          )
        )
        (blocks): ModuleList(
          (0): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (1): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (2): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (3): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (4): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (5): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (6): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (7): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (8): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (9): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (10): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (11): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
        )
        (output_conv): Sequential(
          (0): LeakyReLU(negative_slope=0.01)
          (1): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,))
          (2): Tanh()
        )
        (global_conv): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
      )
      (posterior_encoder): PosteriorEncoder(
        (input_conv): Conv1d(513, 192, kernel_size=(1,), stride=(1,))
        (encoder): WaveNet(
          (conv_layers): ModuleList(
            (0-15): 16 x ResidualBlock(
              (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
              (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
              (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
            )
          )
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (flow): ResidualAffineCouplingBlock(
        (flows): ModuleList(
          (0): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (1): FlipFlow()
          (2): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (3): FlipFlow()
          (4): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (5): FlipFlow()
          (6): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (7): FlipFlow()
        )
      )
      (duration_predictor): StochasticDurationPredictor(
        (pre): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (log_flow): LogFlow()
        (flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (post_pre): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
        (post_dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (post_proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (post_flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (global_conv): Conv1d(256, 192, kernel_size=(1,), stride=(1,))
      )
      (global_emb): Embedding(128, 256)
    )
    (discriminator): HiFiGANMultiScaleMultiPeriodDiscriminator(
      (msd): HiFiGANMultiScaleDiscriminator(
        (discriminators): ModuleList(
          (0): HiFiGANScaleDiscriminator(
            (layers): ModuleList(
              (0): Sequential(
                (0): Conv1d(1, 128, kernel_size=(15,), stride=(1,), padding=(7,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv1d(128, 128, kernel_size=(41,), stride=(2,), padding=(20,), groups=4)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv1d(128, 256, kernel_size=(41,), stride=(2,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv1d(256, 512, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv1d(512, 1024, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (5): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(41,), stride=(1,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (6): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (7): Conv1d(1024, 1, kernel_size=(3,), stride=(1,), padding=(1,))
            )
          )
        )
      )
      (mpd): HiFiGANMultiPeriodDiscriminator(
        (discriminators): ModuleList(
          (0-4): 5 x HiFiGANPeriodDiscriminator(
            (convs): ModuleList(
              (0): Sequential(
                (0): Conv2d(1, 32, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv2d(32, 128, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv2d(128, 512, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv2d(512, 1024, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv2d(1024, 1024, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
            )
            (output_conv): Conv2d(1024, 1, kernel_size=(2, 1), stride=(1, 1), padding=(1, 0))
          )
        )
      )
    )
    (generator_adv_loss): GeneratorAdversarialLoss()
    (discriminator_adv_loss): DiscriminatorAdversarialLoss()
    (feat_match_loss): FeatureMatchLoss()
    (mel_loss): MelSpectrogramLoss(
      (wav_to_mel): LogMelFbank(
        (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
        (logmel): LogMel(sr=22050, n_fft=1024, n_mels=80, fmin=0, fmax=11025.0, htk=False)
      )
    )
    (kl_loss): KLDivergenceLoss()
  )
)

Model summary:
    Class Name: ESPnetGANTTSModel
    Total Number of model parameters: 96.37 M
    Number of trainable parameters: 96.37 M (100.0%)
    Size: 385.46 MB
    Type: torch.float32
Optimizer:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler: <torch.optim.lr_scheduler.ExponentialLR object at 0x151aed6655b0>
Optimizer2:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler2: <torch.optim.lr_scheduler.ExponentialLR object at 0x151aed665970>
Saving the configuration in exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.4/config.yaml
Namespace(config='conf/tuning/train_multi_spk_vits.yaml', print_config=False, log_level='INFO', drop_last_iter=False, dry_run=False, iterator_type='sequence', valid_iterator_type=None, output_dir='exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.4', ngpu=0, seed=777, num_workers=4, num_att_plot=3, dist_backend='nccl', dist_init_method='env://', dist_world_size=None, dist_rank=None, local_rank=None, dist_master_addr=None, dist_master_port=None, dist_launcher=None, multiprocessing_distributed=False, unused_parameters=True, sharded_ddp=False, use_deepspeed=False, deepspeed_config=None, gradient_as_bucket_view=True, ddp_comm_hook=None, cudnn_enabled=True, cudnn_benchmark=False, cudnn_deterministic=False, use_tf32=False, collect_stats=True, write_collected_feats=False, max_epoch=1000, patience=None, val_scheduler_criterion=('valid', 'loss'), early_stopping_criterion=('valid', 'loss', 'min'), best_model_criterion=[['train', 'total_count', 'max']], keep_nbest_models=10, nbest_averaging_interval=0, grad_clip=-1, grad_clip_type=2.0, grad_noise=False, accum_grad=1, no_forward_run=False, resume=False, train_dtype='float32', use_amp=False, log_interval=50, use_matplotlib=True, use_tensorboard=True, create_graph_in_tensorboard=False, use_wandb=False, wandb_project=None, wandb_id=None, wandb_entity=None, wandb_name=None, wandb_model_log_interval=-1, detect_anomaly=False, use_adapter=False, adapter='lora', save_strategy='all', adapter_conf={}, pretrain_path=None, init_param=[], ignore_init_mismatch=False, freeze_param=[], num_iters_per_epoch=1000, batch_size=20, valid_batch_size=None, batch_bins=3000000, valid_batch_bins=None, category_sample_size=10, train_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.4.scp'], valid_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.4.scp'], batch_type='numel', valid_batch_type=None, fold_length=[], sort_in_batch='descending', shuffle_within_batch=False, sort_batch='descending', multiple_iterator=False, chunk_length=500, chunk_shift_ratio=0.5, num_cache_chunks=1024, chunk_excluded_key_prefixes=[], chunk_default_fs=None, chunk_max_abs_length=None, chunk_discard_short_samples=True, train_data_path_and_name_and_type=[('dump/22k/raw/tr_no_dev/text', 'text', 'text'), ('dump/22k/raw/tr_no_dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/tr_no_dev/utt2sid', 'sids', 'text_int')], valid_data_path_and_name_and_type=[('dump/22k/raw/dev/text', 'text', 'text'), ('dump/22k/raw/dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/dev/utt2sid', 'sids', 'text_int')], multi_task_dataset=False, allow_variable_data_keys=False, max_cache_size=0.0, max_cache_fd=32, allow_multi_rates=False, valid_max_cache_size=None, exclude_weight_decay=False, exclude_weight_decay_conf={}, optim='adamw', optim_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler='exponentiallr', scheduler_conf={'gamma': 0.999875}, optim2='adamw', optim2_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler2='exponentiallr', scheduler2_conf={'gamma': 0.999875}, generator_first=False, skip_discriminator_prob=0.0, token_list=['<blank>', '<unk>', ' ', 'AH0', 'N', 'T', 'D', 'S', 'R', 'L', 'IH1', 'DH', 'M', 'EH1', 'Z', 'AE1', 'K', 'IH0', 'AH1', 'HH', 'W', 'ER0', 'V', 'IY1', 'F', 'UW1', 'P', 'AY1', 'B', 'AA1', 'AO1', 'EY1', 'IY0', 'OW1', 'NG', 'SH', 'G', 'Y', 'AW1', 'CH', 'ER1', 'UH1', 'TH', 'JH', 'OW0', 'EH2', 'IH2', 'OY1', 'EY2', 'AY2', 'EH0', 'UW0', 'AA2', 'AE2', 'OW2', 'AH2', 'AA0', 'ZH', 'AE0', 'AO2', 'UW2', 'AO0', 'AY0', 'IY2', 'AW2', 'UH2', 'EY0', 'ER2', 'AW0', 'UH0', 'OY2', 'OY0', "'", '<sos/eos>'], odim=None, model_conf={}, use_preprocessor=True, token_type='phn', bpemodel=None, non_linguistic_symbols=None, cleaner='tacotron', g2p='g2p_en', feats_extract='linear_spectrogram', feats_extract_conf={'n_fft': 1024, 'hop_length': 256, 'win_length': None}, normalize=None, normalize_conf={}, tts='vits', tts_conf={'generator_type': 'vits_generator', 'generator_params': {'hidden_channels': 192, 'spks': 128, 'global_channels': 256, 'segment_size': 32, 'text_encoder_attention_heads': 2, 'text_encoder_ffn_expand': 4, 'text_encoder_blocks': 6, 'text_encoder_positionwise_layer_type': 'conv1d', 'text_encoder_positionwise_conv_kernel_size': 3, 'text_encoder_positional_encoding_layer_type': 'rel_pos', 'text_encoder_self_attention_layer_type': 'rel_selfattn', 'text_encoder_activation_type': 'swish', 'text_encoder_normalize_before': True, 'text_encoder_dropout_rate': 0.1, 'text_encoder_positional_dropout_rate': 0.0, 'text_encoder_attention_dropout_rate': 0.1, 'use_macaron_style_in_text_encoder': True, 'use_conformer_conv_in_text_encoder': False, 'text_encoder_conformer_kernel_size': -1, 'decoder_kernel_size': 7, 'decoder_channels': 512, 'decoder_upsample_scales': [8, 8, 2, 2], 'decoder_upsample_kernel_sizes': [16, 16, 4, 4], 'decoder_resblock_kernel_sizes': [3, 7, 11], 'decoder_resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'use_weight_norm_in_decoder': True, 'posterior_encoder_kernel_size': 5, 'posterior_encoder_layers': 16, 'posterior_encoder_stacks': 1, 'posterior_encoder_base_dilation': 1, 'posterior_encoder_dropout_rate': 0.0, 'use_weight_norm_in_posterior_encoder': True, 'flow_flows': 4, 'flow_kernel_size': 5, 'flow_base_dilation': 1, 'flow_layers': 4, 'flow_dropout_rate': 0.0, 'use_weight_norm_in_flow': True, 'use_only_mean_in_flow': True, 'stochastic_duration_predictor_kernel_size': 3, 'stochastic_duration_predictor_dropout_rate': 0.5, 'stochastic_duration_predictor_flows': 4, 'stochastic_duration_predictor_dds_conv_layers': 3, 'vocabs': 74, 'aux_channels': 513}, 'discriminator_type': 'hifigan_multi_scale_multi_period_discriminator', 'discriminator_params': {'scales': 1, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'stride': 2, 'padding': 2}, 'scale_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'channels': 128, 'max_downsample_channels': 1024, 'max_groups': 16, 'bias': True, 'downsample_scales': [2, 2, 4, 4, 1], 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}, 'follow_official_norm': False, 'periods': [2, 3, 5, 7, 11], 'period_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [5, 3], 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'max_downsample_channels': 1024, 'bias': True, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}}, 'generator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'discriminator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'feat_match_loss_params': {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, 'mel_loss_params': {'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None, 'window': 'hann', 'n_mels': 80, 'fmin': 0, 'fmax': None, 'log_base': None}, 'lambda_adv': 1.0, 'lambda_mel': 45.0, 'lambda_feat_match': 2.0, 'lambda_dur': 1.0, 'lambda_kl': 1.0, 'sampling_rate': 22050, 'cache_generator_outputs': True, 'plot_pred_mos': False, 'mos_pred_tool': 'utmos'}, pitch_extract=None, pitch_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'f0max': 400, 'f0min': 80}, pitch_normalize=None, pitch_normalize_conf={}, energy_extract=None, energy_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None}, energy_normalize=None, energy_normalize_conf={}, required=['output_dir', 'token_list'], version='202503', distributed=False)
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1284, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 64547) is killed by signal: Killed. 

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 22, in <module>
    main()
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 18, in main
    GANTTSTask.main(cmd=cmd)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1225, in main
    cls.main_worker(args)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1441, in main_worker
    collect_stats(
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/main_funcs/collect_stats.py", line 51, in collect_stats
    for iiter, (keys, batch) in enumerate(itr, 1):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 733, in __next__
    data = self._next_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1491, in _next_data
    idx, data = self._get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1453, in _get_data
    success, data = self._try_get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1297, in _try_get_data
    raise RuntimeError(
RuntimeError: DataLoader worker (pid(s) 64547, 64550) exited unexpectedly
# Accounting: begin_time=1750873256
# Accounting: end_time=1750873472
# Accounting: time=216 threads=1
# Finished at Wed Jun 25 13:44:32 EDT 2025 with status 1
# Running on r023.ib.bridges2.psc.edu
# Started at Wed Jun 25 13:40:56 EDT 2025
# SLURMD_NODENAME=r023
# SLURM_ARRAY_JOB_ID=32990217
# SLURM_ARRAY_TASK_COUNT=32
# SLURM_ARRAY_TASK_ID=5
# SLURM_ARRAY_TASK_MAX=32
# SLURM_ARRAY_TASK_MIN=1
# SLURM_ARRAY_TASK_STEP=1
# SLURM_CLUSTER_NAME=bridges2
# SLURM_CONF=/var/spool/slurm/d/conf-cache/slurm.conf
# SLURM_CPUS_ON_NODE=1
# SLURM_CPU_BIND=quiet,mask_cpu:0x07C0000000
# SLURM_CPU_BIND_LIST=0x07C0000000
# SLURM_CPU_BIND_TYPE=mask_cpu:
# SLURM_CPU_BIND_VERBOSE=quiet
# SLURM_EXPORT_ENV=ALL
# SLURM_GET_USER_ENV=1
# SLURM_GTIDS=0
# SLURM_JOBID=32990223
# SLURM_JOB_ACCOUNT=cis210027p
# SLURM_JOB_CPUS_PER_NODE=1
# SLURM_JOB_GID=24886
# SLURM_JOB_ID=32990223
# SLURM_JOB_NAME=stats.sh
# SLURM_JOB_NODELIST=r023
# SLURM_JOB_NUM_NODES=1
# SLURM_JOB_PARTITION=RM-shared
# SLURM_JOB_QOS=rm
# SLURM_JOB_UID=97947
# SLURM_JOB_USER=ttao3
# SLURM_LAUNCH_NODE_IPADDR=10.8.11.29
# SLURM_LOCALID=0
# SLURM_MEM_PER_CPU=1900
# SLURM_NNODES=1
# SLURM_NODEID=0
# SLURM_NODELIST=r023
# SLURM_NODE_ALIASES='(null)'
# SLURM_NPROCS=1
# SLURM_NTASKS=1
# SLURM_OPEN_MODE=a
# SLURM_PRIO_PROCESS=0
# SLURM_PROCID=0
# SLURM_PTY_PORT=33025
# SLURM_PTY_WIN_COL=126
# SLURM_PTY_WIN_ROW=21
# SLURM_SCRIPT_CONTEXT=prolog_task
# SLURM_SRUN_COMM_HOST=10.8.11.29
# SLURM_SRUN_COMM_PORT=35045
# SLURM_STEPID=0
# SLURM_STEP_GPUS=6
# SLURM_STEP_ID=0
# SLURM_STEP_LAUNCHER_PORT=35045
# SLURM_STEP_NODELIST=v029
# SLURM_STEP_NUM_NODES=1
# SLURM_STEP_NUM_TASKS=1
# SLURM_STEP_TASKS_PER_NODE=1
# SLURM_SUBMIT_DIR=/ocean/projects/cis210027p/ttao3/espnet/egs2/hifitts/tts1
# SLURM_SUBMIT_HOST=v029.ib.bridges2.psc.edu
# SLURM_TASKS_PER_NODE=1
# SLURM_TASK_PID=63756
# SLURM_TOPOLOGY_ADDR=r023
# SLURM_TOPOLOGY_ADDR_PATTERN=node
# SLURM_WORKING_CLUSTER=bridges2:br003:6810:9728:109
# python3 -m espnet2.bin.gan_tts_train --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.5.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.5.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.5 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int 
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/librosa/util/files.py:10: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_filename
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/bin/python3 /ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.5.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.5.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.5 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int
Failed to import Flash Attention, using ESPnet default: No module named 'flash_attn_2_cuda'
Vocabulary size: 74
encoder self-attention layer type = relative self-attention
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/ocean/projects/cis210027p/ttao3/espnet/espnet2/gan_tts/vits/monotonic_align/__init__.py:19: UserWarning: Cython version is not available. Fallback to 'EXPERIMETAL' numba version. If you want to use the cython version, please build it as follows: `cd espnet2/gan_tts/vits/monotonic_align; python setup.py build_ext --inplace`
  warnings.warn(
pytorch.version=2.7.1+cu126, cuda.available=False, cudnn.version=90501, cudnn.benchmark=False, cudnn.deterministic=False
Model structure:
ESPnetGANTTSModel(
  (feats_extract): LinearSpectrogram(
    (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
  )
  (tts): VITS(
    (generator): VITSGenerator(
      (text_encoder): TextEncoder(
        (emb): Embedding(74, 192)
        (encoder): Encoder(
          (embed): Sequential(
            (0): RelPositionalEncoding(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (encoders): MultiSequential(
            (0): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (2): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (3): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (4): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (5): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (after_norm): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (decoder): HiFiGANGenerator(
        (input_conv): Conv1d(192, 512, kernel_size=(7,), stride=(1,), padding=(3,))
        (upsamples): ModuleList(
          (0): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (1): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(256, 128, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (2): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,))
          )
          (3): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,))
          )
        )
        (blocks): ModuleList(
          (0): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (1): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (2): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (3): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (4): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (5): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (6): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (7): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (8): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (9): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (10): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (11): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
        )
        (output_conv): Sequential(
          (0): LeakyReLU(negative_slope=0.01)
          (1): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,))
          (2): Tanh()
        )
        (global_conv): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
      )
      (posterior_encoder): PosteriorEncoder(
        (input_conv): Conv1d(513, 192, kernel_size=(1,), stride=(1,))
        (encoder): WaveNet(
          (conv_layers): ModuleList(
            (0-15): 16 x ResidualBlock(
              (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
              (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
              (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
            )
          )
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (flow): ResidualAffineCouplingBlock(
        (flows): ModuleList(
          (0): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (1): FlipFlow()
          (2): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (3): FlipFlow()
          (4): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (5): FlipFlow()
          (6): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (7): FlipFlow()
        )
      )
      (duration_predictor): StochasticDurationPredictor(
        (pre): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (log_flow): LogFlow()
        (flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (post_pre): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
        (post_dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (post_proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (post_flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (global_conv): Conv1d(256, 192, kernel_size=(1,), stride=(1,))
      )
      (global_emb): Embedding(128, 256)
    )
    (discriminator): HiFiGANMultiScaleMultiPeriodDiscriminator(
      (msd): HiFiGANMultiScaleDiscriminator(
        (discriminators): ModuleList(
          (0): HiFiGANScaleDiscriminator(
            (layers): ModuleList(
              (0): Sequential(
                (0): Conv1d(1, 128, kernel_size=(15,), stride=(1,), padding=(7,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv1d(128, 128, kernel_size=(41,), stride=(2,), padding=(20,), groups=4)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv1d(128, 256, kernel_size=(41,), stride=(2,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv1d(256, 512, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv1d(512, 1024, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (5): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(41,), stride=(1,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (6): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (7): Conv1d(1024, 1, kernel_size=(3,), stride=(1,), padding=(1,))
            )
          )
        )
      )
      (mpd): HiFiGANMultiPeriodDiscriminator(
        (discriminators): ModuleList(
          (0-4): 5 x HiFiGANPeriodDiscriminator(
            (convs): ModuleList(
              (0): Sequential(
                (0): Conv2d(1, 32, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv2d(32, 128, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv2d(128, 512, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv2d(512, 1024, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv2d(1024, 1024, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
            )
            (output_conv): Conv2d(1024, 1, kernel_size=(2, 1), stride=(1, 1), padding=(1, 0))
          )
        )
      )
    )
    (generator_adv_loss): GeneratorAdversarialLoss()
    (discriminator_adv_loss): DiscriminatorAdversarialLoss()
    (feat_match_loss): FeatureMatchLoss()
    (mel_loss): MelSpectrogramLoss(
      (wav_to_mel): LogMelFbank(
        (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
        (logmel): LogMel(sr=22050, n_fft=1024, n_mels=80, fmin=0, fmax=11025.0, htk=False)
      )
    )
    (kl_loss): KLDivergenceLoss()
  )
)

Model summary:
    Class Name: ESPnetGANTTSModel
    Total Number of model parameters: 96.37 M
    Number of trainable parameters: 96.37 M (100.0%)
    Size: 385.46 MB
    Type: torch.float32
Optimizer:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler: <torch.optim.lr_scheduler.ExponentialLR object at 0x1467eab135e0>
Optimizer2:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler2: <torch.optim.lr_scheduler.ExponentialLR object at 0x1467eab139d0>
Saving the configuration in exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.5/config.yaml
Namespace(config='conf/tuning/train_multi_spk_vits.yaml', print_config=False, log_level='INFO', drop_last_iter=False, dry_run=False, iterator_type='sequence', valid_iterator_type=None, output_dir='exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.5', ngpu=0, seed=777, num_workers=4, num_att_plot=3, dist_backend='nccl', dist_init_method='env://', dist_world_size=None, dist_rank=None, local_rank=None, dist_master_addr=None, dist_master_port=None, dist_launcher=None, multiprocessing_distributed=False, unused_parameters=True, sharded_ddp=False, use_deepspeed=False, deepspeed_config=None, gradient_as_bucket_view=True, ddp_comm_hook=None, cudnn_enabled=True, cudnn_benchmark=False, cudnn_deterministic=False, use_tf32=False, collect_stats=True, write_collected_feats=False, max_epoch=1000, patience=None, val_scheduler_criterion=('valid', 'loss'), early_stopping_criterion=('valid', 'loss', 'min'), best_model_criterion=[['train', 'total_count', 'max']], keep_nbest_models=10, nbest_averaging_interval=0, grad_clip=-1, grad_clip_type=2.0, grad_noise=False, accum_grad=1, no_forward_run=False, resume=False, train_dtype='float32', use_amp=False, log_interval=50, use_matplotlib=True, use_tensorboard=True, create_graph_in_tensorboard=False, use_wandb=False, wandb_project=None, wandb_id=None, wandb_entity=None, wandb_name=None, wandb_model_log_interval=-1, detect_anomaly=False, use_adapter=False, adapter='lora', save_strategy='all', adapter_conf={}, pretrain_path=None, init_param=[], ignore_init_mismatch=False, freeze_param=[], num_iters_per_epoch=1000, batch_size=20, valid_batch_size=None, batch_bins=3000000, valid_batch_bins=None, category_sample_size=10, train_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.5.scp'], valid_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.5.scp'], batch_type='numel', valid_batch_type=None, fold_length=[], sort_in_batch='descending', shuffle_within_batch=False, sort_batch='descending', multiple_iterator=False, chunk_length=500, chunk_shift_ratio=0.5, num_cache_chunks=1024, chunk_excluded_key_prefixes=[], chunk_default_fs=None, chunk_max_abs_length=None, chunk_discard_short_samples=True, train_data_path_and_name_and_type=[('dump/22k/raw/tr_no_dev/text', 'text', 'text'), ('dump/22k/raw/tr_no_dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/tr_no_dev/utt2sid', 'sids', 'text_int')], valid_data_path_and_name_and_type=[('dump/22k/raw/dev/text', 'text', 'text'), ('dump/22k/raw/dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/dev/utt2sid', 'sids', 'text_int')], multi_task_dataset=False, allow_variable_data_keys=False, max_cache_size=0.0, max_cache_fd=32, allow_multi_rates=False, valid_max_cache_size=None, exclude_weight_decay=False, exclude_weight_decay_conf={}, optim='adamw', optim_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler='exponentiallr', scheduler_conf={'gamma': 0.999875}, optim2='adamw', optim2_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler2='exponentiallr', scheduler2_conf={'gamma': 0.999875}, generator_first=False, skip_discriminator_prob=0.0, token_list=['<blank>', '<unk>', ' ', 'AH0', 'N', 'T', 'D', 'S', 'R', 'L', 'IH1', 'DH', 'M', 'EH1', 'Z', 'AE1', 'K', 'IH0', 'AH1', 'HH', 'W', 'ER0', 'V', 'IY1', 'F', 'UW1', 'P', 'AY1', 'B', 'AA1', 'AO1', 'EY1', 'IY0', 'OW1', 'NG', 'SH', 'G', 'Y', 'AW1', 'CH', 'ER1', 'UH1', 'TH', 'JH', 'OW0', 'EH2', 'IH2', 'OY1', 'EY2', 'AY2', 'EH0', 'UW0', 'AA2', 'AE2', 'OW2', 'AH2', 'AA0', 'ZH', 'AE0', 'AO2', 'UW2', 'AO0', 'AY0', 'IY2', 'AW2', 'UH2', 'EY0', 'ER2', 'AW0', 'UH0', 'OY2', 'OY0', "'", '<sos/eos>'], odim=None, model_conf={}, use_preprocessor=True, token_type='phn', bpemodel=None, non_linguistic_symbols=None, cleaner='tacotron', g2p='g2p_en', feats_extract='linear_spectrogram', feats_extract_conf={'n_fft': 1024, 'hop_length': 256, 'win_length': None}, normalize=None, normalize_conf={}, tts='vits', tts_conf={'generator_type': 'vits_generator', 'generator_params': {'hidden_channels': 192, 'spks': 128, 'global_channels': 256, 'segment_size': 32, 'text_encoder_attention_heads': 2, 'text_encoder_ffn_expand': 4, 'text_encoder_blocks': 6, 'text_encoder_positionwise_layer_type': 'conv1d', 'text_encoder_positionwise_conv_kernel_size': 3, 'text_encoder_positional_encoding_layer_type': 'rel_pos', 'text_encoder_self_attention_layer_type': 'rel_selfattn', 'text_encoder_activation_type': 'swish', 'text_encoder_normalize_before': True, 'text_encoder_dropout_rate': 0.1, 'text_encoder_positional_dropout_rate': 0.0, 'text_encoder_attention_dropout_rate': 0.1, 'use_macaron_style_in_text_encoder': True, 'use_conformer_conv_in_text_encoder': False, 'text_encoder_conformer_kernel_size': -1, 'decoder_kernel_size': 7, 'decoder_channels': 512, 'decoder_upsample_scales': [8, 8, 2, 2], 'decoder_upsample_kernel_sizes': [16, 16, 4, 4], 'decoder_resblock_kernel_sizes': [3, 7, 11], 'decoder_resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'use_weight_norm_in_decoder': True, 'posterior_encoder_kernel_size': 5, 'posterior_encoder_layers': 16, 'posterior_encoder_stacks': 1, 'posterior_encoder_base_dilation': 1, 'posterior_encoder_dropout_rate': 0.0, 'use_weight_norm_in_posterior_encoder': True, 'flow_flows': 4, 'flow_kernel_size': 5, 'flow_base_dilation': 1, 'flow_layers': 4, 'flow_dropout_rate': 0.0, 'use_weight_norm_in_flow': True, 'use_only_mean_in_flow': True, 'stochastic_duration_predictor_kernel_size': 3, 'stochastic_duration_predictor_dropout_rate': 0.5, 'stochastic_duration_predictor_flows': 4, 'stochastic_duration_predictor_dds_conv_layers': 3, 'vocabs': 74, 'aux_channels': 513}, 'discriminator_type': 'hifigan_multi_scale_multi_period_discriminator', 'discriminator_params': {'scales': 1, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'stride': 2, 'padding': 2}, 'scale_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'channels': 128, 'max_downsample_channels': 1024, 'max_groups': 16, 'bias': True, 'downsample_scales': [2, 2, 4, 4, 1], 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}, 'follow_official_norm': False, 'periods': [2, 3, 5, 7, 11], 'period_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [5, 3], 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'max_downsample_channels': 1024, 'bias': True, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}}, 'generator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'discriminator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'feat_match_loss_params': {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, 'mel_loss_params': {'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None, 'window': 'hann', 'n_mels': 80, 'fmin': 0, 'fmax': None, 'log_base': None}, 'lambda_adv': 1.0, 'lambda_mel': 45.0, 'lambda_feat_match': 2.0, 'lambda_dur': 1.0, 'lambda_kl': 1.0, 'sampling_rate': 22050, 'cache_generator_outputs': True, 'plot_pred_mos': False, 'mos_pred_tool': 'utmos'}, pitch_extract=None, pitch_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'f0max': 400, 'f0min': 80}, pitch_normalize=None, pitch_normalize_conf={}, energy_extract=None, energy_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None}, energy_normalize=None, energy_normalize_conf={}, required=['output_dir', 'token_list'], version='202503', distributed=False)
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1284, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 64544) is killed by signal: Killed. 

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 22, in <module>
    main()
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 18, in main
    GANTTSTask.main(cmd=cmd)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1225, in main
    cls.main_worker(args)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1441, in main_worker
    collect_stats(
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/main_funcs/collect_stats.py", line 51, in collect_stats
    for iiter, (keys, batch) in enumerate(itr, 1):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 733, in __next__
    data = self._next_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1491, in _next_data
    idx, data = self._get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1453, in _get_data
    success, data = self._try_get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1297, in _try_get_data
    raise RuntimeError(
RuntimeError: DataLoader worker (pid(s) 64544) exited unexpectedly
# Accounting: begin_time=1750873256
# Accounting: end_time=1750873472
# Accounting: time=216 threads=1
# Finished at Wed Jun 25 13:44:32 EDT 2025 with status 1
# Running on r196.ib.bridges2.psc.edu
# Started at Wed Jun 25 13:40:56 EDT 2025
# SLURMD_NODENAME=r196
# SLURM_ARRAY_JOB_ID=32990217
# SLURM_ARRAY_TASK_COUNT=32
# SLURM_ARRAY_TASK_ID=6
# SLURM_ARRAY_TASK_MAX=32
# SLURM_ARRAY_TASK_MIN=1
# SLURM_ARRAY_TASK_STEP=1
# SLURM_CLUSTER_NAME=bridges2
# SLURM_CONF=/var/spool/slurm/d/conf-cache/slurm.conf
# SLURM_CPUS_ON_NODE=1
# SLURM_CPU_BIND=quiet,mask_cpu:0x07C0000000
# SLURM_CPU_BIND_LIST=0x07C0000000
# SLURM_CPU_BIND_TYPE=mask_cpu:
# SLURM_CPU_BIND_VERBOSE=quiet
# SLURM_EXPORT_ENV=ALL
# SLURM_GET_USER_ENV=1
# SLURM_GTIDS=0
# SLURM_JOBID=32990224
# SLURM_JOB_ACCOUNT=cis210027p
# SLURM_JOB_CPUS_PER_NODE=1
# SLURM_JOB_GID=24886
# SLURM_JOB_ID=32990224
# SLURM_JOB_NAME=stats.sh
# SLURM_JOB_NODELIST=r196
# SLURM_JOB_NUM_NODES=1
# SLURM_JOB_PARTITION=RM-shared
# SLURM_JOB_QOS=rm
# SLURM_JOB_UID=97947
# SLURM_JOB_USER=ttao3
# SLURM_LAUNCH_NODE_IPADDR=10.8.11.29
# SLURM_LOCALID=0
# SLURM_MEM_PER_CPU=1900
# SLURM_NNODES=1
# SLURM_NODEID=0
# SLURM_NODELIST=r196
# SLURM_NODE_ALIASES='(null)'
# SLURM_NPROCS=1
# SLURM_NTASKS=1
# SLURM_OPEN_MODE=a
# SLURM_PRIO_PROCESS=0
# SLURM_PROCID=0
# SLURM_PTY_PORT=33025
# SLURM_PTY_WIN_COL=126
# SLURM_PTY_WIN_ROW=21
# SLURM_SCRIPT_CONTEXT=prolog_task
# SLURM_SRUN_COMM_HOST=10.8.11.29
# SLURM_SRUN_COMM_PORT=35045
# SLURM_STEPID=0
# SLURM_STEP_GPUS=6
# SLURM_STEP_ID=0
# SLURM_STEP_LAUNCHER_PORT=35045
# SLURM_STEP_NODELIST=v029
# SLURM_STEP_NUM_NODES=1
# SLURM_STEP_NUM_TASKS=1
# SLURM_STEP_TASKS_PER_NODE=1
# SLURM_SUBMIT_DIR=/ocean/projects/cis210027p/ttao3/espnet/egs2/hifitts/tts1
# SLURM_SUBMIT_HOST=v029.ib.bridges2.psc.edu
# SLURM_TASKS_PER_NODE=1
# SLURM_TASK_PID=102092
# SLURM_TOPOLOGY_ADDR=r196
# SLURM_TOPOLOGY_ADDR_PATTERN=node
# SLURM_WORKING_CLUSTER=bridges2:br003:6810:9728:109
# python3 -m espnet2.bin.gan_tts_train --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.6.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.6.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.6 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int 
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/librosa/util/files.py:10: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_filename
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/bin/python3 /ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.6.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.6.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.6 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int
Failed to import Flash Attention, using ESPnet default: No module named 'flash_attn_2_cuda'
Vocabulary size: 74
encoder self-attention layer type = relative self-attention
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/ocean/projects/cis210027p/ttao3/espnet/espnet2/gan_tts/vits/monotonic_align/__init__.py:19: UserWarning: Cython version is not available. Fallback to 'EXPERIMETAL' numba version. If you want to use the cython version, please build it as follows: `cd espnet2/gan_tts/vits/monotonic_align; python setup.py build_ext --inplace`
  warnings.warn(
pytorch.version=2.7.1+cu126, cuda.available=False, cudnn.version=90501, cudnn.benchmark=False, cudnn.deterministic=False
Model structure:
ESPnetGANTTSModel(
  (feats_extract): LinearSpectrogram(
    (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
  )
  (tts): VITS(
    (generator): VITSGenerator(
      (text_encoder): TextEncoder(
        (emb): Embedding(74, 192)
        (encoder): Encoder(
          (embed): Sequential(
            (0): RelPositionalEncoding(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (encoders): MultiSequential(
            (0): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (2): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (3): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (4): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (5): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (after_norm): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (decoder): HiFiGANGenerator(
        (input_conv): Conv1d(192, 512, kernel_size=(7,), stride=(1,), padding=(3,))
        (upsamples): ModuleList(
          (0): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (1): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(256, 128, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (2): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,))
          )
          (3): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,))
          )
        )
        (blocks): ModuleList(
          (0): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (1): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (2): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (3): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (4): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (5): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (6): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (7): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (8): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (9): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (10): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (11): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
        )
        (output_conv): Sequential(
          (0): LeakyReLU(negative_slope=0.01)
          (1): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,))
          (2): Tanh()
        )
        (global_conv): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
      )
      (posterior_encoder): PosteriorEncoder(
        (input_conv): Conv1d(513, 192, kernel_size=(1,), stride=(1,))
        (encoder): WaveNet(
          (conv_layers): ModuleList(
            (0-15): 16 x ResidualBlock(
              (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
              (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
              (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
            )
          )
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (flow): ResidualAffineCouplingBlock(
        (flows): ModuleList(
          (0): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (1): FlipFlow()
          (2): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (3): FlipFlow()
          (4): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (5): FlipFlow()
          (6): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (7): FlipFlow()
        )
      )
      (duration_predictor): StochasticDurationPredictor(
        (pre): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (log_flow): LogFlow()
        (flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (post_pre): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
        (post_dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (post_proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (post_flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (global_conv): Conv1d(256, 192, kernel_size=(1,), stride=(1,))
      )
      (global_emb): Embedding(128, 256)
    )
    (discriminator): HiFiGANMultiScaleMultiPeriodDiscriminator(
      (msd): HiFiGANMultiScaleDiscriminator(
        (discriminators): ModuleList(
          (0): HiFiGANScaleDiscriminator(
            (layers): ModuleList(
              (0): Sequential(
                (0): Conv1d(1, 128, kernel_size=(15,), stride=(1,), padding=(7,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv1d(128, 128, kernel_size=(41,), stride=(2,), padding=(20,), groups=4)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv1d(128, 256, kernel_size=(41,), stride=(2,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv1d(256, 512, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv1d(512, 1024, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (5): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(41,), stride=(1,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (6): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (7): Conv1d(1024, 1, kernel_size=(3,), stride=(1,), padding=(1,))
            )
          )
        )
      )
      (mpd): HiFiGANMultiPeriodDiscriminator(
        (discriminators): ModuleList(
          (0-4): 5 x HiFiGANPeriodDiscriminator(
            (convs): ModuleList(
              (0): Sequential(
                (0): Conv2d(1, 32, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv2d(32, 128, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv2d(128, 512, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv2d(512, 1024, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv2d(1024, 1024, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
            )
            (output_conv): Conv2d(1024, 1, kernel_size=(2, 1), stride=(1, 1), padding=(1, 0))
          )
        )
      )
    )
    (generator_adv_loss): GeneratorAdversarialLoss()
    (discriminator_adv_loss): DiscriminatorAdversarialLoss()
    (feat_match_loss): FeatureMatchLoss()
    (mel_loss): MelSpectrogramLoss(
      (wav_to_mel): LogMelFbank(
        (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
        (logmel): LogMel(sr=22050, n_fft=1024, n_mels=80, fmin=0, fmax=11025.0, htk=False)
      )
    )
    (kl_loss): KLDivergenceLoss()
  )
)

Model summary:
    Class Name: ESPnetGANTTSModel
    Total Number of model parameters: 96.37 M
    Number of trainable parameters: 96.37 M (100.0%)
    Size: 385.46 MB
    Type: torch.float32
Optimizer:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler: <torch.optim.lr_scheduler.ExponentialLR object at 0x153b199435b0>
Optimizer2:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler2: <torch.optim.lr_scheduler.ExponentialLR object at 0x153b19943970>
Saving the configuration in exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.6/config.yaml
Namespace(config='conf/tuning/train_multi_spk_vits.yaml', print_config=False, log_level='INFO', drop_last_iter=False, dry_run=False, iterator_type='sequence', valid_iterator_type=None, output_dir='exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.6', ngpu=0, seed=777, num_workers=4, num_att_plot=3, dist_backend='nccl', dist_init_method='env://', dist_world_size=None, dist_rank=None, local_rank=None, dist_master_addr=None, dist_master_port=None, dist_launcher=None, multiprocessing_distributed=False, unused_parameters=True, sharded_ddp=False, use_deepspeed=False, deepspeed_config=None, gradient_as_bucket_view=True, ddp_comm_hook=None, cudnn_enabled=True, cudnn_benchmark=False, cudnn_deterministic=False, use_tf32=False, collect_stats=True, write_collected_feats=False, max_epoch=1000, patience=None, val_scheduler_criterion=('valid', 'loss'), early_stopping_criterion=('valid', 'loss', 'min'), best_model_criterion=[['train', 'total_count', 'max']], keep_nbest_models=10, nbest_averaging_interval=0, grad_clip=-1, grad_clip_type=2.0, grad_noise=False, accum_grad=1, no_forward_run=False, resume=False, train_dtype='float32', use_amp=False, log_interval=50, use_matplotlib=True, use_tensorboard=True, create_graph_in_tensorboard=False, use_wandb=False, wandb_project=None, wandb_id=None, wandb_entity=None, wandb_name=None, wandb_model_log_interval=-1, detect_anomaly=False, use_adapter=False, adapter='lora', save_strategy='all', adapter_conf={}, pretrain_path=None, init_param=[], ignore_init_mismatch=False, freeze_param=[], num_iters_per_epoch=1000, batch_size=20, valid_batch_size=None, batch_bins=3000000, valid_batch_bins=None, category_sample_size=10, train_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.6.scp'], valid_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.6.scp'], batch_type='numel', valid_batch_type=None, fold_length=[], sort_in_batch='descending', shuffle_within_batch=False, sort_batch='descending', multiple_iterator=False, chunk_length=500, chunk_shift_ratio=0.5, num_cache_chunks=1024, chunk_excluded_key_prefixes=[], chunk_default_fs=None, chunk_max_abs_length=None, chunk_discard_short_samples=True, train_data_path_and_name_and_type=[('dump/22k/raw/tr_no_dev/text', 'text', 'text'), ('dump/22k/raw/tr_no_dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/tr_no_dev/utt2sid', 'sids', 'text_int')], valid_data_path_and_name_and_type=[('dump/22k/raw/dev/text', 'text', 'text'), ('dump/22k/raw/dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/dev/utt2sid', 'sids', 'text_int')], multi_task_dataset=False, allow_variable_data_keys=False, max_cache_size=0.0, max_cache_fd=32, allow_multi_rates=False, valid_max_cache_size=None, exclude_weight_decay=False, exclude_weight_decay_conf={}, optim='adamw', optim_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler='exponentiallr', scheduler_conf={'gamma': 0.999875}, optim2='adamw', optim2_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler2='exponentiallr', scheduler2_conf={'gamma': 0.999875}, generator_first=False, skip_discriminator_prob=0.0, token_list=['<blank>', '<unk>', ' ', 'AH0', 'N', 'T', 'D', 'S', 'R', 'L', 'IH1', 'DH', 'M', 'EH1', 'Z', 'AE1', 'K', 'IH0', 'AH1', 'HH', 'W', 'ER0', 'V', 'IY1', 'F', 'UW1', 'P', 'AY1', 'B', 'AA1', 'AO1', 'EY1', 'IY0', 'OW1', 'NG', 'SH', 'G', 'Y', 'AW1', 'CH', 'ER1', 'UH1', 'TH', 'JH', 'OW0', 'EH2', 'IH2', 'OY1', 'EY2', 'AY2', 'EH0', 'UW0', 'AA2', 'AE2', 'OW2', 'AH2', 'AA0', 'ZH', 'AE0', 'AO2', 'UW2', 'AO0', 'AY0', 'IY2', 'AW2', 'UH2', 'EY0', 'ER2', 'AW0', 'UH0', 'OY2', 'OY0', "'", '<sos/eos>'], odim=None, model_conf={}, use_preprocessor=True, token_type='phn', bpemodel=None, non_linguistic_symbols=None, cleaner='tacotron', g2p='g2p_en', feats_extract='linear_spectrogram', feats_extract_conf={'n_fft': 1024, 'hop_length': 256, 'win_length': None}, normalize=None, normalize_conf={}, tts='vits', tts_conf={'generator_type': 'vits_generator', 'generator_params': {'hidden_channels': 192, 'spks': 128, 'global_channels': 256, 'segment_size': 32, 'text_encoder_attention_heads': 2, 'text_encoder_ffn_expand': 4, 'text_encoder_blocks': 6, 'text_encoder_positionwise_layer_type': 'conv1d', 'text_encoder_positionwise_conv_kernel_size': 3, 'text_encoder_positional_encoding_layer_type': 'rel_pos', 'text_encoder_self_attention_layer_type': 'rel_selfattn', 'text_encoder_activation_type': 'swish', 'text_encoder_normalize_before': True, 'text_encoder_dropout_rate': 0.1, 'text_encoder_positional_dropout_rate': 0.0, 'text_encoder_attention_dropout_rate': 0.1, 'use_macaron_style_in_text_encoder': True, 'use_conformer_conv_in_text_encoder': False, 'text_encoder_conformer_kernel_size': -1, 'decoder_kernel_size': 7, 'decoder_channels': 512, 'decoder_upsample_scales': [8, 8, 2, 2], 'decoder_upsample_kernel_sizes': [16, 16, 4, 4], 'decoder_resblock_kernel_sizes': [3, 7, 11], 'decoder_resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'use_weight_norm_in_decoder': True, 'posterior_encoder_kernel_size': 5, 'posterior_encoder_layers': 16, 'posterior_encoder_stacks': 1, 'posterior_encoder_base_dilation': 1, 'posterior_encoder_dropout_rate': 0.0, 'use_weight_norm_in_posterior_encoder': True, 'flow_flows': 4, 'flow_kernel_size': 5, 'flow_base_dilation': 1, 'flow_layers': 4, 'flow_dropout_rate': 0.0, 'use_weight_norm_in_flow': True, 'use_only_mean_in_flow': True, 'stochastic_duration_predictor_kernel_size': 3, 'stochastic_duration_predictor_dropout_rate': 0.5, 'stochastic_duration_predictor_flows': 4, 'stochastic_duration_predictor_dds_conv_layers': 3, 'vocabs': 74, 'aux_channels': 513}, 'discriminator_type': 'hifigan_multi_scale_multi_period_discriminator', 'discriminator_params': {'scales': 1, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'stride': 2, 'padding': 2}, 'scale_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'channels': 128, 'max_downsample_channels': 1024, 'max_groups': 16, 'bias': True, 'downsample_scales': [2, 2, 4, 4, 1], 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}, 'follow_official_norm': False, 'periods': [2, 3, 5, 7, 11], 'period_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [5, 3], 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'max_downsample_channels': 1024, 'bias': True, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}}, 'generator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'discriminator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'feat_match_loss_params': {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, 'mel_loss_params': {'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None, 'window': 'hann', 'n_mels': 80, 'fmin': 0, 'fmax': None, 'log_base': None}, 'lambda_adv': 1.0, 'lambda_mel': 45.0, 'lambda_feat_match': 2.0, 'lambda_dur': 1.0, 'lambda_kl': 1.0, 'sampling_rate': 22050, 'cache_generator_outputs': True, 'plot_pred_mos': False, 'mos_pred_tool': 'utmos'}, pitch_extract=None, pitch_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'f0max': 400, 'f0min': 80}, pitch_normalize=None, pitch_normalize_conf={}, energy_extract=None, energy_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None}, energy_normalize=None, energy_normalize_conf={}, required=['output_dir', 'token_list'], version='202503', distributed=False)
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1284, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 102160) is killed by signal: Killed. 

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 22, in <module>
    main()
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 18, in main
    GANTTSTask.main(cmd=cmd)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1225, in main
    cls.main_worker(args)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1441, in main_worker
    collect_stats(
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/main_funcs/collect_stats.py", line 51, in collect_stats
    for iiter, (keys, batch) in enumerate(itr, 1):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 733, in __next__
    data = self._next_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1491, in _next_data
    idx, data = self._get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1453, in _get_data
    success, data = self._try_get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1297, in _try_get_data
    raise RuntimeError(
RuntimeError: DataLoader worker (pid(s) 102160) exited unexpectedly
# Accounting: begin_time=1750873256
# Accounting: end_time=1750873472
# Accounting: time=216 threads=1
# Finished at Wed Jun 25 13:44:32 EDT 2025 with status 1
# Running on r196.ib.bridges2.psc.edu
# Started at Wed Jun 25 13:40:56 EDT 2025
# SLURMD_NODENAME=r196
# SLURM_ARRAY_JOB_ID=32990217
# SLURM_ARRAY_TASK_COUNT=32
# SLURM_ARRAY_TASK_ID=7
# SLURM_ARRAY_TASK_MAX=32
# SLURM_ARRAY_TASK_MIN=1
# SLURM_ARRAY_TASK_STEP=1
# SLURM_CLUSTER_NAME=bridges2
# SLURM_CONF=/var/spool/slurm/d/conf-cache/slurm.conf
# SLURM_CPUS_ON_NODE=1
# SLURM_CPU_BIND=quiet,mask_cpu:0x07C0000000
# SLURM_CPU_BIND_LIST=0x07C0000000
# SLURM_CPU_BIND_TYPE=mask_cpu:
# SLURM_CPU_BIND_VERBOSE=quiet
# SLURM_EXPORT_ENV=ALL
# SLURM_GET_USER_ENV=1
# SLURM_GTIDS=0
# SLURM_JOBID=32990225
# SLURM_JOB_ACCOUNT=cis210027p
# SLURM_JOB_CPUS_PER_NODE=1
# SLURM_JOB_GID=24886
# SLURM_JOB_ID=32990225
# SLURM_JOB_NAME=stats.sh
# SLURM_JOB_NODELIST=r196
# SLURM_JOB_NUM_NODES=1
# SLURM_JOB_PARTITION=RM-shared
# SLURM_JOB_QOS=rm
# SLURM_JOB_UID=97947
# SLURM_JOB_USER=ttao3
# SLURM_LAUNCH_NODE_IPADDR=10.8.11.29
# SLURM_LOCALID=0
# SLURM_MEM_PER_CPU=1900
# SLURM_NNODES=1
# SLURM_NODEID=0
# SLURM_NODELIST=r196
# SLURM_NODE_ALIASES='(null)'
# SLURM_NPROCS=1
# SLURM_NTASKS=1
# SLURM_OPEN_MODE=a
# SLURM_PRIO_PROCESS=0
# SLURM_PROCID=0
# SLURM_PTY_PORT=33025
# SLURM_PTY_WIN_COL=126
# SLURM_PTY_WIN_ROW=21
# SLURM_SCRIPT_CONTEXT=prolog_task
# SLURM_SRUN_COMM_HOST=10.8.11.29
# SLURM_SRUN_COMM_PORT=35045
# SLURM_STEPID=0
# SLURM_STEP_GPUS=6
# SLURM_STEP_ID=0
# SLURM_STEP_LAUNCHER_PORT=35045
# SLURM_STEP_NODELIST=v029
# SLURM_STEP_NUM_NODES=1
# SLURM_STEP_NUM_TASKS=1
# SLURM_STEP_TASKS_PER_NODE=1
# SLURM_SUBMIT_DIR=/ocean/projects/cis210027p/ttao3/espnet/egs2/hifitts/tts1
# SLURM_SUBMIT_HOST=v029.ib.bridges2.psc.edu
# SLURM_TASKS_PER_NODE=1
# SLURM_TASK_PID=102093
# SLURM_TOPOLOGY_ADDR=r196
# SLURM_TOPOLOGY_ADDR_PATTERN=node
# SLURM_WORKING_CLUSTER=bridges2:br003:6810:9728:109
# python3 -m espnet2.bin.gan_tts_train --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.7.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.7.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.7 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int 
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/librosa/util/files.py:10: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_filename
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/bin/python3 /ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.7.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.7.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.7 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int
Failed to import Flash Attention, using ESPnet default: No module named 'flash_attn_2_cuda'
Vocabulary size: 74
encoder self-attention layer type = relative self-attention
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/ocean/projects/cis210027p/ttao3/espnet/espnet2/gan_tts/vits/monotonic_align/__init__.py:19: UserWarning: Cython version is not available. Fallback to 'EXPERIMETAL' numba version. If you want to use the cython version, please build it as follows: `cd espnet2/gan_tts/vits/monotonic_align; python setup.py build_ext --inplace`
  warnings.warn(
pytorch.version=2.7.1+cu126, cuda.available=False, cudnn.version=90501, cudnn.benchmark=False, cudnn.deterministic=False
Model structure:
ESPnetGANTTSModel(
  (feats_extract): LinearSpectrogram(
    (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
  )
  (tts): VITS(
    (generator): VITSGenerator(
      (text_encoder): TextEncoder(
        (emb): Embedding(74, 192)
        (encoder): Encoder(
          (embed): Sequential(
            (0): RelPositionalEncoding(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (encoders): MultiSequential(
            (0): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (2): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (3): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (4): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (5): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (after_norm): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (decoder): HiFiGANGenerator(
        (input_conv): Conv1d(192, 512, kernel_size=(7,), stride=(1,), padding=(3,))
        (upsamples): ModuleList(
          (0): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (1): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(256, 128, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (2): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,))
          )
          (3): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,))
          )
        )
        (blocks): ModuleList(
          (0): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (1): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (2): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (3): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (4): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (5): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (6): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (7): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (8): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (9): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (10): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (11): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
        )
        (output_conv): Sequential(
          (0): LeakyReLU(negative_slope=0.01)
          (1): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,))
          (2): Tanh()
        )
        (global_conv): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
      )
      (posterior_encoder): PosteriorEncoder(
        (input_conv): Conv1d(513, 192, kernel_size=(1,), stride=(1,))
        (encoder): WaveNet(
          (conv_layers): ModuleList(
            (0-15): 16 x ResidualBlock(
              (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
              (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
              (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
            )
          )
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (flow): ResidualAffineCouplingBlock(
        (flows): ModuleList(
          (0): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (1): FlipFlow()
          (2): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (3): FlipFlow()
          (4): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (5): FlipFlow()
          (6): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (7): FlipFlow()
        )
      )
      (duration_predictor): StochasticDurationPredictor(
        (pre): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (log_flow): LogFlow()
        (flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (post_pre): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
        (post_dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (post_proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (post_flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (global_conv): Conv1d(256, 192, kernel_size=(1,), stride=(1,))
      )
      (global_emb): Embedding(128, 256)
    )
    (discriminator): HiFiGANMultiScaleMultiPeriodDiscriminator(
      (msd): HiFiGANMultiScaleDiscriminator(
        (discriminators): ModuleList(
          (0): HiFiGANScaleDiscriminator(
            (layers): ModuleList(
              (0): Sequential(
                (0): Conv1d(1, 128, kernel_size=(15,), stride=(1,), padding=(7,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv1d(128, 128, kernel_size=(41,), stride=(2,), padding=(20,), groups=4)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv1d(128, 256, kernel_size=(41,), stride=(2,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv1d(256, 512, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv1d(512, 1024, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (5): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(41,), stride=(1,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (6): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (7): Conv1d(1024, 1, kernel_size=(3,), stride=(1,), padding=(1,))
            )
          )
        )
      )
      (mpd): HiFiGANMultiPeriodDiscriminator(
        (discriminators): ModuleList(
          (0-4): 5 x HiFiGANPeriodDiscriminator(
            (convs): ModuleList(
              (0): Sequential(
                (0): Conv2d(1, 32, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv2d(32, 128, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv2d(128, 512, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv2d(512, 1024, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv2d(1024, 1024, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
            )
            (output_conv): Conv2d(1024, 1, kernel_size=(2, 1), stride=(1, 1), padding=(1, 0))
          )
        )
      )
    )
    (generator_adv_loss): GeneratorAdversarialLoss()
    (discriminator_adv_loss): DiscriminatorAdversarialLoss()
    (feat_match_loss): FeatureMatchLoss()
    (mel_loss): MelSpectrogramLoss(
      (wav_to_mel): LogMelFbank(
        (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
        (logmel): LogMel(sr=22050, n_fft=1024, n_mels=80, fmin=0, fmax=11025.0, htk=False)
      )
    )
    (kl_loss): KLDivergenceLoss()
  )
)

Model summary:
    Class Name: ESPnetGANTTSModel
    Total Number of model parameters: 96.37 M
    Number of trainable parameters: 96.37 M (100.0%)
    Size: 385.46 MB
    Type: torch.float32
Optimizer:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler: <torch.optim.lr_scheduler.ExponentialLR object at 0x14b259d27580>
Optimizer2:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler2: <torch.optim.lr_scheduler.ExponentialLR object at 0x14b259d27940>
Saving the configuration in exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.7/config.yaml
Namespace(config='conf/tuning/train_multi_spk_vits.yaml', print_config=False, log_level='INFO', drop_last_iter=False, dry_run=False, iterator_type='sequence', valid_iterator_type=None, output_dir='exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.7', ngpu=0, seed=777, num_workers=4, num_att_plot=3, dist_backend='nccl', dist_init_method='env://', dist_world_size=None, dist_rank=None, local_rank=None, dist_master_addr=None, dist_master_port=None, dist_launcher=None, multiprocessing_distributed=False, unused_parameters=True, sharded_ddp=False, use_deepspeed=False, deepspeed_config=None, gradient_as_bucket_view=True, ddp_comm_hook=None, cudnn_enabled=True, cudnn_benchmark=False, cudnn_deterministic=False, use_tf32=False, collect_stats=True, write_collected_feats=False, max_epoch=1000, patience=None, val_scheduler_criterion=('valid', 'loss'), early_stopping_criterion=('valid', 'loss', 'min'), best_model_criterion=[['train', 'total_count', 'max']], keep_nbest_models=10, nbest_averaging_interval=0, grad_clip=-1, grad_clip_type=2.0, grad_noise=False, accum_grad=1, no_forward_run=False, resume=False, train_dtype='float32', use_amp=False, log_interval=50, use_matplotlib=True, use_tensorboard=True, create_graph_in_tensorboard=False, use_wandb=False, wandb_project=None, wandb_id=None, wandb_entity=None, wandb_name=None, wandb_model_log_interval=-1, detect_anomaly=False, use_adapter=False, adapter='lora', save_strategy='all', adapter_conf={}, pretrain_path=None, init_param=[], ignore_init_mismatch=False, freeze_param=[], num_iters_per_epoch=1000, batch_size=20, valid_batch_size=None, batch_bins=3000000, valid_batch_bins=None, category_sample_size=10, train_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.7.scp'], valid_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.7.scp'], batch_type='numel', valid_batch_type=None, fold_length=[], sort_in_batch='descending', shuffle_within_batch=False, sort_batch='descending', multiple_iterator=False, chunk_length=500, chunk_shift_ratio=0.5, num_cache_chunks=1024, chunk_excluded_key_prefixes=[], chunk_default_fs=None, chunk_max_abs_length=None, chunk_discard_short_samples=True, train_data_path_and_name_and_type=[('dump/22k/raw/tr_no_dev/text', 'text', 'text'), ('dump/22k/raw/tr_no_dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/tr_no_dev/utt2sid', 'sids', 'text_int')], valid_data_path_and_name_and_type=[('dump/22k/raw/dev/text', 'text', 'text'), ('dump/22k/raw/dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/dev/utt2sid', 'sids', 'text_int')], multi_task_dataset=False, allow_variable_data_keys=False, max_cache_size=0.0, max_cache_fd=32, allow_multi_rates=False, valid_max_cache_size=None, exclude_weight_decay=False, exclude_weight_decay_conf={}, optim='adamw', optim_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler='exponentiallr', scheduler_conf={'gamma': 0.999875}, optim2='adamw', optim2_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler2='exponentiallr', scheduler2_conf={'gamma': 0.999875}, generator_first=False, skip_discriminator_prob=0.0, token_list=['<blank>', '<unk>', ' ', 'AH0', 'N', 'T', 'D', 'S', 'R', 'L', 'IH1', 'DH', 'M', 'EH1', 'Z', 'AE1', 'K', 'IH0', 'AH1', 'HH', 'W', 'ER0', 'V', 'IY1', 'F', 'UW1', 'P', 'AY1', 'B', 'AA1', 'AO1', 'EY1', 'IY0', 'OW1', 'NG', 'SH', 'G', 'Y', 'AW1', 'CH', 'ER1', 'UH1', 'TH', 'JH', 'OW0', 'EH2', 'IH2', 'OY1', 'EY2', 'AY2', 'EH0', 'UW0', 'AA2', 'AE2', 'OW2', 'AH2', 'AA0', 'ZH', 'AE0', 'AO2', 'UW2', 'AO0', 'AY0', 'IY2', 'AW2', 'UH2', 'EY0', 'ER2', 'AW0', 'UH0', 'OY2', 'OY0', "'", '<sos/eos>'], odim=None, model_conf={}, use_preprocessor=True, token_type='phn', bpemodel=None, non_linguistic_symbols=None, cleaner='tacotron', g2p='g2p_en', feats_extract='linear_spectrogram', feats_extract_conf={'n_fft': 1024, 'hop_length': 256, 'win_length': None}, normalize=None, normalize_conf={}, tts='vits', tts_conf={'generator_type': 'vits_generator', 'generator_params': {'hidden_channels': 192, 'spks': 128, 'global_channels': 256, 'segment_size': 32, 'text_encoder_attention_heads': 2, 'text_encoder_ffn_expand': 4, 'text_encoder_blocks': 6, 'text_encoder_positionwise_layer_type': 'conv1d', 'text_encoder_positionwise_conv_kernel_size': 3, 'text_encoder_positional_encoding_layer_type': 'rel_pos', 'text_encoder_self_attention_layer_type': 'rel_selfattn', 'text_encoder_activation_type': 'swish', 'text_encoder_normalize_before': True, 'text_encoder_dropout_rate': 0.1, 'text_encoder_positional_dropout_rate': 0.0, 'text_encoder_attention_dropout_rate': 0.1, 'use_macaron_style_in_text_encoder': True, 'use_conformer_conv_in_text_encoder': False, 'text_encoder_conformer_kernel_size': -1, 'decoder_kernel_size': 7, 'decoder_channels': 512, 'decoder_upsample_scales': [8, 8, 2, 2], 'decoder_upsample_kernel_sizes': [16, 16, 4, 4], 'decoder_resblock_kernel_sizes': [3, 7, 11], 'decoder_resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'use_weight_norm_in_decoder': True, 'posterior_encoder_kernel_size': 5, 'posterior_encoder_layers': 16, 'posterior_encoder_stacks': 1, 'posterior_encoder_base_dilation': 1, 'posterior_encoder_dropout_rate': 0.0, 'use_weight_norm_in_posterior_encoder': True, 'flow_flows': 4, 'flow_kernel_size': 5, 'flow_base_dilation': 1, 'flow_layers': 4, 'flow_dropout_rate': 0.0, 'use_weight_norm_in_flow': True, 'use_only_mean_in_flow': True, 'stochastic_duration_predictor_kernel_size': 3, 'stochastic_duration_predictor_dropout_rate': 0.5, 'stochastic_duration_predictor_flows': 4, 'stochastic_duration_predictor_dds_conv_layers': 3, 'vocabs': 74, 'aux_channels': 513}, 'discriminator_type': 'hifigan_multi_scale_multi_period_discriminator', 'discriminator_params': {'scales': 1, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'stride': 2, 'padding': 2}, 'scale_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'channels': 128, 'max_downsample_channels': 1024, 'max_groups': 16, 'bias': True, 'downsample_scales': [2, 2, 4, 4, 1], 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}, 'follow_official_norm': False, 'periods': [2, 3, 5, 7, 11], 'period_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [5, 3], 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'max_downsample_channels': 1024, 'bias': True, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}}, 'generator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'discriminator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'feat_match_loss_params': {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, 'mel_loss_params': {'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None, 'window': 'hann', 'n_mels': 80, 'fmin': 0, 'fmax': None, 'log_base': None}, 'lambda_adv': 1.0, 'lambda_mel': 45.0, 'lambda_feat_match': 2.0, 'lambda_dur': 1.0, 'lambda_kl': 1.0, 'sampling_rate': 22050, 'cache_generator_outputs': True, 'plot_pred_mos': False, 'mos_pred_tool': 'utmos'}, pitch_extract=None, pitch_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'f0max': 400, 'f0min': 80}, pitch_normalize=None, pitch_normalize_conf={}, energy_extract=None, energy_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None}, energy_normalize=None, energy_normalize_conf={}, required=['output_dir', 'token_list'], version='202503', distributed=False)
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1284, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 102163) is killed by signal: Killed. 

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 22, in <module>
    main()
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 18, in main
    GANTTSTask.main(cmd=cmd)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1225, in main
    cls.main_worker(args)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1441, in main_worker
    collect_stats(
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/main_funcs/collect_stats.py", line 51, in collect_stats
    for iiter, (keys, batch) in enumerate(itr, 1):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 733, in __next__
    data = self._next_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1491, in _next_data
    idx, data = self._get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1453, in _get_data
    success, data = self._try_get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1297, in _try_get_data
    raise RuntimeError(
RuntimeError: DataLoader worker (pid(s) 102163) exited unexpectedly
# Accounting: begin_time=1750873256
# Accounting: end_time=1750873472
# Accounting: time=216 threads=1
# Finished at Wed Jun 25 13:44:32 EDT 2025 with status 1
# Running on r214.ib.bridges2.psc.edu
# Started at Wed Jun 25 13:40:56 EDT 2025
# SLURMD_NODENAME=r214
# SLURM_ARRAY_JOB_ID=32990217
# SLURM_ARRAY_TASK_COUNT=32
# SLURM_ARRAY_TASK_ID=8
# SLURM_ARRAY_TASK_MAX=32
# SLURM_ARRAY_TASK_MIN=1
# SLURM_ARRAY_TASK_STEP=1
# SLURM_CLUSTER_NAME=bridges2
# SLURM_CONF=/var/spool/slurm/d/conf-cache/slurm.conf
# SLURM_CPUS_ON_NODE=1
# SLURM_CPU_BIND=quiet,mask_cpu:0x07C0000000
# SLURM_CPU_BIND_LIST=0x07C0000000
# SLURM_CPU_BIND_TYPE=mask_cpu:
# SLURM_CPU_BIND_VERBOSE=quiet
# SLURM_EXPORT_ENV=ALL
# SLURM_GET_USER_ENV=1
# SLURM_GTIDS=0
# SLURM_JOBID=32990226
# SLURM_JOB_ACCOUNT=cis210027p
# SLURM_JOB_CPUS_PER_NODE=1
# SLURM_JOB_GID=24886
# SLURM_JOB_ID=32990226
# SLURM_JOB_NAME=stats.sh
# SLURM_JOB_NODELIST=r214
# SLURM_JOB_NUM_NODES=1
# SLURM_JOB_PARTITION=RM-shared
# SLURM_JOB_QOS=rm
# SLURM_JOB_UID=97947
# SLURM_JOB_USER=ttao3
# SLURM_LAUNCH_NODE_IPADDR=10.8.11.29
# SLURM_LOCALID=0
# SLURM_MEM_PER_CPU=1900
# SLURM_NNODES=1
# SLURM_NODEID=0
# SLURM_NODELIST=r214
# SLURM_NODE_ALIASES='(null)'
# SLURM_NPROCS=1
# SLURM_NTASKS=1
# SLURM_OPEN_MODE=a
# SLURM_PRIO_PROCESS=0
# SLURM_PROCID=0
# SLURM_PTY_PORT=33025
# SLURM_PTY_WIN_COL=126
# SLURM_PTY_WIN_ROW=21
# SLURM_SCRIPT_CONTEXT=prolog_task
# SLURM_SRUN_COMM_HOST=10.8.11.29
# SLURM_SRUN_COMM_PORT=35045
# SLURM_STEPID=0
# SLURM_STEP_GPUS=6
# SLURM_STEP_ID=0
# SLURM_STEP_LAUNCHER_PORT=35045
# SLURM_STEP_NODELIST=v029
# SLURM_STEP_NUM_NODES=1
# SLURM_STEP_NUM_TASKS=1
# SLURM_STEP_TASKS_PER_NODE=1
# SLURM_SUBMIT_DIR=/ocean/projects/cis210027p/ttao3/espnet/egs2/hifitts/tts1
# SLURM_SUBMIT_HOST=v029.ib.bridges2.psc.edu
# SLURM_TASKS_PER_NODE=1
# SLURM_TASK_PID=53641
# SLURM_TOPOLOGY_ADDR=r214
# SLURM_TOPOLOGY_ADDR_PATTERN=node
# SLURM_WORKING_CLUSTER=bridges2:br003:6810:9728:109
# python3 -m espnet2.bin.gan_tts_train --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.8.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.8.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.8 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int 
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/librosa/util/files.py:10: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_filename
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/bin/python3 /ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.8.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.8.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.8 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int
Failed to import Flash Attention, using ESPnet default: No module named 'flash_attn_2_cuda'
Vocabulary size: 74
encoder self-attention layer type = relative self-attention
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/ocean/projects/cis210027p/ttao3/espnet/espnet2/gan_tts/vits/monotonic_align/__init__.py:19: UserWarning: Cython version is not available. Fallback to 'EXPERIMETAL' numba version. If you want to use the cython version, please build it as follows: `cd espnet2/gan_tts/vits/monotonic_align; python setup.py build_ext --inplace`
  warnings.warn(
pytorch.version=2.7.1+cu126, cuda.available=False, cudnn.version=90501, cudnn.benchmark=False, cudnn.deterministic=False
Model structure:
ESPnetGANTTSModel(
  (feats_extract): LinearSpectrogram(
    (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
  )
  (tts): VITS(
    (generator): VITSGenerator(
      (text_encoder): TextEncoder(
        (emb): Embedding(74, 192)
        (encoder): Encoder(
          (embed): Sequential(
            (0): RelPositionalEncoding(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (encoders): MultiSequential(
            (0): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (2): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (3): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (4): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (5): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (after_norm): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (decoder): HiFiGANGenerator(
        (input_conv): Conv1d(192, 512, kernel_size=(7,), stride=(1,), padding=(3,))
        (upsamples): ModuleList(
          (0): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (1): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(256, 128, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (2): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,))
          )
          (3): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,))
          )
        )
        (blocks): ModuleList(
          (0): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (1): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (2): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (3): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (4): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (5): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (6): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (7): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (8): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (9): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (10): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (11): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
        )
        (output_conv): Sequential(
          (0): LeakyReLU(negative_slope=0.01)
          (1): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,))
          (2): Tanh()
        )
        (global_conv): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
      )
      (posterior_encoder): PosteriorEncoder(
        (input_conv): Conv1d(513, 192, kernel_size=(1,), stride=(1,))
        (encoder): WaveNet(
          (conv_layers): ModuleList(
            (0-15): 16 x ResidualBlock(
              (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
              (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
              (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
            )
          )
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (flow): ResidualAffineCouplingBlock(
        (flows): ModuleList(
          (0): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (1): FlipFlow()
          (2): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (3): FlipFlow()
          (4): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (5): FlipFlow()
          (6): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (7): FlipFlow()
        )
      )
      (duration_predictor): StochasticDurationPredictor(
        (pre): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (log_flow): LogFlow()
        (flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (post_pre): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
        (post_dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (post_proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (post_flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (global_conv): Conv1d(256, 192, kernel_size=(1,), stride=(1,))
      )
      (global_emb): Embedding(128, 256)
    )
    (discriminator): HiFiGANMultiScaleMultiPeriodDiscriminator(
      (msd): HiFiGANMultiScaleDiscriminator(
        (discriminators): ModuleList(
          (0): HiFiGANScaleDiscriminator(
            (layers): ModuleList(
              (0): Sequential(
                (0): Conv1d(1, 128, kernel_size=(15,), stride=(1,), padding=(7,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv1d(128, 128, kernel_size=(41,), stride=(2,), padding=(20,), groups=4)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv1d(128, 256, kernel_size=(41,), stride=(2,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv1d(256, 512, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv1d(512, 1024, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (5): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(41,), stride=(1,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (6): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (7): Conv1d(1024, 1, kernel_size=(3,), stride=(1,), padding=(1,))
            )
          )
        )
      )
      (mpd): HiFiGANMultiPeriodDiscriminator(
        (discriminators): ModuleList(
          (0-4): 5 x HiFiGANPeriodDiscriminator(
            (convs): ModuleList(
              (0): Sequential(
                (0): Conv2d(1, 32, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv2d(32, 128, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv2d(128, 512, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv2d(512, 1024, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv2d(1024, 1024, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
            )
            (output_conv): Conv2d(1024, 1, kernel_size=(2, 1), stride=(1, 1), padding=(1, 0))
          )
        )
      )
    )
    (generator_adv_loss): GeneratorAdversarialLoss()
    (discriminator_adv_loss): DiscriminatorAdversarialLoss()
    (feat_match_loss): FeatureMatchLoss()
    (mel_loss): MelSpectrogramLoss(
      (wav_to_mel): LogMelFbank(
        (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
        (logmel): LogMel(sr=22050, n_fft=1024, n_mels=80, fmin=0, fmax=11025.0, htk=False)
      )
    )
    (kl_loss): KLDivergenceLoss()
  )
)

Model summary:
    Class Name: ESPnetGANTTSModel
    Total Number of model parameters: 96.37 M
    Number of trainable parameters: 96.37 M (100.0%)
    Size: 385.46 MB
    Type: torch.float32
Optimizer:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler: <torch.optim.lr_scheduler.ExponentialLR object at 0x146de2b0b5e0>
Optimizer2:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler2: <torch.optim.lr_scheduler.ExponentialLR object at 0x146de2b0b9d0>
Saving the configuration in exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.8/config.yaml
Namespace(config='conf/tuning/train_multi_spk_vits.yaml', print_config=False, log_level='INFO', drop_last_iter=False, dry_run=False, iterator_type='sequence', valid_iterator_type=None, output_dir='exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.8', ngpu=0, seed=777, num_workers=4, num_att_plot=3, dist_backend='nccl', dist_init_method='env://', dist_world_size=None, dist_rank=None, local_rank=None, dist_master_addr=None, dist_master_port=None, dist_launcher=None, multiprocessing_distributed=False, unused_parameters=True, sharded_ddp=False, use_deepspeed=False, deepspeed_config=None, gradient_as_bucket_view=True, ddp_comm_hook=None, cudnn_enabled=True, cudnn_benchmark=False, cudnn_deterministic=False, use_tf32=False, collect_stats=True, write_collected_feats=False, max_epoch=1000, patience=None, val_scheduler_criterion=('valid', 'loss'), early_stopping_criterion=('valid', 'loss', 'min'), best_model_criterion=[['train', 'total_count', 'max']], keep_nbest_models=10, nbest_averaging_interval=0, grad_clip=-1, grad_clip_type=2.0, grad_noise=False, accum_grad=1, no_forward_run=False, resume=False, train_dtype='float32', use_amp=False, log_interval=50, use_matplotlib=True, use_tensorboard=True, create_graph_in_tensorboard=False, use_wandb=False, wandb_project=None, wandb_id=None, wandb_entity=None, wandb_name=None, wandb_model_log_interval=-1, detect_anomaly=False, use_adapter=False, adapter='lora', save_strategy='all', adapter_conf={}, pretrain_path=None, init_param=[], ignore_init_mismatch=False, freeze_param=[], num_iters_per_epoch=1000, batch_size=20, valid_batch_size=None, batch_bins=3000000, valid_batch_bins=None, category_sample_size=10, train_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.8.scp'], valid_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.8.scp'], batch_type='numel', valid_batch_type=None, fold_length=[], sort_in_batch='descending', shuffle_within_batch=False, sort_batch='descending', multiple_iterator=False, chunk_length=500, chunk_shift_ratio=0.5, num_cache_chunks=1024, chunk_excluded_key_prefixes=[], chunk_default_fs=None, chunk_max_abs_length=None, chunk_discard_short_samples=True, train_data_path_and_name_and_type=[('dump/22k/raw/tr_no_dev/text', 'text', 'text'), ('dump/22k/raw/tr_no_dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/tr_no_dev/utt2sid', 'sids', 'text_int')], valid_data_path_and_name_and_type=[('dump/22k/raw/dev/text', 'text', 'text'), ('dump/22k/raw/dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/dev/utt2sid', 'sids', 'text_int')], multi_task_dataset=False, allow_variable_data_keys=False, max_cache_size=0.0, max_cache_fd=32, allow_multi_rates=False, valid_max_cache_size=None, exclude_weight_decay=False, exclude_weight_decay_conf={}, optim='adamw', optim_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler='exponentiallr', scheduler_conf={'gamma': 0.999875}, optim2='adamw', optim2_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler2='exponentiallr', scheduler2_conf={'gamma': 0.999875}, generator_first=False, skip_discriminator_prob=0.0, token_list=['<blank>', '<unk>', ' ', 'AH0', 'N', 'T', 'D', 'S', 'R', 'L', 'IH1', 'DH', 'M', 'EH1', 'Z', 'AE1', 'K', 'IH0', 'AH1', 'HH', 'W', 'ER0', 'V', 'IY1', 'F', 'UW1', 'P', 'AY1', 'B', 'AA1', 'AO1', 'EY1', 'IY0', 'OW1', 'NG', 'SH', 'G', 'Y', 'AW1', 'CH', 'ER1', 'UH1', 'TH', 'JH', 'OW0', 'EH2', 'IH2', 'OY1', 'EY2', 'AY2', 'EH0', 'UW0', 'AA2', 'AE2', 'OW2', 'AH2', 'AA0', 'ZH', 'AE0', 'AO2', 'UW2', 'AO0', 'AY0', 'IY2', 'AW2', 'UH2', 'EY0', 'ER2', 'AW0', 'UH0', 'OY2', 'OY0', "'", '<sos/eos>'], odim=None, model_conf={}, use_preprocessor=True, token_type='phn', bpemodel=None, non_linguistic_symbols=None, cleaner='tacotron', g2p='g2p_en', feats_extract='linear_spectrogram', feats_extract_conf={'n_fft': 1024, 'hop_length': 256, 'win_length': None}, normalize=None, normalize_conf={}, tts='vits', tts_conf={'generator_type': 'vits_generator', 'generator_params': {'hidden_channels': 192, 'spks': 128, 'global_channels': 256, 'segment_size': 32, 'text_encoder_attention_heads': 2, 'text_encoder_ffn_expand': 4, 'text_encoder_blocks': 6, 'text_encoder_positionwise_layer_type': 'conv1d', 'text_encoder_positionwise_conv_kernel_size': 3, 'text_encoder_positional_encoding_layer_type': 'rel_pos', 'text_encoder_self_attention_layer_type': 'rel_selfattn', 'text_encoder_activation_type': 'swish', 'text_encoder_normalize_before': True, 'text_encoder_dropout_rate': 0.1, 'text_encoder_positional_dropout_rate': 0.0, 'text_encoder_attention_dropout_rate': 0.1, 'use_macaron_style_in_text_encoder': True, 'use_conformer_conv_in_text_encoder': False, 'text_encoder_conformer_kernel_size': -1, 'decoder_kernel_size': 7, 'decoder_channels': 512, 'decoder_upsample_scales': [8, 8, 2, 2], 'decoder_upsample_kernel_sizes': [16, 16, 4, 4], 'decoder_resblock_kernel_sizes': [3, 7, 11], 'decoder_resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'use_weight_norm_in_decoder': True, 'posterior_encoder_kernel_size': 5, 'posterior_encoder_layers': 16, 'posterior_encoder_stacks': 1, 'posterior_encoder_base_dilation': 1, 'posterior_encoder_dropout_rate': 0.0, 'use_weight_norm_in_posterior_encoder': True, 'flow_flows': 4, 'flow_kernel_size': 5, 'flow_base_dilation': 1, 'flow_layers': 4, 'flow_dropout_rate': 0.0, 'use_weight_norm_in_flow': True, 'use_only_mean_in_flow': True, 'stochastic_duration_predictor_kernel_size': 3, 'stochastic_duration_predictor_dropout_rate': 0.5, 'stochastic_duration_predictor_flows': 4, 'stochastic_duration_predictor_dds_conv_layers': 3, 'vocabs': 74, 'aux_channels': 513}, 'discriminator_type': 'hifigan_multi_scale_multi_period_discriminator', 'discriminator_params': {'scales': 1, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'stride': 2, 'padding': 2}, 'scale_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'channels': 128, 'max_downsample_channels': 1024, 'max_groups': 16, 'bias': True, 'downsample_scales': [2, 2, 4, 4, 1], 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}, 'follow_official_norm': False, 'periods': [2, 3, 5, 7, 11], 'period_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [5, 3], 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'max_downsample_channels': 1024, 'bias': True, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}}, 'generator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'discriminator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'feat_match_loss_params': {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, 'mel_loss_params': {'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None, 'window': 'hann', 'n_mels': 80, 'fmin': 0, 'fmax': None, 'log_base': None}, 'lambda_adv': 1.0, 'lambda_mel': 45.0, 'lambda_feat_match': 2.0, 'lambda_dur': 1.0, 'lambda_kl': 1.0, 'sampling_rate': 22050, 'cache_generator_outputs': True, 'plot_pred_mos': False, 'mos_pred_tool': 'utmos'}, pitch_extract=None, pitch_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'f0max': 400, 'f0min': 80}, pitch_normalize=None, pitch_normalize_conf={}, energy_extract=None, energy_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None}, energy_normalize=None, energy_normalize_conf={}, required=['output_dir', 'token_list'], version='202503', distributed=False)
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1284, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 53710) is killed by signal: Killed. 

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 22, in <module>
    main()
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 18, in main
    GANTTSTask.main(cmd=cmd)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1225, in main
    cls.main_worker(args)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1441, in main_worker
    collect_stats(
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/main_funcs/collect_stats.py", line 51, in collect_stats
    for iiter, (keys, batch) in enumerate(itr, 1):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 733, in __next__
    data = self._next_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1491, in _next_data
    idx, data = self._get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1453, in _get_data
    success, data = self._try_get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1297, in _try_get_data
    raise RuntimeError(
RuntimeError: DataLoader worker (pid(s) 53710) exited unexpectedly
# Accounting: begin_time=1750873256
# Accounting: end_time=1750873472
# Accounting: time=216 threads=1
# Finished at Wed Jun 25 13:44:32 EDT 2025 with status 1
# Running on r214.ib.bridges2.psc.edu
# Started at Wed Jun 25 13:40:56 EDT 2025
# SLURMD_NODENAME=r214
# SLURM_ARRAY_JOB_ID=32990217
# SLURM_ARRAY_TASK_COUNT=32
# SLURM_ARRAY_TASK_ID=9
# SLURM_ARRAY_TASK_MAX=32
# SLURM_ARRAY_TASK_MIN=1
# SLURM_ARRAY_TASK_STEP=1
# SLURM_CLUSTER_NAME=bridges2
# SLURM_CONF=/var/spool/slurm/d/conf-cache/slurm.conf
# SLURM_CPUS_ON_NODE=1
# SLURM_CPU_BIND=quiet,mask_cpu:0x07C0000000
# SLURM_CPU_BIND_LIST=0x07C0000000
# SLURM_CPU_BIND_TYPE=mask_cpu:
# SLURM_CPU_BIND_VERBOSE=quiet
# SLURM_EXPORT_ENV=ALL
# SLURM_GET_USER_ENV=1
# SLURM_GTIDS=0
# SLURM_JOBID=32990227
# SLURM_JOB_ACCOUNT=cis210027p
# SLURM_JOB_CPUS_PER_NODE=1
# SLURM_JOB_GID=24886
# SLURM_JOB_ID=32990227
# SLURM_JOB_NAME=stats.sh
# SLURM_JOB_NODELIST=r214
# SLURM_JOB_NUM_NODES=1
# SLURM_JOB_PARTITION=RM-shared
# SLURM_JOB_QOS=rm
# SLURM_JOB_UID=97947
# SLURM_JOB_USER=ttao3
# SLURM_LAUNCH_NODE_IPADDR=10.8.11.29
# SLURM_LOCALID=0
# SLURM_MEM_PER_CPU=1900
# SLURM_NNODES=1
# SLURM_NODEID=0
# SLURM_NODELIST=r214
# SLURM_NODE_ALIASES='(null)'
# SLURM_NPROCS=1
# SLURM_NTASKS=1
# SLURM_OPEN_MODE=a
# SLURM_PRIO_PROCESS=0
# SLURM_PROCID=0
# SLURM_PTY_PORT=33025
# SLURM_PTY_WIN_COL=126
# SLURM_PTY_WIN_ROW=21
# SLURM_SCRIPT_CONTEXT=prolog_task
# SLURM_SRUN_COMM_HOST=10.8.11.29
# SLURM_SRUN_COMM_PORT=35045
# SLURM_STEPID=0
# SLURM_STEP_GPUS=6
# SLURM_STEP_ID=0
# SLURM_STEP_LAUNCHER_PORT=35045
# SLURM_STEP_NODELIST=v029
# SLURM_STEP_NUM_NODES=1
# SLURM_STEP_NUM_TASKS=1
# SLURM_STEP_TASKS_PER_NODE=1
# SLURM_SUBMIT_DIR=/ocean/projects/cis210027p/ttao3/espnet/egs2/hifitts/tts1
# SLURM_SUBMIT_HOST=v029.ib.bridges2.psc.edu
# SLURM_TASKS_PER_NODE=1
# SLURM_TASK_PID=53642
# SLURM_TOPOLOGY_ADDR=r214
# SLURM_TOPOLOGY_ADDR_PATTERN=node
# SLURM_WORKING_CLUSTER=bridges2:br003:6810:9728:109
# python3 -m espnet2.bin.gan_tts_train --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.9.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.9.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.9 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int 
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/librosa/util/files.py:10: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_filename
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/bin/python3 /ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.9.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.9.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.9 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int
Failed to import Flash Attention, using ESPnet default: No module named 'flash_attn_2_cuda'
Vocabulary size: 74
encoder self-attention layer type = relative self-attention
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/ocean/projects/cis210027p/ttao3/espnet/espnet2/gan_tts/vits/monotonic_align/__init__.py:19: UserWarning: Cython version is not available. Fallback to 'EXPERIMETAL' numba version. If you want to use the cython version, please build it as follows: `cd espnet2/gan_tts/vits/monotonic_align; python setup.py build_ext --inplace`
  warnings.warn(
pytorch.version=2.7.1+cu126, cuda.available=False, cudnn.version=90501, cudnn.benchmark=False, cudnn.deterministic=False
Model structure:
ESPnetGANTTSModel(
  (feats_extract): LinearSpectrogram(
    (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
  )
  (tts): VITS(
    (generator): VITSGenerator(
      (text_encoder): TextEncoder(
        (emb): Embedding(74, 192)
        (encoder): Encoder(
          (embed): Sequential(
            (0): RelPositionalEncoding(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (encoders): MultiSequential(
            (0): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (2): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (3): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (4): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (5): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (after_norm): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (decoder): HiFiGANGenerator(
        (input_conv): Conv1d(192, 512, kernel_size=(7,), stride=(1,), padding=(3,))
        (upsamples): ModuleList(
          (0): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (1): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(256, 128, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (2): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,))
          )
          (3): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,))
          )
        )
        (blocks): ModuleList(
          (0): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (1): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (2): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (3): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (4): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (5): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (6): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (7): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (8): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (9): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (10): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (11): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
        )
        (output_conv): Sequential(
          (0): LeakyReLU(negative_slope=0.01)
          (1): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,))
          (2): Tanh()
        )
        (global_conv): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
      )
      (posterior_encoder): PosteriorEncoder(
        (input_conv): Conv1d(513, 192, kernel_size=(1,), stride=(1,))
        (encoder): WaveNet(
          (conv_layers): ModuleList(
            (0-15): 16 x ResidualBlock(
              (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
              (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
              (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
            )
          )
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (flow): ResidualAffineCouplingBlock(
        (flows): ModuleList(
          (0): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (1): FlipFlow()
          (2): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (3): FlipFlow()
          (4): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (5): FlipFlow()
          (6): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (7): FlipFlow()
        )
      )
      (duration_predictor): StochasticDurationPredictor(
        (pre): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (log_flow): LogFlow()
        (flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (post_pre): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
        (post_dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (post_proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (post_flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (global_conv): Conv1d(256, 192, kernel_size=(1,), stride=(1,))
      )
      (global_emb): Embedding(128, 256)
    )
    (discriminator): HiFiGANMultiScaleMultiPeriodDiscriminator(
      (msd): HiFiGANMultiScaleDiscriminator(
        (discriminators): ModuleList(
          (0): HiFiGANScaleDiscriminator(
            (layers): ModuleList(
              (0): Sequential(
                (0): Conv1d(1, 128, kernel_size=(15,), stride=(1,), padding=(7,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv1d(128, 128, kernel_size=(41,), stride=(2,), padding=(20,), groups=4)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv1d(128, 256, kernel_size=(41,), stride=(2,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv1d(256, 512, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv1d(512, 1024, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (5): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(41,), stride=(1,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (6): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (7): Conv1d(1024, 1, kernel_size=(3,), stride=(1,), padding=(1,))
            )
          )
        )
      )
      (mpd): HiFiGANMultiPeriodDiscriminator(
        (discriminators): ModuleList(
          (0-4): 5 x HiFiGANPeriodDiscriminator(
            (convs): ModuleList(
              (0): Sequential(
                (0): Conv2d(1, 32, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv2d(32, 128, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv2d(128, 512, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv2d(512, 1024, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv2d(1024, 1024, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
            )
            (output_conv): Conv2d(1024, 1, kernel_size=(2, 1), stride=(1, 1), padding=(1, 0))
          )
        )
      )
    )
    (generator_adv_loss): GeneratorAdversarialLoss()
    (discriminator_adv_loss): DiscriminatorAdversarialLoss()
    (feat_match_loss): FeatureMatchLoss()
    (mel_loss): MelSpectrogramLoss(
      (wav_to_mel): LogMelFbank(
        (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
        (logmel): LogMel(sr=22050, n_fft=1024, n_mels=80, fmin=0, fmax=11025.0, htk=False)
      )
    )
    (kl_loss): KLDivergenceLoss()
  )
)

Model summary:
    Class Name: ESPnetGANTTSModel
    Total Number of model parameters: 96.37 M
    Number of trainable parameters: 96.37 M (100.0%)
    Size: 385.46 MB
    Type: torch.float32
Optimizer:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler: <torch.optim.lr_scheduler.ExponentialLR object at 0x1506af3944c0>
Optimizer2:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler2: <torch.optim.lr_scheduler.ExponentialLR object at 0x1506af3948e0>
Saving the configuration in exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.9/config.yaml
Namespace(config='conf/tuning/train_multi_spk_vits.yaml', print_config=False, log_level='INFO', drop_last_iter=False, dry_run=False, iterator_type='sequence', valid_iterator_type=None, output_dir='exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.9', ngpu=0, seed=777, num_workers=4, num_att_plot=3, dist_backend='nccl', dist_init_method='env://', dist_world_size=None, dist_rank=None, local_rank=None, dist_master_addr=None, dist_master_port=None, dist_launcher=None, multiprocessing_distributed=False, unused_parameters=True, sharded_ddp=False, use_deepspeed=False, deepspeed_config=None, gradient_as_bucket_view=True, ddp_comm_hook=None, cudnn_enabled=True, cudnn_benchmark=False, cudnn_deterministic=False, use_tf32=False, collect_stats=True, write_collected_feats=False, max_epoch=1000, patience=None, val_scheduler_criterion=('valid', 'loss'), early_stopping_criterion=('valid', 'loss', 'min'), best_model_criterion=[['train', 'total_count', 'max']], keep_nbest_models=10, nbest_averaging_interval=0, grad_clip=-1, grad_clip_type=2.0, grad_noise=False, accum_grad=1, no_forward_run=False, resume=False, train_dtype='float32', use_amp=False, log_interval=50, use_matplotlib=True, use_tensorboard=True, create_graph_in_tensorboard=False, use_wandb=False, wandb_project=None, wandb_id=None, wandb_entity=None, wandb_name=None, wandb_model_log_interval=-1, detect_anomaly=False, use_adapter=False, adapter='lora', save_strategy='all', adapter_conf={}, pretrain_path=None, init_param=[], ignore_init_mismatch=False, freeze_param=[], num_iters_per_epoch=1000, batch_size=20, valid_batch_size=None, batch_bins=3000000, valid_batch_bins=None, category_sample_size=10, train_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.9.scp'], valid_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.9.scp'], batch_type='numel', valid_batch_type=None, fold_length=[], sort_in_batch='descending', shuffle_within_batch=False, sort_batch='descending', multiple_iterator=False, chunk_length=500, chunk_shift_ratio=0.5, num_cache_chunks=1024, chunk_excluded_key_prefixes=[], chunk_default_fs=None, chunk_max_abs_length=None, chunk_discard_short_samples=True, train_data_path_and_name_and_type=[('dump/22k/raw/tr_no_dev/text', 'text', 'text'), ('dump/22k/raw/tr_no_dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/tr_no_dev/utt2sid', 'sids', 'text_int')], valid_data_path_and_name_and_type=[('dump/22k/raw/dev/text', 'text', 'text'), ('dump/22k/raw/dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/dev/utt2sid', 'sids', 'text_int')], multi_task_dataset=False, allow_variable_data_keys=False, max_cache_size=0.0, max_cache_fd=32, allow_multi_rates=False, valid_max_cache_size=None, exclude_weight_decay=False, exclude_weight_decay_conf={}, optim='adamw', optim_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler='exponentiallr', scheduler_conf={'gamma': 0.999875}, optim2='adamw', optim2_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler2='exponentiallr', scheduler2_conf={'gamma': 0.999875}, generator_first=False, skip_discriminator_prob=0.0, token_list=['<blank>', '<unk>', ' ', 'AH0', 'N', 'T', 'D', 'S', 'R', 'L', 'IH1', 'DH', 'M', 'EH1', 'Z', 'AE1', 'K', 'IH0', 'AH1', 'HH', 'W', 'ER0', 'V', 'IY1', 'F', 'UW1', 'P', 'AY1', 'B', 'AA1', 'AO1', 'EY1', 'IY0', 'OW1', 'NG', 'SH', 'G', 'Y', 'AW1', 'CH', 'ER1', 'UH1', 'TH', 'JH', 'OW0', 'EH2', 'IH2', 'OY1', 'EY2', 'AY2', 'EH0', 'UW0', 'AA2', 'AE2', 'OW2', 'AH2', 'AA0', 'ZH', 'AE0', 'AO2', 'UW2', 'AO0', 'AY0', 'IY2', 'AW2', 'UH2', 'EY0', 'ER2', 'AW0', 'UH0', 'OY2', 'OY0', "'", '<sos/eos>'], odim=None, model_conf={}, use_preprocessor=True, token_type='phn', bpemodel=None, non_linguistic_symbols=None, cleaner='tacotron', g2p='g2p_en', feats_extract='linear_spectrogram', feats_extract_conf={'n_fft': 1024, 'hop_length': 256, 'win_length': None}, normalize=None, normalize_conf={}, tts='vits', tts_conf={'generator_type': 'vits_generator', 'generator_params': {'hidden_channels': 192, 'spks': 128, 'global_channels': 256, 'segment_size': 32, 'text_encoder_attention_heads': 2, 'text_encoder_ffn_expand': 4, 'text_encoder_blocks': 6, 'text_encoder_positionwise_layer_type': 'conv1d', 'text_encoder_positionwise_conv_kernel_size': 3, 'text_encoder_positional_encoding_layer_type': 'rel_pos', 'text_encoder_self_attention_layer_type': 'rel_selfattn', 'text_encoder_activation_type': 'swish', 'text_encoder_normalize_before': True, 'text_encoder_dropout_rate': 0.1, 'text_encoder_positional_dropout_rate': 0.0, 'text_encoder_attention_dropout_rate': 0.1, 'use_macaron_style_in_text_encoder': True, 'use_conformer_conv_in_text_encoder': False, 'text_encoder_conformer_kernel_size': -1, 'decoder_kernel_size': 7, 'decoder_channels': 512, 'decoder_upsample_scales': [8, 8, 2, 2], 'decoder_upsample_kernel_sizes': [16, 16, 4, 4], 'decoder_resblock_kernel_sizes': [3, 7, 11], 'decoder_resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'use_weight_norm_in_decoder': True, 'posterior_encoder_kernel_size': 5, 'posterior_encoder_layers': 16, 'posterior_encoder_stacks': 1, 'posterior_encoder_base_dilation': 1, 'posterior_encoder_dropout_rate': 0.0, 'use_weight_norm_in_posterior_encoder': True, 'flow_flows': 4, 'flow_kernel_size': 5, 'flow_base_dilation': 1, 'flow_layers': 4, 'flow_dropout_rate': 0.0, 'use_weight_norm_in_flow': True, 'use_only_mean_in_flow': True, 'stochastic_duration_predictor_kernel_size': 3, 'stochastic_duration_predictor_dropout_rate': 0.5, 'stochastic_duration_predictor_flows': 4, 'stochastic_duration_predictor_dds_conv_layers': 3, 'vocabs': 74, 'aux_channels': 513}, 'discriminator_type': 'hifigan_multi_scale_multi_period_discriminator', 'discriminator_params': {'scales': 1, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'stride': 2, 'padding': 2}, 'scale_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'channels': 128, 'max_downsample_channels': 1024, 'max_groups': 16, 'bias': True, 'downsample_scales': [2, 2, 4, 4, 1], 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}, 'follow_official_norm': False, 'periods': [2, 3, 5, 7, 11], 'period_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [5, 3], 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'max_downsample_channels': 1024, 'bias': True, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}}, 'generator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'discriminator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'feat_match_loss_params': {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, 'mel_loss_params': {'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None, 'window': 'hann', 'n_mels': 80, 'fmin': 0, 'fmax': None, 'log_base': None}, 'lambda_adv': 1.0, 'lambda_mel': 45.0, 'lambda_feat_match': 2.0, 'lambda_dur': 1.0, 'lambda_kl': 1.0, 'sampling_rate': 22050, 'cache_generator_outputs': True, 'plot_pred_mos': False, 'mos_pred_tool': 'utmos'}, pitch_extract=None, pitch_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'f0max': 400, 'f0min': 80}, pitch_normalize=None, pitch_normalize_conf={}, energy_extract=None, energy_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None}, energy_normalize=None, energy_normalize_conf={}, required=['output_dir', 'token_list'], version='202503', distributed=False)
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1284, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 53709) is killed by signal: Killed. 

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 22, in <module>
    main()
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 18, in main
    GANTTSTask.main(cmd=cmd)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1225, in main
    cls.main_worker(args)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1441, in main_worker
    collect_stats(
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/main_funcs/collect_stats.py", line 51, in collect_stats
    for iiter, (keys, batch) in enumerate(itr, 1):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 733, in __next__
    data = self._next_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1491, in _next_data
    idx, data = self._get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1453, in _get_data
    success, data = self._try_get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1297, in _try_get_data
    raise RuntimeError(
RuntimeError: DataLoader worker (pid(s) 53709) exited unexpectedly
# Accounting: begin_time=1750873256
# Accounting: end_time=1750873472
# Accounting: time=216 threads=1
# Finished at Wed Jun 25 13:44:32 EDT 2025 with status 1
