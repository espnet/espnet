2025-06-25T03:30:14 (tts.sh:225:main) ./tts.sh --use_sid true --fs 22050 --n_fft 1024 --n_shift 256 --win_length null --dumpdir dump/22k --expdir exp/22k --tts_task gan_tts --feats_extract linear_spectrogram --feats_normalize none --train_config conf/tuning/train_multi_spk_vits.yaml --inference_config conf/tuning/decode_vits.yaml --train_set tr_no_dev --valid_set dev --test_sets test --srctexts data/tr_no_dev/text data/dev/text data/test/text --audio_format flac --stage 6 --stop-stage 6
2025-06-25T03:30:29 (tts.sh:592:main) Stage 6: TTS collect stats: train_set=dump/22k/raw/tr_no_dev, valid_set=dump/22k/raw/dev
2025-06-25T03:30:33 (tts.sh:679:main) Generate 'exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/run.sh'. You can resume the process from stage 6 using this script
2025-06-25T03:30:33 (tts.sh:683:main) TTS collect_stats started... log: 'exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.*.log'
/ocean/projects/cis210027p/ttao3/espnet/egs2/hifitts/tts1/utils/slurm.pl: Error: Job 32966037 seems to no longer exists:
'squeue -j 32966037' returned error code 1 and said:
  slurm_load_jobs error: Invalid job id specified

Syncfile exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/q/done.3562023.1 does not exist, meaning that the job did not finish.
Log is in exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.1.log. Last line '# Finished at Wed Jun 25 03:32:32 EDT 2025 with status 137' does not end in 'status 0'.
Possible reasons:
  a) Exceeded time limit? -> Use more jobs!
  b) Shutdown/Frozen machine? -> Run again! squeue:
slurm_load_jobs error: Invalid job id specified
# Running on r334.ib.bridges2.psc.edu
# Started at Wed Jun 25 03:30:46 EDT 2025
# SLURMD_NODENAME=r334
# SLURM_ARRAY_JOB_ID=32966037
# SLURM_ARRAY_TASK_COUNT=32
# SLURM_ARRAY_TASK_ID=10
# SLURM_ARRAY_TASK_MAX=32
# SLURM_ARRAY_TASK_MIN=1
# SLURM_ARRAY_TASK_STEP=1
# SLURM_CLUSTER_NAME=bridges2
# SLURM_CONF=/var/spool/slurm/d/conf-cache/slurm.conf
# SLURM_CPUS_ON_NODE=1
# SLURM_EXPORT_ENV=ALL
# SLURM_GET_USER_ENV=1
# SLURM_GTIDS=0
# SLURM_JOBID=32966047
# SLURM_JOB_ACCOUNT=cis210027p
# SLURM_JOB_CPUS_PER_NODE=1
# SLURM_JOB_GID=24886
# SLURM_JOB_ID=32966047
# SLURM_JOB_NAME=stats.sh
# SLURM_JOB_NODELIST=r334
# SLURM_JOB_NUM_NODES=1
# SLURM_JOB_PARTITION=RM-shared
# SLURM_JOB_QOS=rm
# SLURM_JOB_UID=97947
# SLURM_JOB_USER=ttao3
# SLURM_LOCALID=0
# SLURM_MEM_PER_CPU=1900
# SLURM_NNODES=1
# SLURM_NODEID=0
# SLURM_NODELIST=r334
# SLURM_NODE_ALIASES='(null)'
# SLURM_OPEN_MODE=a
# SLURM_PRIO_PROCESS=0
# SLURM_PROCID=0
# SLURM_SCRIPT_CONTEXT=prolog_task
# SLURM_SUBMIT_DIR=/ocean/projects/cis210027p/ttao3/espnet/egs2/hifitts/tts1
# SLURM_SUBMIT_HOST=br013.ib.bridges2.psc.edu
# SLURM_TASKS_PER_NODE=1
# SLURM_TASK_PID=99169
# SLURM_TOPOLOGY_ADDR=r334
# SLURM_TOPOLOGY_ADDR_PATTERN=node
# SLURM_WORKING_CLUSTER=bridges2:br003:6810:9728:109
# python3 -m espnet2.bin.gan_tts_train --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.10.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.10.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.10 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int 
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/librosa/util/files.py:10: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_filename
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/bin/python3 /ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.10.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.10.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.10 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int
Failed to import Flash Attention, using ESPnet default: No module named 'flash_attn_2_cuda'
Vocabulary size: 74
encoder self-attention layer type = relative self-attention
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/ocean/projects/cis210027p/ttao3/espnet/espnet2/gan_tts/vits/monotonic_align/__init__.py:19: UserWarning: Cython version is not available. Fallback to 'EXPERIMETAL' numba version. If you want to use the cython version, please build it as follows: `cd espnet2/gan_tts/vits/monotonic_align; python setup.py build_ext --inplace`
  warnings.warn(
pytorch.version=2.7.1+cu126, cuda.available=False, cudnn.version=90501, cudnn.benchmark=False, cudnn.deterministic=False
Model structure:
ESPnetGANTTSModel(
  (feats_extract): LinearSpectrogram(
    (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
  )
  (tts): VITS(
    (generator): VITSGenerator(
      (text_encoder): TextEncoder(
        (emb): Embedding(74, 192)
        (encoder): Encoder(
          (embed): Sequential(
            (0): RelPositionalEncoding(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (encoders): MultiSequential(
            (0): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (2): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (3): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (4): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (5): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (after_norm): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (decoder): HiFiGANGenerator(
        (input_conv): Conv1d(192, 512, kernel_size=(7,), stride=(1,), padding=(3,))
        (upsamples): ModuleList(
          (0): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (1): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(256, 128, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (2): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,))
          )
          (3): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,))
          )
        )
        (blocks): ModuleList(
          (0): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (1): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (2): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (3): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (4): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (5): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (6): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (7): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (8): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (9): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (10): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (11): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
        )
        (output_conv): Sequential(
          (0): LeakyReLU(negative_slope=0.01)
          (1): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,))
          (2): Tanh()
        )
        (global_conv): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
      )
      (posterior_encoder): PosteriorEncoder(
        (input_conv): Conv1d(513, 192, kernel_size=(1,), stride=(1,))
        (encoder): WaveNet(
          (conv_layers): ModuleList(
            (0-15): 16 x ResidualBlock(
              (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
              (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
              (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
            )
          )
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (flow): ResidualAffineCouplingBlock(
        (flows): ModuleList(
          (0): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (1): FlipFlow()
          (2): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (3): FlipFlow()
          (4): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (5): FlipFlow()
          (6): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (7): FlipFlow()
        )
      )
      (duration_predictor): StochasticDurationPredictor(
        (pre): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (log_flow): LogFlow()
        (flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (post_pre): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
        (post_dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (post_proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (post_flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (global_conv): Conv1d(256, 192, kernel_size=(1,), stride=(1,))
      )
      (global_emb): Embedding(128, 256)
    )
    (discriminator): HiFiGANMultiScaleMultiPeriodDiscriminator(
      (msd): HiFiGANMultiScaleDiscriminator(
        (discriminators): ModuleList(
          (0): HiFiGANScaleDiscriminator(
            (layers): ModuleList(
              (0): Sequential(
                (0): Conv1d(1, 128, kernel_size=(15,), stride=(1,), padding=(7,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv1d(128, 128, kernel_size=(41,), stride=(2,), padding=(20,), groups=4)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv1d(128, 256, kernel_size=(41,), stride=(2,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv1d(256, 512, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv1d(512, 1024, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (5): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(41,), stride=(1,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (6): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (7): Conv1d(1024, 1, kernel_size=(3,), stride=(1,), padding=(1,))
            )
          )
        )
      )
      (mpd): HiFiGANMultiPeriodDiscriminator(
        (discriminators): ModuleList(
          (0-4): 5 x HiFiGANPeriodDiscriminator(
            (convs): ModuleList(
              (0): Sequential(
                (0): Conv2d(1, 32, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv2d(32, 128, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv2d(128, 512, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv2d(512, 1024, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv2d(1024, 1024, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
            )
            (output_conv): Conv2d(1024, 1, kernel_size=(2, 1), stride=(1, 1), padding=(1, 0))
          )
        )
      )
    )
    (generator_adv_loss): GeneratorAdversarialLoss()
    (discriminator_adv_loss): DiscriminatorAdversarialLoss()
    (feat_match_loss): FeatureMatchLoss()
    (mel_loss): MelSpectrogramLoss(
      (wav_to_mel): LogMelFbank(
        (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
        (logmel): LogMel(sr=22050, n_fft=1024, n_mels=80, fmin=0, fmax=11025.0, htk=False)
      )
    )
    (kl_loss): KLDivergenceLoss()
  )
)

Model summary:
    Class Name: ESPnetGANTTSModel
    Total Number of model parameters: 96.37 M
    Number of trainable parameters: 96.37 M (100.0%)
    Size: 385.46 MB
    Type: torch.float32
Optimizer:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler: <torch.optim.lr_scheduler.ExponentialLR object at 0x151defdf7250>
Optimizer2:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler2: <torch.optim.lr_scheduler.ExponentialLR object at 0x151defdf7670>
Saving the configuration in exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.10/config.yaml
Namespace(config='conf/tuning/train_multi_spk_vits.yaml', print_config=False, log_level='INFO', drop_last_iter=False, dry_run=False, iterator_type='sequence', valid_iterator_type=None, output_dir='exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.10', ngpu=0, seed=777, num_workers=4, num_att_plot=3, dist_backend='nccl', dist_init_method='env://', dist_world_size=None, dist_rank=None, local_rank=None, dist_master_addr=None, dist_master_port=None, dist_launcher=None, multiprocessing_distributed=False, unused_parameters=True, sharded_ddp=False, use_deepspeed=False, deepspeed_config=None, gradient_as_bucket_view=True, ddp_comm_hook=None, cudnn_enabled=True, cudnn_benchmark=False, cudnn_deterministic=False, use_tf32=False, collect_stats=True, write_collected_feats=False, max_epoch=1000, patience=None, val_scheduler_criterion=('valid', 'loss'), early_stopping_criterion=('valid', 'loss', 'min'), best_model_criterion=[['train', 'total_count', 'max']], keep_nbest_models=10, nbest_averaging_interval=0, grad_clip=-1, grad_clip_type=2.0, grad_noise=False, accum_grad=1, no_forward_run=False, resume=False, train_dtype='float32', use_amp=False, log_interval=50, use_matplotlib=True, use_tensorboard=True, create_graph_in_tensorboard=False, use_wandb=False, wandb_project=None, wandb_id=None, wandb_entity=None, wandb_name=None, wandb_model_log_interval=-1, detect_anomaly=False, use_adapter=False, adapter='lora', save_strategy='all', adapter_conf={}, pretrain_path=None, init_param=[], ignore_init_mismatch=False, freeze_param=[], num_iters_per_epoch=1000, batch_size=20, valid_batch_size=None, batch_bins=3000000, valid_batch_bins=None, category_sample_size=10, train_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.10.scp'], valid_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.10.scp'], batch_type='numel', valid_batch_type=None, fold_length=[], sort_in_batch='descending', shuffle_within_batch=False, sort_batch='descending', multiple_iterator=False, chunk_length=500, chunk_shift_ratio=0.5, num_cache_chunks=1024, chunk_excluded_key_prefixes=[], chunk_default_fs=None, chunk_max_abs_length=None, chunk_discard_short_samples=True, train_data_path_and_name_and_type=[('dump/22k/raw/tr_no_dev/text', 'text', 'text'), ('dump/22k/raw/tr_no_dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/tr_no_dev/utt2sid', 'sids', 'text_int')], valid_data_path_and_name_and_type=[('dump/22k/raw/dev/text', 'text', 'text'), ('dump/22k/raw/dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/dev/utt2sid', 'sids', 'text_int')], multi_task_dataset=False, allow_variable_data_keys=False, max_cache_size=0.0, max_cache_fd=32, allow_multi_rates=False, valid_max_cache_size=None, exclude_weight_decay=False, exclude_weight_decay_conf={}, optim='adamw', optim_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler='exponentiallr', scheduler_conf={'gamma': 0.999875}, optim2='adamw', optim2_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler2='exponentiallr', scheduler2_conf={'gamma': 0.999875}, generator_first=False, skip_discriminator_prob=0.0, token_list=['<blank>', '<unk>', ' ', 'AH0', 'N', 'T', 'D', 'S', 'R', 'L', 'IH1', 'DH', 'M', 'EH1', 'Z', 'AE1', 'K', 'IH0', 'AH1', 'HH', 'W', 'ER0', 'V', 'IY1', 'F', 'UW1', 'P', 'AY1', 'B', 'AA1', 'AO1', 'EY1', 'IY0', 'OW1', 'NG', 'SH', 'G', 'Y', 'AW1', 'CH', 'ER1', 'UH1', 'TH', 'JH', 'OW0', 'EH2', 'IH2', 'OY1', 'EY2', 'AY2', 'EH0', 'UW0', 'AA2', 'AE2', 'OW2', 'AH2', 'AA0', 'ZH', 'AE0', 'AO2', 'UW2', 'AO0', 'AY0', 'IY2', 'AW2', 'UH2', 'EY0', 'ER2', 'AW0', 'UH0', 'OY2', 'OY0', "'", '<sos/eos>'], odim=None, model_conf={}, use_preprocessor=True, token_type='phn', bpemodel=None, non_linguistic_symbols=None, cleaner='tacotron', g2p='g2p_en', feats_extract='linear_spectrogram', feats_extract_conf={'n_fft': 1024, 'hop_length': 256, 'win_length': None}, normalize=None, normalize_conf={}, tts='vits', tts_conf={'generator_type': 'vits_generator', 'generator_params': {'hidden_channels': 192, 'spks': 128, 'global_channels': 256, 'segment_size': 32, 'text_encoder_attention_heads': 2, 'text_encoder_ffn_expand': 4, 'text_encoder_blocks': 6, 'text_encoder_positionwise_layer_type': 'conv1d', 'text_encoder_positionwise_conv_kernel_size': 3, 'text_encoder_positional_encoding_layer_type': 'rel_pos', 'text_encoder_self_attention_layer_type': 'rel_selfattn', 'text_encoder_activation_type': 'swish', 'text_encoder_normalize_before': True, 'text_encoder_dropout_rate': 0.1, 'text_encoder_positional_dropout_rate': 0.0, 'text_encoder_attention_dropout_rate': 0.1, 'use_macaron_style_in_text_encoder': True, 'use_conformer_conv_in_text_encoder': False, 'text_encoder_conformer_kernel_size': -1, 'decoder_kernel_size': 7, 'decoder_channels': 512, 'decoder_upsample_scales': [8, 8, 2, 2], 'decoder_upsample_kernel_sizes': [16, 16, 4, 4], 'decoder_resblock_kernel_sizes': [3, 7, 11], 'decoder_resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'use_weight_norm_in_decoder': True, 'posterior_encoder_kernel_size': 5, 'posterior_encoder_layers': 16, 'posterior_encoder_stacks': 1, 'posterior_encoder_base_dilation': 1, 'posterior_encoder_dropout_rate': 0.0, 'use_weight_norm_in_posterior_encoder': True, 'flow_flows': 4, 'flow_kernel_size': 5, 'flow_base_dilation': 1, 'flow_layers': 4, 'flow_dropout_rate': 0.0, 'use_weight_norm_in_flow': True, 'use_only_mean_in_flow': True, 'stochastic_duration_predictor_kernel_size': 3, 'stochastic_duration_predictor_dropout_rate': 0.5, 'stochastic_duration_predictor_flows': 4, 'stochastic_duration_predictor_dds_conv_layers': 3, 'vocabs': 74, 'aux_channels': 513}, 'discriminator_type': 'hifigan_multi_scale_multi_period_discriminator', 'discriminator_params': {'scales': 1, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'stride': 2, 'padding': 2}, 'scale_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'channels': 128, 'max_downsample_channels': 1024, 'max_groups': 16, 'bias': True, 'downsample_scales': [2, 2, 4, 4, 1], 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}, 'follow_official_norm': False, 'periods': [2, 3, 5, 7, 11], 'period_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [5, 3], 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'max_downsample_channels': 1024, 'bias': True, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}}, 'generator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'discriminator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'feat_match_loss_params': {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, 'mel_loss_params': {'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None, 'window': 'hann', 'n_mels': 80, 'fmin': 0, 'fmax': None, 'log_base': None}, 'lambda_adv': 1.0, 'lambda_mel': 45.0, 'lambda_feat_match': 2.0, 'lambda_dur': 1.0, 'lambda_kl': 1.0, 'sampling_rate': 22050, 'cache_generator_outputs': True, 'plot_pred_mos': False, 'mos_pred_tool': 'utmos'}, pitch_extract=None, pitch_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'f0max': 400, 'f0min': 80}, pitch_normalize=None, pitch_normalize_conf={}, energy_extract=None, energy_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None}, energy_normalize=None, energy_normalize_conf={}, required=['output_dir', 'token_list'], version='202503', distributed=False)
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1284, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 99367) is killed by signal: Killed. 

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 22, in <module>
    main()
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 18, in main
    GANTTSTask.main(cmd=cmd)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1225, in main
    cls.main_worker(args)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1441, in main_worker
    collect_stats(
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/main_funcs/collect_stats.py", line 51, in collect_stats
    for iiter, (keys, batch) in enumerate(itr, 1):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 733, in __next__
    data = self._next_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1491, in _next_data
    idx, data = self._get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1453, in _get_data
    success, data = self._try_get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1297, in _try_get_data
    raise RuntimeError(
RuntimeError: DataLoader worker (pid(s) 99367) exited unexpectedly
# Accounting: begin_time=1750836646
# Accounting: end_time=1750836799
# Accounting: time=153 threads=1
# Finished at Wed Jun 25 03:33:19 EDT 2025 with status 1
# Running on r334.ib.bridges2.psc.edu
# Started at Wed Jun 25 03:30:46 EDT 2025
# SLURMD_NODENAME=r334
# SLURM_ARRAY_JOB_ID=32966037
# SLURM_ARRAY_TASK_COUNT=32
# SLURM_ARRAY_TASK_ID=11
# SLURM_ARRAY_TASK_MAX=32
# SLURM_ARRAY_TASK_MIN=1
# SLURM_ARRAY_TASK_STEP=1
# SLURM_CLUSTER_NAME=bridges2
# SLURM_CONF=/var/spool/slurm/d/conf-cache/slurm.conf
# SLURM_CPUS_ON_NODE=1
# SLURM_EXPORT_ENV=ALL
# SLURM_GET_USER_ENV=1
# SLURM_GTIDS=0
# SLURM_JOBID=32966048
# SLURM_JOB_ACCOUNT=cis210027p
# SLURM_JOB_CPUS_PER_NODE=1
# SLURM_JOB_GID=24886
# SLURM_JOB_ID=32966048
# SLURM_JOB_NAME=stats.sh
# SLURM_JOB_NODELIST=r334
# SLURM_JOB_NUM_NODES=1
# SLURM_JOB_PARTITION=RM-shared
# SLURM_JOB_QOS=rm
# SLURM_JOB_UID=97947
# SLURM_JOB_USER=ttao3
# SLURM_LOCALID=0
# SLURM_MEM_PER_CPU=1900
# SLURM_NNODES=1
# SLURM_NODEID=0
# SLURM_NODELIST=r334
# SLURM_NODE_ALIASES='(null)'
# SLURM_OPEN_MODE=a
# SLURM_PRIO_PROCESS=0
# SLURM_PROCID=0
# SLURM_SCRIPT_CONTEXT=prolog_task
# SLURM_SUBMIT_DIR=/ocean/projects/cis210027p/ttao3/espnet/egs2/hifitts/tts1
# SLURM_SUBMIT_HOST=br013.ib.bridges2.psc.edu
# SLURM_TASKS_PER_NODE=1
# SLURM_TASK_PID=99178
# SLURM_TOPOLOGY_ADDR=r334
# SLURM_TOPOLOGY_ADDR_PATTERN=node
# SLURM_WORKING_CLUSTER=bridges2:br003:6810:9728:109
# python3 -m espnet2.bin.gan_tts_train --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.11.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.11.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.11 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int 
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/librosa/util/files.py:10: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_filename
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/bin/python3 /ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.11.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.11.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.11 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int
Failed to import Flash Attention, using ESPnet default: No module named 'flash_attn_2_cuda'
Vocabulary size: 74
encoder self-attention layer type = relative self-attention
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/ocean/projects/cis210027p/ttao3/espnet/espnet2/gan_tts/vits/monotonic_align/__init__.py:19: UserWarning: Cython version is not available. Fallback to 'EXPERIMETAL' numba version. If you want to use the cython version, please build it as follows: `cd espnet2/gan_tts/vits/monotonic_align; python setup.py build_ext --inplace`
  warnings.warn(
pytorch.version=2.7.1+cu126, cuda.available=False, cudnn.version=90501, cudnn.benchmark=False, cudnn.deterministic=False
Model structure:
ESPnetGANTTSModel(
  (feats_extract): LinearSpectrogram(
    (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
  )
  (tts): VITS(
    (generator): VITSGenerator(
      (text_encoder): TextEncoder(
        (emb): Embedding(74, 192)
        (encoder): Encoder(
          (embed): Sequential(
            (0): RelPositionalEncoding(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (encoders): MultiSequential(
            (0): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (2): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (3): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (4): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (5): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (after_norm): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (decoder): HiFiGANGenerator(
        (input_conv): Conv1d(192, 512, kernel_size=(7,), stride=(1,), padding=(3,))
        (upsamples): ModuleList(
          (0): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (1): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(256, 128, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (2): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,))
          )
          (3): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,))
          )
        )
        (blocks): ModuleList(
          (0): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (1): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (2): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (3): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (4): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (5): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (6): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (7): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (8): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (9): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (10): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (11): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
        )
        (output_conv): Sequential(
          (0): LeakyReLU(negative_slope=0.01)
          (1): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,))
          (2): Tanh()
        )
        (global_conv): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
      )
      (posterior_encoder): PosteriorEncoder(
        (input_conv): Conv1d(513, 192, kernel_size=(1,), stride=(1,))
        (encoder): WaveNet(
          (conv_layers): ModuleList(
            (0-15): 16 x ResidualBlock(
              (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
              (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
              (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
            )
          )
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (flow): ResidualAffineCouplingBlock(
        (flows): ModuleList(
          (0): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (1): FlipFlow()
          (2): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (3): FlipFlow()
          (4): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (5): FlipFlow()
          (6): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (7): FlipFlow()
        )
      )
      (duration_predictor): StochasticDurationPredictor(
        (pre): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (log_flow): LogFlow()
        (flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (post_pre): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
        (post_dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (post_proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (post_flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (global_conv): Conv1d(256, 192, kernel_size=(1,), stride=(1,))
      )
      (global_emb): Embedding(128, 256)
    )
    (discriminator): HiFiGANMultiScaleMultiPeriodDiscriminator(
      (msd): HiFiGANMultiScaleDiscriminator(
        (discriminators): ModuleList(
          (0): HiFiGANScaleDiscriminator(
            (layers): ModuleList(
              (0): Sequential(
                (0): Conv1d(1, 128, kernel_size=(15,), stride=(1,), padding=(7,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv1d(128, 128, kernel_size=(41,), stride=(2,), padding=(20,), groups=4)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv1d(128, 256, kernel_size=(41,), stride=(2,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv1d(256, 512, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv1d(512, 1024, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (5): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(41,), stride=(1,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (6): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (7): Conv1d(1024, 1, kernel_size=(3,), stride=(1,), padding=(1,))
            )
          )
        )
      )
      (mpd): HiFiGANMultiPeriodDiscriminator(
        (discriminators): ModuleList(
          (0-4): 5 x HiFiGANPeriodDiscriminator(
            (convs): ModuleList(
              (0): Sequential(
                (0): Conv2d(1, 32, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv2d(32, 128, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv2d(128, 512, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv2d(512, 1024, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv2d(1024, 1024, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
            )
            (output_conv): Conv2d(1024, 1, kernel_size=(2, 1), stride=(1, 1), padding=(1, 0))
          )
        )
      )
    )
    (generator_adv_loss): GeneratorAdversarialLoss()
    (discriminator_adv_loss): DiscriminatorAdversarialLoss()
    (feat_match_loss): FeatureMatchLoss()
    (mel_loss): MelSpectrogramLoss(
      (wav_to_mel): LogMelFbank(
        (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
        (logmel): LogMel(sr=22050, n_fft=1024, n_mels=80, fmin=0, fmax=11025.0, htk=False)
      )
    )
    (kl_loss): KLDivergenceLoss()
  )
)

Model summary:
    Class Name: ESPnetGANTTSModel
    Total Number of model parameters: 96.37 M
    Number of trainable parameters: 96.37 M (100.0%)
    Size: 385.46 MB
    Type: torch.float32
Optimizer:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler: <torch.optim.lr_scheduler.ExponentialLR object at 0x1539c8d13250>
Optimizer2:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler2: <torch.optim.lr_scheduler.ExponentialLR object at 0x1539c8d13670>
Saving the configuration in exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.11/config.yaml
Namespace(config='conf/tuning/train_multi_spk_vits.yaml', print_config=False, log_level='INFO', drop_last_iter=False, dry_run=False, iterator_type='sequence', valid_iterator_type=None, output_dir='exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.11', ngpu=0, seed=777, num_workers=4, num_att_plot=3, dist_backend='nccl', dist_init_method='env://', dist_world_size=None, dist_rank=None, local_rank=None, dist_master_addr=None, dist_master_port=None, dist_launcher=None, multiprocessing_distributed=False, unused_parameters=True, sharded_ddp=False, use_deepspeed=False, deepspeed_config=None, gradient_as_bucket_view=True, ddp_comm_hook=None, cudnn_enabled=True, cudnn_benchmark=False, cudnn_deterministic=False, use_tf32=False, collect_stats=True, write_collected_feats=False, max_epoch=1000, patience=None, val_scheduler_criterion=('valid', 'loss'), early_stopping_criterion=('valid', 'loss', 'min'), best_model_criterion=[['train', 'total_count', 'max']], keep_nbest_models=10, nbest_averaging_interval=0, grad_clip=-1, grad_clip_type=2.0, grad_noise=False, accum_grad=1, no_forward_run=False, resume=False, train_dtype='float32', use_amp=False, log_interval=50, use_matplotlib=True, use_tensorboard=True, create_graph_in_tensorboard=False, use_wandb=False, wandb_project=None, wandb_id=None, wandb_entity=None, wandb_name=None, wandb_model_log_interval=-1, detect_anomaly=False, use_adapter=False, adapter='lora', save_strategy='all', adapter_conf={}, pretrain_path=None, init_param=[], ignore_init_mismatch=False, freeze_param=[], num_iters_per_epoch=1000, batch_size=20, valid_batch_size=None, batch_bins=3000000, valid_batch_bins=None, category_sample_size=10, train_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.11.scp'], valid_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.11.scp'], batch_type='numel', valid_batch_type=None, fold_length=[], sort_in_batch='descending', shuffle_within_batch=False, sort_batch='descending', multiple_iterator=False, chunk_length=500, chunk_shift_ratio=0.5, num_cache_chunks=1024, chunk_excluded_key_prefixes=[], chunk_default_fs=None, chunk_max_abs_length=None, chunk_discard_short_samples=True, train_data_path_and_name_and_type=[('dump/22k/raw/tr_no_dev/text', 'text', 'text'), ('dump/22k/raw/tr_no_dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/tr_no_dev/utt2sid', 'sids', 'text_int')], valid_data_path_and_name_and_type=[('dump/22k/raw/dev/text', 'text', 'text'), ('dump/22k/raw/dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/dev/utt2sid', 'sids', 'text_int')], multi_task_dataset=False, allow_variable_data_keys=False, max_cache_size=0.0, max_cache_fd=32, allow_multi_rates=False, valid_max_cache_size=None, exclude_weight_decay=False, exclude_weight_decay_conf={}, optim='adamw', optim_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler='exponentiallr', scheduler_conf={'gamma': 0.999875}, optim2='adamw', optim2_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler2='exponentiallr', scheduler2_conf={'gamma': 0.999875}, generator_first=False, skip_discriminator_prob=0.0, token_list=['<blank>', '<unk>', ' ', 'AH0', 'N', 'T', 'D', 'S', 'R', 'L', 'IH1', 'DH', 'M', 'EH1', 'Z', 'AE1', 'K', 'IH0', 'AH1', 'HH', 'W', 'ER0', 'V', 'IY1', 'F', 'UW1', 'P', 'AY1', 'B', 'AA1', 'AO1', 'EY1', 'IY0', 'OW1', 'NG', 'SH', 'G', 'Y', 'AW1', 'CH', 'ER1', 'UH1', 'TH', 'JH', 'OW0', 'EH2', 'IH2', 'OY1', 'EY2', 'AY2', 'EH0', 'UW0', 'AA2', 'AE2', 'OW2', 'AH2', 'AA0', 'ZH', 'AE0', 'AO2', 'UW2', 'AO0', 'AY0', 'IY2', 'AW2', 'UH2', 'EY0', 'ER2', 'AW0', 'UH0', 'OY2', 'OY0', "'", '<sos/eos>'], odim=None, model_conf={}, use_preprocessor=True, token_type='phn', bpemodel=None, non_linguistic_symbols=None, cleaner='tacotron', g2p='g2p_en', feats_extract='linear_spectrogram', feats_extract_conf={'n_fft': 1024, 'hop_length': 256, 'win_length': None}, normalize=None, normalize_conf={}, tts='vits', tts_conf={'generator_type': 'vits_generator', 'generator_params': {'hidden_channels': 192, 'spks': 128, 'global_channels': 256, 'segment_size': 32, 'text_encoder_attention_heads': 2, 'text_encoder_ffn_expand': 4, 'text_encoder_blocks': 6, 'text_encoder_positionwise_layer_type': 'conv1d', 'text_encoder_positionwise_conv_kernel_size': 3, 'text_encoder_positional_encoding_layer_type': 'rel_pos', 'text_encoder_self_attention_layer_type': 'rel_selfattn', 'text_encoder_activation_type': 'swish', 'text_encoder_normalize_before': True, 'text_encoder_dropout_rate': 0.1, 'text_encoder_positional_dropout_rate': 0.0, 'text_encoder_attention_dropout_rate': 0.1, 'use_macaron_style_in_text_encoder': True, 'use_conformer_conv_in_text_encoder': False, 'text_encoder_conformer_kernel_size': -1, 'decoder_kernel_size': 7, 'decoder_channels': 512, 'decoder_upsample_scales': [8, 8, 2, 2], 'decoder_upsample_kernel_sizes': [16, 16, 4, 4], 'decoder_resblock_kernel_sizes': [3, 7, 11], 'decoder_resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'use_weight_norm_in_decoder': True, 'posterior_encoder_kernel_size': 5, 'posterior_encoder_layers': 16, 'posterior_encoder_stacks': 1, 'posterior_encoder_base_dilation': 1, 'posterior_encoder_dropout_rate': 0.0, 'use_weight_norm_in_posterior_encoder': True, 'flow_flows': 4, 'flow_kernel_size': 5, 'flow_base_dilation': 1, 'flow_layers': 4, 'flow_dropout_rate': 0.0, 'use_weight_norm_in_flow': True, 'use_only_mean_in_flow': True, 'stochastic_duration_predictor_kernel_size': 3, 'stochastic_duration_predictor_dropout_rate': 0.5, 'stochastic_duration_predictor_flows': 4, 'stochastic_duration_predictor_dds_conv_layers': 3, 'vocabs': 74, 'aux_channels': 513}, 'discriminator_type': 'hifigan_multi_scale_multi_period_discriminator', 'discriminator_params': {'scales': 1, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'stride': 2, 'padding': 2}, 'scale_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'channels': 128, 'max_downsample_channels': 1024, 'max_groups': 16, 'bias': True, 'downsample_scales': [2, 2, 4, 4, 1], 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}, 'follow_official_norm': False, 'periods': [2, 3, 5, 7, 11], 'period_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [5, 3], 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'max_downsample_channels': 1024, 'bias': True, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}}, 'generator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'discriminator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'feat_match_loss_params': {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, 'mel_loss_params': {'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None, 'window': 'hann', 'n_mels': 80, 'fmin': 0, 'fmax': None, 'log_base': None}, 'lambda_adv': 1.0, 'lambda_mel': 45.0, 'lambda_feat_match': 2.0, 'lambda_dur': 1.0, 'lambda_kl': 1.0, 'sampling_rate': 22050, 'cache_generator_outputs': True, 'plot_pred_mos': False, 'mos_pred_tool': 'utmos'}, pitch_extract=None, pitch_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'f0max': 400, 'f0min': 80}, pitch_normalize=None, pitch_normalize_conf={}, energy_extract=None, energy_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None}, energy_normalize=None, energy_normalize_conf={}, required=['output_dir', 'token_list'], version='202503', distributed=False)
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1284, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 99363) is killed by signal: Killed. 

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 22, in <module>
    main()
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 18, in main
    GANTTSTask.main(cmd=cmd)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1225, in main
    cls.main_worker(args)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1441, in main_worker
    collect_stats(
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/main_funcs/collect_stats.py", line 51, in collect_stats
    for iiter, (keys, batch) in enumerate(itr, 1):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 733, in __next__
    data = self._next_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1491, in _next_data
    idx, data = self._get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1453, in _get_data
    success, data = self._try_get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1297, in _try_get_data
    raise RuntimeError(
RuntimeError: DataLoader worker (pid(s) 99363) exited unexpectedly
# Accounting: begin_time=1750836646
# Accounting: end_time=1750836799
# Accounting: time=153 threads=1
# Finished at Wed Jun 25 03:33:19 EDT 2025 with status 1
# Running on r334.ib.bridges2.psc.edu
# Started at Wed Jun 25 03:30:45 EDT 2025
# SLURMD_NODENAME=r334
# SLURM_ARRAY_JOB_ID=32966037
# SLURM_ARRAY_TASK_COUNT=32
# SLURM_ARRAY_TASK_ID=12
# SLURM_ARRAY_TASK_MAX=32
# SLURM_ARRAY_TASK_MIN=1
# SLURM_ARRAY_TASK_STEP=1
# SLURM_CLUSTER_NAME=bridges2
# SLURM_CONF=/var/spool/slurm/d/conf-cache/slurm.conf
# SLURM_CPUS_ON_NODE=1
# SLURM_EXPORT_ENV=ALL
# SLURM_GET_USER_ENV=1
# SLURM_GTIDS=0
# SLURM_JOBID=32966049
# SLURM_JOB_ACCOUNT=cis210027p
# SLURM_JOB_CPUS_PER_NODE=1
# SLURM_JOB_GID=24886
# SLURM_JOB_ID=32966049
# SLURM_JOB_NAME=stats.sh
# SLURM_JOB_NODELIST=r334
# SLURM_JOB_NUM_NODES=1
# SLURM_JOB_PARTITION=RM-shared
# SLURM_JOB_QOS=rm
# SLURM_JOB_UID=97947
# SLURM_JOB_USER=ttao3
# SLURM_LOCALID=0
# SLURM_MEM_PER_CPU=1900
# SLURM_NNODES=1
# SLURM_NODEID=0
# SLURM_NODELIST=r334
# SLURM_NODE_ALIASES='(null)'
# SLURM_OPEN_MODE=a
# SLURM_PRIO_PROCESS=0
# SLURM_PROCID=0
# SLURM_SCRIPT_CONTEXT=prolog_task
# SLURM_SUBMIT_DIR=/ocean/projects/cis210027p/ttao3/espnet/egs2/hifitts/tts1
# SLURM_SUBMIT_HOST=br013.ib.bridges2.psc.edu
# SLURM_TASKS_PER_NODE=1
# SLURM_TASK_PID=99106
# SLURM_TOPOLOGY_ADDR=r334
# SLURM_TOPOLOGY_ADDR_PATTERN=node
# SLURM_WORKING_CLUSTER=bridges2:br003:6810:9728:109
# python3 -m espnet2.bin.gan_tts_train --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.12.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.12.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.12 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int 
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/librosa/util/files.py:10: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_filename
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/bin/python3 /ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.12.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.12.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.12 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int
Failed to import Flash Attention, using ESPnet default: No module named 'flash_attn_2_cuda'
Vocabulary size: 74
encoder self-attention layer type = relative self-attention
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/ocean/projects/cis210027p/ttao3/espnet/espnet2/gan_tts/vits/monotonic_align/__init__.py:19: UserWarning: Cython version is not available. Fallback to 'EXPERIMETAL' numba version. If you want to use the cython version, please build it as follows: `cd espnet2/gan_tts/vits/monotonic_align; python setup.py build_ext --inplace`
  warnings.warn(
pytorch.version=2.7.1+cu126, cuda.available=False, cudnn.version=90501, cudnn.benchmark=False, cudnn.deterministic=False
Model structure:
ESPnetGANTTSModel(
  (feats_extract): LinearSpectrogram(
    (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
  )
  (tts): VITS(
    (generator): VITSGenerator(
      (text_encoder): TextEncoder(
        (emb): Embedding(74, 192)
        (encoder): Encoder(
          (embed): Sequential(
            (0): RelPositionalEncoding(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (encoders): MultiSequential(
            (0): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (2): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (3): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (4): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (5): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (after_norm): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (decoder): HiFiGANGenerator(
        (input_conv): Conv1d(192, 512, kernel_size=(7,), stride=(1,), padding=(3,))
        (upsamples): ModuleList(
          (0): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (1): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(256, 128, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (2): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,))
          )
          (3): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,))
          )
        )
        (blocks): ModuleList(
          (0): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (1): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (2): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (3): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (4): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (5): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (6): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (7): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (8): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (9): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (10): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (11): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
        )
        (output_conv): Sequential(
          (0): LeakyReLU(negative_slope=0.01)
          (1): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,))
          (2): Tanh()
        )
        (global_conv): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
      )
      (posterior_encoder): PosteriorEncoder(
        (input_conv): Conv1d(513, 192, kernel_size=(1,), stride=(1,))
        (encoder): WaveNet(
          (conv_layers): ModuleList(
            (0-15): 16 x ResidualBlock(
              (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
              (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
              (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
            )
          )
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (flow): ResidualAffineCouplingBlock(
        (flows): ModuleList(
          (0): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (1): FlipFlow()
          (2): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (3): FlipFlow()
          (4): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (5): FlipFlow()
          (6): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (7): FlipFlow()
        )
      )
      (duration_predictor): StochasticDurationPredictor(
        (pre): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (log_flow): LogFlow()
        (flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (post_pre): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
        (post_dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (post_proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (post_flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (global_conv): Conv1d(256, 192, kernel_size=(1,), stride=(1,))
      )
      (global_emb): Embedding(128, 256)
    )
    (discriminator): HiFiGANMultiScaleMultiPeriodDiscriminator(
      (msd): HiFiGANMultiScaleDiscriminator(
        (discriminators): ModuleList(
          (0): HiFiGANScaleDiscriminator(
            (layers): ModuleList(
              (0): Sequential(
                (0): Conv1d(1, 128, kernel_size=(15,), stride=(1,), padding=(7,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv1d(128, 128, kernel_size=(41,), stride=(2,), padding=(20,), groups=4)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv1d(128, 256, kernel_size=(41,), stride=(2,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv1d(256, 512, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv1d(512, 1024, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (5): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(41,), stride=(1,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (6): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (7): Conv1d(1024, 1, kernel_size=(3,), stride=(1,), padding=(1,))
            )
          )
        )
      )
      (mpd): HiFiGANMultiPeriodDiscriminator(
        (discriminators): ModuleList(
          (0-4): 5 x HiFiGANPeriodDiscriminator(
            (convs): ModuleList(
              (0): Sequential(
                (0): Conv2d(1, 32, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv2d(32, 128, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv2d(128, 512, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv2d(512, 1024, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv2d(1024, 1024, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
            )
            (output_conv): Conv2d(1024, 1, kernel_size=(2, 1), stride=(1, 1), padding=(1, 0))
          )
        )
      )
    )
    (generator_adv_loss): GeneratorAdversarialLoss()
    (discriminator_adv_loss): DiscriminatorAdversarialLoss()
    (feat_match_loss): FeatureMatchLoss()
    (mel_loss): MelSpectrogramLoss(
      (wav_to_mel): LogMelFbank(
        (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
        (logmel): LogMel(sr=22050, n_fft=1024, n_mels=80, fmin=0, fmax=11025.0, htk=False)
      )
    )
    (kl_loss): KLDivergenceLoss()
  )
)

Model summary:
    Class Name: ESPnetGANTTSModel
    Total Number of model parameters: 96.37 M
    Number of trainable parameters: 96.37 M (100.0%)
    Size: 385.46 MB
    Type: torch.float32
Optimizer:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler: <torch.optim.lr_scheduler.ExponentialLR object at 0x152a88fba1f0>
Optimizer2:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler2: <torch.optim.lr_scheduler.ExponentialLR object at 0x152a88fba610>
Saving the configuration in exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.12/config.yaml
Namespace(config='conf/tuning/train_multi_spk_vits.yaml', print_config=False, log_level='INFO', drop_last_iter=False, dry_run=False, iterator_type='sequence', valid_iterator_type=None, output_dir='exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.12', ngpu=0, seed=777, num_workers=4, num_att_plot=3, dist_backend='nccl', dist_init_method='env://', dist_world_size=None, dist_rank=None, local_rank=None, dist_master_addr=None, dist_master_port=None, dist_launcher=None, multiprocessing_distributed=False, unused_parameters=True, sharded_ddp=False, use_deepspeed=False, deepspeed_config=None, gradient_as_bucket_view=True, ddp_comm_hook=None, cudnn_enabled=True, cudnn_benchmark=False, cudnn_deterministic=False, use_tf32=False, collect_stats=True, write_collected_feats=False, max_epoch=1000, patience=None, val_scheduler_criterion=('valid', 'loss'), early_stopping_criterion=('valid', 'loss', 'min'), best_model_criterion=[['train', 'total_count', 'max']], keep_nbest_models=10, nbest_averaging_interval=0, grad_clip=-1, grad_clip_type=2.0, grad_noise=False, accum_grad=1, no_forward_run=False, resume=False, train_dtype='float32', use_amp=False, log_interval=50, use_matplotlib=True, use_tensorboard=True, create_graph_in_tensorboard=False, use_wandb=False, wandb_project=None, wandb_id=None, wandb_entity=None, wandb_name=None, wandb_model_log_interval=-1, detect_anomaly=False, use_adapter=False, adapter='lora', save_strategy='all', adapter_conf={}, pretrain_path=None, init_param=[], ignore_init_mismatch=False, freeze_param=[], num_iters_per_epoch=1000, batch_size=20, valid_batch_size=None, batch_bins=3000000, valid_batch_bins=None, category_sample_size=10, train_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.12.scp'], valid_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.12.scp'], batch_type='numel', valid_batch_type=None, fold_length=[], sort_in_batch='descending', shuffle_within_batch=False, sort_batch='descending', multiple_iterator=False, chunk_length=500, chunk_shift_ratio=0.5, num_cache_chunks=1024, chunk_excluded_key_prefixes=[], chunk_default_fs=None, chunk_max_abs_length=None, chunk_discard_short_samples=True, train_data_path_and_name_and_type=[('dump/22k/raw/tr_no_dev/text', 'text', 'text'), ('dump/22k/raw/tr_no_dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/tr_no_dev/utt2sid', 'sids', 'text_int')], valid_data_path_and_name_and_type=[('dump/22k/raw/dev/text', 'text', 'text'), ('dump/22k/raw/dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/dev/utt2sid', 'sids', 'text_int')], multi_task_dataset=False, allow_variable_data_keys=False, max_cache_size=0.0, max_cache_fd=32, allow_multi_rates=False, valid_max_cache_size=None, exclude_weight_decay=False, exclude_weight_decay_conf={}, optim='adamw', optim_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler='exponentiallr', scheduler_conf={'gamma': 0.999875}, optim2='adamw', optim2_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler2='exponentiallr', scheduler2_conf={'gamma': 0.999875}, generator_first=False, skip_discriminator_prob=0.0, token_list=['<blank>', '<unk>', ' ', 'AH0', 'N', 'T', 'D', 'S', 'R', 'L', 'IH1', 'DH', 'M', 'EH1', 'Z', 'AE1', 'K', 'IH0', 'AH1', 'HH', 'W', 'ER0', 'V', 'IY1', 'F', 'UW1', 'P', 'AY1', 'B', 'AA1', 'AO1', 'EY1', 'IY0', 'OW1', 'NG', 'SH', 'G', 'Y', 'AW1', 'CH', 'ER1', 'UH1', 'TH', 'JH', 'OW0', 'EH2', 'IH2', 'OY1', 'EY2', 'AY2', 'EH0', 'UW0', 'AA2', 'AE2', 'OW2', 'AH2', 'AA0', 'ZH', 'AE0', 'AO2', 'UW2', 'AO0', 'AY0', 'IY2', 'AW2', 'UH2', 'EY0', 'ER2', 'AW0', 'UH0', 'OY2', 'OY0', "'", '<sos/eos>'], odim=None, model_conf={}, use_preprocessor=True, token_type='phn', bpemodel=None, non_linguistic_symbols=None, cleaner='tacotron', g2p='g2p_en', feats_extract='linear_spectrogram', feats_extract_conf={'n_fft': 1024, 'hop_length': 256, 'win_length': None}, normalize=None, normalize_conf={}, tts='vits', tts_conf={'generator_type': 'vits_generator', 'generator_params': {'hidden_channels': 192, 'spks': 128, 'global_channels': 256, 'segment_size': 32, 'text_encoder_attention_heads': 2, 'text_encoder_ffn_expand': 4, 'text_encoder_blocks': 6, 'text_encoder_positionwise_layer_type': 'conv1d', 'text_encoder_positionwise_conv_kernel_size': 3, 'text_encoder_positional_encoding_layer_type': 'rel_pos', 'text_encoder_self_attention_layer_type': 'rel_selfattn', 'text_encoder_activation_type': 'swish', 'text_encoder_normalize_before': True, 'text_encoder_dropout_rate': 0.1, 'text_encoder_positional_dropout_rate': 0.0, 'text_encoder_attention_dropout_rate': 0.1, 'use_macaron_style_in_text_encoder': True, 'use_conformer_conv_in_text_encoder': False, 'text_encoder_conformer_kernel_size': -1, 'decoder_kernel_size': 7, 'decoder_channels': 512, 'decoder_upsample_scales': [8, 8, 2, 2], 'decoder_upsample_kernel_sizes': [16, 16, 4, 4], 'decoder_resblock_kernel_sizes': [3, 7, 11], 'decoder_resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'use_weight_norm_in_decoder': True, 'posterior_encoder_kernel_size': 5, 'posterior_encoder_layers': 16, 'posterior_encoder_stacks': 1, 'posterior_encoder_base_dilation': 1, 'posterior_encoder_dropout_rate': 0.0, 'use_weight_norm_in_posterior_encoder': True, 'flow_flows': 4, 'flow_kernel_size': 5, 'flow_base_dilation': 1, 'flow_layers': 4, 'flow_dropout_rate': 0.0, 'use_weight_norm_in_flow': True, 'use_only_mean_in_flow': True, 'stochastic_duration_predictor_kernel_size': 3, 'stochastic_duration_predictor_dropout_rate': 0.5, 'stochastic_duration_predictor_flows': 4, 'stochastic_duration_predictor_dds_conv_layers': 3, 'vocabs': 74, 'aux_channels': 513}, 'discriminator_type': 'hifigan_multi_scale_multi_period_discriminator', 'discriminator_params': {'scales': 1, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'stride': 2, 'padding': 2}, 'scale_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'channels': 128, 'max_downsample_channels': 1024, 'max_groups': 16, 'bias': True, 'downsample_scales': [2, 2, 4, 4, 1], 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}, 'follow_official_norm': False, 'periods': [2, 3, 5, 7, 11], 'period_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [5, 3], 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'max_downsample_channels': 1024, 'bias': True, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}}, 'generator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'discriminator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'feat_match_loss_params': {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, 'mel_loss_params': {'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None, 'window': 'hann', 'n_mels': 80, 'fmin': 0, 'fmax': None, 'log_base': None}, 'lambda_adv': 1.0, 'lambda_mel': 45.0, 'lambda_feat_match': 2.0, 'lambda_dur': 1.0, 'lambda_kl': 1.0, 'sampling_rate': 22050, 'cache_generator_outputs': True, 'plot_pred_mos': False, 'mos_pred_tool': 'utmos'}, pitch_extract=None, pitch_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'f0max': 400, 'f0min': 80}, pitch_normalize=None, pitch_normalize_conf={}, energy_extract=None, energy_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None}, energy_normalize=None, energy_normalize_conf={}, required=['output_dir', 'token_list'], version='202503', distributed=False)
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1284, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 99361) is killed by signal: Killed. 

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 22, in <module>
    main()
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 18, in main
    GANTTSTask.main(cmd=cmd)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1225, in main
    cls.main_worker(args)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1441, in main_worker
    collect_stats(
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/main_funcs/collect_stats.py", line 51, in collect_stats
    for iiter, (keys, batch) in enumerate(itr, 1):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 733, in __next__
    data = self._next_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1491, in _next_data
    idx, data = self._get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1453, in _get_data
    success, data = self._try_get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1297, in _try_get_data
    raise RuntimeError(
RuntimeError: DataLoader worker (pid(s) 99361) exited unexpectedly
# Accounting: begin_time=1750836645
# Accounting: end_time=1750836799
# Accounting: time=154 threads=1
# Finished at Wed Jun 25 03:33:19 EDT 2025 with status 1
# Running on r334.ib.bridges2.psc.edu
# Started at Wed Jun 25 03:30:46 EDT 2025
# SLURMD_NODENAME=r334
# SLURM_ARRAY_JOB_ID=32966037
# SLURM_ARRAY_TASK_COUNT=32
# SLURM_ARRAY_TASK_ID=13
# SLURM_ARRAY_TASK_MAX=32
# SLURM_ARRAY_TASK_MIN=1
# SLURM_ARRAY_TASK_STEP=1
# SLURM_CLUSTER_NAME=bridges2
# SLURM_CONF=/var/spool/slurm/d/conf-cache/slurm.conf
# SLURM_CPUS_ON_NODE=1
# SLURM_EXPORT_ENV=ALL
# SLURM_GET_USER_ENV=1
# SLURM_GTIDS=0
# SLURM_JOBID=32966050
# SLURM_JOB_ACCOUNT=cis210027p
# SLURM_JOB_CPUS_PER_NODE=1
# SLURM_JOB_GID=24886
# SLURM_JOB_ID=32966050
# SLURM_JOB_NAME=stats.sh
# SLURM_JOB_NODELIST=r334
# SLURM_JOB_NUM_NODES=1
# SLURM_JOB_PARTITION=RM-shared
# SLURM_JOB_QOS=rm
# SLURM_JOB_UID=97947
# SLURM_JOB_USER=ttao3
# SLURM_LOCALID=0
# SLURM_MEM_PER_CPU=1900
# SLURM_NNODES=1
# SLURM_NODEID=0
# SLURM_NODELIST=r334
# SLURM_NODE_ALIASES='(null)'
# SLURM_OPEN_MODE=a
# SLURM_PRIO_PROCESS=0
# SLURM_PROCID=0
# SLURM_SCRIPT_CONTEXT=prolog_task
# SLURM_SUBMIT_DIR=/ocean/projects/cis210027p/ttao3/espnet/egs2/hifitts/tts1
# SLURM_SUBMIT_HOST=br013.ib.bridges2.psc.edu
# SLURM_TASKS_PER_NODE=1
# SLURM_TASK_PID=99176
# SLURM_TOPOLOGY_ADDR=r334
# SLURM_TOPOLOGY_ADDR_PATTERN=node
# SLURM_WORKING_CLUSTER=bridges2:br003:6810:9728:109
# python3 -m espnet2.bin.gan_tts_train --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.13.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.13.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.13 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int 
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/librosa/util/files.py:10: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_filename
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/bin/python3 /ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.13.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.13.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.13 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int
Failed to import Flash Attention, using ESPnet default: No module named 'flash_attn_2_cuda'
Vocabulary size: 74
encoder self-attention layer type = relative self-attention
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/ocean/projects/cis210027p/ttao3/espnet/espnet2/gan_tts/vits/monotonic_align/__init__.py:19: UserWarning: Cython version is not available. Fallback to 'EXPERIMETAL' numba version. If you want to use the cython version, please build it as follows: `cd espnet2/gan_tts/vits/monotonic_align; python setup.py build_ext --inplace`
  warnings.warn(
pytorch.version=2.7.1+cu126, cuda.available=False, cudnn.version=90501, cudnn.benchmark=False, cudnn.deterministic=False
Model structure:
ESPnetGANTTSModel(
  (feats_extract): LinearSpectrogram(
    (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
  )
  (tts): VITS(
    (generator): VITSGenerator(
      (text_encoder): TextEncoder(
        (emb): Embedding(74, 192)
        (encoder): Encoder(
          (embed): Sequential(
            (0): RelPositionalEncoding(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (encoders): MultiSequential(
            (0): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (2): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (3): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (4): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (5): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (after_norm): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (decoder): HiFiGANGenerator(
        (input_conv): Conv1d(192, 512, kernel_size=(7,), stride=(1,), padding=(3,))
        (upsamples): ModuleList(
          (0): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (1): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(256, 128, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (2): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,))
          )
          (3): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,))
          )
        )
        (blocks): ModuleList(
          (0): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (1): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (2): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (3): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (4): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (5): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (6): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (7): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (8): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (9): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (10): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (11): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
        )
        (output_conv): Sequential(
          (0): LeakyReLU(negative_slope=0.01)
          (1): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,))
          (2): Tanh()
        )
        (global_conv): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
      )
      (posterior_encoder): PosteriorEncoder(
        (input_conv): Conv1d(513, 192, kernel_size=(1,), stride=(1,))
        (encoder): WaveNet(
          (conv_layers): ModuleList(
            (0-15): 16 x ResidualBlock(
              (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
              (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
              (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
            )
          )
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (flow): ResidualAffineCouplingBlock(
        (flows): ModuleList(
          (0): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (1): FlipFlow()
          (2): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (3): FlipFlow()
          (4): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (5): FlipFlow()
          (6): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (7): FlipFlow()
        )
      )
      (duration_predictor): StochasticDurationPredictor(
        (pre): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (log_flow): LogFlow()
        (flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (post_pre): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
        (post_dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (post_proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (post_flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (global_conv): Conv1d(256, 192, kernel_size=(1,), stride=(1,))
      )
      (global_emb): Embedding(128, 256)
    )
    (discriminator): HiFiGANMultiScaleMultiPeriodDiscriminator(
      (msd): HiFiGANMultiScaleDiscriminator(
        (discriminators): ModuleList(
          (0): HiFiGANScaleDiscriminator(
            (layers): ModuleList(
              (0): Sequential(
                (0): Conv1d(1, 128, kernel_size=(15,), stride=(1,), padding=(7,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv1d(128, 128, kernel_size=(41,), stride=(2,), padding=(20,), groups=4)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv1d(128, 256, kernel_size=(41,), stride=(2,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv1d(256, 512, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv1d(512, 1024, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (5): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(41,), stride=(1,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (6): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (7): Conv1d(1024, 1, kernel_size=(3,), stride=(1,), padding=(1,))
            )
          )
        )
      )
      (mpd): HiFiGANMultiPeriodDiscriminator(
        (discriminators): ModuleList(
          (0-4): 5 x HiFiGANPeriodDiscriminator(
            (convs): ModuleList(
              (0): Sequential(
                (0): Conv2d(1, 32, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv2d(32, 128, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv2d(128, 512, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv2d(512, 1024, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv2d(1024, 1024, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
            )
            (output_conv): Conv2d(1024, 1, kernel_size=(2, 1), stride=(1, 1), padding=(1, 0))
          )
        )
      )
    )
    (generator_adv_loss): GeneratorAdversarialLoss()
    (discriminator_adv_loss): DiscriminatorAdversarialLoss()
    (feat_match_loss): FeatureMatchLoss()
    (mel_loss): MelSpectrogramLoss(
      (wav_to_mel): LogMelFbank(
        (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
        (logmel): LogMel(sr=22050, n_fft=1024, n_mels=80, fmin=0, fmax=11025.0, htk=False)
      )
    )
    (kl_loss): KLDivergenceLoss()
  )
)

Model summary:
    Class Name: ESPnetGANTTSModel
    Total Number of model parameters: 96.37 M
    Number of trainable parameters: 96.37 M (100.0%)
    Size: 385.46 MB
    Type: torch.float32
Optimizer:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler: <torch.optim.lr_scheduler.ExponentialLR object at 0x14d15d2d0220>
Optimizer2:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler2: <torch.optim.lr_scheduler.ExponentialLR object at 0x14d15d2d0640>
Saving the configuration in exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.13/config.yaml
Namespace(config='conf/tuning/train_multi_spk_vits.yaml', print_config=False, log_level='INFO', drop_last_iter=False, dry_run=False, iterator_type='sequence', valid_iterator_type=None, output_dir='exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.13', ngpu=0, seed=777, num_workers=4, num_att_plot=3, dist_backend='nccl', dist_init_method='env://', dist_world_size=None, dist_rank=None, local_rank=None, dist_master_addr=None, dist_master_port=None, dist_launcher=None, multiprocessing_distributed=False, unused_parameters=True, sharded_ddp=False, use_deepspeed=False, deepspeed_config=None, gradient_as_bucket_view=True, ddp_comm_hook=None, cudnn_enabled=True, cudnn_benchmark=False, cudnn_deterministic=False, use_tf32=False, collect_stats=True, write_collected_feats=False, max_epoch=1000, patience=None, val_scheduler_criterion=('valid', 'loss'), early_stopping_criterion=('valid', 'loss', 'min'), best_model_criterion=[['train', 'total_count', 'max']], keep_nbest_models=10, nbest_averaging_interval=0, grad_clip=-1, grad_clip_type=2.0, grad_noise=False, accum_grad=1, no_forward_run=False, resume=False, train_dtype='float32', use_amp=False, log_interval=50, use_matplotlib=True, use_tensorboard=True, create_graph_in_tensorboard=False, use_wandb=False, wandb_project=None, wandb_id=None, wandb_entity=None, wandb_name=None, wandb_model_log_interval=-1, detect_anomaly=False, use_adapter=False, adapter='lora', save_strategy='all', adapter_conf={}, pretrain_path=None, init_param=[], ignore_init_mismatch=False, freeze_param=[], num_iters_per_epoch=1000, batch_size=20, valid_batch_size=None, batch_bins=3000000, valid_batch_bins=None, category_sample_size=10, train_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.13.scp'], valid_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.13.scp'], batch_type='numel', valid_batch_type=None, fold_length=[], sort_in_batch='descending', shuffle_within_batch=False, sort_batch='descending', multiple_iterator=False, chunk_length=500, chunk_shift_ratio=0.5, num_cache_chunks=1024, chunk_excluded_key_prefixes=[], chunk_default_fs=None, chunk_max_abs_length=None, chunk_discard_short_samples=True, train_data_path_and_name_and_type=[('dump/22k/raw/tr_no_dev/text', 'text', 'text'), ('dump/22k/raw/tr_no_dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/tr_no_dev/utt2sid', 'sids', 'text_int')], valid_data_path_and_name_and_type=[('dump/22k/raw/dev/text', 'text', 'text'), ('dump/22k/raw/dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/dev/utt2sid', 'sids', 'text_int')], multi_task_dataset=False, allow_variable_data_keys=False, max_cache_size=0.0, max_cache_fd=32, allow_multi_rates=False, valid_max_cache_size=None, exclude_weight_decay=False, exclude_weight_decay_conf={}, optim='adamw', optim_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler='exponentiallr', scheduler_conf={'gamma': 0.999875}, optim2='adamw', optim2_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler2='exponentiallr', scheduler2_conf={'gamma': 0.999875}, generator_first=False, skip_discriminator_prob=0.0, token_list=['<blank>', '<unk>', ' ', 'AH0', 'N', 'T', 'D', 'S', 'R', 'L', 'IH1', 'DH', 'M', 'EH1', 'Z', 'AE1', 'K', 'IH0', 'AH1', 'HH', 'W', 'ER0', 'V', 'IY1', 'F', 'UW1', 'P', 'AY1', 'B', 'AA1', 'AO1', 'EY1', 'IY0', 'OW1', 'NG', 'SH', 'G', 'Y', 'AW1', 'CH', 'ER1', 'UH1', 'TH', 'JH', 'OW0', 'EH2', 'IH2', 'OY1', 'EY2', 'AY2', 'EH0', 'UW0', 'AA2', 'AE2', 'OW2', 'AH2', 'AA0', 'ZH', 'AE0', 'AO2', 'UW2', 'AO0', 'AY0', 'IY2', 'AW2', 'UH2', 'EY0', 'ER2', 'AW0', 'UH0', 'OY2', 'OY0', "'", '<sos/eos>'], odim=None, model_conf={}, use_preprocessor=True, token_type='phn', bpemodel=None, non_linguistic_symbols=None, cleaner='tacotron', g2p='g2p_en', feats_extract='linear_spectrogram', feats_extract_conf={'n_fft': 1024, 'hop_length': 256, 'win_length': None}, normalize=None, normalize_conf={}, tts='vits', tts_conf={'generator_type': 'vits_generator', 'generator_params': {'hidden_channels': 192, 'spks': 128, 'global_channels': 256, 'segment_size': 32, 'text_encoder_attention_heads': 2, 'text_encoder_ffn_expand': 4, 'text_encoder_blocks': 6, 'text_encoder_positionwise_layer_type': 'conv1d', 'text_encoder_positionwise_conv_kernel_size': 3, 'text_encoder_positional_encoding_layer_type': 'rel_pos', 'text_encoder_self_attention_layer_type': 'rel_selfattn', 'text_encoder_activation_type': 'swish', 'text_encoder_normalize_before': True, 'text_encoder_dropout_rate': 0.1, 'text_encoder_positional_dropout_rate': 0.0, 'text_encoder_attention_dropout_rate': 0.1, 'use_macaron_style_in_text_encoder': True, 'use_conformer_conv_in_text_encoder': False, 'text_encoder_conformer_kernel_size': -1, 'decoder_kernel_size': 7, 'decoder_channels': 512, 'decoder_upsample_scales': [8, 8, 2, 2], 'decoder_upsample_kernel_sizes': [16, 16, 4, 4], 'decoder_resblock_kernel_sizes': [3, 7, 11], 'decoder_resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'use_weight_norm_in_decoder': True, 'posterior_encoder_kernel_size': 5, 'posterior_encoder_layers': 16, 'posterior_encoder_stacks': 1, 'posterior_encoder_base_dilation': 1, 'posterior_encoder_dropout_rate': 0.0, 'use_weight_norm_in_posterior_encoder': True, 'flow_flows': 4, 'flow_kernel_size': 5, 'flow_base_dilation': 1, 'flow_layers': 4, 'flow_dropout_rate': 0.0, 'use_weight_norm_in_flow': True, 'use_only_mean_in_flow': True, 'stochastic_duration_predictor_kernel_size': 3, 'stochastic_duration_predictor_dropout_rate': 0.5, 'stochastic_duration_predictor_flows': 4, 'stochastic_duration_predictor_dds_conv_layers': 3, 'vocabs': 74, 'aux_channels': 513}, 'discriminator_type': 'hifigan_multi_scale_multi_period_discriminator', 'discriminator_params': {'scales': 1, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'stride': 2, 'padding': 2}, 'scale_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'channels': 128, 'max_downsample_channels': 1024, 'max_groups': 16, 'bias': True, 'downsample_scales': [2, 2, 4, 4, 1], 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}, 'follow_official_norm': False, 'periods': [2, 3, 5, 7, 11], 'period_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [5, 3], 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'max_downsample_channels': 1024, 'bias': True, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}}, 'generator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'discriminator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'feat_match_loss_params': {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, 'mel_loss_params': {'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None, 'window': 'hann', 'n_mels': 80, 'fmin': 0, 'fmax': None, 'log_base': None}, 'lambda_adv': 1.0, 'lambda_mel': 45.0, 'lambda_feat_match': 2.0, 'lambda_dur': 1.0, 'lambda_kl': 1.0, 'sampling_rate': 22050, 'cache_generator_outputs': True, 'plot_pred_mos': False, 'mos_pred_tool': 'utmos'}, pitch_extract=None, pitch_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'f0max': 400, 'f0min': 80}, pitch_normalize=None, pitch_normalize_conf={}, energy_extract=None, energy_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None}, energy_normalize=None, energy_normalize_conf={}, required=['output_dir', 'token_list'], version='202503', distributed=False)
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1284, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 99380) is killed by signal: Killed. 

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 22, in <module>
    main()
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 18, in main
    GANTTSTask.main(cmd=cmd)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1225, in main
    cls.main_worker(args)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1441, in main_worker
    collect_stats(
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/main_funcs/collect_stats.py", line 51, in collect_stats
    for iiter, (keys, batch) in enumerate(itr, 1):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 733, in __next__
    data = self._next_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1491, in _next_data
    idx, data = self._get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1453, in _get_data
    success, data = self._try_get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1297, in _try_get_data
    raise RuntimeError(
RuntimeError: DataLoader worker (pid(s) 99380) exited unexpectedly
# Accounting: begin_time=1750836646
# Accounting: end_time=1750836799
# Accounting: time=153 threads=1
# Finished at Wed Jun 25 03:33:19 EDT 2025 with status 1
# Running on r334.ib.bridges2.psc.edu
# Started at Wed Jun 25 03:30:46 EDT 2025
# SLURMD_NODENAME=r334
# SLURM_ARRAY_JOB_ID=32966037
# SLURM_ARRAY_TASK_COUNT=32
# SLURM_ARRAY_TASK_ID=14
# SLURM_ARRAY_TASK_MAX=32
# SLURM_ARRAY_TASK_MIN=1
# SLURM_ARRAY_TASK_STEP=1
# SLURM_CLUSTER_NAME=bridges2
# SLURM_CONF=/var/spool/slurm/d/conf-cache/slurm.conf
# SLURM_CPUS_ON_NODE=1
# SLURM_EXPORT_ENV=ALL
# SLURM_GET_USER_ENV=1
# SLURM_GTIDS=0
# SLURM_JOBID=32966051
# SLURM_JOB_ACCOUNT=cis210027p
# SLURM_JOB_CPUS_PER_NODE=1
# SLURM_JOB_GID=24886
# SLURM_JOB_ID=32966051
# SLURM_JOB_NAME=stats.sh
# SLURM_JOB_NODELIST=r334
# SLURM_JOB_NUM_NODES=1
# SLURM_JOB_PARTITION=RM-shared
# SLURM_JOB_QOS=rm
# SLURM_JOB_UID=97947
# SLURM_JOB_USER=ttao3
# SLURM_LOCALID=0
# SLURM_MEM_PER_CPU=1900
# SLURM_NNODES=1
# SLURM_NODEID=0
# SLURM_NODELIST=r334
# SLURM_NODE_ALIASES='(null)'
# SLURM_OPEN_MODE=a
# SLURM_PRIO_PROCESS=0
# SLURM_PROCID=0
# SLURM_SCRIPT_CONTEXT=prolog_task
# SLURM_SUBMIT_DIR=/ocean/projects/cis210027p/ttao3/espnet/egs2/hifitts/tts1
# SLURM_SUBMIT_HOST=br013.ib.bridges2.psc.edu
# SLURM_TASKS_PER_NODE=1
# SLURM_TASK_PID=99177
# SLURM_TOPOLOGY_ADDR=r334
# SLURM_TOPOLOGY_ADDR_PATTERN=node
# SLURM_WORKING_CLUSTER=bridges2:br003:6810:9728:109
# python3 -m espnet2.bin.gan_tts_train --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.14.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.14.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.14 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int 
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/librosa/util/files.py:10: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_filename
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/bin/python3 /ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.14.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.14.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.14 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int
Failed to import Flash Attention, using ESPnet default: No module named 'flash_attn_2_cuda'
Vocabulary size: 74
encoder self-attention layer type = relative self-attention
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/ocean/projects/cis210027p/ttao3/espnet/espnet2/gan_tts/vits/monotonic_align/__init__.py:19: UserWarning: Cython version is not available. Fallback to 'EXPERIMETAL' numba version. If you want to use the cython version, please build it as follows: `cd espnet2/gan_tts/vits/monotonic_align; python setup.py build_ext --inplace`
  warnings.warn(
pytorch.version=2.7.1+cu126, cuda.available=False, cudnn.version=90501, cudnn.benchmark=False, cudnn.deterministic=False
Model structure:
ESPnetGANTTSModel(
  (feats_extract): LinearSpectrogram(
    (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
  )
  (tts): VITS(
    (generator): VITSGenerator(
      (text_encoder): TextEncoder(
        (emb): Embedding(74, 192)
        (encoder): Encoder(
          (embed): Sequential(
            (0): RelPositionalEncoding(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (encoders): MultiSequential(
            (0): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (2): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (3): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (4): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (5): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (after_norm): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (decoder): HiFiGANGenerator(
        (input_conv): Conv1d(192, 512, kernel_size=(7,), stride=(1,), padding=(3,))
        (upsamples): ModuleList(
          (0): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (1): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(256, 128, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (2): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,))
          )
          (3): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,))
          )
        )
        (blocks): ModuleList(
          (0): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (1): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (2): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (3): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (4): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (5): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (6): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (7): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (8): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (9): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (10): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (11): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
        )
        (output_conv): Sequential(
          (0): LeakyReLU(negative_slope=0.01)
          (1): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,))
          (2): Tanh()
        )
        (global_conv): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
      )
      (posterior_encoder): PosteriorEncoder(
        (input_conv): Conv1d(513, 192, kernel_size=(1,), stride=(1,))
        (encoder): WaveNet(
          (conv_layers): ModuleList(
            (0-15): 16 x ResidualBlock(
              (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
              (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
              (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
            )
          )
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (flow): ResidualAffineCouplingBlock(
        (flows): ModuleList(
          (0): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (1): FlipFlow()
          (2): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (3): FlipFlow()
          (4): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (5): FlipFlow()
          (6): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (7): FlipFlow()
        )
      )
      (duration_predictor): StochasticDurationPredictor(
        (pre): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (log_flow): LogFlow()
        (flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (post_pre): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
        (post_dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (post_proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (post_flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (global_conv): Conv1d(256, 192, kernel_size=(1,), stride=(1,))
      )
      (global_emb): Embedding(128, 256)
    )
    (discriminator): HiFiGANMultiScaleMultiPeriodDiscriminator(
      (msd): HiFiGANMultiScaleDiscriminator(
        (discriminators): ModuleList(
          (0): HiFiGANScaleDiscriminator(
            (layers): ModuleList(
              (0): Sequential(
                (0): Conv1d(1, 128, kernel_size=(15,), stride=(1,), padding=(7,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv1d(128, 128, kernel_size=(41,), stride=(2,), padding=(20,), groups=4)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv1d(128, 256, kernel_size=(41,), stride=(2,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv1d(256, 512, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv1d(512, 1024, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (5): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(41,), stride=(1,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (6): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (7): Conv1d(1024, 1, kernel_size=(3,), stride=(1,), padding=(1,))
            )
          )
        )
      )
      (mpd): HiFiGANMultiPeriodDiscriminator(
        (discriminators): ModuleList(
          (0-4): 5 x HiFiGANPeriodDiscriminator(
            (convs): ModuleList(
              (0): Sequential(
                (0): Conv2d(1, 32, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv2d(32, 128, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv2d(128, 512, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv2d(512, 1024, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv2d(1024, 1024, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
            )
            (output_conv): Conv2d(1024, 1, kernel_size=(2, 1), stride=(1, 1), padding=(1, 0))
          )
        )
      )
    )
    (generator_adv_loss): GeneratorAdversarialLoss()
    (discriminator_adv_loss): DiscriminatorAdversarialLoss()
    (feat_match_loss): FeatureMatchLoss()
    (mel_loss): MelSpectrogramLoss(
      (wav_to_mel): LogMelFbank(
        (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
        (logmel): LogMel(sr=22050, n_fft=1024, n_mels=80, fmin=0, fmax=11025.0, htk=False)
      )
    )
    (kl_loss): KLDivergenceLoss()
  )
)

Model summary:
    Class Name: ESPnetGANTTSModel
    Total Number of model parameters: 96.37 M
    Number of trainable parameters: 96.37 M (100.0%)
    Size: 385.46 MB
    Type: torch.float32
Optimizer:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler: <torch.optim.lr_scheduler.ExponentialLR object at 0x148c35072250>
Optimizer2:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler2: <torch.optim.lr_scheduler.ExponentialLR object at 0x148c35072670>
Saving the configuration in exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.14/config.yaml
Namespace(config='conf/tuning/train_multi_spk_vits.yaml', print_config=False, log_level='INFO', drop_last_iter=False, dry_run=False, iterator_type='sequence', valid_iterator_type=None, output_dir='exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.14', ngpu=0, seed=777, num_workers=4, num_att_plot=3, dist_backend='nccl', dist_init_method='env://', dist_world_size=None, dist_rank=None, local_rank=None, dist_master_addr=None, dist_master_port=None, dist_launcher=None, multiprocessing_distributed=False, unused_parameters=True, sharded_ddp=False, use_deepspeed=False, deepspeed_config=None, gradient_as_bucket_view=True, ddp_comm_hook=None, cudnn_enabled=True, cudnn_benchmark=False, cudnn_deterministic=False, use_tf32=False, collect_stats=True, write_collected_feats=False, max_epoch=1000, patience=None, val_scheduler_criterion=('valid', 'loss'), early_stopping_criterion=('valid', 'loss', 'min'), best_model_criterion=[['train', 'total_count', 'max']], keep_nbest_models=10, nbest_averaging_interval=0, grad_clip=-1, grad_clip_type=2.0, grad_noise=False, accum_grad=1, no_forward_run=False, resume=False, train_dtype='float32', use_amp=False, log_interval=50, use_matplotlib=True, use_tensorboard=True, create_graph_in_tensorboard=False, use_wandb=False, wandb_project=None, wandb_id=None, wandb_entity=None, wandb_name=None, wandb_model_log_interval=-1, detect_anomaly=False, use_adapter=False, adapter='lora', save_strategy='all', adapter_conf={}, pretrain_path=None, init_param=[], ignore_init_mismatch=False, freeze_param=[], num_iters_per_epoch=1000, batch_size=20, valid_batch_size=None, batch_bins=3000000, valid_batch_bins=None, category_sample_size=10, train_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.14.scp'], valid_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.14.scp'], batch_type='numel', valid_batch_type=None, fold_length=[], sort_in_batch='descending', shuffle_within_batch=False, sort_batch='descending', multiple_iterator=False, chunk_length=500, chunk_shift_ratio=0.5, num_cache_chunks=1024, chunk_excluded_key_prefixes=[], chunk_default_fs=None, chunk_max_abs_length=None, chunk_discard_short_samples=True, train_data_path_and_name_and_type=[('dump/22k/raw/tr_no_dev/text', 'text', 'text'), ('dump/22k/raw/tr_no_dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/tr_no_dev/utt2sid', 'sids', 'text_int')], valid_data_path_and_name_and_type=[('dump/22k/raw/dev/text', 'text', 'text'), ('dump/22k/raw/dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/dev/utt2sid', 'sids', 'text_int')], multi_task_dataset=False, allow_variable_data_keys=False, max_cache_size=0.0, max_cache_fd=32, allow_multi_rates=False, valid_max_cache_size=None, exclude_weight_decay=False, exclude_weight_decay_conf={}, optim='adamw', optim_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler='exponentiallr', scheduler_conf={'gamma': 0.999875}, optim2='adamw', optim2_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler2='exponentiallr', scheduler2_conf={'gamma': 0.999875}, generator_first=False, skip_discriminator_prob=0.0, token_list=['<blank>', '<unk>', ' ', 'AH0', 'N', 'T', 'D', 'S', 'R', 'L', 'IH1', 'DH', 'M', 'EH1', 'Z', 'AE1', 'K', 'IH0', 'AH1', 'HH', 'W', 'ER0', 'V', 'IY1', 'F', 'UW1', 'P', 'AY1', 'B', 'AA1', 'AO1', 'EY1', 'IY0', 'OW1', 'NG', 'SH', 'G', 'Y', 'AW1', 'CH', 'ER1', 'UH1', 'TH', 'JH', 'OW0', 'EH2', 'IH2', 'OY1', 'EY2', 'AY2', 'EH0', 'UW0', 'AA2', 'AE2', 'OW2', 'AH2', 'AA0', 'ZH', 'AE0', 'AO2', 'UW2', 'AO0', 'AY0', 'IY2', 'AW2', 'UH2', 'EY0', 'ER2', 'AW0', 'UH0', 'OY2', 'OY0', "'", '<sos/eos>'], odim=None, model_conf={}, use_preprocessor=True, token_type='phn', bpemodel=None, non_linguistic_symbols=None, cleaner='tacotron', g2p='g2p_en', feats_extract='linear_spectrogram', feats_extract_conf={'n_fft': 1024, 'hop_length': 256, 'win_length': None}, normalize=None, normalize_conf={}, tts='vits', tts_conf={'generator_type': 'vits_generator', 'generator_params': {'hidden_channels': 192, 'spks': 128, 'global_channels': 256, 'segment_size': 32, 'text_encoder_attention_heads': 2, 'text_encoder_ffn_expand': 4, 'text_encoder_blocks': 6, 'text_encoder_positionwise_layer_type': 'conv1d', 'text_encoder_positionwise_conv_kernel_size': 3, 'text_encoder_positional_encoding_layer_type': 'rel_pos', 'text_encoder_self_attention_layer_type': 'rel_selfattn', 'text_encoder_activation_type': 'swish', 'text_encoder_normalize_before': True, 'text_encoder_dropout_rate': 0.1, 'text_encoder_positional_dropout_rate': 0.0, 'text_encoder_attention_dropout_rate': 0.1, 'use_macaron_style_in_text_encoder': True, 'use_conformer_conv_in_text_encoder': False, 'text_encoder_conformer_kernel_size': -1, 'decoder_kernel_size': 7, 'decoder_channels': 512, 'decoder_upsample_scales': [8, 8, 2, 2], 'decoder_upsample_kernel_sizes': [16, 16, 4, 4], 'decoder_resblock_kernel_sizes': [3, 7, 11], 'decoder_resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'use_weight_norm_in_decoder': True, 'posterior_encoder_kernel_size': 5, 'posterior_encoder_layers': 16, 'posterior_encoder_stacks': 1, 'posterior_encoder_base_dilation': 1, 'posterior_encoder_dropout_rate': 0.0, 'use_weight_norm_in_posterior_encoder': True, 'flow_flows': 4, 'flow_kernel_size': 5, 'flow_base_dilation': 1, 'flow_layers': 4, 'flow_dropout_rate': 0.0, 'use_weight_norm_in_flow': True, 'use_only_mean_in_flow': True, 'stochastic_duration_predictor_kernel_size': 3, 'stochastic_duration_predictor_dropout_rate': 0.5, 'stochastic_duration_predictor_flows': 4, 'stochastic_duration_predictor_dds_conv_layers': 3, 'vocabs': 74, 'aux_channels': 513}, 'discriminator_type': 'hifigan_multi_scale_multi_period_discriminator', 'discriminator_params': {'scales': 1, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'stride': 2, 'padding': 2}, 'scale_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'channels': 128, 'max_downsample_channels': 1024, 'max_groups': 16, 'bias': True, 'downsample_scales': [2, 2, 4, 4, 1], 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}, 'follow_official_norm': False, 'periods': [2, 3, 5, 7, 11], 'period_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [5, 3], 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'max_downsample_channels': 1024, 'bias': True, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}}, 'generator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'discriminator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'feat_match_loss_params': {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, 'mel_loss_params': {'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None, 'window': 'hann', 'n_mels': 80, 'fmin': 0, 'fmax': None, 'log_base': None}, 'lambda_adv': 1.0, 'lambda_mel': 45.0, 'lambda_feat_match': 2.0, 'lambda_dur': 1.0, 'lambda_kl': 1.0, 'sampling_rate': 22050, 'cache_generator_outputs': True, 'plot_pred_mos': False, 'mos_pred_tool': 'utmos'}, pitch_extract=None, pitch_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'f0max': 400, 'f0min': 80}, pitch_normalize=None, pitch_normalize_conf={}, energy_extract=None, energy_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None}, energy_normalize=None, energy_normalize_conf={}, required=['output_dir', 'token_list'], version='202503', distributed=False)
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1284, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 99364) is killed by signal: Killed. 

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 22, in <module>
    main()
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 18, in main
    GANTTSTask.main(cmd=cmd)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1225, in main
    cls.main_worker(args)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1441, in main_worker
    collect_stats(
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/main_funcs/collect_stats.py", line 51, in collect_stats
    for iiter, (keys, batch) in enumerate(itr, 1):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 733, in __next__
    data = self._next_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1491, in _next_data
    idx, data = self._get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1453, in _get_data
    success, data = self._try_get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1297, in _try_get_data
    raise RuntimeError(
RuntimeError: DataLoader worker (pid(s) 99364) exited unexpectedly
# Accounting: begin_time=1750836646
# Accounting: end_time=1750836799
# Accounting: time=153 threads=1
# Finished at Wed Jun 25 03:33:19 EDT 2025 with status 1
# Running on r005.ib.bridges2.psc.edu
# Started at Wed Jun 25 03:30:46 EDT 2025
# SLURMD_NODENAME=r005
# SLURM_ARRAY_JOB_ID=32966037
# SLURM_ARRAY_TASK_COUNT=32
# SLURM_ARRAY_TASK_ID=15
# SLURM_ARRAY_TASK_MAX=32
# SLURM_ARRAY_TASK_MIN=1
# SLURM_ARRAY_TASK_STEP=1
# SLURM_CLUSTER_NAME=bridges2
# SLURM_CONF=/var/spool/slurm/d/conf-cache/slurm.conf
# SLURM_CPUS_ON_NODE=1
# SLURM_EXPORT_ENV=ALL
# SLURM_GET_USER_ENV=1
# SLURM_GTIDS=0
# SLURM_JOBID=32966052
# SLURM_JOB_ACCOUNT=cis210027p
# SLURM_JOB_CPUS_PER_NODE=1
# SLURM_JOB_GID=24886
# SLURM_JOB_ID=32966052
# SLURM_JOB_NAME=stats.sh
# SLURM_JOB_NODELIST=r005
# SLURM_JOB_NUM_NODES=1
# SLURM_JOB_PARTITION=RM-shared
# SLURM_JOB_QOS=rm
# SLURM_JOB_UID=97947
# SLURM_JOB_USER=ttao3
# SLURM_LOCALID=0
# SLURM_MEM_PER_CPU=1900
# SLURM_NNODES=1
# SLURM_NODEID=0
# SLURM_NODELIST=r005
# SLURM_NODE_ALIASES='(null)'
# SLURM_OPEN_MODE=a
# SLURM_PRIO_PROCESS=0
# SLURM_PROCID=0
# SLURM_SCRIPT_CONTEXT=prolog_task
# SLURM_SUBMIT_DIR=/ocean/projects/cis210027p/ttao3/espnet/egs2/hifitts/tts1
# SLURM_SUBMIT_HOST=br013.ib.bridges2.psc.edu
# SLURM_TASKS_PER_NODE=1
# SLURM_TASK_PID=85589
# SLURM_TOPOLOGY_ADDR=r005
# SLURM_TOPOLOGY_ADDR_PATTERN=node
# SLURM_WORKING_CLUSTER=bridges2:br003:6810:9728:109
# python3 -m espnet2.bin.gan_tts_train --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.15.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.15.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.15 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int 
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/librosa/util/files.py:10: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_filename
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/bin/python3 /ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.15.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.15.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.15 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int
Failed to import Flash Attention, using ESPnet default: No module named 'flash_attn_2_cuda'
Vocabulary size: 74
encoder self-attention layer type = relative self-attention
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/ocean/projects/cis210027p/ttao3/espnet/espnet2/gan_tts/vits/monotonic_align/__init__.py:19: UserWarning: Cython version is not available. Fallback to 'EXPERIMETAL' numba version. If you want to use the cython version, please build it as follows: `cd espnet2/gan_tts/vits/monotonic_align; python setup.py build_ext --inplace`
  warnings.warn(
pytorch.version=2.7.1+cu126, cuda.available=False, cudnn.version=90501, cudnn.benchmark=False, cudnn.deterministic=False
Model structure:
ESPnetGANTTSModel(
  (feats_extract): LinearSpectrogram(
    (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
  )
  (tts): VITS(
    (generator): VITSGenerator(
      (text_encoder): TextEncoder(
        (emb): Embedding(74, 192)
        (encoder): Encoder(
          (embed): Sequential(
            (0): RelPositionalEncoding(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (encoders): MultiSequential(
            (0): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (2): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (3): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (4): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (5): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (after_norm): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (decoder): HiFiGANGenerator(
        (input_conv): Conv1d(192, 512, kernel_size=(7,), stride=(1,), padding=(3,))
        (upsamples): ModuleList(
          (0): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (1): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(256, 128, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (2): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,))
          )
          (3): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,))
          )
        )
        (blocks): ModuleList(
          (0): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (1): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (2): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (3): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (4): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (5): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (6): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (7): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (8): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (9): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (10): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (11): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
        )
        (output_conv): Sequential(
          (0): LeakyReLU(negative_slope=0.01)
          (1): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,))
          (2): Tanh()
        )
        (global_conv): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
      )
      (posterior_encoder): PosteriorEncoder(
        (input_conv): Conv1d(513, 192, kernel_size=(1,), stride=(1,))
        (encoder): WaveNet(
          (conv_layers): ModuleList(
            (0-15): 16 x ResidualBlock(
              (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
              (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
              (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
            )
          )
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (flow): ResidualAffineCouplingBlock(
        (flows): ModuleList(
          (0): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (1): FlipFlow()
          (2): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (3): FlipFlow()
          (4): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (5): FlipFlow()
          (6): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (7): FlipFlow()
        )
      )
      (duration_predictor): StochasticDurationPredictor(
        (pre): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (log_flow): LogFlow()
        (flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (post_pre): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
        (post_dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (post_proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (post_flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (global_conv): Conv1d(256, 192, kernel_size=(1,), stride=(1,))
      )
      (global_emb): Embedding(128, 256)
    )
    (discriminator): HiFiGANMultiScaleMultiPeriodDiscriminator(
      (msd): HiFiGANMultiScaleDiscriminator(
        (discriminators): ModuleList(
          (0): HiFiGANScaleDiscriminator(
            (layers): ModuleList(
              (0): Sequential(
                (0): Conv1d(1, 128, kernel_size=(15,), stride=(1,), padding=(7,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv1d(128, 128, kernel_size=(41,), stride=(2,), padding=(20,), groups=4)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv1d(128, 256, kernel_size=(41,), stride=(2,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv1d(256, 512, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv1d(512, 1024, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (5): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(41,), stride=(1,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (6): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (7): Conv1d(1024, 1, kernel_size=(3,), stride=(1,), padding=(1,))
            )
          )
        )
      )
      (mpd): HiFiGANMultiPeriodDiscriminator(
        (discriminators): ModuleList(
          (0-4): 5 x HiFiGANPeriodDiscriminator(
            (convs): ModuleList(
              (0): Sequential(
                (0): Conv2d(1, 32, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv2d(32, 128, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv2d(128, 512, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv2d(512, 1024, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv2d(1024, 1024, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
            )
            (output_conv): Conv2d(1024, 1, kernel_size=(2, 1), stride=(1, 1), padding=(1, 0))
          )
        )
      )
    )
    (generator_adv_loss): GeneratorAdversarialLoss()
    (discriminator_adv_loss): DiscriminatorAdversarialLoss()
    (feat_match_loss): FeatureMatchLoss()
    (mel_loss): MelSpectrogramLoss(
      (wav_to_mel): LogMelFbank(
        (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
        (logmel): LogMel(sr=22050, n_fft=1024, n_mels=80, fmin=0, fmax=11025.0, htk=False)
      )
    )
    (kl_loss): KLDivergenceLoss()
  )
)

Model summary:
    Class Name: ESPnetGANTTSModel
    Total Number of model parameters: 96.37 M
    Number of trainable parameters: 96.37 M (100.0%)
    Size: 385.46 MB
    Type: torch.float32
Optimizer:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler: <torch.optim.lr_scheduler.ExponentialLR object at 0x14e775e691c0>
Optimizer2:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler2: <torch.optim.lr_scheduler.ExponentialLR object at 0x14e775e695e0>
Saving the configuration in exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.15/config.yaml
Namespace(config='conf/tuning/train_multi_spk_vits.yaml', print_config=False, log_level='INFO', drop_last_iter=False, dry_run=False, iterator_type='sequence', valid_iterator_type=None, output_dir='exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.15', ngpu=0, seed=777, num_workers=4, num_att_plot=3, dist_backend='nccl', dist_init_method='env://', dist_world_size=None, dist_rank=None, local_rank=None, dist_master_addr=None, dist_master_port=None, dist_launcher=None, multiprocessing_distributed=False, unused_parameters=True, sharded_ddp=False, use_deepspeed=False, deepspeed_config=None, gradient_as_bucket_view=True, ddp_comm_hook=None, cudnn_enabled=True, cudnn_benchmark=False, cudnn_deterministic=False, use_tf32=False, collect_stats=True, write_collected_feats=False, max_epoch=1000, patience=None, val_scheduler_criterion=('valid', 'loss'), early_stopping_criterion=('valid', 'loss', 'min'), best_model_criterion=[['train', 'total_count', 'max']], keep_nbest_models=10, nbest_averaging_interval=0, grad_clip=-1, grad_clip_type=2.0, grad_noise=False, accum_grad=1, no_forward_run=False, resume=False, train_dtype='float32', use_amp=False, log_interval=50, use_matplotlib=True, use_tensorboard=True, create_graph_in_tensorboard=False, use_wandb=False, wandb_project=None, wandb_id=None, wandb_entity=None, wandb_name=None, wandb_model_log_interval=-1, detect_anomaly=False, use_adapter=False, adapter='lora', save_strategy='all', adapter_conf={}, pretrain_path=None, init_param=[], ignore_init_mismatch=False, freeze_param=[], num_iters_per_epoch=1000, batch_size=20, valid_batch_size=None, batch_bins=3000000, valid_batch_bins=None, category_sample_size=10, train_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.15.scp'], valid_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.15.scp'], batch_type='numel', valid_batch_type=None, fold_length=[], sort_in_batch='descending', shuffle_within_batch=False, sort_batch='descending', multiple_iterator=False, chunk_length=500, chunk_shift_ratio=0.5, num_cache_chunks=1024, chunk_excluded_key_prefixes=[], chunk_default_fs=None, chunk_max_abs_length=None, chunk_discard_short_samples=True, train_data_path_and_name_and_type=[('dump/22k/raw/tr_no_dev/text', 'text', 'text'), ('dump/22k/raw/tr_no_dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/tr_no_dev/utt2sid', 'sids', 'text_int')], valid_data_path_and_name_and_type=[('dump/22k/raw/dev/text', 'text', 'text'), ('dump/22k/raw/dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/dev/utt2sid', 'sids', 'text_int')], multi_task_dataset=False, allow_variable_data_keys=False, max_cache_size=0.0, max_cache_fd=32, allow_multi_rates=False, valid_max_cache_size=None, exclude_weight_decay=False, exclude_weight_decay_conf={}, optim='adamw', optim_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler='exponentiallr', scheduler_conf={'gamma': 0.999875}, optim2='adamw', optim2_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler2='exponentiallr', scheduler2_conf={'gamma': 0.999875}, generator_first=False, skip_discriminator_prob=0.0, token_list=['<blank>', '<unk>', ' ', 'AH0', 'N', 'T', 'D', 'S', 'R', 'L', 'IH1', 'DH', 'M', 'EH1', 'Z', 'AE1', 'K', 'IH0', 'AH1', 'HH', 'W', 'ER0', 'V', 'IY1', 'F', 'UW1', 'P', 'AY1', 'B', 'AA1', 'AO1', 'EY1', 'IY0', 'OW1', 'NG', 'SH', 'G', 'Y', 'AW1', 'CH', 'ER1', 'UH1', 'TH', 'JH', 'OW0', 'EH2', 'IH2', 'OY1', 'EY2', 'AY2', 'EH0', 'UW0', 'AA2', 'AE2', 'OW2', 'AH2', 'AA0', 'ZH', 'AE0', 'AO2', 'UW2', 'AO0', 'AY0', 'IY2', 'AW2', 'UH2', 'EY0', 'ER2', 'AW0', 'UH0', 'OY2', 'OY0', "'", '<sos/eos>'], odim=None, model_conf={}, use_preprocessor=True, token_type='phn', bpemodel=None, non_linguistic_symbols=None, cleaner='tacotron', g2p='g2p_en', feats_extract='linear_spectrogram', feats_extract_conf={'n_fft': 1024, 'hop_length': 256, 'win_length': None}, normalize=None, normalize_conf={}, tts='vits', tts_conf={'generator_type': 'vits_generator', 'generator_params': {'hidden_channels': 192, 'spks': 128, 'global_channels': 256, 'segment_size': 32, 'text_encoder_attention_heads': 2, 'text_encoder_ffn_expand': 4, 'text_encoder_blocks': 6, 'text_encoder_positionwise_layer_type': 'conv1d', 'text_encoder_positionwise_conv_kernel_size': 3, 'text_encoder_positional_encoding_layer_type': 'rel_pos', 'text_encoder_self_attention_layer_type': 'rel_selfattn', 'text_encoder_activation_type': 'swish', 'text_encoder_normalize_before': True, 'text_encoder_dropout_rate': 0.1, 'text_encoder_positional_dropout_rate': 0.0, 'text_encoder_attention_dropout_rate': 0.1, 'use_macaron_style_in_text_encoder': True, 'use_conformer_conv_in_text_encoder': False, 'text_encoder_conformer_kernel_size': -1, 'decoder_kernel_size': 7, 'decoder_channels': 512, 'decoder_upsample_scales': [8, 8, 2, 2], 'decoder_upsample_kernel_sizes': [16, 16, 4, 4], 'decoder_resblock_kernel_sizes': [3, 7, 11], 'decoder_resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'use_weight_norm_in_decoder': True, 'posterior_encoder_kernel_size': 5, 'posterior_encoder_layers': 16, 'posterior_encoder_stacks': 1, 'posterior_encoder_base_dilation': 1, 'posterior_encoder_dropout_rate': 0.0, 'use_weight_norm_in_posterior_encoder': True, 'flow_flows': 4, 'flow_kernel_size': 5, 'flow_base_dilation': 1, 'flow_layers': 4, 'flow_dropout_rate': 0.0, 'use_weight_norm_in_flow': True, 'use_only_mean_in_flow': True, 'stochastic_duration_predictor_kernel_size': 3, 'stochastic_duration_predictor_dropout_rate': 0.5, 'stochastic_duration_predictor_flows': 4, 'stochastic_duration_predictor_dds_conv_layers': 3, 'vocabs': 74, 'aux_channels': 513}, 'discriminator_type': 'hifigan_multi_scale_multi_period_discriminator', 'discriminator_params': {'scales': 1, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'stride': 2, 'padding': 2}, 'scale_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'channels': 128, 'max_downsample_channels': 1024, 'max_groups': 16, 'bias': True, 'downsample_scales': [2, 2, 4, 4, 1], 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}, 'follow_official_norm': False, 'periods': [2, 3, 5, 7, 11], 'period_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [5, 3], 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'max_downsample_channels': 1024, 'bias': True, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}}, 'generator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'discriminator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'feat_match_loss_params': {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, 'mel_loss_params': {'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None, 'window': 'hann', 'n_mels': 80, 'fmin': 0, 'fmax': None, 'log_base': None}, 'lambda_adv': 1.0, 'lambda_mel': 45.0, 'lambda_feat_match': 2.0, 'lambda_dur': 1.0, 'lambda_kl': 1.0, 'sampling_rate': 22050, 'cache_generator_outputs': True, 'plot_pred_mos': False, 'mos_pred_tool': 'utmos'}, pitch_extract=None, pitch_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'f0max': 400, 'f0min': 80}, pitch_normalize=None, pitch_normalize_conf={}, energy_extract=None, energy_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None}, energy_normalize=None, energy_normalize_conf={}, required=['output_dir', 'token_list'], version='202503', distributed=False)
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1284, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 85842) is killed by signal: Killed. 

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 22, in <module>
    main()
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 18, in main
    GANTTSTask.main(cmd=cmd)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1225, in main
    cls.main_worker(args)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1441, in main_worker
    collect_stats(
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/main_funcs/collect_stats.py", line 51, in collect_stats
    for iiter, (keys, batch) in enumerate(itr, 1):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 733, in __next__
    data = self._next_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1491, in _next_data
    idx, data = self._get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1453, in _get_data
    success, data = self._try_get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1297, in _try_get_data
    raise RuntimeError(
RuntimeError: DataLoader worker (pid(s) 85842) exited unexpectedly
# Accounting: begin_time=1750836646
# Accounting: end_time=1750836799
# Accounting: time=153 threads=1
# Finished at Wed Jun 25 03:33:19 EDT 2025 with status 1
# Running on r005.ib.bridges2.psc.edu
# Started at Wed Jun 25 03:30:46 EDT 2025
# SLURMD_NODENAME=r005
# SLURM_ARRAY_JOB_ID=32966037
# SLURM_ARRAY_TASK_COUNT=32
# SLURM_ARRAY_TASK_ID=16
# SLURM_ARRAY_TASK_MAX=32
# SLURM_ARRAY_TASK_MIN=1
# SLURM_ARRAY_TASK_STEP=1
# SLURM_CLUSTER_NAME=bridges2
# SLURM_CONF=/var/spool/slurm/d/conf-cache/slurm.conf
# SLURM_CPUS_ON_NODE=1
# SLURM_EXPORT_ENV=ALL
# SLURM_GET_USER_ENV=1
# SLURM_GTIDS=0
# SLURM_JOBID=32966053
# SLURM_JOB_ACCOUNT=cis210027p
# SLURM_JOB_CPUS_PER_NODE=1
# SLURM_JOB_GID=24886
# SLURM_JOB_ID=32966053
# SLURM_JOB_NAME=stats.sh
# SLURM_JOB_NODELIST=r005
# SLURM_JOB_NUM_NODES=1
# SLURM_JOB_PARTITION=RM-shared
# SLURM_JOB_QOS=rm
# SLURM_JOB_UID=97947
# SLURM_JOB_USER=ttao3
# SLURM_LOCALID=0
# SLURM_MEM_PER_CPU=1900
# SLURM_NNODES=1
# SLURM_NODEID=0
# SLURM_NODELIST=r005
# SLURM_NODE_ALIASES='(null)'
# SLURM_OPEN_MODE=a
# SLURM_PRIO_PROCESS=0
# SLURM_PROCID=0
# SLURM_SCRIPT_CONTEXT=prolog_task
# SLURM_SUBMIT_DIR=/ocean/projects/cis210027p/ttao3/espnet/egs2/hifitts/tts1
# SLURM_SUBMIT_HOST=br013.ib.bridges2.psc.edu
# SLURM_TASKS_PER_NODE=1
# SLURM_TASK_PID=85590
# SLURM_TOPOLOGY_ADDR=r005
# SLURM_TOPOLOGY_ADDR_PATTERN=node
# SLURM_WORKING_CLUSTER=bridges2:br003:6810:9728:109
# python3 -m espnet2.bin.gan_tts_train --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.16.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.16.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.16 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int 
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/librosa/util/files.py:10: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_filename
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/bin/python3 /ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.16.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.16.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.16 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int
Failed to import Flash Attention, using ESPnet default: No module named 'flash_attn_2_cuda'
Vocabulary size: 74
encoder self-attention layer type = relative self-attention
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/ocean/projects/cis210027p/ttao3/espnet/espnet2/gan_tts/vits/monotonic_align/__init__.py:19: UserWarning: Cython version is not available. Fallback to 'EXPERIMETAL' numba version. If you want to use the cython version, please build it as follows: `cd espnet2/gan_tts/vits/monotonic_align; python setup.py build_ext --inplace`
  warnings.warn(
pytorch.version=2.7.1+cu126, cuda.available=False, cudnn.version=90501, cudnn.benchmark=False, cudnn.deterministic=False
Model structure:
ESPnetGANTTSModel(
  (feats_extract): LinearSpectrogram(
    (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
  )
  (tts): VITS(
    (generator): VITSGenerator(
      (text_encoder): TextEncoder(
        (emb): Embedding(74, 192)
        (encoder): Encoder(
          (embed): Sequential(
            (0): RelPositionalEncoding(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (encoders): MultiSequential(
            (0): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (2): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (3): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (4): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (5): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (after_norm): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (decoder): HiFiGANGenerator(
        (input_conv): Conv1d(192, 512, kernel_size=(7,), stride=(1,), padding=(3,))
        (upsamples): ModuleList(
          (0): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (1): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(256, 128, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (2): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,))
          )
          (3): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,))
          )
        )
        (blocks): ModuleList(
          (0): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (1): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (2): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (3): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (4): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (5): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (6): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (7): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (8): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (9): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (10): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (11): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
        )
        (output_conv): Sequential(
          (0): LeakyReLU(negative_slope=0.01)
          (1): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,))
          (2): Tanh()
        )
        (global_conv): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
      )
      (posterior_encoder): PosteriorEncoder(
        (input_conv): Conv1d(513, 192, kernel_size=(1,), stride=(1,))
        (encoder): WaveNet(
          (conv_layers): ModuleList(
            (0-15): 16 x ResidualBlock(
              (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
              (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
              (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
            )
          )
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (flow): ResidualAffineCouplingBlock(
        (flows): ModuleList(
          (0): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (1): FlipFlow()
          (2): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (3): FlipFlow()
          (4): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (5): FlipFlow()
          (6): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (7): FlipFlow()
        )
      )
      (duration_predictor): StochasticDurationPredictor(
        (pre): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (log_flow): LogFlow()
        (flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (post_pre): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
        (post_dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (post_proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (post_flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (global_conv): Conv1d(256, 192, kernel_size=(1,), stride=(1,))
      )
      (global_emb): Embedding(128, 256)
    )
    (discriminator): HiFiGANMultiScaleMultiPeriodDiscriminator(
      (msd): HiFiGANMultiScaleDiscriminator(
        (discriminators): ModuleList(
          (0): HiFiGANScaleDiscriminator(
            (layers): ModuleList(
              (0): Sequential(
                (0): Conv1d(1, 128, kernel_size=(15,), stride=(1,), padding=(7,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv1d(128, 128, kernel_size=(41,), stride=(2,), padding=(20,), groups=4)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv1d(128, 256, kernel_size=(41,), stride=(2,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv1d(256, 512, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv1d(512, 1024, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (5): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(41,), stride=(1,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (6): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (7): Conv1d(1024, 1, kernel_size=(3,), stride=(1,), padding=(1,))
            )
          )
        )
      )
      (mpd): HiFiGANMultiPeriodDiscriminator(
        (discriminators): ModuleList(
          (0-4): 5 x HiFiGANPeriodDiscriminator(
            (convs): ModuleList(
              (0): Sequential(
                (0): Conv2d(1, 32, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv2d(32, 128, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv2d(128, 512, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv2d(512, 1024, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv2d(1024, 1024, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
            )
            (output_conv): Conv2d(1024, 1, kernel_size=(2, 1), stride=(1, 1), padding=(1, 0))
          )
        )
      )
    )
    (generator_adv_loss): GeneratorAdversarialLoss()
    (discriminator_adv_loss): DiscriminatorAdversarialLoss()
    (feat_match_loss): FeatureMatchLoss()
    (mel_loss): MelSpectrogramLoss(
      (wav_to_mel): LogMelFbank(
        (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
        (logmel): LogMel(sr=22050, n_fft=1024, n_mels=80, fmin=0, fmax=11025.0, htk=False)
      )
    )
    (kl_loss): KLDivergenceLoss()
  )
)

Model summary:
    Class Name: ESPnetGANTTSModel
    Total Number of model parameters: 96.37 M
    Number of trainable parameters: 96.37 M (100.0%)
    Size: 385.46 MB
    Type: torch.float32
Optimizer:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler: <torch.optim.lr_scheduler.ExponentialLR object at 0x148bc9950250>
Optimizer2:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler2: <torch.optim.lr_scheduler.ExponentialLR object at 0x148bc9950670>
Saving the configuration in exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.16/config.yaml
Namespace(config='conf/tuning/train_multi_spk_vits.yaml', print_config=False, log_level='INFO', drop_last_iter=False, dry_run=False, iterator_type='sequence', valid_iterator_type=None, output_dir='exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.16', ngpu=0, seed=777, num_workers=4, num_att_plot=3, dist_backend='nccl', dist_init_method='env://', dist_world_size=None, dist_rank=None, local_rank=None, dist_master_addr=None, dist_master_port=None, dist_launcher=None, multiprocessing_distributed=False, unused_parameters=True, sharded_ddp=False, use_deepspeed=False, deepspeed_config=None, gradient_as_bucket_view=True, ddp_comm_hook=None, cudnn_enabled=True, cudnn_benchmark=False, cudnn_deterministic=False, use_tf32=False, collect_stats=True, write_collected_feats=False, max_epoch=1000, patience=None, val_scheduler_criterion=('valid', 'loss'), early_stopping_criterion=('valid', 'loss', 'min'), best_model_criterion=[['train', 'total_count', 'max']], keep_nbest_models=10, nbest_averaging_interval=0, grad_clip=-1, grad_clip_type=2.0, grad_noise=False, accum_grad=1, no_forward_run=False, resume=False, train_dtype='float32', use_amp=False, log_interval=50, use_matplotlib=True, use_tensorboard=True, create_graph_in_tensorboard=False, use_wandb=False, wandb_project=None, wandb_id=None, wandb_entity=None, wandb_name=None, wandb_model_log_interval=-1, detect_anomaly=False, use_adapter=False, adapter='lora', save_strategy='all', adapter_conf={}, pretrain_path=None, init_param=[], ignore_init_mismatch=False, freeze_param=[], num_iters_per_epoch=1000, batch_size=20, valid_batch_size=None, batch_bins=3000000, valid_batch_bins=None, category_sample_size=10, train_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.16.scp'], valid_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.16.scp'], batch_type='numel', valid_batch_type=None, fold_length=[], sort_in_batch='descending', shuffle_within_batch=False, sort_batch='descending', multiple_iterator=False, chunk_length=500, chunk_shift_ratio=0.5, num_cache_chunks=1024, chunk_excluded_key_prefixes=[], chunk_default_fs=None, chunk_max_abs_length=None, chunk_discard_short_samples=True, train_data_path_and_name_and_type=[('dump/22k/raw/tr_no_dev/text', 'text', 'text'), ('dump/22k/raw/tr_no_dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/tr_no_dev/utt2sid', 'sids', 'text_int')], valid_data_path_and_name_and_type=[('dump/22k/raw/dev/text', 'text', 'text'), ('dump/22k/raw/dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/dev/utt2sid', 'sids', 'text_int')], multi_task_dataset=False, allow_variable_data_keys=False, max_cache_size=0.0, max_cache_fd=32, allow_multi_rates=False, valid_max_cache_size=None, exclude_weight_decay=False, exclude_weight_decay_conf={}, optim='adamw', optim_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler='exponentiallr', scheduler_conf={'gamma': 0.999875}, optim2='adamw', optim2_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler2='exponentiallr', scheduler2_conf={'gamma': 0.999875}, generator_first=False, skip_discriminator_prob=0.0, token_list=['<blank>', '<unk>', ' ', 'AH0', 'N', 'T', 'D', 'S', 'R', 'L', 'IH1', 'DH', 'M', 'EH1', 'Z', 'AE1', 'K', 'IH0', 'AH1', 'HH', 'W', 'ER0', 'V', 'IY1', 'F', 'UW1', 'P', 'AY1', 'B', 'AA1', 'AO1', 'EY1', 'IY0', 'OW1', 'NG', 'SH', 'G', 'Y', 'AW1', 'CH', 'ER1', 'UH1', 'TH', 'JH', 'OW0', 'EH2', 'IH2', 'OY1', 'EY2', 'AY2', 'EH0', 'UW0', 'AA2', 'AE2', 'OW2', 'AH2', 'AA0', 'ZH', 'AE0', 'AO2', 'UW2', 'AO0', 'AY0', 'IY2', 'AW2', 'UH2', 'EY0', 'ER2', 'AW0', 'UH0', 'OY2', 'OY0', "'", '<sos/eos>'], odim=None, model_conf={}, use_preprocessor=True, token_type='phn', bpemodel=None, non_linguistic_symbols=None, cleaner='tacotron', g2p='g2p_en', feats_extract='linear_spectrogram', feats_extract_conf={'n_fft': 1024, 'hop_length': 256, 'win_length': None}, normalize=None, normalize_conf={}, tts='vits', tts_conf={'generator_type': 'vits_generator', 'generator_params': {'hidden_channels': 192, 'spks': 128, 'global_channels': 256, 'segment_size': 32, 'text_encoder_attention_heads': 2, 'text_encoder_ffn_expand': 4, 'text_encoder_blocks': 6, 'text_encoder_positionwise_layer_type': 'conv1d', 'text_encoder_positionwise_conv_kernel_size': 3, 'text_encoder_positional_encoding_layer_type': 'rel_pos', 'text_encoder_self_attention_layer_type': 'rel_selfattn', 'text_encoder_activation_type': 'swish', 'text_encoder_normalize_before': True, 'text_encoder_dropout_rate': 0.1, 'text_encoder_positional_dropout_rate': 0.0, 'text_encoder_attention_dropout_rate': 0.1, 'use_macaron_style_in_text_encoder': True, 'use_conformer_conv_in_text_encoder': False, 'text_encoder_conformer_kernel_size': -1, 'decoder_kernel_size': 7, 'decoder_channels': 512, 'decoder_upsample_scales': [8, 8, 2, 2], 'decoder_upsample_kernel_sizes': [16, 16, 4, 4], 'decoder_resblock_kernel_sizes': [3, 7, 11], 'decoder_resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'use_weight_norm_in_decoder': True, 'posterior_encoder_kernel_size': 5, 'posterior_encoder_layers': 16, 'posterior_encoder_stacks': 1, 'posterior_encoder_base_dilation': 1, 'posterior_encoder_dropout_rate': 0.0, 'use_weight_norm_in_posterior_encoder': True, 'flow_flows': 4, 'flow_kernel_size': 5, 'flow_base_dilation': 1, 'flow_layers': 4, 'flow_dropout_rate': 0.0, 'use_weight_norm_in_flow': True, 'use_only_mean_in_flow': True, 'stochastic_duration_predictor_kernel_size': 3, 'stochastic_duration_predictor_dropout_rate': 0.5, 'stochastic_duration_predictor_flows': 4, 'stochastic_duration_predictor_dds_conv_layers': 3, 'vocabs': 74, 'aux_channels': 513}, 'discriminator_type': 'hifigan_multi_scale_multi_period_discriminator', 'discriminator_params': {'scales': 1, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'stride': 2, 'padding': 2}, 'scale_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'channels': 128, 'max_downsample_channels': 1024, 'max_groups': 16, 'bias': True, 'downsample_scales': [2, 2, 4, 4, 1], 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}, 'follow_official_norm': False, 'periods': [2, 3, 5, 7, 11], 'period_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [5, 3], 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'max_downsample_channels': 1024, 'bias': True, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}}, 'generator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'discriminator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'feat_match_loss_params': {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, 'mel_loss_params': {'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None, 'window': 'hann', 'n_mels': 80, 'fmin': 0, 'fmax': None, 'log_base': None}, 'lambda_adv': 1.0, 'lambda_mel': 45.0, 'lambda_feat_match': 2.0, 'lambda_dur': 1.0, 'lambda_kl': 1.0, 'sampling_rate': 22050, 'cache_generator_outputs': True, 'plot_pred_mos': False, 'mos_pred_tool': 'utmos'}, pitch_extract=None, pitch_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'f0max': 400, 'f0min': 80}, pitch_normalize=None, pitch_normalize_conf={}, energy_extract=None, energy_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None}, energy_normalize=None, energy_normalize_conf={}, required=['output_dir', 'token_list'], version='202503', distributed=False)
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1284, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 85861) is killed by signal: Killed. 

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 22, in <module>
    main()
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 18, in main
    GANTTSTask.main(cmd=cmd)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1225, in main
    cls.main_worker(args)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1441, in main_worker
    collect_stats(
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/main_funcs/collect_stats.py", line 51, in collect_stats
    for iiter, (keys, batch) in enumerate(itr, 1):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 733, in __next__
    data = self._next_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1491, in _next_data
    idx, data = self._get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1453, in _get_data
    success, data = self._try_get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1297, in _try_get_data
    raise RuntimeError(
RuntimeError: DataLoader worker (pid(s) 85861) exited unexpectedly
# Accounting: begin_time=1750836646
# Accounting: end_time=1750836799
# Accounting: time=153 threads=1
# Finished at Wed Jun 25 03:33:19 EDT 2025 with status 1
# Running on r005.ib.bridges2.psc.edu
# Started at Wed Jun 25 03:30:45 EDT 2025
# SLURMD_NODENAME=r005
# SLURM_ARRAY_JOB_ID=32966037
# SLURM_ARRAY_TASK_COUNT=32
# SLURM_ARRAY_TASK_ID=19
# SLURM_ARRAY_TASK_MAX=32
# SLURM_ARRAY_TASK_MIN=1
# SLURM_ARRAY_TASK_STEP=1
# SLURM_CLUSTER_NAME=bridges2
# SLURM_CONF=/var/spool/slurm/d/conf-cache/slurm.conf
# SLURM_CPUS_ON_NODE=1
# SLURM_EXPORT_ENV=ALL
# SLURM_GET_USER_ENV=1
# SLURM_GTIDS=0
# SLURM_JOBID=32966056
# SLURM_JOB_ACCOUNT=cis210027p
# SLURM_JOB_CPUS_PER_NODE=1
# SLURM_JOB_GID=24886
# SLURM_JOB_ID=32966056
# SLURM_JOB_NAME=stats.sh
# SLURM_JOB_NODELIST=r005
# SLURM_JOB_NUM_NODES=1
# SLURM_JOB_PARTITION=RM-shared
# SLURM_JOB_QOS=rm
# SLURM_JOB_UID=97947
# SLURM_JOB_USER=ttao3
# SLURM_LOCALID=0
# SLURM_MEM_PER_CPU=1900
# SLURM_NNODES=1
# SLURM_NODEID=0
# SLURM_NODELIST=r005
# SLURM_NODE_ALIASES='(null)'
# SLURM_OPEN_MODE=a
# SLURM_PRIO_PROCESS=0
# SLURM_PROCID=0
# SLURM_SCRIPT_CONTEXT=prolog_task
# SLURM_SUBMIT_DIR=/ocean/projects/cis210027p/ttao3/espnet/egs2/hifitts/tts1
# SLURM_SUBMIT_HOST=br013.ib.bridges2.psc.edu
# SLURM_TASKS_PER_NODE=1
# SLURM_TASK_PID=85521
# SLURM_TOPOLOGY_ADDR=r005
# SLURM_TOPOLOGY_ADDR_PATTERN=node
# SLURM_WORKING_CLUSTER=bridges2:br003:6810:9728:109
# python3 -m espnet2.bin.gan_tts_train --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.19.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.19.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.19 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int 
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/librosa/util/files.py:10: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_filename
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/bin/python3 /ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.19.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.19.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.19 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int
Failed to import Flash Attention, using ESPnet default: No module named 'flash_attn_2_cuda'
Vocabulary size: 74
encoder self-attention layer type = relative self-attention
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/ocean/projects/cis210027p/ttao3/espnet/espnet2/gan_tts/vits/monotonic_align/__init__.py:19: UserWarning: Cython version is not available. Fallback to 'EXPERIMETAL' numba version. If you want to use the cython version, please build it as follows: `cd espnet2/gan_tts/vits/monotonic_align; python setup.py build_ext --inplace`
  warnings.warn(
pytorch.version=2.7.1+cu126, cuda.available=False, cudnn.version=90501, cudnn.benchmark=False, cudnn.deterministic=False
Model structure:
ESPnetGANTTSModel(
  (feats_extract): LinearSpectrogram(
    (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
  )
  (tts): VITS(
    (generator): VITSGenerator(
      (text_encoder): TextEncoder(
        (emb): Embedding(74, 192)
        (encoder): Encoder(
          (embed): Sequential(
            (0): RelPositionalEncoding(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (encoders): MultiSequential(
            (0): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (2): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (3): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (4): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (5): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (after_norm): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (decoder): HiFiGANGenerator(
        (input_conv): Conv1d(192, 512, kernel_size=(7,), stride=(1,), padding=(3,))
        (upsamples): ModuleList(
          (0): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (1): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(256, 128, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (2): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,))
          )
          (3): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,))
          )
        )
        (blocks): ModuleList(
          (0): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (1): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (2): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (3): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (4): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (5): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (6): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (7): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (8): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (9): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (10): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (11): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
        )
        (output_conv): Sequential(
          (0): LeakyReLU(negative_slope=0.01)
          (1): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,))
          (2): Tanh()
        )
        (global_conv): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
      )
      (posterior_encoder): PosteriorEncoder(
        (input_conv): Conv1d(513, 192, kernel_size=(1,), stride=(1,))
        (encoder): WaveNet(
          (conv_layers): ModuleList(
            (0-15): 16 x ResidualBlock(
              (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
              (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
              (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
            )
          )
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (flow): ResidualAffineCouplingBlock(
        (flows): ModuleList(
          (0): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (1): FlipFlow()
          (2): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (3): FlipFlow()
          (4): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (5): FlipFlow()
          (6): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (7): FlipFlow()
        )
      )
      (duration_predictor): StochasticDurationPredictor(
        (pre): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (log_flow): LogFlow()
        (flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (post_pre): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
        (post_dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (post_proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (post_flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (global_conv): Conv1d(256, 192, kernel_size=(1,), stride=(1,))
      )
      (global_emb): Embedding(128, 256)
    )
    (discriminator): HiFiGANMultiScaleMultiPeriodDiscriminator(
      (msd): HiFiGANMultiScaleDiscriminator(
        (discriminators): ModuleList(
          (0): HiFiGANScaleDiscriminator(
            (layers): ModuleList(
              (0): Sequential(
                (0): Conv1d(1, 128, kernel_size=(15,), stride=(1,), padding=(7,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv1d(128, 128, kernel_size=(41,), stride=(2,), padding=(20,), groups=4)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv1d(128, 256, kernel_size=(41,), stride=(2,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv1d(256, 512, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv1d(512, 1024, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (5): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(41,), stride=(1,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (6): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (7): Conv1d(1024, 1, kernel_size=(3,), stride=(1,), padding=(1,))
            )
          )
        )
      )
      (mpd): HiFiGANMultiPeriodDiscriminator(
        (discriminators): ModuleList(
          (0-4): 5 x HiFiGANPeriodDiscriminator(
            (convs): ModuleList(
              (0): Sequential(
                (0): Conv2d(1, 32, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv2d(32, 128, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv2d(128, 512, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv2d(512, 1024, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv2d(1024, 1024, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
            )
            (output_conv): Conv2d(1024, 1, kernel_size=(2, 1), stride=(1, 1), padding=(1, 0))
          )
        )
      )
    )
    (generator_adv_loss): GeneratorAdversarialLoss()
    (discriminator_adv_loss): DiscriminatorAdversarialLoss()
    (feat_match_loss): FeatureMatchLoss()
    (mel_loss): MelSpectrogramLoss(
      (wav_to_mel): LogMelFbank(
        (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
        (logmel): LogMel(sr=22050, n_fft=1024, n_mels=80, fmin=0, fmax=11025.0, htk=False)
      )
    )
    (kl_loss): KLDivergenceLoss()
  )
)

Model summary:
    Class Name: ESPnetGANTTSModel
    Total Number of model parameters: 96.37 M
    Number of trainable parameters: 96.37 M (100.0%)
    Size: 385.46 MB
    Type: torch.float32
Optimizer:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler: <torch.optim.lr_scheduler.ExponentialLR object at 0x14f995c28220>
Optimizer2:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler2: <torch.optim.lr_scheduler.ExponentialLR object at 0x14f995c28640>
Saving the configuration in exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.19/config.yaml
Namespace(config='conf/tuning/train_multi_spk_vits.yaml', print_config=False, log_level='INFO', drop_last_iter=False, dry_run=False, iterator_type='sequence', valid_iterator_type=None, output_dir='exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.19', ngpu=0, seed=777, num_workers=4, num_att_plot=3, dist_backend='nccl', dist_init_method='env://', dist_world_size=None, dist_rank=None, local_rank=None, dist_master_addr=None, dist_master_port=None, dist_launcher=None, multiprocessing_distributed=False, unused_parameters=True, sharded_ddp=False, use_deepspeed=False, deepspeed_config=None, gradient_as_bucket_view=True, ddp_comm_hook=None, cudnn_enabled=True, cudnn_benchmark=False, cudnn_deterministic=False, use_tf32=False, collect_stats=True, write_collected_feats=False, max_epoch=1000, patience=None, val_scheduler_criterion=('valid', 'loss'), early_stopping_criterion=('valid', 'loss', 'min'), best_model_criterion=[['train', 'total_count', 'max']], keep_nbest_models=10, nbest_averaging_interval=0, grad_clip=-1, grad_clip_type=2.0, grad_noise=False, accum_grad=1, no_forward_run=False, resume=False, train_dtype='float32', use_amp=False, log_interval=50, use_matplotlib=True, use_tensorboard=True, create_graph_in_tensorboard=False, use_wandb=False, wandb_project=None, wandb_id=None, wandb_entity=None, wandb_name=None, wandb_model_log_interval=-1, detect_anomaly=False, use_adapter=False, adapter='lora', save_strategy='all', adapter_conf={}, pretrain_path=None, init_param=[], ignore_init_mismatch=False, freeze_param=[], num_iters_per_epoch=1000, batch_size=20, valid_batch_size=None, batch_bins=3000000, valid_batch_bins=None, category_sample_size=10, train_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.19.scp'], valid_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.19.scp'], batch_type='numel', valid_batch_type=None, fold_length=[], sort_in_batch='descending', shuffle_within_batch=False, sort_batch='descending', multiple_iterator=False, chunk_length=500, chunk_shift_ratio=0.5, num_cache_chunks=1024, chunk_excluded_key_prefixes=[], chunk_default_fs=None, chunk_max_abs_length=None, chunk_discard_short_samples=True, train_data_path_and_name_and_type=[('dump/22k/raw/tr_no_dev/text', 'text', 'text'), ('dump/22k/raw/tr_no_dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/tr_no_dev/utt2sid', 'sids', 'text_int')], valid_data_path_and_name_and_type=[('dump/22k/raw/dev/text', 'text', 'text'), ('dump/22k/raw/dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/dev/utt2sid', 'sids', 'text_int')], multi_task_dataset=False, allow_variable_data_keys=False, max_cache_size=0.0, max_cache_fd=32, allow_multi_rates=False, valid_max_cache_size=None, exclude_weight_decay=False, exclude_weight_decay_conf={}, optim='adamw', optim_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler='exponentiallr', scheduler_conf={'gamma': 0.999875}, optim2='adamw', optim2_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler2='exponentiallr', scheduler2_conf={'gamma': 0.999875}, generator_first=False, skip_discriminator_prob=0.0, token_list=['<blank>', '<unk>', ' ', 'AH0', 'N', 'T', 'D', 'S', 'R', 'L', 'IH1', 'DH', 'M', 'EH1', 'Z', 'AE1', 'K', 'IH0', 'AH1', 'HH', 'W', 'ER0', 'V', 'IY1', 'F', 'UW1', 'P', 'AY1', 'B', 'AA1', 'AO1', 'EY1', 'IY0', 'OW1', 'NG', 'SH', 'G', 'Y', 'AW1', 'CH', 'ER1', 'UH1', 'TH', 'JH', 'OW0', 'EH2', 'IH2', 'OY1', 'EY2', 'AY2', 'EH0', 'UW0', 'AA2', 'AE2', 'OW2', 'AH2', 'AA0', 'ZH', 'AE0', 'AO2', 'UW2', 'AO0', 'AY0', 'IY2', 'AW2', 'UH2', 'EY0', 'ER2', 'AW0', 'UH0', 'OY2', 'OY0', "'", '<sos/eos>'], odim=None, model_conf={}, use_preprocessor=True, token_type='phn', bpemodel=None, non_linguistic_symbols=None, cleaner='tacotron', g2p='g2p_en', feats_extract='linear_spectrogram', feats_extract_conf={'n_fft': 1024, 'hop_length': 256, 'win_length': None}, normalize=None, normalize_conf={}, tts='vits', tts_conf={'generator_type': 'vits_generator', 'generator_params': {'hidden_channels': 192, 'spks': 128, 'global_channels': 256, 'segment_size': 32, 'text_encoder_attention_heads': 2, 'text_encoder_ffn_expand': 4, 'text_encoder_blocks': 6, 'text_encoder_positionwise_layer_type': 'conv1d', 'text_encoder_positionwise_conv_kernel_size': 3, 'text_encoder_positional_encoding_layer_type': 'rel_pos', 'text_encoder_self_attention_layer_type': 'rel_selfattn', 'text_encoder_activation_type': 'swish', 'text_encoder_normalize_before': True, 'text_encoder_dropout_rate': 0.1, 'text_encoder_positional_dropout_rate': 0.0, 'text_encoder_attention_dropout_rate': 0.1, 'use_macaron_style_in_text_encoder': True, 'use_conformer_conv_in_text_encoder': False, 'text_encoder_conformer_kernel_size': -1, 'decoder_kernel_size': 7, 'decoder_channels': 512, 'decoder_upsample_scales': [8, 8, 2, 2], 'decoder_upsample_kernel_sizes': [16, 16, 4, 4], 'decoder_resblock_kernel_sizes': [3, 7, 11], 'decoder_resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'use_weight_norm_in_decoder': True, 'posterior_encoder_kernel_size': 5, 'posterior_encoder_layers': 16, 'posterior_encoder_stacks': 1, 'posterior_encoder_base_dilation': 1, 'posterior_encoder_dropout_rate': 0.0, 'use_weight_norm_in_posterior_encoder': True, 'flow_flows': 4, 'flow_kernel_size': 5, 'flow_base_dilation': 1, 'flow_layers': 4, 'flow_dropout_rate': 0.0, 'use_weight_norm_in_flow': True, 'use_only_mean_in_flow': True, 'stochastic_duration_predictor_kernel_size': 3, 'stochastic_duration_predictor_dropout_rate': 0.5, 'stochastic_duration_predictor_flows': 4, 'stochastic_duration_predictor_dds_conv_layers': 3, 'vocabs': 74, 'aux_channels': 513}, 'discriminator_type': 'hifigan_multi_scale_multi_period_discriminator', 'discriminator_params': {'scales': 1, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'stride': 2, 'padding': 2}, 'scale_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'channels': 128, 'max_downsample_channels': 1024, 'max_groups': 16, 'bias': True, 'downsample_scales': [2, 2, 4, 4, 1], 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}, 'follow_official_norm': False, 'periods': [2, 3, 5, 7, 11], 'period_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [5, 3], 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'max_downsample_channels': 1024, 'bias': True, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}}, 'generator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'discriminator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'feat_match_loss_params': {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, 'mel_loss_params': {'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None, 'window': 'hann', 'n_mels': 80, 'fmin': 0, 'fmax': None, 'log_base': None}, 'lambda_adv': 1.0, 'lambda_mel': 45.0, 'lambda_feat_match': 2.0, 'lambda_dur': 1.0, 'lambda_kl': 1.0, 'sampling_rate': 22050, 'cache_generator_outputs': True, 'plot_pred_mos': False, 'mos_pred_tool': 'utmos'}, pitch_extract=None, pitch_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'f0max': 400, 'f0min': 80}, pitch_normalize=None, pitch_normalize_conf={}, energy_extract=None, energy_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None}, energy_normalize=None, energy_normalize_conf={}, required=['output_dir', 'token_list'], version='202503', distributed=False)
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1284, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 85835) is killed by signal: Killed. 

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 22, in <module>
    main()
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 18, in main
    GANTTSTask.main(cmd=cmd)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1225, in main
    cls.main_worker(args)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1441, in main_worker
    collect_stats(
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/main_funcs/collect_stats.py", line 51, in collect_stats
    for iiter, (keys, batch) in enumerate(itr, 1):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 733, in __next__
    data = self._next_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1491, in _next_data
    idx, data = self._get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1453, in _get_data
    success, data = self._try_get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1297, in _try_get_data
    raise RuntimeError(
RuntimeError: DataLoader worker (pid(s) 85835) exited unexpectedly
# Accounting: begin_time=1750836645
# Accounting: end_time=1750836799
# Accounting: time=154 threads=1
# Finished at Wed Jun 25 03:33:19 EDT 2025 with status 1
# Running on r005.ib.bridges2.psc.edu
# Started at Wed Jun 25 03:30:45 EDT 2025
# SLURMD_NODENAME=r005
# SLURM_ARRAY_JOB_ID=32966037
# SLURM_ARRAY_TASK_COUNT=32
# SLURM_ARRAY_TASK_ID=20
# SLURM_ARRAY_TASK_MAX=32
# SLURM_ARRAY_TASK_MIN=1
# SLURM_ARRAY_TASK_STEP=1
# SLURM_CLUSTER_NAME=bridges2
# SLURM_CONF=/var/spool/slurm/d/conf-cache/slurm.conf
# SLURM_CPUS_ON_NODE=1
# SLURM_EXPORT_ENV=ALL
# SLURM_GET_USER_ENV=1
# SLURM_GTIDS=0
# SLURM_JOBID=32966057
# SLURM_JOB_ACCOUNT=cis210027p
# SLURM_JOB_CPUS_PER_NODE=1
# SLURM_JOB_GID=24886
# SLURM_JOB_ID=32966057
# SLURM_JOB_NAME=stats.sh
# SLURM_JOB_NODELIST=r005
# SLURM_JOB_NUM_NODES=1
# SLURM_JOB_PARTITION=RM-shared
# SLURM_JOB_QOS=rm
# SLURM_JOB_UID=97947
# SLURM_JOB_USER=ttao3
# SLURM_LOCALID=0
# SLURM_MEM_PER_CPU=1900
# SLURM_NNODES=1
# SLURM_NODEID=0
# SLURM_NODELIST=r005
# SLURM_NODE_ALIASES='(null)'
# SLURM_OPEN_MODE=a
# SLURM_PRIO_PROCESS=0
# SLURM_PROCID=0
# SLURM_SCRIPT_CONTEXT=prolog_task
# SLURM_SUBMIT_DIR=/ocean/projects/cis210027p/ttao3/espnet/egs2/hifitts/tts1
# SLURM_SUBMIT_HOST=br013.ib.bridges2.psc.edu
# SLURM_TASKS_PER_NODE=1
# SLURM_TASK_PID=85522
# SLURM_TOPOLOGY_ADDR=r005
# SLURM_TOPOLOGY_ADDR_PATTERN=node
# SLURM_WORKING_CLUSTER=bridges2:br003:6810:9728:109
# python3 -m espnet2.bin.gan_tts_train --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.20.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.20.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.20 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int 
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/librosa/util/files.py:10: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_filename
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/bin/python3 /ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.20.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.20.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.20 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int
Failed to import Flash Attention, using ESPnet default: No module named 'flash_attn_2_cuda'
Vocabulary size: 74
encoder self-attention layer type = relative self-attention
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/ocean/projects/cis210027p/ttao3/espnet/espnet2/gan_tts/vits/monotonic_align/__init__.py:19: UserWarning: Cython version is not available. Fallback to 'EXPERIMETAL' numba version. If you want to use the cython version, please build it as follows: `cd espnet2/gan_tts/vits/monotonic_align; python setup.py build_ext --inplace`
  warnings.warn(
pytorch.version=2.7.1+cu126, cuda.available=False, cudnn.version=90501, cudnn.benchmark=False, cudnn.deterministic=False
Model structure:
ESPnetGANTTSModel(
  (feats_extract): LinearSpectrogram(
    (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
  )
  (tts): VITS(
    (generator): VITSGenerator(
      (text_encoder): TextEncoder(
        (emb): Embedding(74, 192)
        (encoder): Encoder(
          (embed): Sequential(
            (0): RelPositionalEncoding(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (encoders): MultiSequential(
            (0): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (2): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (3): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (4): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (5): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (after_norm): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (decoder): HiFiGANGenerator(
        (input_conv): Conv1d(192, 512, kernel_size=(7,), stride=(1,), padding=(3,))
        (upsamples): ModuleList(
          (0): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (1): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(256, 128, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (2): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,))
          )
          (3): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,))
          )
        )
        (blocks): ModuleList(
          (0): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (1): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (2): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (3): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (4): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (5): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (6): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (7): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (8): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (9): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (10): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (11): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
        )
        (output_conv): Sequential(
          (0): LeakyReLU(negative_slope=0.01)
          (1): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,))
          (2): Tanh()
        )
        (global_conv): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
      )
      (posterior_encoder): PosteriorEncoder(
        (input_conv): Conv1d(513, 192, kernel_size=(1,), stride=(1,))
        (encoder): WaveNet(
          (conv_layers): ModuleList(
            (0-15): 16 x ResidualBlock(
              (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
              (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
              (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
            )
          )
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (flow): ResidualAffineCouplingBlock(
        (flows): ModuleList(
          (0): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (1): FlipFlow()
          (2): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (3): FlipFlow()
          (4): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (5): FlipFlow()
          (6): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (7): FlipFlow()
        )
      )
      (duration_predictor): StochasticDurationPredictor(
        (pre): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (log_flow): LogFlow()
        (flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (post_pre): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
        (post_dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (post_proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (post_flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (global_conv): Conv1d(256, 192, kernel_size=(1,), stride=(1,))
      )
      (global_emb): Embedding(128, 256)
    )
    (discriminator): HiFiGANMultiScaleMultiPeriodDiscriminator(
      (msd): HiFiGANMultiScaleDiscriminator(
        (discriminators): ModuleList(
          (0): HiFiGANScaleDiscriminator(
            (layers): ModuleList(
              (0): Sequential(
                (0): Conv1d(1, 128, kernel_size=(15,), stride=(1,), padding=(7,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv1d(128, 128, kernel_size=(41,), stride=(2,), padding=(20,), groups=4)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv1d(128, 256, kernel_size=(41,), stride=(2,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv1d(256, 512, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv1d(512, 1024, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (5): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(41,), stride=(1,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (6): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (7): Conv1d(1024, 1, kernel_size=(3,), stride=(1,), padding=(1,))
            )
          )
        )
      )
      (mpd): HiFiGANMultiPeriodDiscriminator(
        (discriminators): ModuleList(
          (0-4): 5 x HiFiGANPeriodDiscriminator(
            (convs): ModuleList(
              (0): Sequential(
                (0): Conv2d(1, 32, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv2d(32, 128, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv2d(128, 512, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv2d(512, 1024, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv2d(1024, 1024, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
            )
            (output_conv): Conv2d(1024, 1, kernel_size=(2, 1), stride=(1, 1), padding=(1, 0))
          )
        )
      )
    )
    (generator_adv_loss): GeneratorAdversarialLoss()
    (discriminator_adv_loss): DiscriminatorAdversarialLoss()
    (feat_match_loss): FeatureMatchLoss()
    (mel_loss): MelSpectrogramLoss(
      (wav_to_mel): LogMelFbank(
        (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
        (logmel): LogMel(sr=22050, n_fft=1024, n_mels=80, fmin=0, fmax=11025.0, htk=False)
      )
    )
    (kl_loss): KLDivergenceLoss()
  )
)

Model summary:
    Class Name: ESPnetGANTTSModel
    Total Number of model parameters: 96.37 M
    Number of trainable parameters: 96.37 M (100.0%)
    Size: 385.46 MB
    Type: torch.float32
Optimizer:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler: <torch.optim.lr_scheduler.ExponentialLR object at 0x15398a0bc1c0>
Optimizer2:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler2: <torch.optim.lr_scheduler.ExponentialLR object at 0x15398a0bc5e0>
Saving the configuration in exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.20/config.yaml
Namespace(config='conf/tuning/train_multi_spk_vits.yaml', print_config=False, log_level='INFO', drop_last_iter=False, dry_run=False, iterator_type='sequence', valid_iterator_type=None, output_dir='exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.20', ngpu=0, seed=777, num_workers=4, num_att_plot=3, dist_backend='nccl', dist_init_method='env://', dist_world_size=None, dist_rank=None, local_rank=None, dist_master_addr=None, dist_master_port=None, dist_launcher=None, multiprocessing_distributed=False, unused_parameters=True, sharded_ddp=False, use_deepspeed=False, deepspeed_config=None, gradient_as_bucket_view=True, ddp_comm_hook=None, cudnn_enabled=True, cudnn_benchmark=False, cudnn_deterministic=False, use_tf32=False, collect_stats=True, write_collected_feats=False, max_epoch=1000, patience=None, val_scheduler_criterion=('valid', 'loss'), early_stopping_criterion=('valid', 'loss', 'min'), best_model_criterion=[['train', 'total_count', 'max']], keep_nbest_models=10, nbest_averaging_interval=0, grad_clip=-1, grad_clip_type=2.0, grad_noise=False, accum_grad=1, no_forward_run=False, resume=False, train_dtype='float32', use_amp=False, log_interval=50, use_matplotlib=True, use_tensorboard=True, create_graph_in_tensorboard=False, use_wandb=False, wandb_project=None, wandb_id=None, wandb_entity=None, wandb_name=None, wandb_model_log_interval=-1, detect_anomaly=False, use_adapter=False, adapter='lora', save_strategy='all', adapter_conf={}, pretrain_path=None, init_param=[], ignore_init_mismatch=False, freeze_param=[], num_iters_per_epoch=1000, batch_size=20, valid_batch_size=None, batch_bins=3000000, valid_batch_bins=None, category_sample_size=10, train_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.20.scp'], valid_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.20.scp'], batch_type='numel', valid_batch_type=None, fold_length=[], sort_in_batch='descending', shuffle_within_batch=False, sort_batch='descending', multiple_iterator=False, chunk_length=500, chunk_shift_ratio=0.5, num_cache_chunks=1024, chunk_excluded_key_prefixes=[], chunk_default_fs=None, chunk_max_abs_length=None, chunk_discard_short_samples=True, train_data_path_and_name_and_type=[('dump/22k/raw/tr_no_dev/text', 'text', 'text'), ('dump/22k/raw/tr_no_dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/tr_no_dev/utt2sid', 'sids', 'text_int')], valid_data_path_and_name_and_type=[('dump/22k/raw/dev/text', 'text', 'text'), ('dump/22k/raw/dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/dev/utt2sid', 'sids', 'text_int')], multi_task_dataset=False, allow_variable_data_keys=False, max_cache_size=0.0, max_cache_fd=32, allow_multi_rates=False, valid_max_cache_size=None, exclude_weight_decay=False, exclude_weight_decay_conf={}, optim='adamw', optim_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler='exponentiallr', scheduler_conf={'gamma': 0.999875}, optim2='adamw', optim2_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler2='exponentiallr', scheduler2_conf={'gamma': 0.999875}, generator_first=False, skip_discriminator_prob=0.0, token_list=['<blank>', '<unk>', ' ', 'AH0', 'N', 'T', 'D', 'S', 'R', 'L', 'IH1', 'DH', 'M', 'EH1', 'Z', 'AE1', 'K', 'IH0', 'AH1', 'HH', 'W', 'ER0', 'V', 'IY1', 'F', 'UW1', 'P', 'AY1', 'B', 'AA1', 'AO1', 'EY1', 'IY0', 'OW1', 'NG', 'SH', 'G', 'Y', 'AW1', 'CH', 'ER1', 'UH1', 'TH', 'JH', 'OW0', 'EH2', 'IH2', 'OY1', 'EY2', 'AY2', 'EH0', 'UW0', 'AA2', 'AE2', 'OW2', 'AH2', 'AA0', 'ZH', 'AE0', 'AO2', 'UW2', 'AO0', 'AY0', 'IY2', 'AW2', 'UH2', 'EY0', 'ER2', 'AW0', 'UH0', 'OY2', 'OY0', "'", '<sos/eos>'], odim=None, model_conf={}, use_preprocessor=True, token_type='phn', bpemodel=None, non_linguistic_symbols=None, cleaner='tacotron', g2p='g2p_en', feats_extract='linear_spectrogram', feats_extract_conf={'n_fft': 1024, 'hop_length': 256, 'win_length': None}, normalize=None, normalize_conf={}, tts='vits', tts_conf={'generator_type': 'vits_generator', 'generator_params': {'hidden_channels': 192, 'spks': 128, 'global_channels': 256, 'segment_size': 32, 'text_encoder_attention_heads': 2, 'text_encoder_ffn_expand': 4, 'text_encoder_blocks': 6, 'text_encoder_positionwise_layer_type': 'conv1d', 'text_encoder_positionwise_conv_kernel_size': 3, 'text_encoder_positional_encoding_layer_type': 'rel_pos', 'text_encoder_self_attention_layer_type': 'rel_selfattn', 'text_encoder_activation_type': 'swish', 'text_encoder_normalize_before': True, 'text_encoder_dropout_rate': 0.1, 'text_encoder_positional_dropout_rate': 0.0, 'text_encoder_attention_dropout_rate': 0.1, 'use_macaron_style_in_text_encoder': True, 'use_conformer_conv_in_text_encoder': False, 'text_encoder_conformer_kernel_size': -1, 'decoder_kernel_size': 7, 'decoder_channels': 512, 'decoder_upsample_scales': [8, 8, 2, 2], 'decoder_upsample_kernel_sizes': [16, 16, 4, 4], 'decoder_resblock_kernel_sizes': [3, 7, 11], 'decoder_resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'use_weight_norm_in_decoder': True, 'posterior_encoder_kernel_size': 5, 'posterior_encoder_layers': 16, 'posterior_encoder_stacks': 1, 'posterior_encoder_base_dilation': 1, 'posterior_encoder_dropout_rate': 0.0, 'use_weight_norm_in_posterior_encoder': True, 'flow_flows': 4, 'flow_kernel_size': 5, 'flow_base_dilation': 1, 'flow_layers': 4, 'flow_dropout_rate': 0.0, 'use_weight_norm_in_flow': True, 'use_only_mean_in_flow': True, 'stochastic_duration_predictor_kernel_size': 3, 'stochastic_duration_predictor_dropout_rate': 0.5, 'stochastic_duration_predictor_flows': 4, 'stochastic_duration_predictor_dds_conv_layers': 3, 'vocabs': 74, 'aux_channels': 513}, 'discriminator_type': 'hifigan_multi_scale_multi_period_discriminator', 'discriminator_params': {'scales': 1, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'stride': 2, 'padding': 2}, 'scale_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'channels': 128, 'max_downsample_channels': 1024, 'max_groups': 16, 'bias': True, 'downsample_scales': [2, 2, 4, 4, 1], 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}, 'follow_official_norm': False, 'periods': [2, 3, 5, 7, 11], 'period_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [5, 3], 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'max_downsample_channels': 1024, 'bias': True, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}}, 'generator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'discriminator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'feat_match_loss_params': {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, 'mel_loss_params': {'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None, 'window': 'hann', 'n_mels': 80, 'fmin': 0, 'fmax': None, 'log_base': None}, 'lambda_adv': 1.0, 'lambda_mel': 45.0, 'lambda_feat_match': 2.0, 'lambda_dur': 1.0, 'lambda_kl': 1.0, 'sampling_rate': 22050, 'cache_generator_outputs': True, 'plot_pred_mos': False, 'mos_pred_tool': 'utmos'}, pitch_extract=None, pitch_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'f0max': 400, 'f0min': 80}, pitch_normalize=None, pitch_normalize_conf={}, energy_extract=None, energy_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None}, energy_normalize=None, energy_normalize_conf={}, required=['output_dir', 'token_list'], version='202503', distributed=False)
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1284, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 85846) is killed by signal: Killed. 

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 22, in <module>
    main()
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 18, in main
    GANTTSTask.main(cmd=cmd)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1225, in main
    cls.main_worker(args)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1441, in main_worker
    collect_stats(
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/main_funcs/collect_stats.py", line 51, in collect_stats
    for iiter, (keys, batch) in enumerate(itr, 1):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 733, in __next__
    data = self._next_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1491, in _next_data
    idx, data = self._get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1453, in _get_data
    success, data = self._try_get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1297, in _try_get_data
    raise RuntimeError(
RuntimeError: DataLoader worker (pid(s) 85846) exited unexpectedly
# Accounting: begin_time=1750836645
# Accounting: end_time=1750836799
# Accounting: time=154 threads=1
# Finished at Wed Jun 25 03:33:19 EDT 2025 with status 1
# Running on r005.ib.bridges2.psc.edu
# Started at Wed Jun 25 03:30:45 EDT 2025
# SLURMD_NODENAME=r005
# SLURM_ARRAY_JOB_ID=32966037
# SLURM_ARRAY_TASK_COUNT=32
# SLURM_ARRAY_TASK_ID=22
# SLURM_ARRAY_TASK_MAX=32
# SLURM_ARRAY_TASK_MIN=1
# SLURM_ARRAY_TASK_STEP=1
# SLURM_CLUSTER_NAME=bridges2
# SLURM_CONF=/var/spool/slurm/d/conf-cache/slurm.conf
# SLURM_CPUS_ON_NODE=1
# SLURM_EXPORT_ENV=ALL
# SLURM_GET_USER_ENV=1
# SLURM_GTIDS=0
# SLURM_JOBID=32966059
# SLURM_JOB_ACCOUNT=cis210027p
# SLURM_JOB_CPUS_PER_NODE=1
# SLURM_JOB_GID=24886
# SLURM_JOB_ID=32966059
# SLURM_JOB_NAME=stats.sh
# SLURM_JOB_NODELIST=r005
# SLURM_JOB_NUM_NODES=1
# SLURM_JOB_PARTITION=RM-shared
# SLURM_JOB_QOS=rm
# SLURM_JOB_UID=97947
# SLURM_JOB_USER=ttao3
# SLURM_LOCALID=0
# SLURM_MEM_PER_CPU=1900
# SLURM_NNODES=1
# SLURM_NODEID=0
# SLURM_NODELIST=r005
# SLURM_NODE_ALIASES='(null)'
# SLURM_OPEN_MODE=a
# SLURM_PRIO_PROCESS=0
# SLURM_PROCID=0
# SLURM_SCRIPT_CONTEXT=prolog_task
# SLURM_SUBMIT_DIR=/ocean/projects/cis210027p/ttao3/espnet/egs2/hifitts/tts1
# SLURM_SUBMIT_HOST=br013.ib.bridges2.psc.edu
# SLURM_TASKS_PER_NODE=1
# SLURM_TASK_PID=85517
# SLURM_TOPOLOGY_ADDR=r005
# SLURM_TOPOLOGY_ADDR_PATTERN=node
# SLURM_WORKING_CLUSTER=bridges2:br003:6810:9728:109
# python3 -m espnet2.bin.gan_tts_train --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.22.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.22.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.22 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int 
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/librosa/util/files.py:10: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_filename
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/bin/python3 /ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.22.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.22.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.22 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int
Failed to import Flash Attention, using ESPnet default: No module named 'flash_attn_2_cuda'
Vocabulary size: 74
encoder self-attention layer type = relative self-attention
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/ocean/projects/cis210027p/ttao3/espnet/espnet2/gan_tts/vits/monotonic_align/__init__.py:19: UserWarning: Cython version is not available. Fallback to 'EXPERIMETAL' numba version. If you want to use the cython version, please build it as follows: `cd espnet2/gan_tts/vits/monotonic_align; python setup.py build_ext --inplace`
  warnings.warn(
pytorch.version=2.7.1+cu126, cuda.available=False, cudnn.version=90501, cudnn.benchmark=False, cudnn.deterministic=False
Model structure:
ESPnetGANTTSModel(
  (feats_extract): LinearSpectrogram(
    (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
  )
  (tts): VITS(
    (generator): VITSGenerator(
      (text_encoder): TextEncoder(
        (emb): Embedding(74, 192)
        (encoder): Encoder(
          (embed): Sequential(
            (0): RelPositionalEncoding(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (encoders): MultiSequential(
            (0): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (2): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (3): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (4): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (5): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (after_norm): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (decoder): HiFiGANGenerator(
        (input_conv): Conv1d(192, 512, kernel_size=(7,), stride=(1,), padding=(3,))
        (upsamples): ModuleList(
          (0): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (1): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(256, 128, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (2): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,))
          )
          (3): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,))
          )
        )
        (blocks): ModuleList(
          (0): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (1): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (2): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (3): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (4): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (5): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (6): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (7): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (8): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (9): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (10): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (11): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
        )
        (output_conv): Sequential(
          (0): LeakyReLU(negative_slope=0.01)
          (1): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,))
          (2): Tanh()
        )
        (global_conv): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
      )
      (posterior_encoder): PosteriorEncoder(
        (input_conv): Conv1d(513, 192, kernel_size=(1,), stride=(1,))
        (encoder): WaveNet(
          (conv_layers): ModuleList(
            (0-15): 16 x ResidualBlock(
              (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
              (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
              (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
            )
          )
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (flow): ResidualAffineCouplingBlock(
        (flows): ModuleList(
          (0): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (1): FlipFlow()
          (2): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (3): FlipFlow()
          (4): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (5): FlipFlow()
          (6): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (7): FlipFlow()
        )
      )
      (duration_predictor): StochasticDurationPredictor(
        (pre): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (log_flow): LogFlow()
        (flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (post_pre): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
        (post_dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (post_proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (post_flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (global_conv): Conv1d(256, 192, kernel_size=(1,), stride=(1,))
      )
      (global_emb): Embedding(128, 256)
    )
    (discriminator): HiFiGANMultiScaleMultiPeriodDiscriminator(
      (msd): HiFiGANMultiScaleDiscriminator(
        (discriminators): ModuleList(
          (0): HiFiGANScaleDiscriminator(
            (layers): ModuleList(
              (0): Sequential(
                (0): Conv1d(1, 128, kernel_size=(15,), stride=(1,), padding=(7,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv1d(128, 128, kernel_size=(41,), stride=(2,), padding=(20,), groups=4)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv1d(128, 256, kernel_size=(41,), stride=(2,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv1d(256, 512, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv1d(512, 1024, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (5): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(41,), stride=(1,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (6): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (7): Conv1d(1024, 1, kernel_size=(3,), stride=(1,), padding=(1,))
            )
          )
        )
      )
      (mpd): HiFiGANMultiPeriodDiscriminator(
        (discriminators): ModuleList(
          (0-4): 5 x HiFiGANPeriodDiscriminator(
            (convs): ModuleList(
              (0): Sequential(
                (0): Conv2d(1, 32, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv2d(32, 128, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv2d(128, 512, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv2d(512, 1024, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv2d(1024, 1024, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
            )
            (output_conv): Conv2d(1024, 1, kernel_size=(2, 1), stride=(1, 1), padding=(1, 0))
          )
        )
      )
    )
    (generator_adv_loss): GeneratorAdversarialLoss()
    (discriminator_adv_loss): DiscriminatorAdversarialLoss()
    (feat_match_loss): FeatureMatchLoss()
    (mel_loss): MelSpectrogramLoss(
      (wav_to_mel): LogMelFbank(
        (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
        (logmel): LogMel(sr=22050, n_fft=1024, n_mels=80, fmin=0, fmax=11025.0, htk=False)
      )
    )
    (kl_loss): KLDivergenceLoss()
  )
)

Model summary:
    Class Name: ESPnetGANTTSModel
    Total Number of model parameters: 96.37 M
    Number of trainable parameters: 96.37 M (100.0%)
    Size: 385.46 MB
    Type: torch.float32
Optimizer:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler: <torch.optim.lr_scheduler.ExponentialLR object at 0x148ba2926220>
Optimizer2:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler2: <torch.optim.lr_scheduler.ExponentialLR object at 0x148ba2926640>
Saving the configuration in exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.22/config.yaml
Namespace(config='conf/tuning/train_multi_spk_vits.yaml', print_config=False, log_level='INFO', drop_last_iter=False, dry_run=False, iterator_type='sequence', valid_iterator_type=None, output_dir='exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.22', ngpu=0, seed=777, num_workers=4, num_att_plot=3, dist_backend='nccl', dist_init_method='env://', dist_world_size=None, dist_rank=None, local_rank=None, dist_master_addr=None, dist_master_port=None, dist_launcher=None, multiprocessing_distributed=False, unused_parameters=True, sharded_ddp=False, use_deepspeed=False, deepspeed_config=None, gradient_as_bucket_view=True, ddp_comm_hook=None, cudnn_enabled=True, cudnn_benchmark=False, cudnn_deterministic=False, use_tf32=False, collect_stats=True, write_collected_feats=False, max_epoch=1000, patience=None, val_scheduler_criterion=('valid', 'loss'), early_stopping_criterion=('valid', 'loss', 'min'), best_model_criterion=[['train', 'total_count', 'max']], keep_nbest_models=10, nbest_averaging_interval=0, grad_clip=-1, grad_clip_type=2.0, grad_noise=False, accum_grad=1, no_forward_run=False, resume=False, train_dtype='float32', use_amp=False, log_interval=50, use_matplotlib=True, use_tensorboard=True, create_graph_in_tensorboard=False, use_wandb=False, wandb_project=None, wandb_id=None, wandb_entity=None, wandb_name=None, wandb_model_log_interval=-1, detect_anomaly=False, use_adapter=False, adapter='lora', save_strategy='all', adapter_conf={}, pretrain_path=None, init_param=[], ignore_init_mismatch=False, freeze_param=[], num_iters_per_epoch=1000, batch_size=20, valid_batch_size=None, batch_bins=3000000, valid_batch_bins=None, category_sample_size=10, train_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.22.scp'], valid_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.22.scp'], batch_type='numel', valid_batch_type=None, fold_length=[], sort_in_batch='descending', shuffle_within_batch=False, sort_batch='descending', multiple_iterator=False, chunk_length=500, chunk_shift_ratio=0.5, num_cache_chunks=1024, chunk_excluded_key_prefixes=[], chunk_default_fs=None, chunk_max_abs_length=None, chunk_discard_short_samples=True, train_data_path_and_name_and_type=[('dump/22k/raw/tr_no_dev/text', 'text', 'text'), ('dump/22k/raw/tr_no_dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/tr_no_dev/utt2sid', 'sids', 'text_int')], valid_data_path_and_name_and_type=[('dump/22k/raw/dev/text', 'text', 'text'), ('dump/22k/raw/dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/dev/utt2sid', 'sids', 'text_int')], multi_task_dataset=False, allow_variable_data_keys=False, max_cache_size=0.0, max_cache_fd=32, allow_multi_rates=False, valid_max_cache_size=None, exclude_weight_decay=False, exclude_weight_decay_conf={}, optim='adamw', optim_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler='exponentiallr', scheduler_conf={'gamma': 0.999875}, optim2='adamw', optim2_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler2='exponentiallr', scheduler2_conf={'gamma': 0.999875}, generator_first=False, skip_discriminator_prob=0.0, token_list=['<blank>', '<unk>', ' ', 'AH0', 'N', 'T', 'D', 'S', 'R', 'L', 'IH1', 'DH', 'M', 'EH1', 'Z', 'AE1', 'K', 'IH0', 'AH1', 'HH', 'W', 'ER0', 'V', 'IY1', 'F', 'UW1', 'P', 'AY1', 'B', 'AA1', 'AO1', 'EY1', 'IY0', 'OW1', 'NG', 'SH', 'G', 'Y', 'AW1', 'CH', 'ER1', 'UH1', 'TH', 'JH', 'OW0', 'EH2', 'IH2', 'OY1', 'EY2', 'AY2', 'EH0', 'UW0', 'AA2', 'AE2', 'OW2', 'AH2', 'AA0', 'ZH', 'AE0', 'AO2', 'UW2', 'AO0', 'AY0', 'IY2', 'AW2', 'UH2', 'EY0', 'ER2', 'AW0', 'UH0', 'OY2', 'OY0', "'", '<sos/eos>'], odim=None, model_conf={}, use_preprocessor=True, token_type='phn', bpemodel=None, non_linguistic_symbols=None, cleaner='tacotron', g2p='g2p_en', feats_extract='linear_spectrogram', feats_extract_conf={'n_fft': 1024, 'hop_length': 256, 'win_length': None}, normalize=None, normalize_conf={}, tts='vits', tts_conf={'generator_type': 'vits_generator', 'generator_params': {'hidden_channels': 192, 'spks': 128, 'global_channels': 256, 'segment_size': 32, 'text_encoder_attention_heads': 2, 'text_encoder_ffn_expand': 4, 'text_encoder_blocks': 6, 'text_encoder_positionwise_layer_type': 'conv1d', 'text_encoder_positionwise_conv_kernel_size': 3, 'text_encoder_positional_encoding_layer_type': 'rel_pos', 'text_encoder_self_attention_layer_type': 'rel_selfattn', 'text_encoder_activation_type': 'swish', 'text_encoder_normalize_before': True, 'text_encoder_dropout_rate': 0.1, 'text_encoder_positional_dropout_rate': 0.0, 'text_encoder_attention_dropout_rate': 0.1, 'use_macaron_style_in_text_encoder': True, 'use_conformer_conv_in_text_encoder': False, 'text_encoder_conformer_kernel_size': -1, 'decoder_kernel_size': 7, 'decoder_channels': 512, 'decoder_upsample_scales': [8, 8, 2, 2], 'decoder_upsample_kernel_sizes': [16, 16, 4, 4], 'decoder_resblock_kernel_sizes': [3, 7, 11], 'decoder_resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'use_weight_norm_in_decoder': True, 'posterior_encoder_kernel_size': 5, 'posterior_encoder_layers': 16, 'posterior_encoder_stacks': 1, 'posterior_encoder_base_dilation': 1, 'posterior_encoder_dropout_rate': 0.0, 'use_weight_norm_in_posterior_encoder': True, 'flow_flows': 4, 'flow_kernel_size': 5, 'flow_base_dilation': 1, 'flow_layers': 4, 'flow_dropout_rate': 0.0, 'use_weight_norm_in_flow': True, 'use_only_mean_in_flow': True, 'stochastic_duration_predictor_kernel_size': 3, 'stochastic_duration_predictor_dropout_rate': 0.5, 'stochastic_duration_predictor_flows': 4, 'stochastic_duration_predictor_dds_conv_layers': 3, 'vocabs': 74, 'aux_channels': 513}, 'discriminator_type': 'hifigan_multi_scale_multi_period_discriminator', 'discriminator_params': {'scales': 1, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'stride': 2, 'padding': 2}, 'scale_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'channels': 128, 'max_downsample_channels': 1024, 'max_groups': 16, 'bias': True, 'downsample_scales': [2, 2, 4, 4, 1], 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}, 'follow_official_norm': False, 'periods': [2, 3, 5, 7, 11], 'period_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [5, 3], 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'max_downsample_channels': 1024, 'bias': True, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}}, 'generator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'discriminator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'feat_match_loss_params': {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, 'mel_loss_params': {'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None, 'window': 'hann', 'n_mels': 80, 'fmin': 0, 'fmax': None, 'log_base': None}, 'lambda_adv': 1.0, 'lambda_mel': 45.0, 'lambda_feat_match': 2.0, 'lambda_dur': 1.0, 'lambda_kl': 1.0, 'sampling_rate': 22050, 'cache_generator_outputs': True, 'plot_pred_mos': False, 'mos_pred_tool': 'utmos'}, pitch_extract=None, pitch_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'f0max': 400, 'f0min': 80}, pitch_normalize=None, pitch_normalize_conf={}, energy_extract=None, energy_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None}, energy_normalize=None, energy_normalize_conf={}, required=['output_dir', 'token_list'], version='202503', distributed=False)
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1284, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 85859) is killed by signal: Killed. 

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 22, in <module>
    main()
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 18, in main
    GANTTSTask.main(cmd=cmd)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1225, in main
    cls.main_worker(args)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1441, in main_worker
    collect_stats(
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/main_funcs/collect_stats.py", line 51, in collect_stats
    for iiter, (keys, batch) in enumerate(itr, 1):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 733, in __next__
    data = self._next_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1491, in _next_data
    idx, data = self._get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1453, in _get_data
    success, data = self._try_get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1297, in _try_get_data
    raise RuntimeError(
RuntimeError: DataLoader worker (pid(s) 85859) exited unexpectedly
# Accounting: begin_time=1750836645
# Accounting: end_time=1750836799
# Accounting: time=154 threads=1
# Finished at Wed Jun 25 03:33:19 EDT 2025 with status 1
# Running on r005.ib.bridges2.psc.edu
# Started at Wed Jun 25 03:30:46 EDT 2025
# SLURMD_NODENAME=r005
# SLURM_ARRAY_JOB_ID=32966037
# SLURM_ARRAY_TASK_COUNT=32
# SLURM_ARRAY_TASK_ID=23
# SLURM_ARRAY_TASK_MAX=32
# SLURM_ARRAY_TASK_MIN=1
# SLURM_ARRAY_TASK_STEP=1
# SLURM_CLUSTER_NAME=bridges2
# SLURM_CONF=/var/spool/slurm/d/conf-cache/slurm.conf
# SLURM_CPUS_ON_NODE=1
# SLURM_EXPORT_ENV=ALL
# SLURM_GET_USER_ENV=1
# SLURM_GTIDS=0
# SLURM_JOBID=32966060
# SLURM_JOB_ACCOUNT=cis210027p
# SLURM_JOB_CPUS_PER_NODE=1
# SLURM_JOB_GID=24886
# SLURM_JOB_ID=32966060
# SLURM_JOB_NAME=stats.sh
# SLURM_JOB_NODELIST=r005
# SLURM_JOB_NUM_NODES=1
# SLURM_JOB_PARTITION=RM-shared
# SLURM_JOB_QOS=rm
# SLURM_JOB_UID=97947
# SLURM_JOB_USER=ttao3
# SLURM_LOCALID=0
# SLURM_MEM_PER_CPU=1900
# SLURM_NNODES=1
# SLURM_NODEID=0
# SLURM_NODELIST=r005
# SLURM_NODE_ALIASES='(null)'
# SLURM_OPEN_MODE=a
# SLURM_PRIO_PROCESS=0
# SLURM_PROCID=0
# SLURM_SCRIPT_CONTEXT=prolog_task
# SLURM_SUBMIT_DIR=/ocean/projects/cis210027p/ttao3/espnet/egs2/hifitts/tts1
# SLURM_SUBMIT_HOST=br013.ib.bridges2.psc.edu
# SLURM_TASKS_PER_NODE=1
# SLURM_TASK_PID=85586
# SLURM_TOPOLOGY_ADDR=r005
# SLURM_TOPOLOGY_ADDR_PATTERN=node
# SLURM_WORKING_CLUSTER=bridges2:br003:6810:9728:109
# python3 -m espnet2.bin.gan_tts_train --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.23.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.23.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.23 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int 
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/librosa/util/files.py:10: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_filename
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/bin/python3 /ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.23.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.23.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.23 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int
Failed to import Flash Attention, using ESPnet default: No module named 'flash_attn_2_cuda'
Vocabulary size: 74
encoder self-attention layer type = relative self-attention
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/ocean/projects/cis210027p/ttao3/espnet/espnet2/gan_tts/vits/monotonic_align/__init__.py:19: UserWarning: Cython version is not available. Fallback to 'EXPERIMETAL' numba version. If you want to use the cython version, please build it as follows: `cd espnet2/gan_tts/vits/monotonic_align; python setup.py build_ext --inplace`
  warnings.warn(
pytorch.version=2.7.1+cu126, cuda.available=False, cudnn.version=90501, cudnn.benchmark=False, cudnn.deterministic=False
Model structure:
ESPnetGANTTSModel(
  (feats_extract): LinearSpectrogram(
    (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
  )
  (tts): VITS(
    (generator): VITSGenerator(
      (text_encoder): TextEncoder(
        (emb): Embedding(74, 192)
        (encoder): Encoder(
          (embed): Sequential(
            (0): RelPositionalEncoding(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (encoders): MultiSequential(
            (0): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (2): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (3): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (4): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (5): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (after_norm): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (decoder): HiFiGANGenerator(
        (input_conv): Conv1d(192, 512, kernel_size=(7,), stride=(1,), padding=(3,))
        (upsamples): ModuleList(
          (0): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (1): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(256, 128, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (2): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,))
          )
          (3): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,))
          )
        )
        (blocks): ModuleList(
          (0): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (1): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (2): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (3): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (4): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (5): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (6): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (7): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (8): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (9): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (10): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (11): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
        )
        (output_conv): Sequential(
          (0): LeakyReLU(negative_slope=0.01)
          (1): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,))
          (2): Tanh()
        )
        (global_conv): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
      )
      (posterior_encoder): PosteriorEncoder(
        (input_conv): Conv1d(513, 192, kernel_size=(1,), stride=(1,))
        (encoder): WaveNet(
          (conv_layers): ModuleList(
            (0-15): 16 x ResidualBlock(
              (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
              (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
              (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
            )
          )
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (flow): ResidualAffineCouplingBlock(
        (flows): ModuleList(
          (0): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (1): FlipFlow()
          (2): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (3): FlipFlow()
          (4): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (5): FlipFlow()
          (6): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (7): FlipFlow()
        )
      )
      (duration_predictor): StochasticDurationPredictor(
        (pre): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (log_flow): LogFlow()
        (flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (post_pre): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
        (post_dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (post_proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (post_flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (global_conv): Conv1d(256, 192, kernel_size=(1,), stride=(1,))
      )
      (global_emb): Embedding(128, 256)
    )
    (discriminator): HiFiGANMultiScaleMultiPeriodDiscriminator(
      (msd): HiFiGANMultiScaleDiscriminator(
        (discriminators): ModuleList(
          (0): HiFiGANScaleDiscriminator(
            (layers): ModuleList(
              (0): Sequential(
                (0): Conv1d(1, 128, kernel_size=(15,), stride=(1,), padding=(7,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv1d(128, 128, kernel_size=(41,), stride=(2,), padding=(20,), groups=4)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv1d(128, 256, kernel_size=(41,), stride=(2,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv1d(256, 512, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv1d(512, 1024, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (5): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(41,), stride=(1,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (6): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (7): Conv1d(1024, 1, kernel_size=(3,), stride=(1,), padding=(1,))
            )
          )
        )
      )
      (mpd): HiFiGANMultiPeriodDiscriminator(
        (discriminators): ModuleList(
          (0-4): 5 x HiFiGANPeriodDiscriminator(
            (convs): ModuleList(
              (0): Sequential(
                (0): Conv2d(1, 32, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv2d(32, 128, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv2d(128, 512, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv2d(512, 1024, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv2d(1024, 1024, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
            )
            (output_conv): Conv2d(1024, 1, kernel_size=(2, 1), stride=(1, 1), padding=(1, 0))
          )
        )
      )
    )
    (generator_adv_loss): GeneratorAdversarialLoss()
    (discriminator_adv_loss): DiscriminatorAdversarialLoss()
    (feat_match_loss): FeatureMatchLoss()
    (mel_loss): MelSpectrogramLoss(
      (wav_to_mel): LogMelFbank(
        (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
        (logmel): LogMel(sr=22050, n_fft=1024, n_mels=80, fmin=0, fmax=11025.0, htk=False)
      )
    )
    (kl_loss): KLDivergenceLoss()
  )
)

Model summary:
    Class Name: ESPnetGANTTSModel
    Total Number of model parameters: 96.37 M
    Number of trainable parameters: 96.37 M (100.0%)
    Size: 385.46 MB
    Type: torch.float32
Optimizer:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler: <torch.optim.lr_scheduler.ExponentialLR object at 0x1472c4537250>
Optimizer2:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler2: <torch.optim.lr_scheduler.ExponentialLR object at 0x1472c4537670>
Saving the configuration in exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.23/config.yaml
Namespace(config='conf/tuning/train_multi_spk_vits.yaml', print_config=False, log_level='INFO', drop_last_iter=False, dry_run=False, iterator_type='sequence', valid_iterator_type=None, output_dir='exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.23', ngpu=0, seed=777, num_workers=4, num_att_plot=3, dist_backend='nccl', dist_init_method='env://', dist_world_size=None, dist_rank=None, local_rank=None, dist_master_addr=None, dist_master_port=None, dist_launcher=None, multiprocessing_distributed=False, unused_parameters=True, sharded_ddp=False, use_deepspeed=False, deepspeed_config=None, gradient_as_bucket_view=True, ddp_comm_hook=None, cudnn_enabled=True, cudnn_benchmark=False, cudnn_deterministic=False, use_tf32=False, collect_stats=True, write_collected_feats=False, max_epoch=1000, patience=None, val_scheduler_criterion=('valid', 'loss'), early_stopping_criterion=('valid', 'loss', 'min'), best_model_criterion=[['train', 'total_count', 'max']], keep_nbest_models=10, nbest_averaging_interval=0, grad_clip=-1, grad_clip_type=2.0, grad_noise=False, accum_grad=1, no_forward_run=False, resume=False, train_dtype='float32', use_amp=False, log_interval=50, use_matplotlib=True, use_tensorboard=True, create_graph_in_tensorboard=False, use_wandb=False, wandb_project=None, wandb_id=None, wandb_entity=None, wandb_name=None, wandb_model_log_interval=-1, detect_anomaly=False, use_adapter=False, adapter='lora', save_strategy='all', adapter_conf={}, pretrain_path=None, init_param=[], ignore_init_mismatch=False, freeze_param=[], num_iters_per_epoch=1000, batch_size=20, valid_batch_size=None, batch_bins=3000000, valid_batch_bins=None, category_sample_size=10, train_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.23.scp'], valid_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.23.scp'], batch_type='numel', valid_batch_type=None, fold_length=[], sort_in_batch='descending', shuffle_within_batch=False, sort_batch='descending', multiple_iterator=False, chunk_length=500, chunk_shift_ratio=0.5, num_cache_chunks=1024, chunk_excluded_key_prefixes=[], chunk_default_fs=None, chunk_max_abs_length=None, chunk_discard_short_samples=True, train_data_path_and_name_and_type=[('dump/22k/raw/tr_no_dev/text', 'text', 'text'), ('dump/22k/raw/tr_no_dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/tr_no_dev/utt2sid', 'sids', 'text_int')], valid_data_path_and_name_and_type=[('dump/22k/raw/dev/text', 'text', 'text'), ('dump/22k/raw/dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/dev/utt2sid', 'sids', 'text_int')], multi_task_dataset=False, allow_variable_data_keys=False, max_cache_size=0.0, max_cache_fd=32, allow_multi_rates=False, valid_max_cache_size=None, exclude_weight_decay=False, exclude_weight_decay_conf={}, optim='adamw', optim_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler='exponentiallr', scheduler_conf={'gamma': 0.999875}, optim2='adamw', optim2_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler2='exponentiallr', scheduler2_conf={'gamma': 0.999875}, generator_first=False, skip_discriminator_prob=0.0, token_list=['<blank>', '<unk>', ' ', 'AH0', 'N', 'T', 'D', 'S', 'R', 'L', 'IH1', 'DH', 'M', 'EH1', 'Z', 'AE1', 'K', 'IH0', 'AH1', 'HH', 'W', 'ER0', 'V', 'IY1', 'F', 'UW1', 'P', 'AY1', 'B', 'AA1', 'AO1', 'EY1', 'IY0', 'OW1', 'NG', 'SH', 'G', 'Y', 'AW1', 'CH', 'ER1', 'UH1', 'TH', 'JH', 'OW0', 'EH2', 'IH2', 'OY1', 'EY2', 'AY2', 'EH0', 'UW0', 'AA2', 'AE2', 'OW2', 'AH2', 'AA0', 'ZH', 'AE0', 'AO2', 'UW2', 'AO0', 'AY0', 'IY2', 'AW2', 'UH2', 'EY0', 'ER2', 'AW0', 'UH0', 'OY2', 'OY0', "'", '<sos/eos>'], odim=None, model_conf={}, use_preprocessor=True, token_type='phn', bpemodel=None, non_linguistic_symbols=None, cleaner='tacotron', g2p='g2p_en', feats_extract='linear_spectrogram', feats_extract_conf={'n_fft': 1024, 'hop_length': 256, 'win_length': None}, normalize=None, normalize_conf={}, tts='vits', tts_conf={'generator_type': 'vits_generator', 'generator_params': {'hidden_channels': 192, 'spks': 128, 'global_channels': 256, 'segment_size': 32, 'text_encoder_attention_heads': 2, 'text_encoder_ffn_expand': 4, 'text_encoder_blocks': 6, 'text_encoder_positionwise_layer_type': 'conv1d', 'text_encoder_positionwise_conv_kernel_size': 3, 'text_encoder_positional_encoding_layer_type': 'rel_pos', 'text_encoder_self_attention_layer_type': 'rel_selfattn', 'text_encoder_activation_type': 'swish', 'text_encoder_normalize_before': True, 'text_encoder_dropout_rate': 0.1, 'text_encoder_positional_dropout_rate': 0.0, 'text_encoder_attention_dropout_rate': 0.1, 'use_macaron_style_in_text_encoder': True, 'use_conformer_conv_in_text_encoder': False, 'text_encoder_conformer_kernel_size': -1, 'decoder_kernel_size': 7, 'decoder_channels': 512, 'decoder_upsample_scales': [8, 8, 2, 2], 'decoder_upsample_kernel_sizes': [16, 16, 4, 4], 'decoder_resblock_kernel_sizes': [3, 7, 11], 'decoder_resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'use_weight_norm_in_decoder': True, 'posterior_encoder_kernel_size': 5, 'posterior_encoder_layers': 16, 'posterior_encoder_stacks': 1, 'posterior_encoder_base_dilation': 1, 'posterior_encoder_dropout_rate': 0.0, 'use_weight_norm_in_posterior_encoder': True, 'flow_flows': 4, 'flow_kernel_size': 5, 'flow_base_dilation': 1, 'flow_layers': 4, 'flow_dropout_rate': 0.0, 'use_weight_norm_in_flow': True, 'use_only_mean_in_flow': True, 'stochastic_duration_predictor_kernel_size': 3, 'stochastic_duration_predictor_dropout_rate': 0.5, 'stochastic_duration_predictor_flows': 4, 'stochastic_duration_predictor_dds_conv_layers': 3, 'vocabs': 74, 'aux_channels': 513}, 'discriminator_type': 'hifigan_multi_scale_multi_period_discriminator', 'discriminator_params': {'scales': 1, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'stride': 2, 'padding': 2}, 'scale_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'channels': 128, 'max_downsample_channels': 1024, 'max_groups': 16, 'bias': True, 'downsample_scales': [2, 2, 4, 4, 1], 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}, 'follow_official_norm': False, 'periods': [2, 3, 5, 7, 11], 'period_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [5, 3], 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'max_downsample_channels': 1024, 'bias': True, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}}, 'generator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'discriminator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'feat_match_loss_params': {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, 'mel_loss_params': {'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None, 'window': 'hann', 'n_mels': 80, 'fmin': 0, 'fmax': None, 'log_base': None}, 'lambda_adv': 1.0, 'lambda_mel': 45.0, 'lambda_feat_match': 2.0, 'lambda_dur': 1.0, 'lambda_kl': 1.0, 'sampling_rate': 22050, 'cache_generator_outputs': True, 'plot_pred_mos': False, 'mos_pred_tool': 'utmos'}, pitch_extract=None, pitch_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'f0max': 400, 'f0min': 80}, pitch_normalize=None, pitch_normalize_conf={}, energy_extract=None, energy_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None}, energy_normalize=None, energy_normalize_conf={}, required=['output_dir', 'token_list'], version='202503', distributed=False)
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1284, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 85860) is killed by signal: Killed. 

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 22, in <module>
    main()
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 18, in main
    GANTTSTask.main(cmd=cmd)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1225, in main
    cls.main_worker(args)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1441, in main_worker
    collect_stats(
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/main_funcs/collect_stats.py", line 51, in collect_stats
    for iiter, (keys, batch) in enumerate(itr, 1):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 733, in __next__
    data = self._next_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1491, in _next_data
    idx, data = self._get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1453, in _get_data
    success, data = self._try_get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1297, in _try_get_data
    raise RuntimeError(
RuntimeError: DataLoader worker (pid(s) 85860) exited unexpectedly
# Accounting: begin_time=1750836646
# Accounting: end_time=1750836799
# Accounting: time=153 threads=1
# Finished at Wed Jun 25 03:33:19 EDT 2025 with status 1
# Running on r005.ib.bridges2.psc.edu
# Started at Wed Jun 25 03:30:45 EDT 2025
# SLURMD_NODENAME=r005
# SLURM_ARRAY_JOB_ID=32966037
# SLURM_ARRAY_TASK_COUNT=32
# SLURM_ARRAY_TASK_ID=24
# SLURM_ARRAY_TASK_MAX=32
# SLURM_ARRAY_TASK_MIN=1
# SLURM_ARRAY_TASK_STEP=1
# SLURM_CLUSTER_NAME=bridges2
# SLURM_CONF=/var/spool/slurm/d/conf-cache/slurm.conf
# SLURM_CPUS_ON_NODE=1
# SLURM_EXPORT_ENV=ALL
# SLURM_GET_USER_ENV=1
# SLURM_GTIDS=0
# SLURM_JOBID=32966061
# SLURM_JOB_ACCOUNT=cis210027p
# SLURM_JOB_CPUS_PER_NODE=1
# SLURM_JOB_GID=24886
# SLURM_JOB_ID=32966061
# SLURM_JOB_NAME=stats.sh
# SLURM_JOB_NODELIST=r005
# SLURM_JOB_NUM_NODES=1
# SLURM_JOB_PARTITION=RM-shared
# SLURM_JOB_QOS=rm
# SLURM_JOB_UID=97947
# SLURM_JOB_USER=ttao3
# SLURM_LOCALID=0
# SLURM_MEM_PER_CPU=1900
# SLURM_NNODES=1
# SLURM_NODEID=0
# SLURM_NODELIST=r005
# SLURM_NODE_ALIASES='(null)'
# SLURM_OPEN_MODE=a
# SLURM_PRIO_PROCESS=0
# SLURM_PROCID=0
# SLURM_SCRIPT_CONTEXT=prolog_task
# SLURM_SUBMIT_DIR=/ocean/projects/cis210027p/ttao3/espnet/egs2/hifitts/tts1
# SLURM_SUBMIT_HOST=br013.ib.bridges2.psc.edu
# SLURM_TASKS_PER_NODE=1
# SLURM_TASK_PID=85520
# SLURM_TOPOLOGY_ADDR=r005
# SLURM_TOPOLOGY_ADDR_PATTERN=node
# SLURM_WORKING_CLUSTER=bridges2:br003:6810:9728:109
# python3 -m espnet2.bin.gan_tts_train --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.24.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.24.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.24 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int 
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/librosa/util/files.py:10: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_filename
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/bin/python3 /ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.24.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.24.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.24 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int
Failed to import Flash Attention, using ESPnet default: No module named 'flash_attn_2_cuda'
Vocabulary size: 74
encoder self-attention layer type = relative self-attention
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/ocean/projects/cis210027p/ttao3/espnet/espnet2/gan_tts/vits/monotonic_align/__init__.py:19: UserWarning: Cython version is not available. Fallback to 'EXPERIMETAL' numba version. If you want to use the cython version, please build it as follows: `cd espnet2/gan_tts/vits/monotonic_align; python setup.py build_ext --inplace`
  warnings.warn(
pytorch.version=2.7.1+cu126, cuda.available=False, cudnn.version=90501, cudnn.benchmark=False, cudnn.deterministic=False
Model structure:
ESPnetGANTTSModel(
  (feats_extract): LinearSpectrogram(
    (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
  )
  (tts): VITS(
    (generator): VITSGenerator(
      (text_encoder): TextEncoder(
        (emb): Embedding(74, 192)
        (encoder): Encoder(
          (embed): Sequential(
            (0): RelPositionalEncoding(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (encoders): MultiSequential(
            (0): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (2): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (3): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (4): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (5): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (after_norm): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (decoder): HiFiGANGenerator(
        (input_conv): Conv1d(192, 512, kernel_size=(7,), stride=(1,), padding=(3,))
        (upsamples): ModuleList(
          (0): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (1): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(256, 128, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (2): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,))
          )
          (3): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,))
          )
        )
        (blocks): ModuleList(
          (0): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (1): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (2): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (3): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (4): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (5): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (6): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (7): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (8): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (9): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (10): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (11): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
        )
        (output_conv): Sequential(
          (0): LeakyReLU(negative_slope=0.01)
          (1): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,))
          (2): Tanh()
        )
        (global_conv): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
      )
      (posterior_encoder): PosteriorEncoder(
        (input_conv): Conv1d(513, 192, kernel_size=(1,), stride=(1,))
        (encoder): WaveNet(
          (conv_layers): ModuleList(
            (0-15): 16 x ResidualBlock(
              (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
              (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
              (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
            )
          )
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (flow): ResidualAffineCouplingBlock(
        (flows): ModuleList(
          (0): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (1): FlipFlow()
          (2): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (3): FlipFlow()
          (4): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (5): FlipFlow()
          (6): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (7): FlipFlow()
        )
      )
      (duration_predictor): StochasticDurationPredictor(
        (pre): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (log_flow): LogFlow()
        (flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (post_pre): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
        (post_dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (post_proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (post_flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (global_conv): Conv1d(256, 192, kernel_size=(1,), stride=(1,))
      )
      (global_emb): Embedding(128, 256)
    )
    (discriminator): HiFiGANMultiScaleMultiPeriodDiscriminator(
      (msd): HiFiGANMultiScaleDiscriminator(
        (discriminators): ModuleList(
          (0): HiFiGANScaleDiscriminator(
            (layers): ModuleList(
              (0): Sequential(
                (0): Conv1d(1, 128, kernel_size=(15,), stride=(1,), padding=(7,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv1d(128, 128, kernel_size=(41,), stride=(2,), padding=(20,), groups=4)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv1d(128, 256, kernel_size=(41,), stride=(2,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv1d(256, 512, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv1d(512, 1024, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (5): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(41,), stride=(1,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (6): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (7): Conv1d(1024, 1, kernel_size=(3,), stride=(1,), padding=(1,))
            )
          )
        )
      )
      (mpd): HiFiGANMultiPeriodDiscriminator(
        (discriminators): ModuleList(
          (0-4): 5 x HiFiGANPeriodDiscriminator(
            (convs): ModuleList(
              (0): Sequential(
                (0): Conv2d(1, 32, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv2d(32, 128, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv2d(128, 512, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv2d(512, 1024, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv2d(1024, 1024, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
            )
            (output_conv): Conv2d(1024, 1, kernel_size=(2, 1), stride=(1, 1), padding=(1, 0))
          )
        )
      )
    )
    (generator_adv_loss): GeneratorAdversarialLoss()
    (discriminator_adv_loss): DiscriminatorAdversarialLoss()
    (feat_match_loss): FeatureMatchLoss()
    (mel_loss): MelSpectrogramLoss(
      (wav_to_mel): LogMelFbank(
        (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
        (logmel): LogMel(sr=22050, n_fft=1024, n_mels=80, fmin=0, fmax=11025.0, htk=False)
      )
    )
    (kl_loss): KLDivergenceLoss()
  )
)

Model summary:
    Class Name: ESPnetGANTTSModel
    Total Number of model parameters: 96.37 M
    Number of trainable parameters: 96.37 M (100.0%)
    Size: 385.46 MB
    Type: torch.float32
Optimizer:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler: <torch.optim.lr_scheduler.ExponentialLR object at 0x14dd04304220>
Optimizer2:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler2: <torch.optim.lr_scheduler.ExponentialLR object at 0x14dd04304640>
Saving the configuration in exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.24/config.yaml
Namespace(config='conf/tuning/train_multi_spk_vits.yaml', print_config=False, log_level='INFO', drop_last_iter=False, dry_run=False, iterator_type='sequence', valid_iterator_type=None, output_dir='exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.24', ngpu=0, seed=777, num_workers=4, num_att_plot=3, dist_backend='nccl', dist_init_method='env://', dist_world_size=None, dist_rank=None, local_rank=None, dist_master_addr=None, dist_master_port=None, dist_launcher=None, multiprocessing_distributed=False, unused_parameters=True, sharded_ddp=False, use_deepspeed=False, deepspeed_config=None, gradient_as_bucket_view=True, ddp_comm_hook=None, cudnn_enabled=True, cudnn_benchmark=False, cudnn_deterministic=False, use_tf32=False, collect_stats=True, write_collected_feats=False, max_epoch=1000, patience=None, val_scheduler_criterion=('valid', 'loss'), early_stopping_criterion=('valid', 'loss', 'min'), best_model_criterion=[['train', 'total_count', 'max']], keep_nbest_models=10, nbest_averaging_interval=0, grad_clip=-1, grad_clip_type=2.0, grad_noise=False, accum_grad=1, no_forward_run=False, resume=False, train_dtype='float32', use_amp=False, log_interval=50, use_matplotlib=True, use_tensorboard=True, create_graph_in_tensorboard=False, use_wandb=False, wandb_project=None, wandb_id=None, wandb_entity=None, wandb_name=None, wandb_model_log_interval=-1, detect_anomaly=False, use_adapter=False, adapter='lora', save_strategy='all', adapter_conf={}, pretrain_path=None, init_param=[], ignore_init_mismatch=False, freeze_param=[], num_iters_per_epoch=1000, batch_size=20, valid_batch_size=None, batch_bins=3000000, valid_batch_bins=None, category_sample_size=10, train_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.24.scp'], valid_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.24.scp'], batch_type='numel', valid_batch_type=None, fold_length=[], sort_in_batch='descending', shuffle_within_batch=False, sort_batch='descending', multiple_iterator=False, chunk_length=500, chunk_shift_ratio=0.5, num_cache_chunks=1024, chunk_excluded_key_prefixes=[], chunk_default_fs=None, chunk_max_abs_length=None, chunk_discard_short_samples=True, train_data_path_and_name_and_type=[('dump/22k/raw/tr_no_dev/text', 'text', 'text'), ('dump/22k/raw/tr_no_dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/tr_no_dev/utt2sid', 'sids', 'text_int')], valid_data_path_and_name_and_type=[('dump/22k/raw/dev/text', 'text', 'text'), ('dump/22k/raw/dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/dev/utt2sid', 'sids', 'text_int')], multi_task_dataset=False, allow_variable_data_keys=False, max_cache_size=0.0, max_cache_fd=32, allow_multi_rates=False, valid_max_cache_size=None, exclude_weight_decay=False, exclude_weight_decay_conf={}, optim='adamw', optim_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler='exponentiallr', scheduler_conf={'gamma': 0.999875}, optim2='adamw', optim2_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler2='exponentiallr', scheduler2_conf={'gamma': 0.999875}, generator_first=False, skip_discriminator_prob=0.0, token_list=['<blank>', '<unk>', ' ', 'AH0', 'N', 'T', 'D', 'S', 'R', 'L', 'IH1', 'DH', 'M', 'EH1', 'Z', 'AE1', 'K', 'IH0', 'AH1', 'HH', 'W', 'ER0', 'V', 'IY1', 'F', 'UW1', 'P', 'AY1', 'B', 'AA1', 'AO1', 'EY1', 'IY0', 'OW1', 'NG', 'SH', 'G', 'Y', 'AW1', 'CH', 'ER1', 'UH1', 'TH', 'JH', 'OW0', 'EH2', 'IH2', 'OY1', 'EY2', 'AY2', 'EH0', 'UW0', 'AA2', 'AE2', 'OW2', 'AH2', 'AA0', 'ZH', 'AE0', 'AO2', 'UW2', 'AO0', 'AY0', 'IY2', 'AW2', 'UH2', 'EY0', 'ER2', 'AW0', 'UH0', 'OY2', 'OY0', "'", '<sos/eos>'], odim=None, model_conf={}, use_preprocessor=True, token_type='phn', bpemodel=None, non_linguistic_symbols=None, cleaner='tacotron', g2p='g2p_en', feats_extract='linear_spectrogram', feats_extract_conf={'n_fft': 1024, 'hop_length': 256, 'win_length': None}, normalize=None, normalize_conf={}, tts='vits', tts_conf={'generator_type': 'vits_generator', 'generator_params': {'hidden_channels': 192, 'spks': 128, 'global_channels': 256, 'segment_size': 32, 'text_encoder_attention_heads': 2, 'text_encoder_ffn_expand': 4, 'text_encoder_blocks': 6, 'text_encoder_positionwise_layer_type': 'conv1d', 'text_encoder_positionwise_conv_kernel_size': 3, 'text_encoder_positional_encoding_layer_type': 'rel_pos', 'text_encoder_self_attention_layer_type': 'rel_selfattn', 'text_encoder_activation_type': 'swish', 'text_encoder_normalize_before': True, 'text_encoder_dropout_rate': 0.1, 'text_encoder_positional_dropout_rate': 0.0, 'text_encoder_attention_dropout_rate': 0.1, 'use_macaron_style_in_text_encoder': True, 'use_conformer_conv_in_text_encoder': False, 'text_encoder_conformer_kernel_size': -1, 'decoder_kernel_size': 7, 'decoder_channels': 512, 'decoder_upsample_scales': [8, 8, 2, 2], 'decoder_upsample_kernel_sizes': [16, 16, 4, 4], 'decoder_resblock_kernel_sizes': [3, 7, 11], 'decoder_resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'use_weight_norm_in_decoder': True, 'posterior_encoder_kernel_size': 5, 'posterior_encoder_layers': 16, 'posterior_encoder_stacks': 1, 'posterior_encoder_base_dilation': 1, 'posterior_encoder_dropout_rate': 0.0, 'use_weight_norm_in_posterior_encoder': True, 'flow_flows': 4, 'flow_kernel_size': 5, 'flow_base_dilation': 1, 'flow_layers': 4, 'flow_dropout_rate': 0.0, 'use_weight_norm_in_flow': True, 'use_only_mean_in_flow': True, 'stochastic_duration_predictor_kernel_size': 3, 'stochastic_duration_predictor_dropout_rate': 0.5, 'stochastic_duration_predictor_flows': 4, 'stochastic_duration_predictor_dds_conv_layers': 3, 'vocabs': 74, 'aux_channels': 513}, 'discriminator_type': 'hifigan_multi_scale_multi_period_discriminator', 'discriminator_params': {'scales': 1, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'stride': 2, 'padding': 2}, 'scale_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'channels': 128, 'max_downsample_channels': 1024, 'max_groups': 16, 'bias': True, 'downsample_scales': [2, 2, 4, 4, 1], 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}, 'follow_official_norm': False, 'periods': [2, 3, 5, 7, 11], 'period_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [5, 3], 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'max_downsample_channels': 1024, 'bias': True, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}}, 'generator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'discriminator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'feat_match_loss_params': {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, 'mel_loss_params': {'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None, 'window': 'hann', 'n_mels': 80, 'fmin': 0, 'fmax': None, 'log_base': None}, 'lambda_adv': 1.0, 'lambda_mel': 45.0, 'lambda_feat_match': 2.0, 'lambda_dur': 1.0, 'lambda_kl': 1.0, 'sampling_rate': 22050, 'cache_generator_outputs': True, 'plot_pred_mos': False, 'mos_pred_tool': 'utmos'}, pitch_extract=None, pitch_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'f0max': 400, 'f0min': 80}, pitch_normalize=None, pitch_normalize_conf={}, energy_extract=None, energy_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None}, energy_normalize=None, energy_normalize_conf={}, required=['output_dir', 'token_list'], version='202503', distributed=False)
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1284, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 85838) is killed by signal: Killed. 

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 22, in <module>
    main()
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 18, in main
    GANTTSTask.main(cmd=cmd)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1225, in main
    cls.main_worker(args)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1441, in main_worker
    collect_stats(
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/main_funcs/collect_stats.py", line 51, in collect_stats
    for iiter, (keys, batch) in enumerate(itr, 1):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 733, in __next__
    data = self._next_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1491, in _next_data
    idx, data = self._get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1453, in _get_data
    success, data = self._try_get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1297, in _try_get_data
    raise RuntimeError(
RuntimeError: DataLoader worker (pid(s) 85838) exited unexpectedly
# Accounting: begin_time=1750836645
# Accounting: end_time=1750836799
# Accounting: time=154 threads=1
# Finished at Wed Jun 25 03:33:19 EDT 2025 with status 1
# Running on r212.ib.bridges2.psc.edu
# Started at Wed Jun 25 03:31:00 EDT 2025
# SLURMD_NODENAME=r212
# SLURM_ARRAY_JOB_ID=32966037
# SLURM_ARRAY_TASK_COUNT=32
# SLURM_ARRAY_TASK_ID=25
# SLURM_ARRAY_TASK_MAX=32
# SLURM_ARRAY_TASK_MIN=1
# SLURM_ARRAY_TASK_STEP=1
# SLURM_CLUSTER_NAME=bridges2
# SLURM_CONF=/var/spool/slurm/d/conf-cache/slurm.conf
# SLURM_CPUS_ON_NODE=1
# SLURM_EXPORT_ENV=ALL
# SLURM_GET_USER_ENV=1
# SLURM_GTIDS=0
# SLURM_JOBID=32966062
# SLURM_JOB_ACCOUNT=cis210027p
# SLURM_JOB_CPUS_PER_NODE=1
# SLURM_JOB_GID=24886
# SLURM_JOB_ID=32966062
# SLURM_JOB_NAME=stats.sh
# SLURM_JOB_NODELIST=r212
# SLURM_JOB_NUM_NODES=1
# SLURM_JOB_PARTITION=RM-shared
# SLURM_JOB_QOS=rm
# SLURM_JOB_UID=97947
# SLURM_JOB_USER=ttao3
# SLURM_LOCALID=0
# SLURM_MEM_PER_CPU=1900
# SLURM_NNODES=1
# SLURM_NODEID=0
# SLURM_NODELIST=r212
# SLURM_NODE_ALIASES='(null)'
# SLURM_OPEN_MODE=a
# SLURM_PRIO_PROCESS=0
# SLURM_PROCID=0
# SLURM_SCRIPT_CONTEXT=prolog_task
# SLURM_SUBMIT_DIR=/ocean/projects/cis210027p/ttao3/espnet/egs2/hifitts/tts1
# SLURM_SUBMIT_HOST=br013.ib.bridges2.psc.edu
# SLURM_TASKS_PER_NODE=1
# SLURM_TASK_PID=59376
# SLURM_TOPOLOGY_ADDR=r212
# SLURM_TOPOLOGY_ADDR_PATTERN=node
# SLURM_WORKING_CLUSTER=bridges2:br003:6810:9728:109
# python3 -m espnet2.bin.gan_tts_train --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.25.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.25.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.25 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int 
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/librosa/util/files.py:10: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_filename
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/bin/python3 /ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.25.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.25.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.25 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int
Failed to import Flash Attention, using ESPnet default: No module named 'flash_attn_2_cuda'
Vocabulary size: 74
encoder self-attention layer type = relative self-attention
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/ocean/projects/cis210027p/ttao3/espnet/espnet2/gan_tts/vits/monotonic_align/__init__.py:19: UserWarning: Cython version is not available. Fallback to 'EXPERIMETAL' numba version. If you want to use the cython version, please build it as follows: `cd espnet2/gan_tts/vits/monotonic_align; python setup.py build_ext --inplace`
  warnings.warn(
pytorch.version=2.7.1+cu126, cuda.available=False, cudnn.version=90501, cudnn.benchmark=False, cudnn.deterministic=False
Model structure:
ESPnetGANTTSModel(
  (feats_extract): LinearSpectrogram(
    (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
  )
  (tts): VITS(
    (generator): VITSGenerator(
      (text_encoder): TextEncoder(
        (emb): Embedding(74, 192)
        (encoder): Encoder(
          (embed): Sequential(
            (0): RelPositionalEncoding(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (encoders): MultiSequential(
            (0): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (2): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (3): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (4): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (5): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (after_norm): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (decoder): HiFiGANGenerator(
        (input_conv): Conv1d(192, 512, kernel_size=(7,), stride=(1,), padding=(3,))
        (upsamples): ModuleList(
          (0): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (1): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(256, 128, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (2): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,))
          )
          (3): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,))
          )
        )
        (blocks): ModuleList(
          (0): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (1): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (2): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (3): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (4): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (5): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (6): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (7): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (8): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (9): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (10): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (11): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
        )
        (output_conv): Sequential(
          (0): LeakyReLU(negative_slope=0.01)
          (1): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,))
          (2): Tanh()
        )
        (global_conv): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
      )
      (posterior_encoder): PosteriorEncoder(
        (input_conv): Conv1d(513, 192, kernel_size=(1,), stride=(1,))
        (encoder): WaveNet(
          (conv_layers): ModuleList(
            (0-15): 16 x ResidualBlock(
              (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
              (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
              (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
            )
          )
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (flow): ResidualAffineCouplingBlock(
        (flows): ModuleList(
          (0): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (1): FlipFlow()
          (2): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (3): FlipFlow()
          (4): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (5): FlipFlow()
          (6): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (7): FlipFlow()
        )
      )
      (duration_predictor): StochasticDurationPredictor(
        (pre): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (log_flow): LogFlow()
        (flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (post_pre): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
        (post_dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (post_proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (post_flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (global_conv): Conv1d(256, 192, kernel_size=(1,), stride=(1,))
      )
      (global_emb): Embedding(128, 256)
    )
    (discriminator): HiFiGANMultiScaleMultiPeriodDiscriminator(
      (msd): HiFiGANMultiScaleDiscriminator(
        (discriminators): ModuleList(
          (0): HiFiGANScaleDiscriminator(
            (layers): ModuleList(
              (0): Sequential(
                (0): Conv1d(1, 128, kernel_size=(15,), stride=(1,), padding=(7,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv1d(128, 128, kernel_size=(41,), stride=(2,), padding=(20,), groups=4)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv1d(128, 256, kernel_size=(41,), stride=(2,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv1d(256, 512, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv1d(512, 1024, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (5): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(41,), stride=(1,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (6): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (7): Conv1d(1024, 1, kernel_size=(3,), stride=(1,), padding=(1,))
            )
          )
        )
      )
      (mpd): HiFiGANMultiPeriodDiscriminator(
        (discriminators): ModuleList(
          (0-4): 5 x HiFiGANPeriodDiscriminator(
            (convs): ModuleList(
              (0): Sequential(
                (0): Conv2d(1, 32, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv2d(32, 128, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv2d(128, 512, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv2d(512, 1024, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv2d(1024, 1024, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
            )
            (output_conv): Conv2d(1024, 1, kernel_size=(2, 1), stride=(1, 1), padding=(1, 0))
          )
        )
      )
    )
    (generator_adv_loss): GeneratorAdversarialLoss()
    (discriminator_adv_loss): DiscriminatorAdversarialLoss()
    (feat_match_loss): FeatureMatchLoss()
    (mel_loss): MelSpectrogramLoss(
      (wav_to_mel): LogMelFbank(
        (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
        (logmel): LogMel(sr=22050, n_fft=1024, n_mels=80, fmin=0, fmax=11025.0, htk=False)
      )
    )
    (kl_loss): KLDivergenceLoss()
  )
)

Model summary:
    Class Name: ESPnetGANTTSModel
    Total Number of model parameters: 96.37 M
    Number of trainable parameters: 96.37 M (100.0%)
    Size: 385.46 MB
    Type: torch.float32
Optimizer:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler: <torch.optim.lr_scheduler.ExponentialLR object at 0x14a3d8e611f0>
Optimizer2:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler2: <torch.optim.lr_scheduler.ExponentialLR object at 0x14a3d8e61610>
Saving the configuration in exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.25/config.yaml
Namespace(config='conf/tuning/train_multi_spk_vits.yaml', print_config=False, log_level='INFO', drop_last_iter=False, dry_run=False, iterator_type='sequence', valid_iterator_type=None, output_dir='exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.25', ngpu=0, seed=777, num_workers=4, num_att_plot=3, dist_backend='nccl', dist_init_method='env://', dist_world_size=None, dist_rank=None, local_rank=None, dist_master_addr=None, dist_master_port=None, dist_launcher=None, multiprocessing_distributed=False, unused_parameters=True, sharded_ddp=False, use_deepspeed=False, deepspeed_config=None, gradient_as_bucket_view=True, ddp_comm_hook=None, cudnn_enabled=True, cudnn_benchmark=False, cudnn_deterministic=False, use_tf32=False, collect_stats=True, write_collected_feats=False, max_epoch=1000, patience=None, val_scheduler_criterion=('valid', 'loss'), early_stopping_criterion=('valid', 'loss', 'min'), best_model_criterion=[['train', 'total_count', 'max']], keep_nbest_models=10, nbest_averaging_interval=0, grad_clip=-1, grad_clip_type=2.0, grad_noise=False, accum_grad=1, no_forward_run=False, resume=False, train_dtype='float32', use_amp=False, log_interval=50, use_matplotlib=True, use_tensorboard=True, create_graph_in_tensorboard=False, use_wandb=False, wandb_project=None, wandb_id=None, wandb_entity=None, wandb_name=None, wandb_model_log_interval=-1, detect_anomaly=False, use_adapter=False, adapter='lora', save_strategy='all', adapter_conf={}, pretrain_path=None, init_param=[], ignore_init_mismatch=False, freeze_param=[], num_iters_per_epoch=1000, batch_size=20, valid_batch_size=None, batch_bins=3000000, valid_batch_bins=None, category_sample_size=10, train_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.25.scp'], valid_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.25.scp'], batch_type='numel', valid_batch_type=None, fold_length=[], sort_in_batch='descending', shuffle_within_batch=False, sort_batch='descending', multiple_iterator=False, chunk_length=500, chunk_shift_ratio=0.5, num_cache_chunks=1024, chunk_excluded_key_prefixes=[], chunk_default_fs=None, chunk_max_abs_length=None, chunk_discard_short_samples=True, train_data_path_and_name_and_type=[('dump/22k/raw/tr_no_dev/text', 'text', 'text'), ('dump/22k/raw/tr_no_dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/tr_no_dev/utt2sid', 'sids', 'text_int')], valid_data_path_and_name_and_type=[('dump/22k/raw/dev/text', 'text', 'text'), ('dump/22k/raw/dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/dev/utt2sid', 'sids', 'text_int')], multi_task_dataset=False, allow_variable_data_keys=False, max_cache_size=0.0, max_cache_fd=32, allow_multi_rates=False, valid_max_cache_size=None, exclude_weight_decay=False, exclude_weight_decay_conf={}, optim='adamw', optim_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler='exponentiallr', scheduler_conf={'gamma': 0.999875}, optim2='adamw', optim2_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler2='exponentiallr', scheduler2_conf={'gamma': 0.999875}, generator_first=False, skip_discriminator_prob=0.0, token_list=['<blank>', '<unk>', ' ', 'AH0', 'N', 'T', 'D', 'S', 'R', 'L', 'IH1', 'DH', 'M', 'EH1', 'Z', 'AE1', 'K', 'IH0', 'AH1', 'HH', 'W', 'ER0', 'V', 'IY1', 'F', 'UW1', 'P', 'AY1', 'B', 'AA1', 'AO1', 'EY1', 'IY0', 'OW1', 'NG', 'SH', 'G', 'Y', 'AW1', 'CH', 'ER1', 'UH1', 'TH', 'JH', 'OW0', 'EH2', 'IH2', 'OY1', 'EY2', 'AY2', 'EH0', 'UW0', 'AA2', 'AE2', 'OW2', 'AH2', 'AA0', 'ZH', 'AE0', 'AO2', 'UW2', 'AO0', 'AY0', 'IY2', 'AW2', 'UH2', 'EY0', 'ER2', 'AW0', 'UH0', 'OY2', 'OY0', "'", '<sos/eos>'], odim=None, model_conf={}, use_preprocessor=True, token_type='phn', bpemodel=None, non_linguistic_symbols=None, cleaner='tacotron', g2p='g2p_en', feats_extract='linear_spectrogram', feats_extract_conf={'n_fft': 1024, 'hop_length': 256, 'win_length': None}, normalize=None, normalize_conf={}, tts='vits', tts_conf={'generator_type': 'vits_generator', 'generator_params': {'hidden_channels': 192, 'spks': 128, 'global_channels': 256, 'segment_size': 32, 'text_encoder_attention_heads': 2, 'text_encoder_ffn_expand': 4, 'text_encoder_blocks': 6, 'text_encoder_positionwise_layer_type': 'conv1d', 'text_encoder_positionwise_conv_kernel_size': 3, 'text_encoder_positional_encoding_layer_type': 'rel_pos', 'text_encoder_self_attention_layer_type': 'rel_selfattn', 'text_encoder_activation_type': 'swish', 'text_encoder_normalize_before': True, 'text_encoder_dropout_rate': 0.1, 'text_encoder_positional_dropout_rate': 0.0, 'text_encoder_attention_dropout_rate': 0.1, 'use_macaron_style_in_text_encoder': True, 'use_conformer_conv_in_text_encoder': False, 'text_encoder_conformer_kernel_size': -1, 'decoder_kernel_size': 7, 'decoder_channels': 512, 'decoder_upsample_scales': [8, 8, 2, 2], 'decoder_upsample_kernel_sizes': [16, 16, 4, 4], 'decoder_resblock_kernel_sizes': [3, 7, 11], 'decoder_resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'use_weight_norm_in_decoder': True, 'posterior_encoder_kernel_size': 5, 'posterior_encoder_layers': 16, 'posterior_encoder_stacks': 1, 'posterior_encoder_base_dilation': 1, 'posterior_encoder_dropout_rate': 0.0, 'use_weight_norm_in_posterior_encoder': True, 'flow_flows': 4, 'flow_kernel_size': 5, 'flow_base_dilation': 1, 'flow_layers': 4, 'flow_dropout_rate': 0.0, 'use_weight_norm_in_flow': True, 'use_only_mean_in_flow': True, 'stochastic_duration_predictor_kernel_size': 3, 'stochastic_duration_predictor_dropout_rate': 0.5, 'stochastic_duration_predictor_flows': 4, 'stochastic_duration_predictor_dds_conv_layers': 3, 'vocabs': 74, 'aux_channels': 513}, 'discriminator_type': 'hifigan_multi_scale_multi_period_discriminator', 'discriminator_params': {'scales': 1, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'stride': 2, 'padding': 2}, 'scale_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'channels': 128, 'max_downsample_channels': 1024, 'max_groups': 16, 'bias': True, 'downsample_scales': [2, 2, 4, 4, 1], 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}, 'follow_official_norm': False, 'periods': [2, 3, 5, 7, 11], 'period_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [5, 3], 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'max_downsample_channels': 1024, 'bias': True, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}}, 'generator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'discriminator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'feat_match_loss_params': {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, 'mel_loss_params': {'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None, 'window': 'hann', 'n_mels': 80, 'fmin': 0, 'fmax': None, 'log_base': None}, 'lambda_adv': 1.0, 'lambda_mel': 45.0, 'lambda_feat_match': 2.0, 'lambda_dur': 1.0, 'lambda_kl': 1.0, 'sampling_rate': 22050, 'cache_generator_outputs': True, 'plot_pred_mos': False, 'mos_pred_tool': 'utmos'}, pitch_extract=None, pitch_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'f0max': 400, 'f0min': 80}, pitch_normalize=None, pitch_normalize_conf={}, energy_extract=None, energy_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None}, energy_normalize=None, energy_normalize_conf={}, required=['output_dir', 'token_list'], version='202503', distributed=False)
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1284, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 59578) is killed by signal: Killed. 

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 22, in <module>
    main()
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 18, in main
    GANTTSTask.main(cmd=cmd)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1225, in main
    cls.main_worker(args)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1441, in main_worker
    collect_stats(
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/main_funcs/collect_stats.py", line 51, in collect_stats
    for iiter, (keys, batch) in enumerate(itr, 1):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 733, in __next__
    data = self._next_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1491, in _next_data
    idx, data = self._get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1453, in _get_data
    success, data = self._try_get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1297, in _try_get_data
    raise RuntimeError(
RuntimeError: DataLoader worker (pid(s) 59578) exited unexpectedly
# Accounting: begin_time=1750836660
# Accounting: end_time=1750836799
# Accounting: time=139 threads=1
# Finished at Wed Jun 25 03:33:19 EDT 2025 with status 1
# Running on r212.ib.bridges2.psc.edu
# Started at Wed Jun 25 03:30:59 EDT 2025
# SLURMD_NODENAME=r212
# SLURM_ARRAY_JOB_ID=32966037
# SLURM_ARRAY_TASK_COUNT=32
# SLURM_ARRAY_TASK_ID=27
# SLURM_ARRAY_TASK_MAX=32
# SLURM_ARRAY_TASK_MIN=1
# SLURM_ARRAY_TASK_STEP=1
# SLURM_CLUSTER_NAME=bridges2
# SLURM_CONF=/var/spool/slurm/d/conf-cache/slurm.conf
# SLURM_CPUS_ON_NODE=1
# SLURM_EXPORT_ENV=ALL
# SLURM_GET_USER_ENV=1
# SLURM_GTIDS=0
# SLURM_JOBID=32966064
# SLURM_JOB_ACCOUNT=cis210027p
# SLURM_JOB_CPUS_PER_NODE=1
# SLURM_JOB_GID=24886
# SLURM_JOB_ID=32966064
# SLURM_JOB_NAME=stats.sh
# SLURM_JOB_NODELIST=r212
# SLURM_JOB_NUM_NODES=1
# SLURM_JOB_PARTITION=RM-shared
# SLURM_JOB_QOS=rm
# SLURM_JOB_UID=97947
# SLURM_JOB_USER=ttao3
# SLURM_LOCALID=0
# SLURM_MEM_PER_CPU=1900
# SLURM_NNODES=1
# SLURM_NODEID=0
# SLURM_NODELIST=r212
# SLURM_NODE_ALIASES='(null)'
# SLURM_OPEN_MODE=a
# SLURM_PRIO_PROCESS=0
# SLURM_PROCID=0
# SLURM_SCRIPT_CONTEXT=prolog_task
# SLURM_SUBMIT_DIR=/ocean/projects/cis210027p/ttao3/espnet/egs2/hifitts/tts1
# SLURM_SUBMIT_HOST=br013.ib.bridges2.psc.edu
# SLURM_TASKS_PER_NODE=1
# SLURM_TASK_PID=59326
# SLURM_TOPOLOGY_ADDR=r212
# SLURM_TOPOLOGY_ADDR_PATTERN=node
# SLURM_WORKING_CLUSTER=bridges2:br003:6810:9728:109
# python3 -m espnet2.bin.gan_tts_train --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.27.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.27.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.27 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int 
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/librosa/util/files.py:10: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_filename
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/bin/python3 /ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.27.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.27.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.27 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int
Failed to import Flash Attention, using ESPnet default: No module named 'flash_attn_2_cuda'
Vocabulary size: 74
encoder self-attention layer type = relative self-attention
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/ocean/projects/cis210027p/ttao3/espnet/espnet2/gan_tts/vits/monotonic_align/__init__.py:19: UserWarning: Cython version is not available. Fallback to 'EXPERIMETAL' numba version. If you want to use the cython version, please build it as follows: `cd espnet2/gan_tts/vits/monotonic_align; python setup.py build_ext --inplace`
  warnings.warn(
pytorch.version=2.7.1+cu126, cuda.available=False, cudnn.version=90501, cudnn.benchmark=False, cudnn.deterministic=False
Model structure:
ESPnetGANTTSModel(
  (feats_extract): LinearSpectrogram(
    (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
  )
  (tts): VITS(
    (generator): VITSGenerator(
      (text_encoder): TextEncoder(
        (emb): Embedding(74, 192)
        (encoder): Encoder(
          (embed): Sequential(
            (0): RelPositionalEncoding(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (encoders): MultiSequential(
            (0): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (2): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (3): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (4): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (5): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (after_norm): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (decoder): HiFiGANGenerator(
        (input_conv): Conv1d(192, 512, kernel_size=(7,), stride=(1,), padding=(3,))
        (upsamples): ModuleList(
          (0): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (1): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(256, 128, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (2): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,))
          )
          (3): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,))
          )
        )
        (blocks): ModuleList(
          (0): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (1): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (2): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (3): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (4): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (5): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (6): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (7): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (8): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (9): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (10): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (11): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
        )
        (output_conv): Sequential(
          (0): LeakyReLU(negative_slope=0.01)
          (1): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,))
          (2): Tanh()
        )
        (global_conv): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
      )
      (posterior_encoder): PosteriorEncoder(
        (input_conv): Conv1d(513, 192, kernel_size=(1,), stride=(1,))
        (encoder): WaveNet(
          (conv_layers): ModuleList(
            (0-15): 16 x ResidualBlock(
              (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
              (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
              (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
            )
          )
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (flow): ResidualAffineCouplingBlock(
        (flows): ModuleList(
          (0): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (1): FlipFlow()
          (2): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (3): FlipFlow()
          (4): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (5): FlipFlow()
          (6): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (7): FlipFlow()
        )
      )
      (duration_predictor): StochasticDurationPredictor(
        (pre): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (log_flow): LogFlow()
        (flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (post_pre): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
        (post_dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (post_proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (post_flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (global_conv): Conv1d(256, 192, kernel_size=(1,), stride=(1,))
      )
      (global_emb): Embedding(128, 256)
    )
    (discriminator): HiFiGANMultiScaleMultiPeriodDiscriminator(
      (msd): HiFiGANMultiScaleDiscriminator(
        (discriminators): ModuleList(
          (0): HiFiGANScaleDiscriminator(
            (layers): ModuleList(
              (0): Sequential(
                (0): Conv1d(1, 128, kernel_size=(15,), stride=(1,), padding=(7,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv1d(128, 128, kernel_size=(41,), stride=(2,), padding=(20,), groups=4)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv1d(128, 256, kernel_size=(41,), stride=(2,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv1d(256, 512, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv1d(512, 1024, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (5): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(41,), stride=(1,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (6): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (7): Conv1d(1024, 1, kernel_size=(3,), stride=(1,), padding=(1,))
            )
          )
        )
      )
      (mpd): HiFiGANMultiPeriodDiscriminator(
        (discriminators): ModuleList(
          (0-4): 5 x HiFiGANPeriodDiscriminator(
            (convs): ModuleList(
              (0): Sequential(
                (0): Conv2d(1, 32, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv2d(32, 128, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv2d(128, 512, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv2d(512, 1024, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv2d(1024, 1024, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
            )
            (output_conv): Conv2d(1024, 1, kernel_size=(2, 1), stride=(1, 1), padding=(1, 0))
          )
        )
      )
    )
    (generator_adv_loss): GeneratorAdversarialLoss()
    (discriminator_adv_loss): DiscriminatorAdversarialLoss()
    (feat_match_loss): FeatureMatchLoss()
    (mel_loss): MelSpectrogramLoss(
      (wav_to_mel): LogMelFbank(
        (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
        (logmel): LogMel(sr=22050, n_fft=1024, n_mels=80, fmin=0, fmax=11025.0, htk=False)
      )
    )
    (kl_loss): KLDivergenceLoss()
  )
)

Model summary:
    Class Name: ESPnetGANTTSModel
    Total Number of model parameters: 96.37 M
    Number of trainable parameters: 96.37 M (100.0%)
    Size: 385.46 MB
    Type: torch.float32
Optimizer:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler: <torch.optim.lr_scheduler.ExponentialLR object at 0x14ef6f778220>
Optimizer2:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler2: <torch.optim.lr_scheduler.ExponentialLR object at 0x14ef6f778640>
Saving the configuration in exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.27/config.yaml
Namespace(config='conf/tuning/train_multi_spk_vits.yaml', print_config=False, log_level='INFO', drop_last_iter=False, dry_run=False, iterator_type='sequence', valid_iterator_type=None, output_dir='exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.27', ngpu=0, seed=777, num_workers=4, num_att_plot=3, dist_backend='nccl', dist_init_method='env://', dist_world_size=None, dist_rank=None, local_rank=None, dist_master_addr=None, dist_master_port=None, dist_launcher=None, multiprocessing_distributed=False, unused_parameters=True, sharded_ddp=False, use_deepspeed=False, deepspeed_config=None, gradient_as_bucket_view=True, ddp_comm_hook=None, cudnn_enabled=True, cudnn_benchmark=False, cudnn_deterministic=False, use_tf32=False, collect_stats=True, write_collected_feats=False, max_epoch=1000, patience=None, val_scheduler_criterion=('valid', 'loss'), early_stopping_criterion=('valid', 'loss', 'min'), best_model_criterion=[['train', 'total_count', 'max']], keep_nbest_models=10, nbest_averaging_interval=0, grad_clip=-1, grad_clip_type=2.0, grad_noise=False, accum_grad=1, no_forward_run=False, resume=False, train_dtype='float32', use_amp=False, log_interval=50, use_matplotlib=True, use_tensorboard=True, create_graph_in_tensorboard=False, use_wandb=False, wandb_project=None, wandb_id=None, wandb_entity=None, wandb_name=None, wandb_model_log_interval=-1, detect_anomaly=False, use_adapter=False, adapter='lora', save_strategy='all', adapter_conf={}, pretrain_path=None, init_param=[], ignore_init_mismatch=False, freeze_param=[], num_iters_per_epoch=1000, batch_size=20, valid_batch_size=None, batch_bins=3000000, valid_batch_bins=None, category_sample_size=10, train_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.27.scp'], valid_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.27.scp'], batch_type='numel', valid_batch_type=None, fold_length=[], sort_in_batch='descending', shuffle_within_batch=False, sort_batch='descending', multiple_iterator=False, chunk_length=500, chunk_shift_ratio=0.5, num_cache_chunks=1024, chunk_excluded_key_prefixes=[], chunk_default_fs=None, chunk_max_abs_length=None, chunk_discard_short_samples=True, train_data_path_and_name_and_type=[('dump/22k/raw/tr_no_dev/text', 'text', 'text'), ('dump/22k/raw/tr_no_dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/tr_no_dev/utt2sid', 'sids', 'text_int')], valid_data_path_and_name_and_type=[('dump/22k/raw/dev/text', 'text', 'text'), ('dump/22k/raw/dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/dev/utt2sid', 'sids', 'text_int')], multi_task_dataset=False, allow_variable_data_keys=False, max_cache_size=0.0, max_cache_fd=32, allow_multi_rates=False, valid_max_cache_size=None, exclude_weight_decay=False, exclude_weight_decay_conf={}, optim='adamw', optim_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler='exponentiallr', scheduler_conf={'gamma': 0.999875}, optim2='adamw', optim2_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler2='exponentiallr', scheduler2_conf={'gamma': 0.999875}, generator_first=False, skip_discriminator_prob=0.0, token_list=['<blank>', '<unk>', ' ', 'AH0', 'N', 'T', 'D', 'S', 'R', 'L', 'IH1', 'DH', 'M', 'EH1', 'Z', 'AE1', 'K', 'IH0', 'AH1', 'HH', 'W', 'ER0', 'V', 'IY1', 'F', 'UW1', 'P', 'AY1', 'B', 'AA1', 'AO1', 'EY1', 'IY0', 'OW1', 'NG', 'SH', 'G', 'Y', 'AW1', 'CH', 'ER1', 'UH1', 'TH', 'JH', 'OW0', 'EH2', 'IH2', 'OY1', 'EY2', 'AY2', 'EH0', 'UW0', 'AA2', 'AE2', 'OW2', 'AH2', 'AA0', 'ZH', 'AE0', 'AO2', 'UW2', 'AO0', 'AY0', 'IY2', 'AW2', 'UH2', 'EY0', 'ER2', 'AW0', 'UH0', 'OY2', 'OY0', "'", '<sos/eos>'], odim=None, model_conf={}, use_preprocessor=True, token_type='phn', bpemodel=None, non_linguistic_symbols=None, cleaner='tacotron', g2p='g2p_en', feats_extract='linear_spectrogram', feats_extract_conf={'n_fft': 1024, 'hop_length': 256, 'win_length': None}, normalize=None, normalize_conf={}, tts='vits', tts_conf={'generator_type': 'vits_generator', 'generator_params': {'hidden_channels': 192, 'spks': 128, 'global_channels': 256, 'segment_size': 32, 'text_encoder_attention_heads': 2, 'text_encoder_ffn_expand': 4, 'text_encoder_blocks': 6, 'text_encoder_positionwise_layer_type': 'conv1d', 'text_encoder_positionwise_conv_kernel_size': 3, 'text_encoder_positional_encoding_layer_type': 'rel_pos', 'text_encoder_self_attention_layer_type': 'rel_selfattn', 'text_encoder_activation_type': 'swish', 'text_encoder_normalize_before': True, 'text_encoder_dropout_rate': 0.1, 'text_encoder_positional_dropout_rate': 0.0, 'text_encoder_attention_dropout_rate': 0.1, 'use_macaron_style_in_text_encoder': True, 'use_conformer_conv_in_text_encoder': False, 'text_encoder_conformer_kernel_size': -1, 'decoder_kernel_size': 7, 'decoder_channels': 512, 'decoder_upsample_scales': [8, 8, 2, 2], 'decoder_upsample_kernel_sizes': [16, 16, 4, 4], 'decoder_resblock_kernel_sizes': [3, 7, 11], 'decoder_resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'use_weight_norm_in_decoder': True, 'posterior_encoder_kernel_size': 5, 'posterior_encoder_layers': 16, 'posterior_encoder_stacks': 1, 'posterior_encoder_base_dilation': 1, 'posterior_encoder_dropout_rate': 0.0, 'use_weight_norm_in_posterior_encoder': True, 'flow_flows': 4, 'flow_kernel_size': 5, 'flow_base_dilation': 1, 'flow_layers': 4, 'flow_dropout_rate': 0.0, 'use_weight_norm_in_flow': True, 'use_only_mean_in_flow': True, 'stochastic_duration_predictor_kernel_size': 3, 'stochastic_duration_predictor_dropout_rate': 0.5, 'stochastic_duration_predictor_flows': 4, 'stochastic_duration_predictor_dds_conv_layers': 3, 'vocabs': 74, 'aux_channels': 513}, 'discriminator_type': 'hifigan_multi_scale_multi_period_discriminator', 'discriminator_params': {'scales': 1, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'stride': 2, 'padding': 2}, 'scale_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'channels': 128, 'max_downsample_channels': 1024, 'max_groups': 16, 'bias': True, 'downsample_scales': [2, 2, 4, 4, 1], 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}, 'follow_official_norm': False, 'periods': [2, 3, 5, 7, 11], 'period_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [5, 3], 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'max_downsample_channels': 1024, 'bias': True, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}}, 'generator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'discriminator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'feat_match_loss_params': {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, 'mel_loss_params': {'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None, 'window': 'hann', 'n_mels': 80, 'fmin': 0, 'fmax': None, 'log_base': None}, 'lambda_adv': 1.0, 'lambda_mel': 45.0, 'lambda_feat_match': 2.0, 'lambda_dur': 1.0, 'lambda_kl': 1.0, 'sampling_rate': 22050, 'cache_generator_outputs': True, 'plot_pred_mos': False, 'mos_pred_tool': 'utmos'}, pitch_extract=None, pitch_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'f0max': 400, 'f0min': 80}, pitch_normalize=None, pitch_normalize_conf={}, energy_extract=None, energy_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None}, energy_normalize=None, energy_normalize_conf={}, required=['output_dir', 'token_list'], version='202503', distributed=False)
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1284, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 59568) is killed by signal: Killed. 

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 22, in <module>
    main()
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 18, in main
    GANTTSTask.main(cmd=cmd)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1225, in main
    cls.main_worker(args)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1441, in main_worker
    collect_stats(
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/main_funcs/collect_stats.py", line 51, in collect_stats
    for iiter, (keys, batch) in enumerate(itr, 1):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 733, in __next__
    data = self._next_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1491, in _next_data
    idx, data = self._get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1453, in _get_data
    success, data = self._try_get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1297, in _try_get_data
    raise RuntimeError(
RuntimeError: DataLoader worker (pid(s) 59568) exited unexpectedly
# Accounting: begin_time=1750836659
# Accounting: end_time=1750836799
# Accounting: time=140 threads=1
# Finished at Wed Jun 25 03:33:19 EDT 2025 with status 1
# Running on r212.ib.bridges2.psc.edu
# Started at Wed Jun 25 03:30:59 EDT 2025
# SLURMD_NODENAME=r212
# SLURM_ARRAY_JOB_ID=32966037
# SLURM_ARRAY_TASK_COUNT=32
# SLURM_ARRAY_TASK_ID=28
# SLURM_ARRAY_TASK_MAX=32
# SLURM_ARRAY_TASK_MIN=1
# SLURM_ARRAY_TASK_STEP=1
# SLURM_CLUSTER_NAME=bridges2
# SLURM_CONF=/var/spool/slurm/d/conf-cache/slurm.conf
# SLURM_CPUS_ON_NODE=1
# SLURM_EXPORT_ENV=ALL
# SLURM_GET_USER_ENV=1
# SLURM_GTIDS=0
# SLURM_JOBID=32966065
# SLURM_JOB_ACCOUNT=cis210027p
# SLURM_JOB_CPUS_PER_NODE=1
# SLURM_JOB_GID=24886
# SLURM_JOB_ID=32966065
# SLURM_JOB_NAME=stats.sh
# SLURM_JOB_NODELIST=r212
# SLURM_JOB_NUM_NODES=1
# SLURM_JOB_PARTITION=RM-shared
# SLURM_JOB_QOS=rm
# SLURM_JOB_UID=97947
# SLURM_JOB_USER=ttao3
# SLURM_LOCALID=0
# SLURM_MEM_PER_CPU=1900
# SLURM_NNODES=1
# SLURM_NODEID=0
# SLURM_NODELIST=r212
# SLURM_NODE_ALIASES='(null)'
# SLURM_OPEN_MODE=a
# SLURM_PRIO_PROCESS=0
# SLURM_PROCID=0
# SLURM_SCRIPT_CONTEXT=prolog_task
# SLURM_SUBMIT_DIR=/ocean/projects/cis210027p/ttao3/espnet/egs2/hifitts/tts1
# SLURM_SUBMIT_HOST=br013.ib.bridges2.psc.edu
# SLURM_TASKS_PER_NODE=1
# SLURM_TASK_PID=59325
# SLURM_TOPOLOGY_ADDR=r212
# SLURM_TOPOLOGY_ADDR_PATTERN=node
# SLURM_WORKING_CLUSTER=bridges2:br003:6810:9728:109
# python3 -m espnet2.bin.gan_tts_train --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.28.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.28.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.28 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int 
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/librosa/util/files.py:10: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_filename
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/bin/python3 /ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.28.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.28.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.28 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int
Failed to import Flash Attention, using ESPnet default: No module named 'flash_attn_2_cuda'
Vocabulary size: 74
encoder self-attention layer type = relative self-attention
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/ocean/projects/cis210027p/ttao3/espnet/espnet2/gan_tts/vits/monotonic_align/__init__.py:19: UserWarning: Cython version is not available. Fallback to 'EXPERIMETAL' numba version. If you want to use the cython version, please build it as follows: `cd espnet2/gan_tts/vits/monotonic_align; python setup.py build_ext --inplace`
  warnings.warn(
pytorch.version=2.7.1+cu126, cuda.available=False, cudnn.version=90501, cudnn.benchmark=False, cudnn.deterministic=False
Model structure:
ESPnetGANTTSModel(
  (feats_extract): LinearSpectrogram(
    (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
  )
  (tts): VITS(
    (generator): VITSGenerator(
      (text_encoder): TextEncoder(
        (emb): Embedding(74, 192)
        (encoder): Encoder(
          (embed): Sequential(
            (0): RelPositionalEncoding(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (encoders): MultiSequential(
            (0): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (2): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (3): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (4): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (5): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (after_norm): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (decoder): HiFiGANGenerator(
        (input_conv): Conv1d(192, 512, kernel_size=(7,), stride=(1,), padding=(3,))
        (upsamples): ModuleList(
          (0): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (1): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(256, 128, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (2): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,))
          )
          (3): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,))
          )
        )
        (blocks): ModuleList(
          (0): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (1): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (2): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (3): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (4): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (5): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (6): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (7): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (8): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (9): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (10): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (11): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
        )
        (output_conv): Sequential(
          (0): LeakyReLU(negative_slope=0.01)
          (1): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,))
          (2): Tanh()
        )
        (global_conv): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
      )
      (posterior_encoder): PosteriorEncoder(
        (input_conv): Conv1d(513, 192, kernel_size=(1,), stride=(1,))
        (encoder): WaveNet(
          (conv_layers): ModuleList(
            (0-15): 16 x ResidualBlock(
              (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
              (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
              (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
            )
          )
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (flow): ResidualAffineCouplingBlock(
        (flows): ModuleList(
          (0): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (1): FlipFlow()
          (2): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (3): FlipFlow()
          (4): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (5): FlipFlow()
          (6): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (7): FlipFlow()
        )
      )
      (duration_predictor): StochasticDurationPredictor(
        (pre): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (log_flow): LogFlow()
        (flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (post_pre): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
        (post_dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (post_proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (post_flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (global_conv): Conv1d(256, 192, kernel_size=(1,), stride=(1,))
      )
      (global_emb): Embedding(128, 256)
    )
    (discriminator): HiFiGANMultiScaleMultiPeriodDiscriminator(
      (msd): HiFiGANMultiScaleDiscriminator(
        (discriminators): ModuleList(
          (0): HiFiGANScaleDiscriminator(
            (layers): ModuleList(
              (0): Sequential(
                (0): Conv1d(1, 128, kernel_size=(15,), stride=(1,), padding=(7,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv1d(128, 128, kernel_size=(41,), stride=(2,), padding=(20,), groups=4)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv1d(128, 256, kernel_size=(41,), stride=(2,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv1d(256, 512, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv1d(512, 1024, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (5): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(41,), stride=(1,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (6): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (7): Conv1d(1024, 1, kernel_size=(3,), stride=(1,), padding=(1,))
            )
          )
        )
      )
      (mpd): HiFiGANMultiPeriodDiscriminator(
        (discriminators): ModuleList(
          (0-4): 5 x HiFiGANPeriodDiscriminator(
            (convs): ModuleList(
              (0): Sequential(
                (0): Conv2d(1, 32, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv2d(32, 128, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv2d(128, 512, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv2d(512, 1024, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv2d(1024, 1024, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
            )
            (output_conv): Conv2d(1024, 1, kernel_size=(2, 1), stride=(1, 1), padding=(1, 0))
          )
        )
      )
    )
    (generator_adv_loss): GeneratorAdversarialLoss()
    (discriminator_adv_loss): DiscriminatorAdversarialLoss()
    (feat_match_loss): FeatureMatchLoss()
    (mel_loss): MelSpectrogramLoss(
      (wav_to_mel): LogMelFbank(
        (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
        (logmel): LogMel(sr=22050, n_fft=1024, n_mels=80, fmin=0, fmax=11025.0, htk=False)
      )
    )
    (kl_loss): KLDivergenceLoss()
  )
)

Model summary:
    Class Name: ESPnetGANTTSModel
    Total Number of model parameters: 96.37 M
    Number of trainable parameters: 96.37 M (100.0%)
    Size: 385.46 MB
    Type: torch.float32
Optimizer:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler: <torch.optim.lr_scheduler.ExponentialLR object at 0x14eeb645a250>
Optimizer2:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler2: <torch.optim.lr_scheduler.ExponentialLR object at 0x14eeb645a670>
Saving the configuration in exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.28/config.yaml
Namespace(config='conf/tuning/train_multi_spk_vits.yaml', print_config=False, log_level='INFO', drop_last_iter=False, dry_run=False, iterator_type='sequence', valid_iterator_type=None, output_dir='exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.28', ngpu=0, seed=777, num_workers=4, num_att_plot=3, dist_backend='nccl', dist_init_method='env://', dist_world_size=None, dist_rank=None, local_rank=None, dist_master_addr=None, dist_master_port=None, dist_launcher=None, multiprocessing_distributed=False, unused_parameters=True, sharded_ddp=False, use_deepspeed=False, deepspeed_config=None, gradient_as_bucket_view=True, ddp_comm_hook=None, cudnn_enabled=True, cudnn_benchmark=False, cudnn_deterministic=False, use_tf32=False, collect_stats=True, write_collected_feats=False, max_epoch=1000, patience=None, val_scheduler_criterion=('valid', 'loss'), early_stopping_criterion=('valid', 'loss', 'min'), best_model_criterion=[['train', 'total_count', 'max']], keep_nbest_models=10, nbest_averaging_interval=0, grad_clip=-1, grad_clip_type=2.0, grad_noise=False, accum_grad=1, no_forward_run=False, resume=False, train_dtype='float32', use_amp=False, log_interval=50, use_matplotlib=True, use_tensorboard=True, create_graph_in_tensorboard=False, use_wandb=False, wandb_project=None, wandb_id=None, wandb_entity=None, wandb_name=None, wandb_model_log_interval=-1, detect_anomaly=False, use_adapter=False, adapter='lora', save_strategy='all', adapter_conf={}, pretrain_path=None, init_param=[], ignore_init_mismatch=False, freeze_param=[], num_iters_per_epoch=1000, batch_size=20, valid_batch_size=None, batch_bins=3000000, valid_batch_bins=None, category_sample_size=10, train_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.28.scp'], valid_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.28.scp'], batch_type='numel', valid_batch_type=None, fold_length=[], sort_in_batch='descending', shuffle_within_batch=False, sort_batch='descending', multiple_iterator=False, chunk_length=500, chunk_shift_ratio=0.5, num_cache_chunks=1024, chunk_excluded_key_prefixes=[], chunk_default_fs=None, chunk_max_abs_length=None, chunk_discard_short_samples=True, train_data_path_and_name_and_type=[('dump/22k/raw/tr_no_dev/text', 'text', 'text'), ('dump/22k/raw/tr_no_dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/tr_no_dev/utt2sid', 'sids', 'text_int')], valid_data_path_and_name_and_type=[('dump/22k/raw/dev/text', 'text', 'text'), ('dump/22k/raw/dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/dev/utt2sid', 'sids', 'text_int')], multi_task_dataset=False, allow_variable_data_keys=False, max_cache_size=0.0, max_cache_fd=32, allow_multi_rates=False, valid_max_cache_size=None, exclude_weight_decay=False, exclude_weight_decay_conf={}, optim='adamw', optim_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler='exponentiallr', scheduler_conf={'gamma': 0.999875}, optim2='adamw', optim2_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler2='exponentiallr', scheduler2_conf={'gamma': 0.999875}, generator_first=False, skip_discriminator_prob=0.0, token_list=['<blank>', '<unk>', ' ', 'AH0', 'N', 'T', 'D', 'S', 'R', 'L', 'IH1', 'DH', 'M', 'EH1', 'Z', 'AE1', 'K', 'IH0', 'AH1', 'HH', 'W', 'ER0', 'V', 'IY1', 'F', 'UW1', 'P', 'AY1', 'B', 'AA1', 'AO1', 'EY1', 'IY0', 'OW1', 'NG', 'SH', 'G', 'Y', 'AW1', 'CH', 'ER1', 'UH1', 'TH', 'JH', 'OW0', 'EH2', 'IH2', 'OY1', 'EY2', 'AY2', 'EH0', 'UW0', 'AA2', 'AE2', 'OW2', 'AH2', 'AA0', 'ZH', 'AE0', 'AO2', 'UW2', 'AO0', 'AY0', 'IY2', 'AW2', 'UH2', 'EY0', 'ER2', 'AW0', 'UH0', 'OY2', 'OY0', "'", '<sos/eos>'], odim=None, model_conf={}, use_preprocessor=True, token_type='phn', bpemodel=None, non_linguistic_symbols=None, cleaner='tacotron', g2p='g2p_en', feats_extract='linear_spectrogram', feats_extract_conf={'n_fft': 1024, 'hop_length': 256, 'win_length': None}, normalize=None, normalize_conf={}, tts='vits', tts_conf={'generator_type': 'vits_generator', 'generator_params': {'hidden_channels': 192, 'spks': 128, 'global_channels': 256, 'segment_size': 32, 'text_encoder_attention_heads': 2, 'text_encoder_ffn_expand': 4, 'text_encoder_blocks': 6, 'text_encoder_positionwise_layer_type': 'conv1d', 'text_encoder_positionwise_conv_kernel_size': 3, 'text_encoder_positional_encoding_layer_type': 'rel_pos', 'text_encoder_self_attention_layer_type': 'rel_selfattn', 'text_encoder_activation_type': 'swish', 'text_encoder_normalize_before': True, 'text_encoder_dropout_rate': 0.1, 'text_encoder_positional_dropout_rate': 0.0, 'text_encoder_attention_dropout_rate': 0.1, 'use_macaron_style_in_text_encoder': True, 'use_conformer_conv_in_text_encoder': False, 'text_encoder_conformer_kernel_size': -1, 'decoder_kernel_size': 7, 'decoder_channels': 512, 'decoder_upsample_scales': [8, 8, 2, 2], 'decoder_upsample_kernel_sizes': [16, 16, 4, 4], 'decoder_resblock_kernel_sizes': [3, 7, 11], 'decoder_resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'use_weight_norm_in_decoder': True, 'posterior_encoder_kernel_size': 5, 'posterior_encoder_layers': 16, 'posterior_encoder_stacks': 1, 'posterior_encoder_base_dilation': 1, 'posterior_encoder_dropout_rate': 0.0, 'use_weight_norm_in_posterior_encoder': True, 'flow_flows': 4, 'flow_kernel_size': 5, 'flow_base_dilation': 1, 'flow_layers': 4, 'flow_dropout_rate': 0.0, 'use_weight_norm_in_flow': True, 'use_only_mean_in_flow': True, 'stochastic_duration_predictor_kernel_size': 3, 'stochastic_duration_predictor_dropout_rate': 0.5, 'stochastic_duration_predictor_flows': 4, 'stochastic_duration_predictor_dds_conv_layers': 3, 'vocabs': 74, 'aux_channels': 513}, 'discriminator_type': 'hifigan_multi_scale_multi_period_discriminator', 'discriminator_params': {'scales': 1, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'stride': 2, 'padding': 2}, 'scale_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'channels': 128, 'max_downsample_channels': 1024, 'max_groups': 16, 'bias': True, 'downsample_scales': [2, 2, 4, 4, 1], 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}, 'follow_official_norm': False, 'periods': [2, 3, 5, 7, 11], 'period_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [5, 3], 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'max_downsample_channels': 1024, 'bias': True, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}}, 'generator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'discriminator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'feat_match_loss_params': {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, 'mel_loss_params': {'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None, 'window': 'hann', 'n_mels': 80, 'fmin': 0, 'fmax': None, 'log_base': None}, 'lambda_adv': 1.0, 'lambda_mel': 45.0, 'lambda_feat_match': 2.0, 'lambda_dur': 1.0, 'lambda_kl': 1.0, 'sampling_rate': 22050, 'cache_generator_outputs': True, 'plot_pred_mos': False, 'mos_pred_tool': 'utmos'}, pitch_extract=None, pitch_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'f0max': 400, 'f0min': 80}, pitch_normalize=None, pitch_normalize_conf={}, energy_extract=None, energy_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None}, energy_normalize=None, energy_normalize_conf={}, required=['output_dir', 'token_list'], version='202503', distributed=False)
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1284, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 59558) is killed by signal: Killed. 

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 22, in <module>
    main()
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 18, in main
    GANTTSTask.main(cmd=cmd)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1225, in main
    cls.main_worker(args)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1441, in main_worker
    collect_stats(
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/main_funcs/collect_stats.py", line 51, in collect_stats
    for iiter, (keys, batch) in enumerate(itr, 1):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 733, in __next__
    data = self._next_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1491, in _next_data
    idx, data = self._get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1453, in _get_data
    success, data = self._try_get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1297, in _try_get_data
    raise RuntimeError(
RuntimeError: DataLoader worker (pid(s) 59558) exited unexpectedly
# Accounting: begin_time=1750836659
# Accounting: end_time=1750836799
# Accounting: time=140 threads=1
# Finished at Wed Jun 25 03:33:19 EDT 2025 with status 1
# Running on r212.ib.bridges2.psc.edu
# Started at Wed Jun 25 03:30:59 EDT 2025
# SLURMD_NODENAME=r212
# SLURM_ARRAY_JOB_ID=32966037
# SLURM_ARRAY_TASK_COUNT=32
# SLURM_ARRAY_TASK_ID=29
# SLURM_ARRAY_TASK_MAX=32
# SLURM_ARRAY_TASK_MIN=1
# SLURM_ARRAY_TASK_STEP=1
# SLURM_CLUSTER_NAME=bridges2
# SLURM_CONF=/var/spool/slurm/d/conf-cache/slurm.conf
# SLURM_CPUS_ON_NODE=1
# SLURM_EXPORT_ENV=ALL
# SLURM_GET_USER_ENV=1
# SLURM_GTIDS=0
# SLURM_JOBID=32966066
# SLURM_JOB_ACCOUNT=cis210027p
# SLURM_JOB_CPUS_PER_NODE=1
# SLURM_JOB_GID=24886
# SLURM_JOB_ID=32966066
# SLURM_JOB_NAME=stats.sh
# SLURM_JOB_NODELIST=r212
# SLURM_JOB_NUM_NODES=1
# SLURM_JOB_PARTITION=RM-shared
# SLURM_JOB_QOS=rm
# SLURM_JOB_UID=97947
# SLURM_JOB_USER=ttao3
# SLURM_LOCALID=0
# SLURM_MEM_PER_CPU=1900
# SLURM_NNODES=1
# SLURM_NODEID=0
# SLURM_NODELIST=r212
# SLURM_NODE_ALIASES='(null)'
# SLURM_OPEN_MODE=a
# SLURM_PRIO_PROCESS=0
# SLURM_PROCID=0
# SLURM_SCRIPT_CONTEXT=prolog_task
# SLURM_SUBMIT_DIR=/ocean/projects/cis210027p/ttao3/espnet/egs2/hifitts/tts1
# SLURM_SUBMIT_HOST=br013.ib.bridges2.psc.edu
# SLURM_TASKS_PER_NODE=1
# SLURM_TASK_PID=59322
# SLURM_TOPOLOGY_ADDR=r212
# SLURM_TOPOLOGY_ADDR_PATTERN=node
# SLURM_WORKING_CLUSTER=bridges2:br003:6810:9728:109
# python3 -m espnet2.bin.gan_tts_train --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.29.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.29.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.29 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int 
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/librosa/util/files.py:10: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_filename
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/bin/python3 /ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.29.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.29.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.29 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int
Failed to import Flash Attention, using ESPnet default: No module named 'flash_attn_2_cuda'
Vocabulary size: 74
encoder self-attention layer type = relative self-attention
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/ocean/projects/cis210027p/ttao3/espnet/espnet2/gan_tts/vits/monotonic_align/__init__.py:19: UserWarning: Cython version is not available. Fallback to 'EXPERIMETAL' numba version. If you want to use the cython version, please build it as follows: `cd espnet2/gan_tts/vits/monotonic_align; python setup.py build_ext --inplace`
  warnings.warn(
pytorch.version=2.7.1+cu126, cuda.available=False, cudnn.version=90501, cudnn.benchmark=False, cudnn.deterministic=False
Model structure:
ESPnetGANTTSModel(
  (feats_extract): LinearSpectrogram(
    (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
  )
  (tts): VITS(
    (generator): VITSGenerator(
      (text_encoder): TextEncoder(
        (emb): Embedding(74, 192)
        (encoder): Encoder(
          (embed): Sequential(
            (0): RelPositionalEncoding(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (encoders): MultiSequential(
            (0): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (2): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (3): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (4): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (5): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (after_norm): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (decoder): HiFiGANGenerator(
        (input_conv): Conv1d(192, 512, kernel_size=(7,), stride=(1,), padding=(3,))
        (upsamples): ModuleList(
          (0): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (1): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(256, 128, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (2): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,))
          )
          (3): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,))
          )
        )
        (blocks): ModuleList(
          (0): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (1): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (2): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (3): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (4): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (5): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (6): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (7): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (8): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (9): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (10): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (11): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
        )
        (output_conv): Sequential(
          (0): LeakyReLU(negative_slope=0.01)
          (1): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,))
          (2): Tanh()
        )
        (global_conv): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
      )
      (posterior_encoder): PosteriorEncoder(
        (input_conv): Conv1d(513, 192, kernel_size=(1,), stride=(1,))
        (encoder): WaveNet(
          (conv_layers): ModuleList(
            (0-15): 16 x ResidualBlock(
              (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
              (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
              (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
            )
          )
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (flow): ResidualAffineCouplingBlock(
        (flows): ModuleList(
          (0): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (1): FlipFlow()
          (2): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (3): FlipFlow()
          (4): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (5): FlipFlow()
          (6): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (7): FlipFlow()
        )
      )
      (duration_predictor): StochasticDurationPredictor(
        (pre): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (log_flow): LogFlow()
        (flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (post_pre): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
        (post_dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (post_proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (post_flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (global_conv): Conv1d(256, 192, kernel_size=(1,), stride=(1,))
      )
      (global_emb): Embedding(128, 256)
    )
    (discriminator): HiFiGANMultiScaleMultiPeriodDiscriminator(
      (msd): HiFiGANMultiScaleDiscriminator(
        (discriminators): ModuleList(
          (0): HiFiGANScaleDiscriminator(
            (layers): ModuleList(
              (0): Sequential(
                (0): Conv1d(1, 128, kernel_size=(15,), stride=(1,), padding=(7,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv1d(128, 128, kernel_size=(41,), stride=(2,), padding=(20,), groups=4)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv1d(128, 256, kernel_size=(41,), stride=(2,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv1d(256, 512, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv1d(512, 1024, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (5): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(41,), stride=(1,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (6): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (7): Conv1d(1024, 1, kernel_size=(3,), stride=(1,), padding=(1,))
            )
          )
        )
      )
      (mpd): HiFiGANMultiPeriodDiscriminator(
        (discriminators): ModuleList(
          (0-4): 5 x HiFiGANPeriodDiscriminator(
            (convs): ModuleList(
              (0): Sequential(
                (0): Conv2d(1, 32, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv2d(32, 128, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv2d(128, 512, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv2d(512, 1024, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv2d(1024, 1024, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
            )
            (output_conv): Conv2d(1024, 1, kernel_size=(2, 1), stride=(1, 1), padding=(1, 0))
          )
        )
      )
    )
    (generator_adv_loss): GeneratorAdversarialLoss()
    (discriminator_adv_loss): DiscriminatorAdversarialLoss()
    (feat_match_loss): FeatureMatchLoss()
    (mel_loss): MelSpectrogramLoss(
      (wav_to_mel): LogMelFbank(
        (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
        (logmel): LogMel(sr=22050, n_fft=1024, n_mels=80, fmin=0, fmax=11025.0, htk=False)
      )
    )
    (kl_loss): KLDivergenceLoss()
  )
)

Model summary:
    Class Name: ESPnetGANTTSModel
    Total Number of model parameters: 96.37 M
    Number of trainable parameters: 96.37 M (100.0%)
    Size: 385.46 MB
    Type: torch.float32
Optimizer:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler: <torch.optim.lr_scheduler.ExponentialLR object at 0x155221434250>
Optimizer2:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler2: <torch.optim.lr_scheduler.ExponentialLR object at 0x155221434670>
Saving the configuration in exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.29/config.yaml
Namespace(config='conf/tuning/train_multi_spk_vits.yaml', print_config=False, log_level='INFO', drop_last_iter=False, dry_run=False, iterator_type='sequence', valid_iterator_type=None, output_dir='exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.29', ngpu=0, seed=777, num_workers=4, num_att_plot=3, dist_backend='nccl', dist_init_method='env://', dist_world_size=None, dist_rank=None, local_rank=None, dist_master_addr=None, dist_master_port=None, dist_launcher=None, multiprocessing_distributed=False, unused_parameters=True, sharded_ddp=False, use_deepspeed=False, deepspeed_config=None, gradient_as_bucket_view=True, ddp_comm_hook=None, cudnn_enabled=True, cudnn_benchmark=False, cudnn_deterministic=False, use_tf32=False, collect_stats=True, write_collected_feats=False, max_epoch=1000, patience=None, val_scheduler_criterion=('valid', 'loss'), early_stopping_criterion=('valid', 'loss', 'min'), best_model_criterion=[['train', 'total_count', 'max']], keep_nbest_models=10, nbest_averaging_interval=0, grad_clip=-1, grad_clip_type=2.0, grad_noise=False, accum_grad=1, no_forward_run=False, resume=False, train_dtype='float32', use_amp=False, log_interval=50, use_matplotlib=True, use_tensorboard=True, create_graph_in_tensorboard=False, use_wandb=False, wandb_project=None, wandb_id=None, wandb_entity=None, wandb_name=None, wandb_model_log_interval=-1, detect_anomaly=False, use_adapter=False, adapter='lora', save_strategy='all', adapter_conf={}, pretrain_path=None, init_param=[], ignore_init_mismatch=False, freeze_param=[], num_iters_per_epoch=1000, batch_size=20, valid_batch_size=None, batch_bins=3000000, valid_batch_bins=None, category_sample_size=10, train_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.29.scp'], valid_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.29.scp'], batch_type='numel', valid_batch_type=None, fold_length=[], sort_in_batch='descending', shuffle_within_batch=False, sort_batch='descending', multiple_iterator=False, chunk_length=500, chunk_shift_ratio=0.5, num_cache_chunks=1024, chunk_excluded_key_prefixes=[], chunk_default_fs=None, chunk_max_abs_length=None, chunk_discard_short_samples=True, train_data_path_and_name_and_type=[('dump/22k/raw/tr_no_dev/text', 'text', 'text'), ('dump/22k/raw/tr_no_dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/tr_no_dev/utt2sid', 'sids', 'text_int')], valid_data_path_and_name_and_type=[('dump/22k/raw/dev/text', 'text', 'text'), ('dump/22k/raw/dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/dev/utt2sid', 'sids', 'text_int')], multi_task_dataset=False, allow_variable_data_keys=False, max_cache_size=0.0, max_cache_fd=32, allow_multi_rates=False, valid_max_cache_size=None, exclude_weight_decay=False, exclude_weight_decay_conf={}, optim='adamw', optim_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler='exponentiallr', scheduler_conf={'gamma': 0.999875}, optim2='adamw', optim2_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler2='exponentiallr', scheduler2_conf={'gamma': 0.999875}, generator_first=False, skip_discriminator_prob=0.0, token_list=['<blank>', '<unk>', ' ', 'AH0', 'N', 'T', 'D', 'S', 'R', 'L', 'IH1', 'DH', 'M', 'EH1', 'Z', 'AE1', 'K', 'IH0', 'AH1', 'HH', 'W', 'ER0', 'V', 'IY1', 'F', 'UW1', 'P', 'AY1', 'B', 'AA1', 'AO1', 'EY1', 'IY0', 'OW1', 'NG', 'SH', 'G', 'Y', 'AW1', 'CH', 'ER1', 'UH1', 'TH', 'JH', 'OW0', 'EH2', 'IH2', 'OY1', 'EY2', 'AY2', 'EH0', 'UW0', 'AA2', 'AE2', 'OW2', 'AH2', 'AA0', 'ZH', 'AE0', 'AO2', 'UW2', 'AO0', 'AY0', 'IY2', 'AW2', 'UH2', 'EY0', 'ER2', 'AW0', 'UH0', 'OY2', 'OY0', "'", '<sos/eos>'], odim=None, model_conf={}, use_preprocessor=True, token_type='phn', bpemodel=None, non_linguistic_symbols=None, cleaner='tacotron', g2p='g2p_en', feats_extract='linear_spectrogram', feats_extract_conf={'n_fft': 1024, 'hop_length': 256, 'win_length': None}, normalize=None, normalize_conf={}, tts='vits', tts_conf={'generator_type': 'vits_generator', 'generator_params': {'hidden_channels': 192, 'spks': 128, 'global_channels': 256, 'segment_size': 32, 'text_encoder_attention_heads': 2, 'text_encoder_ffn_expand': 4, 'text_encoder_blocks': 6, 'text_encoder_positionwise_layer_type': 'conv1d', 'text_encoder_positionwise_conv_kernel_size': 3, 'text_encoder_positional_encoding_layer_type': 'rel_pos', 'text_encoder_self_attention_layer_type': 'rel_selfattn', 'text_encoder_activation_type': 'swish', 'text_encoder_normalize_before': True, 'text_encoder_dropout_rate': 0.1, 'text_encoder_positional_dropout_rate': 0.0, 'text_encoder_attention_dropout_rate': 0.1, 'use_macaron_style_in_text_encoder': True, 'use_conformer_conv_in_text_encoder': False, 'text_encoder_conformer_kernel_size': -1, 'decoder_kernel_size': 7, 'decoder_channels': 512, 'decoder_upsample_scales': [8, 8, 2, 2], 'decoder_upsample_kernel_sizes': [16, 16, 4, 4], 'decoder_resblock_kernel_sizes': [3, 7, 11], 'decoder_resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'use_weight_norm_in_decoder': True, 'posterior_encoder_kernel_size': 5, 'posterior_encoder_layers': 16, 'posterior_encoder_stacks': 1, 'posterior_encoder_base_dilation': 1, 'posterior_encoder_dropout_rate': 0.0, 'use_weight_norm_in_posterior_encoder': True, 'flow_flows': 4, 'flow_kernel_size': 5, 'flow_base_dilation': 1, 'flow_layers': 4, 'flow_dropout_rate': 0.0, 'use_weight_norm_in_flow': True, 'use_only_mean_in_flow': True, 'stochastic_duration_predictor_kernel_size': 3, 'stochastic_duration_predictor_dropout_rate': 0.5, 'stochastic_duration_predictor_flows': 4, 'stochastic_duration_predictor_dds_conv_layers': 3, 'vocabs': 74, 'aux_channels': 513}, 'discriminator_type': 'hifigan_multi_scale_multi_period_discriminator', 'discriminator_params': {'scales': 1, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'stride': 2, 'padding': 2}, 'scale_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'channels': 128, 'max_downsample_channels': 1024, 'max_groups': 16, 'bias': True, 'downsample_scales': [2, 2, 4, 4, 1], 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}, 'follow_official_norm': False, 'periods': [2, 3, 5, 7, 11], 'period_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [5, 3], 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'max_downsample_channels': 1024, 'bias': True, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}}, 'generator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'discriminator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'feat_match_loss_params': {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, 'mel_loss_params': {'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None, 'window': 'hann', 'n_mels': 80, 'fmin': 0, 'fmax': None, 'log_base': None}, 'lambda_adv': 1.0, 'lambda_mel': 45.0, 'lambda_feat_match': 2.0, 'lambda_dur': 1.0, 'lambda_kl': 1.0, 'sampling_rate': 22050, 'cache_generator_outputs': True, 'plot_pred_mos': False, 'mos_pred_tool': 'utmos'}, pitch_extract=None, pitch_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'f0max': 400, 'f0min': 80}, pitch_normalize=None, pitch_normalize_conf={}, energy_extract=None, energy_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None}, energy_normalize=None, energy_normalize_conf={}, required=['output_dir', 'token_list'], version='202503', distributed=False)
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1284, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 59563) is killed by signal: Killed. 

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 22, in <module>
    main()
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 18, in main
    GANTTSTask.main(cmd=cmd)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1225, in main
    cls.main_worker(args)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1441, in main_worker
    collect_stats(
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/main_funcs/collect_stats.py", line 51, in collect_stats
    for iiter, (keys, batch) in enumerate(itr, 1):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 733, in __next__
    data = self._next_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1491, in _next_data
    idx, data = self._get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1453, in _get_data
    success, data = self._try_get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1297, in _try_get_data
    raise RuntimeError(
RuntimeError: DataLoader worker (pid(s) 59563) exited unexpectedly
# Accounting: begin_time=1750836659
# Accounting: end_time=1750836799
# Accounting: time=140 threads=1
# Finished at Wed Jun 25 03:33:19 EDT 2025 with status 1
# Running on r212.ib.bridges2.psc.edu
# Started at Wed Jun 25 03:30:59 EDT 2025
# SLURMD_NODENAME=r212
# SLURM_ARRAY_JOB_ID=32966037
# SLURM_ARRAY_TASK_COUNT=32
# SLURM_ARRAY_TASK_ID=30
# SLURM_ARRAY_TASK_MAX=32
# SLURM_ARRAY_TASK_MIN=1
# SLURM_ARRAY_TASK_STEP=1
# SLURM_CLUSTER_NAME=bridges2
# SLURM_CONF=/var/spool/slurm/d/conf-cache/slurm.conf
# SLURM_CPUS_ON_NODE=1
# SLURM_EXPORT_ENV=ALL
# SLURM_GET_USER_ENV=1
# SLURM_GTIDS=0
# SLURM_JOBID=32966067
# SLURM_JOB_ACCOUNT=cis210027p
# SLURM_JOB_CPUS_PER_NODE=1
# SLURM_JOB_GID=24886
# SLURM_JOB_ID=32966067
# SLURM_JOB_NAME=stats.sh
# SLURM_JOB_NODELIST=r212
# SLURM_JOB_NUM_NODES=1
# SLURM_JOB_PARTITION=RM-shared
# SLURM_JOB_QOS=rm
# SLURM_JOB_UID=97947
# SLURM_JOB_USER=ttao3
# SLURM_LOCALID=0
# SLURM_MEM_PER_CPU=1900
# SLURM_NNODES=1
# SLURM_NODEID=0
# SLURM_NODELIST=r212
# SLURM_NODE_ALIASES='(null)'
# SLURM_OPEN_MODE=a
# SLURM_PRIO_PROCESS=0
# SLURM_PROCID=0
# SLURM_SCRIPT_CONTEXT=prolog_task
# SLURM_SUBMIT_DIR=/ocean/projects/cis210027p/ttao3/espnet/egs2/hifitts/tts1
# SLURM_SUBMIT_HOST=br013.ib.bridges2.psc.edu
# SLURM_TASKS_PER_NODE=1
# SLURM_TASK_PID=59319
# SLURM_TOPOLOGY_ADDR=r212
# SLURM_TOPOLOGY_ADDR_PATTERN=node
# SLURM_WORKING_CLUSTER=bridges2:br003:6810:9728:109
# python3 -m espnet2.bin.gan_tts_train --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.30.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.30.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.30 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int 
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/librosa/util/files.py:10: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_filename
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/bin/python3 /ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.30.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.30.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.30 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int
Failed to import Flash Attention, using ESPnet default: No module named 'flash_attn_2_cuda'
Vocabulary size: 74
encoder self-attention layer type = relative self-attention
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/ocean/projects/cis210027p/ttao3/espnet/espnet2/gan_tts/vits/monotonic_align/__init__.py:19: UserWarning: Cython version is not available. Fallback to 'EXPERIMETAL' numba version. If you want to use the cython version, please build it as follows: `cd espnet2/gan_tts/vits/monotonic_align; python setup.py build_ext --inplace`
  warnings.warn(
pytorch.version=2.7.1+cu126, cuda.available=False, cudnn.version=90501, cudnn.benchmark=False, cudnn.deterministic=False
Model structure:
ESPnetGANTTSModel(
  (feats_extract): LinearSpectrogram(
    (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
  )
  (tts): VITS(
    (generator): VITSGenerator(
      (text_encoder): TextEncoder(
        (emb): Embedding(74, 192)
        (encoder): Encoder(
          (embed): Sequential(
            (0): RelPositionalEncoding(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (encoders): MultiSequential(
            (0): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (2): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (3): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (4): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (5): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (after_norm): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (decoder): HiFiGANGenerator(
        (input_conv): Conv1d(192, 512, kernel_size=(7,), stride=(1,), padding=(3,))
        (upsamples): ModuleList(
          (0): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (1): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(256, 128, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (2): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,))
          )
          (3): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,))
          )
        )
        (blocks): ModuleList(
          (0): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (1): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (2): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (3): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (4): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (5): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (6): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (7): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (8): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (9): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (10): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (11): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
        )
        (output_conv): Sequential(
          (0): LeakyReLU(negative_slope=0.01)
          (1): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,))
          (2): Tanh()
        )
        (global_conv): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
      )
      (posterior_encoder): PosteriorEncoder(
        (input_conv): Conv1d(513, 192, kernel_size=(1,), stride=(1,))
        (encoder): WaveNet(
          (conv_layers): ModuleList(
            (0-15): 16 x ResidualBlock(
              (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
              (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
              (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
            )
          )
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (flow): ResidualAffineCouplingBlock(
        (flows): ModuleList(
          (0): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (1): FlipFlow()
          (2): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (3): FlipFlow()
          (4): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (5): FlipFlow()
          (6): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (7): FlipFlow()
        )
      )
      (duration_predictor): StochasticDurationPredictor(
        (pre): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (log_flow): LogFlow()
        (flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (post_pre): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
        (post_dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (post_proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (post_flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (global_conv): Conv1d(256, 192, kernel_size=(1,), stride=(1,))
      )
      (global_emb): Embedding(128, 256)
    )
    (discriminator): HiFiGANMultiScaleMultiPeriodDiscriminator(
      (msd): HiFiGANMultiScaleDiscriminator(
        (discriminators): ModuleList(
          (0): HiFiGANScaleDiscriminator(
            (layers): ModuleList(
              (0): Sequential(
                (0): Conv1d(1, 128, kernel_size=(15,), stride=(1,), padding=(7,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv1d(128, 128, kernel_size=(41,), stride=(2,), padding=(20,), groups=4)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv1d(128, 256, kernel_size=(41,), stride=(2,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv1d(256, 512, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv1d(512, 1024, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (5): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(41,), stride=(1,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (6): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (7): Conv1d(1024, 1, kernel_size=(3,), stride=(1,), padding=(1,))
            )
          )
        )
      )
      (mpd): HiFiGANMultiPeriodDiscriminator(
        (discriminators): ModuleList(
          (0-4): 5 x HiFiGANPeriodDiscriminator(
            (convs): ModuleList(
              (0): Sequential(
                (0): Conv2d(1, 32, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv2d(32, 128, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv2d(128, 512, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv2d(512, 1024, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv2d(1024, 1024, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
            )
            (output_conv): Conv2d(1024, 1, kernel_size=(2, 1), stride=(1, 1), padding=(1, 0))
          )
        )
      )
    )
    (generator_adv_loss): GeneratorAdversarialLoss()
    (discriminator_adv_loss): DiscriminatorAdversarialLoss()
    (feat_match_loss): FeatureMatchLoss()
    (mel_loss): MelSpectrogramLoss(
      (wav_to_mel): LogMelFbank(
        (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
        (logmel): LogMel(sr=22050, n_fft=1024, n_mels=80, fmin=0, fmax=11025.0, htk=False)
      )
    )
    (kl_loss): KLDivergenceLoss()
  )
)

Model summary:
    Class Name: ESPnetGANTTSModel
    Total Number of model parameters: 96.37 M
    Number of trainable parameters: 96.37 M (100.0%)
    Size: 385.46 MB
    Type: torch.float32
Optimizer:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler: <torch.optim.lr_scheduler.ExponentialLR object at 0x14b5ac3c0250>
Optimizer2:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler2: <torch.optim.lr_scheduler.ExponentialLR object at 0x14b5ac3c0670>
Saving the configuration in exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.30/config.yaml
Namespace(config='conf/tuning/train_multi_spk_vits.yaml', print_config=False, log_level='INFO', drop_last_iter=False, dry_run=False, iterator_type='sequence', valid_iterator_type=None, output_dir='exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.30', ngpu=0, seed=777, num_workers=4, num_att_plot=3, dist_backend='nccl', dist_init_method='env://', dist_world_size=None, dist_rank=None, local_rank=None, dist_master_addr=None, dist_master_port=None, dist_launcher=None, multiprocessing_distributed=False, unused_parameters=True, sharded_ddp=False, use_deepspeed=False, deepspeed_config=None, gradient_as_bucket_view=True, ddp_comm_hook=None, cudnn_enabled=True, cudnn_benchmark=False, cudnn_deterministic=False, use_tf32=False, collect_stats=True, write_collected_feats=False, max_epoch=1000, patience=None, val_scheduler_criterion=('valid', 'loss'), early_stopping_criterion=('valid', 'loss', 'min'), best_model_criterion=[['train', 'total_count', 'max']], keep_nbest_models=10, nbest_averaging_interval=0, grad_clip=-1, grad_clip_type=2.0, grad_noise=False, accum_grad=1, no_forward_run=False, resume=False, train_dtype='float32', use_amp=False, log_interval=50, use_matplotlib=True, use_tensorboard=True, create_graph_in_tensorboard=False, use_wandb=False, wandb_project=None, wandb_id=None, wandb_entity=None, wandb_name=None, wandb_model_log_interval=-1, detect_anomaly=False, use_adapter=False, adapter='lora', save_strategy='all', adapter_conf={}, pretrain_path=None, init_param=[], ignore_init_mismatch=False, freeze_param=[], num_iters_per_epoch=1000, batch_size=20, valid_batch_size=None, batch_bins=3000000, valid_batch_bins=None, category_sample_size=10, train_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.30.scp'], valid_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.30.scp'], batch_type='numel', valid_batch_type=None, fold_length=[], sort_in_batch='descending', shuffle_within_batch=False, sort_batch='descending', multiple_iterator=False, chunk_length=500, chunk_shift_ratio=0.5, num_cache_chunks=1024, chunk_excluded_key_prefixes=[], chunk_default_fs=None, chunk_max_abs_length=None, chunk_discard_short_samples=True, train_data_path_and_name_and_type=[('dump/22k/raw/tr_no_dev/text', 'text', 'text'), ('dump/22k/raw/tr_no_dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/tr_no_dev/utt2sid', 'sids', 'text_int')], valid_data_path_and_name_and_type=[('dump/22k/raw/dev/text', 'text', 'text'), ('dump/22k/raw/dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/dev/utt2sid', 'sids', 'text_int')], multi_task_dataset=False, allow_variable_data_keys=False, max_cache_size=0.0, max_cache_fd=32, allow_multi_rates=False, valid_max_cache_size=None, exclude_weight_decay=False, exclude_weight_decay_conf={}, optim='adamw', optim_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler='exponentiallr', scheduler_conf={'gamma': 0.999875}, optim2='adamw', optim2_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler2='exponentiallr', scheduler2_conf={'gamma': 0.999875}, generator_first=False, skip_discriminator_prob=0.0, token_list=['<blank>', '<unk>', ' ', 'AH0', 'N', 'T', 'D', 'S', 'R', 'L', 'IH1', 'DH', 'M', 'EH1', 'Z', 'AE1', 'K', 'IH0', 'AH1', 'HH', 'W', 'ER0', 'V', 'IY1', 'F', 'UW1', 'P', 'AY1', 'B', 'AA1', 'AO1', 'EY1', 'IY0', 'OW1', 'NG', 'SH', 'G', 'Y', 'AW1', 'CH', 'ER1', 'UH1', 'TH', 'JH', 'OW0', 'EH2', 'IH2', 'OY1', 'EY2', 'AY2', 'EH0', 'UW0', 'AA2', 'AE2', 'OW2', 'AH2', 'AA0', 'ZH', 'AE0', 'AO2', 'UW2', 'AO0', 'AY0', 'IY2', 'AW2', 'UH2', 'EY0', 'ER2', 'AW0', 'UH0', 'OY2', 'OY0', "'", '<sos/eos>'], odim=None, model_conf={}, use_preprocessor=True, token_type='phn', bpemodel=None, non_linguistic_symbols=None, cleaner='tacotron', g2p='g2p_en', feats_extract='linear_spectrogram', feats_extract_conf={'n_fft': 1024, 'hop_length': 256, 'win_length': None}, normalize=None, normalize_conf={}, tts='vits', tts_conf={'generator_type': 'vits_generator', 'generator_params': {'hidden_channels': 192, 'spks': 128, 'global_channels': 256, 'segment_size': 32, 'text_encoder_attention_heads': 2, 'text_encoder_ffn_expand': 4, 'text_encoder_blocks': 6, 'text_encoder_positionwise_layer_type': 'conv1d', 'text_encoder_positionwise_conv_kernel_size': 3, 'text_encoder_positional_encoding_layer_type': 'rel_pos', 'text_encoder_self_attention_layer_type': 'rel_selfattn', 'text_encoder_activation_type': 'swish', 'text_encoder_normalize_before': True, 'text_encoder_dropout_rate': 0.1, 'text_encoder_positional_dropout_rate': 0.0, 'text_encoder_attention_dropout_rate': 0.1, 'use_macaron_style_in_text_encoder': True, 'use_conformer_conv_in_text_encoder': False, 'text_encoder_conformer_kernel_size': -1, 'decoder_kernel_size': 7, 'decoder_channels': 512, 'decoder_upsample_scales': [8, 8, 2, 2], 'decoder_upsample_kernel_sizes': [16, 16, 4, 4], 'decoder_resblock_kernel_sizes': [3, 7, 11], 'decoder_resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'use_weight_norm_in_decoder': True, 'posterior_encoder_kernel_size': 5, 'posterior_encoder_layers': 16, 'posterior_encoder_stacks': 1, 'posterior_encoder_base_dilation': 1, 'posterior_encoder_dropout_rate': 0.0, 'use_weight_norm_in_posterior_encoder': True, 'flow_flows': 4, 'flow_kernel_size': 5, 'flow_base_dilation': 1, 'flow_layers': 4, 'flow_dropout_rate': 0.0, 'use_weight_norm_in_flow': True, 'use_only_mean_in_flow': True, 'stochastic_duration_predictor_kernel_size': 3, 'stochastic_duration_predictor_dropout_rate': 0.5, 'stochastic_duration_predictor_flows': 4, 'stochastic_duration_predictor_dds_conv_layers': 3, 'vocabs': 74, 'aux_channels': 513}, 'discriminator_type': 'hifigan_multi_scale_multi_period_discriminator', 'discriminator_params': {'scales': 1, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'stride': 2, 'padding': 2}, 'scale_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'channels': 128, 'max_downsample_channels': 1024, 'max_groups': 16, 'bias': True, 'downsample_scales': [2, 2, 4, 4, 1], 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}, 'follow_official_norm': False, 'periods': [2, 3, 5, 7, 11], 'period_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [5, 3], 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'max_downsample_channels': 1024, 'bias': True, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}}, 'generator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'discriminator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'feat_match_loss_params': {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, 'mel_loss_params': {'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None, 'window': 'hann', 'n_mels': 80, 'fmin': 0, 'fmax': None, 'log_base': None}, 'lambda_adv': 1.0, 'lambda_mel': 45.0, 'lambda_feat_match': 2.0, 'lambda_dur': 1.0, 'lambda_kl': 1.0, 'sampling_rate': 22050, 'cache_generator_outputs': True, 'plot_pred_mos': False, 'mos_pred_tool': 'utmos'}, pitch_extract=None, pitch_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'f0max': 400, 'f0min': 80}, pitch_normalize=None, pitch_normalize_conf={}, energy_extract=None, energy_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None}, energy_normalize=None, energy_normalize_conf={}, required=['output_dir', 'token_list'], version='202503', distributed=False)
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1284, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 59561) is killed by signal: Killed. 

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 22, in <module>
    main()
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 18, in main
    GANTTSTask.main(cmd=cmd)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1225, in main
    cls.main_worker(args)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1441, in main_worker
    collect_stats(
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/main_funcs/collect_stats.py", line 51, in collect_stats
    for iiter, (keys, batch) in enumerate(itr, 1):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 733, in __next__
    data = self._next_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1491, in _next_data
    idx, data = self._get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1453, in _get_data
    success, data = self._try_get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1297, in _try_get_data
    raise RuntimeError(
RuntimeError: DataLoader worker (pid(s) 59561) exited unexpectedly
# Accounting: begin_time=1750836659
# Accounting: end_time=1750836799
# Accounting: time=140 threads=1
# Finished at Wed Jun 25 03:33:19 EDT 2025 with status 1
# Running on r212.ib.bridges2.psc.edu
# Started at Wed Jun 25 03:31:00 EDT 2025
# SLURMD_NODENAME=r212
# SLURM_ARRAY_JOB_ID=32966037
# SLURM_ARRAY_TASK_COUNT=32
# SLURM_ARRAY_TASK_ID=31
# SLURM_ARRAY_TASK_MAX=32
# SLURM_ARRAY_TASK_MIN=1
# SLURM_ARRAY_TASK_STEP=1
# SLURM_CLUSTER_NAME=bridges2
# SLURM_CONF=/var/spool/slurm/d/conf-cache/slurm.conf
# SLURM_CPUS_ON_NODE=1
# SLURM_EXPORT_ENV=ALL
# SLURM_GET_USER_ENV=1
# SLURM_GTIDS=0
# SLURM_JOBID=32966068
# SLURM_JOB_ACCOUNT=cis210027p
# SLURM_JOB_CPUS_PER_NODE=1
# SLURM_JOB_GID=24886
# SLURM_JOB_ID=32966068
# SLURM_JOB_NAME=stats.sh
# SLURM_JOB_NODELIST=r212
# SLURM_JOB_NUM_NODES=1
# SLURM_JOB_PARTITION=RM-shared
# SLURM_JOB_QOS=rm
# SLURM_JOB_UID=97947
# SLURM_JOB_USER=ttao3
# SLURM_LOCALID=0
# SLURM_MEM_PER_CPU=1900
# SLURM_NNODES=1
# SLURM_NODEID=0
# SLURM_NODELIST=r212
# SLURM_NODE_ALIASES='(null)'
# SLURM_OPEN_MODE=a
# SLURM_PRIO_PROCESS=0
# SLURM_PROCID=0
# SLURM_SCRIPT_CONTEXT=prolog_task
# SLURM_SUBMIT_DIR=/ocean/projects/cis210027p/ttao3/espnet/egs2/hifitts/tts1
# SLURM_SUBMIT_HOST=br013.ib.bridges2.psc.edu
# SLURM_TASKS_PER_NODE=1
# SLURM_TASK_PID=59382
# SLURM_TOPOLOGY_ADDR=r212
# SLURM_TOPOLOGY_ADDR_PATTERN=node
# SLURM_WORKING_CLUSTER=bridges2:br003:6810:9728:109
# python3 -m espnet2.bin.gan_tts_train --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.31.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.31.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.31 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int 
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/librosa/util/files.py:10: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_filename
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/bin/python3 /ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.31.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.31.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.31 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int
Failed to import Flash Attention, using ESPnet default: No module named 'flash_attn_2_cuda'
Vocabulary size: 74
encoder self-attention layer type = relative self-attention
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/ocean/projects/cis210027p/ttao3/espnet/espnet2/gan_tts/vits/monotonic_align/__init__.py:19: UserWarning: Cython version is not available. Fallback to 'EXPERIMETAL' numba version. If you want to use the cython version, please build it as follows: `cd espnet2/gan_tts/vits/monotonic_align; python setup.py build_ext --inplace`
  warnings.warn(
pytorch.version=2.7.1+cu126, cuda.available=False, cudnn.version=90501, cudnn.benchmark=False, cudnn.deterministic=False
Model structure:
ESPnetGANTTSModel(
  (feats_extract): LinearSpectrogram(
    (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
  )
  (tts): VITS(
    (generator): VITSGenerator(
      (text_encoder): TextEncoder(
        (emb): Embedding(74, 192)
        (encoder): Encoder(
          (embed): Sequential(
            (0): RelPositionalEncoding(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (encoders): MultiSequential(
            (0): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (2): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (3): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (4): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (5): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (after_norm): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (decoder): HiFiGANGenerator(
        (input_conv): Conv1d(192, 512, kernel_size=(7,), stride=(1,), padding=(3,))
        (upsamples): ModuleList(
          (0): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (1): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(256, 128, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (2): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,))
          )
          (3): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,))
          )
        )
        (blocks): ModuleList(
          (0): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (1): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (2): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (3): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (4): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (5): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (6): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (7): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (8): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (9): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (10): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (11): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
        )
        (output_conv): Sequential(
          (0): LeakyReLU(negative_slope=0.01)
          (1): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,))
          (2): Tanh()
        )
        (global_conv): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
      )
      (posterior_encoder): PosteriorEncoder(
        (input_conv): Conv1d(513, 192, kernel_size=(1,), stride=(1,))
        (encoder): WaveNet(
          (conv_layers): ModuleList(
            (0-15): 16 x ResidualBlock(
              (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
              (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
              (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
            )
          )
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (flow): ResidualAffineCouplingBlock(
        (flows): ModuleList(
          (0): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (1): FlipFlow()
          (2): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (3): FlipFlow()
          (4): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (5): FlipFlow()
          (6): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (7): FlipFlow()
        )
      )
      (duration_predictor): StochasticDurationPredictor(
        (pre): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (log_flow): LogFlow()
        (flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (post_pre): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
        (post_dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (post_proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (post_flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (global_conv): Conv1d(256, 192, kernel_size=(1,), stride=(1,))
      )
      (global_emb): Embedding(128, 256)
    )
    (discriminator): HiFiGANMultiScaleMultiPeriodDiscriminator(
      (msd): HiFiGANMultiScaleDiscriminator(
        (discriminators): ModuleList(
          (0): HiFiGANScaleDiscriminator(
            (layers): ModuleList(
              (0): Sequential(
                (0): Conv1d(1, 128, kernel_size=(15,), stride=(1,), padding=(7,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv1d(128, 128, kernel_size=(41,), stride=(2,), padding=(20,), groups=4)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv1d(128, 256, kernel_size=(41,), stride=(2,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv1d(256, 512, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv1d(512, 1024, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (5): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(41,), stride=(1,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (6): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (7): Conv1d(1024, 1, kernel_size=(3,), stride=(1,), padding=(1,))
            )
          )
        )
      )
      (mpd): HiFiGANMultiPeriodDiscriminator(
        (discriminators): ModuleList(
          (0-4): 5 x HiFiGANPeriodDiscriminator(
            (convs): ModuleList(
              (0): Sequential(
                (0): Conv2d(1, 32, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv2d(32, 128, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv2d(128, 512, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv2d(512, 1024, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv2d(1024, 1024, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
            )
            (output_conv): Conv2d(1024, 1, kernel_size=(2, 1), stride=(1, 1), padding=(1, 0))
          )
        )
      )
    )
    (generator_adv_loss): GeneratorAdversarialLoss()
    (discriminator_adv_loss): DiscriminatorAdversarialLoss()
    (feat_match_loss): FeatureMatchLoss()
    (mel_loss): MelSpectrogramLoss(
      (wav_to_mel): LogMelFbank(
        (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
        (logmel): LogMel(sr=22050, n_fft=1024, n_mels=80, fmin=0, fmax=11025.0, htk=False)
      )
    )
    (kl_loss): KLDivergenceLoss()
  )
)

Model summary:
    Class Name: ESPnetGANTTSModel
    Total Number of model parameters: 96.37 M
    Number of trainable parameters: 96.37 M (100.0%)
    Size: 385.46 MB
    Type: torch.float32
Optimizer:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler: <torch.optim.lr_scheduler.ExponentialLR object at 0x1521937d1220>
Optimizer2:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler2: <torch.optim.lr_scheduler.ExponentialLR object at 0x1521937d1640>
Saving the configuration in exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.31/config.yaml
Namespace(config='conf/tuning/train_multi_spk_vits.yaml', print_config=False, log_level='INFO', drop_last_iter=False, dry_run=False, iterator_type='sequence', valid_iterator_type=None, output_dir='exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.31', ngpu=0, seed=777, num_workers=4, num_att_plot=3, dist_backend='nccl', dist_init_method='env://', dist_world_size=None, dist_rank=None, local_rank=None, dist_master_addr=None, dist_master_port=None, dist_launcher=None, multiprocessing_distributed=False, unused_parameters=True, sharded_ddp=False, use_deepspeed=False, deepspeed_config=None, gradient_as_bucket_view=True, ddp_comm_hook=None, cudnn_enabled=True, cudnn_benchmark=False, cudnn_deterministic=False, use_tf32=False, collect_stats=True, write_collected_feats=False, max_epoch=1000, patience=None, val_scheduler_criterion=('valid', 'loss'), early_stopping_criterion=('valid', 'loss', 'min'), best_model_criterion=[['train', 'total_count', 'max']], keep_nbest_models=10, nbest_averaging_interval=0, grad_clip=-1, grad_clip_type=2.0, grad_noise=False, accum_grad=1, no_forward_run=False, resume=False, train_dtype='float32', use_amp=False, log_interval=50, use_matplotlib=True, use_tensorboard=True, create_graph_in_tensorboard=False, use_wandb=False, wandb_project=None, wandb_id=None, wandb_entity=None, wandb_name=None, wandb_model_log_interval=-1, detect_anomaly=False, use_adapter=False, adapter='lora', save_strategy='all', adapter_conf={}, pretrain_path=None, init_param=[], ignore_init_mismatch=False, freeze_param=[], num_iters_per_epoch=1000, batch_size=20, valid_batch_size=None, batch_bins=3000000, valid_batch_bins=None, category_sample_size=10, train_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.31.scp'], valid_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.31.scp'], batch_type='numel', valid_batch_type=None, fold_length=[], sort_in_batch='descending', shuffle_within_batch=False, sort_batch='descending', multiple_iterator=False, chunk_length=500, chunk_shift_ratio=0.5, num_cache_chunks=1024, chunk_excluded_key_prefixes=[], chunk_default_fs=None, chunk_max_abs_length=None, chunk_discard_short_samples=True, train_data_path_and_name_and_type=[('dump/22k/raw/tr_no_dev/text', 'text', 'text'), ('dump/22k/raw/tr_no_dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/tr_no_dev/utt2sid', 'sids', 'text_int')], valid_data_path_and_name_and_type=[('dump/22k/raw/dev/text', 'text', 'text'), ('dump/22k/raw/dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/dev/utt2sid', 'sids', 'text_int')], multi_task_dataset=False, allow_variable_data_keys=False, max_cache_size=0.0, max_cache_fd=32, allow_multi_rates=False, valid_max_cache_size=None, exclude_weight_decay=False, exclude_weight_decay_conf={}, optim='adamw', optim_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler='exponentiallr', scheduler_conf={'gamma': 0.999875}, optim2='adamw', optim2_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler2='exponentiallr', scheduler2_conf={'gamma': 0.999875}, generator_first=False, skip_discriminator_prob=0.0, token_list=['<blank>', '<unk>', ' ', 'AH0', 'N', 'T', 'D', 'S', 'R', 'L', 'IH1', 'DH', 'M', 'EH1', 'Z', 'AE1', 'K', 'IH0', 'AH1', 'HH', 'W', 'ER0', 'V', 'IY1', 'F', 'UW1', 'P', 'AY1', 'B', 'AA1', 'AO1', 'EY1', 'IY0', 'OW1', 'NG', 'SH', 'G', 'Y', 'AW1', 'CH', 'ER1', 'UH1', 'TH', 'JH', 'OW0', 'EH2', 'IH2', 'OY1', 'EY2', 'AY2', 'EH0', 'UW0', 'AA2', 'AE2', 'OW2', 'AH2', 'AA0', 'ZH', 'AE0', 'AO2', 'UW2', 'AO0', 'AY0', 'IY2', 'AW2', 'UH2', 'EY0', 'ER2', 'AW0', 'UH0', 'OY2', 'OY0', "'", '<sos/eos>'], odim=None, model_conf={}, use_preprocessor=True, token_type='phn', bpemodel=None, non_linguistic_symbols=None, cleaner='tacotron', g2p='g2p_en', feats_extract='linear_spectrogram', feats_extract_conf={'n_fft': 1024, 'hop_length': 256, 'win_length': None}, normalize=None, normalize_conf={}, tts='vits', tts_conf={'generator_type': 'vits_generator', 'generator_params': {'hidden_channels': 192, 'spks': 128, 'global_channels': 256, 'segment_size': 32, 'text_encoder_attention_heads': 2, 'text_encoder_ffn_expand': 4, 'text_encoder_blocks': 6, 'text_encoder_positionwise_layer_type': 'conv1d', 'text_encoder_positionwise_conv_kernel_size': 3, 'text_encoder_positional_encoding_layer_type': 'rel_pos', 'text_encoder_self_attention_layer_type': 'rel_selfattn', 'text_encoder_activation_type': 'swish', 'text_encoder_normalize_before': True, 'text_encoder_dropout_rate': 0.1, 'text_encoder_positional_dropout_rate': 0.0, 'text_encoder_attention_dropout_rate': 0.1, 'use_macaron_style_in_text_encoder': True, 'use_conformer_conv_in_text_encoder': False, 'text_encoder_conformer_kernel_size': -1, 'decoder_kernel_size': 7, 'decoder_channels': 512, 'decoder_upsample_scales': [8, 8, 2, 2], 'decoder_upsample_kernel_sizes': [16, 16, 4, 4], 'decoder_resblock_kernel_sizes': [3, 7, 11], 'decoder_resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'use_weight_norm_in_decoder': True, 'posterior_encoder_kernel_size': 5, 'posterior_encoder_layers': 16, 'posterior_encoder_stacks': 1, 'posterior_encoder_base_dilation': 1, 'posterior_encoder_dropout_rate': 0.0, 'use_weight_norm_in_posterior_encoder': True, 'flow_flows': 4, 'flow_kernel_size': 5, 'flow_base_dilation': 1, 'flow_layers': 4, 'flow_dropout_rate': 0.0, 'use_weight_norm_in_flow': True, 'use_only_mean_in_flow': True, 'stochastic_duration_predictor_kernel_size': 3, 'stochastic_duration_predictor_dropout_rate': 0.5, 'stochastic_duration_predictor_flows': 4, 'stochastic_duration_predictor_dds_conv_layers': 3, 'vocabs': 74, 'aux_channels': 513}, 'discriminator_type': 'hifigan_multi_scale_multi_period_discriminator', 'discriminator_params': {'scales': 1, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'stride': 2, 'padding': 2}, 'scale_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'channels': 128, 'max_downsample_channels': 1024, 'max_groups': 16, 'bias': True, 'downsample_scales': [2, 2, 4, 4, 1], 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}, 'follow_official_norm': False, 'periods': [2, 3, 5, 7, 11], 'period_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [5, 3], 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'max_downsample_channels': 1024, 'bias': True, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}}, 'generator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'discriminator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'feat_match_loss_params': {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, 'mel_loss_params': {'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None, 'window': 'hann', 'n_mels': 80, 'fmin': 0, 'fmax': None, 'log_base': None}, 'lambda_adv': 1.0, 'lambda_mel': 45.0, 'lambda_feat_match': 2.0, 'lambda_dur': 1.0, 'lambda_kl': 1.0, 'sampling_rate': 22050, 'cache_generator_outputs': True, 'plot_pred_mos': False, 'mos_pred_tool': 'utmos'}, pitch_extract=None, pitch_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'f0max': 400, 'f0min': 80}, pitch_normalize=None, pitch_normalize_conf={}, energy_extract=None, energy_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None}, energy_normalize=None, energy_normalize_conf={}, required=['output_dir', 'token_list'], version='202503', distributed=False)
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1284, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 59560) is killed by signal: Killed. 

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 22, in <module>
    main()
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 18, in main
    GANTTSTask.main(cmd=cmd)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1225, in main
    cls.main_worker(args)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1441, in main_worker
    collect_stats(
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/main_funcs/collect_stats.py", line 51, in collect_stats
    for iiter, (keys, batch) in enumerate(itr, 1):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 733, in __next__
    data = self._next_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1491, in _next_data
    idx, data = self._get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1453, in _get_data
    success, data = self._try_get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1297, in _try_get_data
    raise RuntimeError(
RuntimeError: DataLoader worker (pid(s) 59560) exited unexpectedly
# Accounting: begin_time=1750836660
# Accounting: end_time=1750836799
# Accounting: time=139 threads=1
# Finished at Wed Jun 25 03:33:19 EDT 2025 with status 1
# Running on r212.ib.bridges2.psc.edu
# Started at Wed Jun 25 03:31:00 EDT 2025
# SLURMD_NODENAME=r212
# SLURM_ARRAY_JOB_ID=32966037
# SLURM_ARRAY_TASK_COUNT=32
# SLURM_ARRAY_TASK_ID=32
# SLURM_ARRAY_TASK_MAX=32
# SLURM_ARRAY_TASK_MIN=1
# SLURM_ARRAY_TASK_STEP=1
# SLURM_CLUSTER_NAME=bridges2
# SLURM_CONF=/var/spool/slurm/d/conf-cache/slurm.conf
# SLURM_CPUS_ON_NODE=1
# SLURM_EXPORT_ENV=ALL
# SLURM_GET_USER_ENV=1
# SLURM_GTIDS=0
# SLURM_JOBID=32966037
# SLURM_JOB_ACCOUNT=cis210027p
# SLURM_JOB_CPUS_PER_NODE=1
# SLURM_JOB_GID=24886
# SLURM_JOB_ID=32966037
# SLURM_JOB_NAME=stats.sh
# SLURM_JOB_NODELIST=r212
# SLURM_JOB_NUM_NODES=1
# SLURM_JOB_PARTITION=RM-shared
# SLURM_JOB_QOS=rm
# SLURM_JOB_UID=97947
# SLURM_JOB_USER=ttao3
# SLURM_LOCALID=0
# SLURM_MEM_PER_CPU=1900
# SLURM_NNODES=1
# SLURM_NODEID=0
# SLURM_NODELIST=r212
# SLURM_NODE_ALIASES='(null)'
# SLURM_OPEN_MODE=a
# SLURM_PRIO_PROCESS=0
# SLURM_PROCID=0
# SLURM_SCRIPT_CONTEXT=prolog_task
# SLURM_SUBMIT_DIR=/ocean/projects/cis210027p/ttao3/espnet/egs2/hifitts/tts1
# SLURM_SUBMIT_HOST=br013.ib.bridges2.psc.edu
# SLURM_TASKS_PER_NODE=1
# SLURM_TASK_PID=59383
# SLURM_TOPOLOGY_ADDR=r212
# SLURM_TOPOLOGY_ADDR_PATTERN=node
# SLURM_WORKING_CLUSTER=bridges2:br003:6810:9728:109
# python3 -m espnet2.bin.gan_tts_train --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.32.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.32.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.32 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int 
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/librosa/util/files.py:10: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_filename
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/bin/python3 /ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py --collect_stats true --write_collected_feats false --use_preprocessor true --token_type phn --token_list dump/22k/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --normalize none --pitch_normalize none --energy_normalize none --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/22k/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/22k/raw/dev/wav.scp,speech,sound --train_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.32.scp --valid_shape_file exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.32.scp --output_dir exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.32 --config conf/tuning/train_multi_spk_vits.yaml --feats_extract linear_spectrogram --feats_extract_conf n_fft=1024 --feats_extract_conf hop_length=256 --feats_extract_conf win_length=null --pitch_extract_conf fs=22050 --pitch_extract_conf n_fft=1024 --pitch_extract_conf hop_length=256 --pitch_extract_conf f0max=400 --pitch_extract_conf f0min=80 --energy_extract_conf fs=22050 --energy_extract_conf n_fft=1024 --energy_extract_conf hop_length=256 --energy_extract_conf win_length=null --train_data_path_and_name_and_type dump/22k/raw/tr_no_dev/utt2sid,sids,text_int --valid_data_path_and_name_and_type dump/22k/raw/dev/utt2sid,sids,text_int
Failed to import Flash Attention, using ESPnet default: No module named 'flash_attn_2_cuda'
Vocabulary size: 74
encoder self-attention layer type = relative self-attention
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/ocean/projects/cis210027p/ttao3/espnet/espnet2/gan_tts/vits/monotonic_align/__init__.py:19: UserWarning: Cython version is not available. Fallback to 'EXPERIMETAL' numba version. If you want to use the cython version, please build it as follows: `cd espnet2/gan_tts/vits/monotonic_align; python setup.py build_ext --inplace`
  warnings.warn(
pytorch.version=2.7.1+cu126, cuda.available=False, cudnn.version=90501, cudnn.benchmark=False, cudnn.deterministic=False
Model structure:
ESPnetGANTTSModel(
  (feats_extract): LinearSpectrogram(
    (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
  )
  (tts): VITS(
    (generator): VITSGenerator(
      (text_encoder): TextEncoder(
        (emb): Embedding(74, 192)
        (encoder): Encoder(
          (embed): Sequential(
            (0): RelPositionalEncoding(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (encoders): MultiSequential(
            (0): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (2): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (3): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (4): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (5): EncoderLayer(
              (self_attn): RelPositionMultiHeadedAttention(
                (linear_q): Linear(in_features=192, out_features=192, bias=True)
                (linear_k): Linear(in_features=192, out_features=192, bias=True)
                (linear_v): Linear(in_features=192, out_features=192, bias=True)
                (linear_out): Linear(in_features=192, out_features=192, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (q_norm): Identity()
                (k_norm): Identity()
                (linear_pos): Linear(in_features=192, out_features=192, bias=False)
              )
              (feed_forward): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (feed_forward_macaron): MultiLayeredConv1d(
                (w_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))
                (w_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (norm_ff): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_mha): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (norm_ff_macaron): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (after_norm): LayerNorm((192,), eps=1e-12, elementwise_affine=True)
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (decoder): HiFiGANGenerator(
        (input_conv): Conv1d(192, 512, kernel_size=(7,), stride=(1,), padding=(3,))
        (upsamples): ModuleList(
          (0): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (1): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(256, 128, kernel_size=(16,), stride=(8,), padding=(4,))
          )
          (2): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,))
          )
          (3): Sequential(
            (0): LeakyReLU(negative_slope=0.1)
            (1): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,))
          )
        )
        (blocks): ModuleList(
          (0): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (1): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (2): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (3): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (4): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (5): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (6): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (7): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (8): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
          (9): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              )
            )
          )
          (10): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))
              )
            )
          )
          (11): ResidualBlock(
            (convs1): ModuleList(
              (0): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
              (1): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))
              )
              (2): Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))
              )
            )
            (convs2): ModuleList(
              (0-2): 3 x Sequential(
                (0): LeakyReLU(negative_slope=0.1)
                (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))
              )
            )
          )
        )
        (output_conv): Sequential(
          (0): LeakyReLU(negative_slope=0.01)
          (1): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,))
          (2): Tanh()
        )
        (global_conv): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
      )
      (posterior_encoder): PosteriorEncoder(
        (input_conv): Conv1d(513, 192, kernel_size=(1,), stride=(1,))
        (encoder): WaveNet(
          (conv_layers): ModuleList(
            (0-15): 16 x ResidualBlock(
              (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
              (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
              (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
            )
          )
        )
        (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))
      )
      (flow): ResidualAffineCouplingBlock(
        (flows): ModuleList(
          (0): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (1): FlipFlow()
          (2): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (3): FlipFlow()
          (4): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (5): FlipFlow()
          (6): ResidualAffineCouplingLayer(
            (input_conv): Conv1d(96, 192, kernel_size=(1,), stride=(1,))
            (encoder): WaveNet(
              (conv_layers): ModuleList(
                (0-3): 4 x ResidualBlock(
                  (conv): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
                  (conv1x1_glo): Conv1d1x1(256, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (conv1x1_out): Conv1d1x1(192, 384, kernel_size=(1,), stride=(1,))
                )
              )
            )
            (proj): Conv1d(192, 96, kernel_size=(1,), stride=(1,))
          )
          (7): FlipFlow()
        )
      )
      (duration_predictor): StochasticDurationPredictor(
        (pre): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (log_flow): LogFlow()
        (flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (post_pre): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
        (post_dds): DilatedDepthSeparableConv(
          (convs): ModuleList(
            (0): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (1): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
            (2): Sequential(
              (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
              (1): Transpose()
              (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (3): Transpose()
              (4): GELU(approximate='none')
              (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (6): Transpose()
              (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (8): Transpose()
              (9): GELU(approximate='none')
              (10): Dropout(p=0.5, inplace=False)
            )
          )
        )
        (post_proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        (post_flows): ModuleList(
          (0): ElementwiseAffineFlow()
          (1): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (2): FlipFlow()
          (3): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (4): FlipFlow()
          (5): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (6): FlipFlow()
          (7): ConvFlow(
            (input_conv): Conv1d(1, 192, kernel_size=(1,), stride=(1,))
            (dds_conv): DilatedDepthSeparableConv(
              (convs): ModuleList(
                (0): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (1): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
                (2): Sequential(
                  (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=192)
                  (1): Transpose()
                  (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (3): Transpose()
                  (4): GELU(approximate='none')
                  (5): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
                  (6): Transpose()
                  (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                  (8): Transpose()
                  (9): GELU(approximate='none')
                  (10): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (proj): Conv1d(192, 29, kernel_size=(1,), stride=(1,))
          )
          (8): FlipFlow()
        )
        (global_conv): Conv1d(256, 192, kernel_size=(1,), stride=(1,))
      )
      (global_emb): Embedding(128, 256)
    )
    (discriminator): HiFiGANMultiScaleMultiPeriodDiscriminator(
      (msd): HiFiGANMultiScaleDiscriminator(
        (discriminators): ModuleList(
          (0): HiFiGANScaleDiscriminator(
            (layers): ModuleList(
              (0): Sequential(
                (0): Conv1d(1, 128, kernel_size=(15,), stride=(1,), padding=(7,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv1d(128, 128, kernel_size=(41,), stride=(2,), padding=(20,), groups=4)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv1d(128, 256, kernel_size=(41,), stride=(2,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv1d(256, 512, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv1d(512, 1024, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (5): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(41,), stride=(1,), padding=(20,), groups=16)
                (1): LeakyReLU(negative_slope=0.1)
              )
              (6): Sequential(
                (0): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (7): Conv1d(1024, 1, kernel_size=(3,), stride=(1,), padding=(1,))
            )
          )
        )
      )
      (mpd): HiFiGANMultiPeriodDiscriminator(
        (discriminators): ModuleList(
          (0-4): 5 x HiFiGANPeriodDiscriminator(
            (convs): ModuleList(
              (0): Sequential(
                (0): Conv2d(1, 32, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (1): Sequential(
                (0): Conv2d(32, 128, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (2): Sequential(
                (0): Conv2d(128, 512, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (3): Sequential(
                (0): Conv2d(512, 1024, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
              (4): Sequential(
                (0): Conv2d(1024, 1024, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
                (1): LeakyReLU(negative_slope=0.1)
              )
            )
            (output_conv): Conv2d(1024, 1, kernel_size=(2, 1), stride=(1, 1), padding=(1, 0))
          )
        )
      )
    )
    (generator_adv_loss): GeneratorAdversarialLoss()
    (discriminator_adv_loss): DiscriminatorAdversarialLoss()
    (feat_match_loss): FeatureMatchLoss()
    (mel_loss): MelSpectrogramLoss(
      (wav_to_mel): LogMelFbank(
        (stft): Stft(n_fft=1024, win_length=1024, hop_length=256, center=True, normalized=False, onesided=True)
        (logmel): LogMel(sr=22050, n_fft=1024, n_mels=80, fmin=0, fmax=11025.0, htk=False)
      )
    )
    (kl_loss): KLDivergenceLoss()
  )
)

Model summary:
    Class Name: ESPnetGANTTSModel
    Total Number of model parameters: 96.37 M
    Number of trainable parameters: 96.37 M (100.0%)
    Size: 385.46 MB
    Type: torch.float32
Optimizer:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler: <torch.optim.lr_scheduler.ExponentialLR object at 0x14c4ba6f4220>
Optimizer2:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.8, 0.99]
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-09
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
Scheduler2: <torch.optim.lr_scheduler.ExponentialLR object at 0x14c4ba6f4640>
Saving the configuration in exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.32/config.yaml
Namespace(config='conf/tuning/train_multi_spk_vits.yaml', print_config=False, log_level='INFO', drop_last_iter=False, dry_run=False, iterator_type='sequence', valid_iterator_type=None, output_dir='exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/stats.32', ngpu=0, seed=777, num_workers=4, num_att_plot=3, dist_backend='nccl', dist_init_method='env://', dist_world_size=None, dist_rank=None, local_rank=None, dist_master_addr=None, dist_master_port=None, dist_launcher=None, multiprocessing_distributed=False, unused_parameters=True, sharded_ddp=False, use_deepspeed=False, deepspeed_config=None, gradient_as_bucket_view=True, ddp_comm_hook=None, cudnn_enabled=True, cudnn_benchmark=False, cudnn_deterministic=False, use_tf32=False, collect_stats=True, write_collected_feats=False, max_epoch=1000, patience=None, val_scheduler_criterion=('valid', 'loss'), early_stopping_criterion=('valid', 'loss', 'min'), best_model_criterion=[['train', 'total_count', 'max']], keep_nbest_models=10, nbest_averaging_interval=0, grad_clip=-1, grad_clip_type=2.0, grad_noise=False, accum_grad=1, no_forward_run=False, resume=False, train_dtype='float32', use_amp=False, log_interval=50, use_matplotlib=True, use_tensorboard=True, create_graph_in_tensorboard=False, use_wandb=False, wandb_project=None, wandb_id=None, wandb_entity=None, wandb_name=None, wandb_model_log_interval=-1, detect_anomaly=False, use_adapter=False, adapter='lora', save_strategy='all', adapter_conf={}, pretrain_path=None, init_param=[], ignore_init_mismatch=False, freeze_param=[], num_iters_per_epoch=1000, batch_size=20, valid_batch_size=None, batch_bins=3000000, valid_batch_bins=None, category_sample_size=10, train_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/train.32.scp'], valid_shape_file=['exp/22k/tts_stats_raw_linear_spectrogram_phn_tacotron_g2p_en/logdir/valid.32.scp'], batch_type='numel', valid_batch_type=None, fold_length=[], sort_in_batch='descending', shuffle_within_batch=False, sort_batch='descending', multiple_iterator=False, chunk_length=500, chunk_shift_ratio=0.5, num_cache_chunks=1024, chunk_excluded_key_prefixes=[], chunk_default_fs=None, chunk_max_abs_length=None, chunk_discard_short_samples=True, train_data_path_and_name_and_type=[('dump/22k/raw/tr_no_dev/text', 'text', 'text'), ('dump/22k/raw/tr_no_dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/tr_no_dev/utt2sid', 'sids', 'text_int')], valid_data_path_and_name_and_type=[('dump/22k/raw/dev/text', 'text', 'text'), ('dump/22k/raw/dev/wav.scp', 'speech', 'sound'), ('dump/22k/raw/dev/utt2sid', 'sids', 'text_int')], multi_task_dataset=False, allow_variable_data_keys=False, max_cache_size=0.0, max_cache_fd=32, allow_multi_rates=False, valid_max_cache_size=None, exclude_weight_decay=False, exclude_weight_decay_conf={}, optim='adamw', optim_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler='exponentiallr', scheduler_conf={'gamma': 0.999875}, optim2='adamw', optim2_conf={'lr': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.0}, scheduler2='exponentiallr', scheduler2_conf={'gamma': 0.999875}, generator_first=False, skip_discriminator_prob=0.0, token_list=['<blank>', '<unk>', ' ', 'AH0', 'N', 'T', 'D', 'S', 'R', 'L', 'IH1', 'DH', 'M', 'EH1', 'Z', 'AE1', 'K', 'IH0', 'AH1', 'HH', 'W', 'ER0', 'V', 'IY1', 'F', 'UW1', 'P', 'AY1', 'B', 'AA1', 'AO1', 'EY1', 'IY0', 'OW1', 'NG', 'SH', 'G', 'Y', 'AW1', 'CH', 'ER1', 'UH1', 'TH', 'JH', 'OW0', 'EH2', 'IH2', 'OY1', 'EY2', 'AY2', 'EH0', 'UW0', 'AA2', 'AE2', 'OW2', 'AH2', 'AA0', 'ZH', 'AE0', 'AO2', 'UW2', 'AO0', 'AY0', 'IY2', 'AW2', 'UH2', 'EY0', 'ER2', 'AW0', 'UH0', 'OY2', 'OY0', "'", '<sos/eos>'], odim=None, model_conf={}, use_preprocessor=True, token_type='phn', bpemodel=None, non_linguistic_symbols=None, cleaner='tacotron', g2p='g2p_en', feats_extract='linear_spectrogram', feats_extract_conf={'n_fft': 1024, 'hop_length': 256, 'win_length': None}, normalize=None, normalize_conf={}, tts='vits', tts_conf={'generator_type': 'vits_generator', 'generator_params': {'hidden_channels': 192, 'spks': 128, 'global_channels': 256, 'segment_size': 32, 'text_encoder_attention_heads': 2, 'text_encoder_ffn_expand': 4, 'text_encoder_blocks': 6, 'text_encoder_positionwise_layer_type': 'conv1d', 'text_encoder_positionwise_conv_kernel_size': 3, 'text_encoder_positional_encoding_layer_type': 'rel_pos', 'text_encoder_self_attention_layer_type': 'rel_selfattn', 'text_encoder_activation_type': 'swish', 'text_encoder_normalize_before': True, 'text_encoder_dropout_rate': 0.1, 'text_encoder_positional_dropout_rate': 0.0, 'text_encoder_attention_dropout_rate': 0.1, 'use_macaron_style_in_text_encoder': True, 'use_conformer_conv_in_text_encoder': False, 'text_encoder_conformer_kernel_size': -1, 'decoder_kernel_size': 7, 'decoder_channels': 512, 'decoder_upsample_scales': [8, 8, 2, 2], 'decoder_upsample_kernel_sizes': [16, 16, 4, 4], 'decoder_resblock_kernel_sizes': [3, 7, 11], 'decoder_resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'use_weight_norm_in_decoder': True, 'posterior_encoder_kernel_size': 5, 'posterior_encoder_layers': 16, 'posterior_encoder_stacks': 1, 'posterior_encoder_base_dilation': 1, 'posterior_encoder_dropout_rate': 0.0, 'use_weight_norm_in_posterior_encoder': True, 'flow_flows': 4, 'flow_kernel_size': 5, 'flow_base_dilation': 1, 'flow_layers': 4, 'flow_dropout_rate': 0.0, 'use_weight_norm_in_flow': True, 'use_only_mean_in_flow': True, 'stochastic_duration_predictor_kernel_size': 3, 'stochastic_duration_predictor_dropout_rate': 0.5, 'stochastic_duration_predictor_flows': 4, 'stochastic_duration_predictor_dds_conv_layers': 3, 'vocabs': 74, 'aux_channels': 513}, 'discriminator_type': 'hifigan_multi_scale_multi_period_discriminator', 'discriminator_params': {'scales': 1, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'stride': 2, 'padding': 2}, 'scale_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'channels': 128, 'max_downsample_channels': 1024, 'max_groups': 16, 'bias': True, 'downsample_scales': [2, 2, 4, 4, 1], 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}, 'follow_official_norm': False, 'periods': [2, 3, 5, 7, 11], 'period_discriminator_params': {'in_channels': 1, 'out_channels': 1, 'kernel_sizes': [5, 3], 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'max_downsample_channels': 1024, 'bias': True, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'use_weight_norm': True, 'use_spectral_norm': False}}, 'generator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'discriminator_adv_loss_params': {'average_by_discriminators': False, 'loss_type': 'mse'}, 'feat_match_loss_params': {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, 'mel_loss_params': {'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None, 'window': 'hann', 'n_mels': 80, 'fmin': 0, 'fmax': None, 'log_base': None}, 'lambda_adv': 1.0, 'lambda_mel': 45.0, 'lambda_feat_match': 2.0, 'lambda_dur': 1.0, 'lambda_kl': 1.0, 'sampling_rate': 22050, 'cache_generator_outputs': True, 'plot_pred_mos': False, 'mos_pred_tool': 'utmos'}, pitch_extract=None, pitch_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'f0max': 400, 'f0min': 80}, pitch_normalize=None, pitch_normalize_conf={}, energy_extract=None, energy_extract_conf={'fs': 22050, 'n_fft': 1024, 'hop_length': 256, 'win_length': None}, energy_normalize=None, energy_normalize_conf={}, required=['output_dir', 'token_list'], version='202503', distributed=False)
/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1284, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 59577) is killed by signal: Killed. 

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 22, in <module>
    main()
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/bin/gan_tts_train.py", line 18, in main
    GANTTSTask.main(cmd=cmd)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1225, in main
    cls.main_worker(args)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/tasks/abs_task.py", line 1441, in main_worker
    collect_stats(
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/ocean/projects/cis210027p/ttao3/espnet/espnet2/main_funcs/collect_stats.py", line 51, in collect_stats
    for iiter, (keys, batch) in enumerate(itr, 1):
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 733, in __next__
    data = self._next_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1491, in _next_data
    idx, data = self._get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1453, in _get_data
    success, data = self._try_get_data()
  File "/ocean/projects/cis210027p/ttao3/miniconda3/envs/espnet/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1297, in _try_get_data
    raise RuntimeError(
RuntimeError: DataLoader worker (pid(s) 59577) exited unexpectedly
# Accounting: begin_time=1750836660
# Accounting: end_time=1750836799
# Accounting: time=139 threads=1
# Finished at Wed Jun 25 03:33:19 EDT 2025 with status 1
