grad_clip: 5.0
batch_type: numel
batch_bins: 150000000
accum_grad: 1
max_epoch: 400
patience: none
# Use self-defined function for initialization
init: xavier_uniform 
best_model_criterion:
-   - valid
    - acc
    - max
keep_nbest_models: 10

input_size: 768
encoder: avhubert_pretrain
encoder_conf:
    output_size: 768
    linear_units: 3072
    attention_heads: 8
    num_blocks: 12
    dropout_rate: 0.1
    attention_dropout_rate: 0.0
    dropout_input: 0.1
    dropout_features: 0.1
    skip_masked: false
    skip_nomask: false
    mask_prob: 0.80
    extractor_mode: default
    conv_feature_layers: '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2'
    final_dim: 256
    encoder_layerdrop: 0.05
    feature_grad_mult: 0.1
    untie_final_proj: true
    label_rate: 100
    sample_rate: 16000

model_conf:
    lsm_weight: 0.1
    length_normalized_loss: false
    pred_masked_weight: 1.0
    pred_nomask_weight: 0.0
    loss_weights: 10.0

optim: adam
optim_conf:
    lr: 0.0005
scheduler: warmuplr
scheduler_conf:
    warmup_steps: 25000

unused_parameters: true

frontend: null

normalize: null

specaug: null