# CORAAL (Corpus of Regional African American Language)
CORAAL is a dataset of sociolinguistic interviews (spontaneous speech) with speakers of African American English / African American Language / African American Vernacular English. AAVE is a variety of English spoken by many Black Americans that long been labeled as "incorrect" or "ungrammatical," but linguists recognize it as a legitimate variety of English.

The dataset is public under a CC BY-NC-SA 4.0 license. See [the corpus's website](https://oraal.uoregon.edu/coraal) for more information [3]. "Transcriptions preserve morphosyntactic variation (e.g. null copula) but not phonological variation (e.g. velar nasal fronting). Many reduced constructions (e.g. 'sposta' for 'supposed to') are preserved, but not all are (e.g. 'useta' is transcribed as 'used to'). AAVE-specific lexical items (e.g. bruh) are also preserved" [2].
See [the User Guide](http://lingtools.uoregon.edu/coraal/userguide/CORAALUserGuide_current.pdf) for additional information on the interview and transcription process.

The current version (v 2023.06) consists of 7 cities (Atlanta, GA; Washington, DC; Detroit, MI; Lower East Side, NY; Princeville, NC; Rochester, NY; Valdosta, GA) and speakers across different age groups, genders, and socioeconomic backgrounds.

We create 80/10/10 train/dev/test splits where speakers do not overlap across splits but we try to ensure triplets of location, age group, and gender are included across splits. Regarding text normalization, we follow [2]'s text normalization, which adapted [4]'s text normalization (which removed all punctuation and annotations for overlapping speech, redactions, unintelligibility, inaudible portions, and paralinguistic sounds e.g. coughing or laughing and expanded numbers including dates and ordinal numbers). However, [2] revised [4]'s script to keep apostrophes, swear words, filler words, and dysfluencies and expanded abbreviations (e.g. "ms" → "miss") to match LibriSpeech, additionally normalizing all the reduced constructions, as LibriSpeech (train_clean_100) does not use reduced forms.

Running stage 1 of asr.sh will download the script, create segments from the hour long interviews, split the speakers into train/dev/test splits, and normalize the text. After data preprocessing (not including SpecAug), we end up with 67.4 hours of audio.


<!-- Generated by scripts/utils/show_asr_result.sh -->
# RESULTS

## exp/asr_train_asr_wavlm_transformer_raw_en_bpe5000_sp

GPU: 2 V100-32GB

Model: https://huggingface.co/kalbin/coraal_wavlm_transformer

## Environments
- date: `Wed Aug 28 11:48:57 EDT 2024`
- python version: `3.9.18 (main, Sep 11 2023, 13:41:44)  [GCC 11.2.0]`
- espnet version: `espnet 202402`
- pytorch version: `pytorch 1.12.1`
- Git hash: `b514bee2573e38b64b83a91d8d53e88f6875ce6b`
  - Commit date: `Wed Aug 28 10:32:30 2024 -0400`

### WER

|dataset|Snt|Wrd|Corr|Sub|Del|Ins|Err|S.Err|
|---|---|---|---|---|---|---|---|---|
|decode_asr_asr_model_valid.acc.best/test|4351|80482|90.5|7.8|1.7|1.3|10.9|62.9|

### CER

|dataset|Snt|Wrd|Corr|Sub|Del|Ins|Err|S.Err|
|---|---|---|---|---|---|---|---|---|
|decode_asr_asr_model_valid.acc.best/test|4351|385167|95.6|2.1|2.3|1.7|6.1|62.9|

### TER

|dataset|Snt|Wrd|Corr|Sub|Del|Ins|Err|S.Err|
|---|---|---|---|---|---|---|---|---|
|decode_asr_asr_model_valid.acc.best/test|4351|93612|88.5|6.9|4.6|1.5|13.0|62.9|



## exp/asr_train_asr_wavlm_conformer_raw_en_bpe5000_sp

GPU: 2 V100-32GB

Model: https://huggingface.co/kalbin/coraal_wavlm_conformer

## Environments
- date: `Thu Aug 29 22:20:14 EDT 2024`
- python version: `3.9.18 (main, Sep 11 2023, 13:41:44)  [GCC 11.2.0]`
- espnet version: `espnet 202402`
- pytorch version: `pytorch 1.12.1`
- Git hash: `dec40a70f8a9bdf2adc44b77cb1548e2dfcd5ba2`
  - Commit date: `Thu Aug 29 19:30:13 2024 +0000`


### WER

|dataset|Snt|Wrd|Corr|Sub|Del|Ins|Err|S.Err|
|---|---|---|---|---|---|---|---|---|
|decode_asr_asr_model_valid.acc.best/test|4351|80482|90.6|7.7|1.7|1.2|10.6|63.9|

### CER

|dataset|Snt|Wrd|Corr|Sub|Del|Ins|Err|S.Err|
|---|---|---|---|---|---|---|---|---|
|decode_asr_asr_model_valid.acc.best/test|4351|385167|95.5|2.1|2.4|1.7|6.2|63.9|

### TER

|dataset|Snt|Wrd|Corr|Sub|Del|Ins|Err|S.Err|
|---|---|---|---|---|---|---|---|---|
|decode_asr_asr_model_valid.acc.best/test|4351|93612|88.7|6.7|4.7|2.1|13.5|63.9|



# References

[1] W. Wolfram, "Sociolinguistic premises and the nature of nonstandard dialects," *Communication Education*, vol. 19, no. 3, pp. 177–184, 1970.

[2] K. Chang, Y.-H. Chou, J. Shi, H.-M. Chen, N. Holliday, O. Scharenborg, and D. Mortensen. "Self-supervised Speech Representations Still Struggle with African American Vernacular English," In *Proceedings of INTERSPEECH 2024*, 2024.

[3] T. Kendall and C. Farrington. 2023. The Corpus of Regional African American Language. Version 2023.06. Eugene, OR: The Online Resources for African American Language Project. [https://doi.org/10.7264/1ad5-6t35].

[4] A. Koenecke, A. Nam et al., "Racial disparities in automated speech recognition," *PNAS*, vol. 117, no. 14, pp. 7684–7689, 2020.
