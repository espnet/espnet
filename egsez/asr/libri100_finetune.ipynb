{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune Model with ESPnet-Easy\n",
    "\n",
    "In this notebook, we will explore the process of finetuning a pretrained model using the Librispeech-100 dataset. We'll start by downloading a pretrained model from the Hugging Face model hub and apply Low-Rank Adaptation (LoRA) techniques to reduce the number of training parameters.\n",
    "\n",
    "In this notebook, we assume that the dump files have been already created. If you need guidance on creating the dump files, you can refer to the `libri100.ipynb` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install loralib"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the `libri100.ipynb` notebook, we need to provide a dictionary to specify the file path and type for each data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DUMP_DIR = \"./dump/libri100\"\n",
    "data_info = {\n",
    "    \"speech\": [\"wav.scp\", \"sound\"],\n",
    "    \"text\": [\"text\", \"text\"],\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a pretrained model\n",
    "\n",
    "In ESPnet-Easy, you have the flexibility to define a custom model using the `build_model_fn` method. Additionally, you can load a pretrained model when needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from espnet2.bin.asr_inference import Speech2Text\n",
    "from espnet2.layers.create_lora_adapter import create_lora_adapter\n",
    "\n",
    "\n",
    "def build_model_fn(args):\n",
    "    pretrained_model = Speech2Text.from_pretrained('pyf98/librispeech_conformer_hop_length160')\n",
    "    model = pretrained_model.asr_model\n",
    "    model.train()\n",
    "\n",
    "    # apply lora\n",
    "    create_lora_adapter(model, target_modules=['linear_q'])\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with a pretrained model, the configuration is inherited from the model by default. To activate the LoRA model, it's essential to set the `use_lora` parameter to `True`. This configuration update can be easily achieved using the `update_finetune_config` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import espnetez as ez\n",
    "\n",
    "\n",
    "pretrained_model = Speech2Text.from_pretrained('pyf98/librispeech_conformer_hop_length160')\n",
    "pretrain_config = vars(pretrained_model.asr_train_args)\n",
    "del pretrained_model\n",
    "\n",
    "finetune_config = ez.config.update_finetune_config(\n",
    "\t'asr',\n",
    "\tpretrain_config,\n",
    "\t'finetune_with_lora.yaml'\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Finally, let's start training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_DIR = \"exp/finetune\"\n",
    "STATS_DIR = \"exp/stats_finetune\"\n",
    "\n",
    "trainer = ez.Trainer(\n",
    "    task='asr',\n",
    "    train_config=finetune_config,\n",
    "    train_dump_dir=\"dump/libri100/train\",\n",
    "    valid_dump_dir=\"dump/libri100/dev\",\n",
    "    build_model_fn=build_model_fn, # provide the pre-trained model\n",
    "    data_info=data_info,\n",
    "    output_dir=EXP_DIR,\n",
    "    stats_dir=STATS_DIR,\n",
    "    ngpu=1\n",
    ")\n",
    "trainer.collect_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
