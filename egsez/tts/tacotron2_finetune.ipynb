{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune Model with ESPnet-Easy\n",
    "\n",
    "In this notebook, we will explore the process of finetuning a pretrained model using the LJSpeech dataset. We'll start by downloading a pretrained model from the Hugging Face model hub.\n",
    "\n",
    "In this notebook, we assume that the dump files have been already created. If you need guidance on creating the dump files, you can refer to the `tacotron2.ipynb` notebook."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the `tacotron2.ipynb` notebook, we need to provide a dictionary to specify the file path and type for each data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DUMP_DIR = \"./dump/ljspeech\"\n",
    "data_info = {\n",
    "    \"speech\": [\"wav.scp\", \"sound\"],\n",
    "    \"text\": [\"text\", \"text\"],\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a pretrained model\n",
    "\n",
    "In ESPnet-Easy, you have the flexibility to define a custom model using the `build_model_fn` method. Additionally, you can load a pretrained model when needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from espnet2.bin.tts_inference import Text2Speech\n",
    "\n",
    "def build_model_fn(args):\n",
    "    pretrained_model = Text2Speech.from_pretrained('espnet/kan-bayashi_ljspeech_tacotron2')\n",
    "    model = pretrained_model.model\n",
    "    model.train()\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with a pretrained model, the configuration is inherited from the model by default. This configuration update can be easily achieved using the `update_finetune_config` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import espnetez as ez\n",
    "\n",
    "\n",
    "pretrained_model = Text2Speech.from_pretrained('espnet/kan-bayashi_ljspeech_tacotron2')\n",
    "pretrain_config = vars(pretrained_model.train_args)\n",
    "if pretrain_config['pretrain_path'] is not None:\n",
    "    pretrain_config['pretrain_path'] = None\n",
    "\n",
    "del pretrained_model\n",
    "\n",
    "finetune_config = ez.config.update_finetune_config(\n",
    "\t'tts',\n",
    "\tpretrain_config,\n",
    "\t'finetune.yaml'\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Finally, let's start training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_DIR = \"exp/finetune\"\n",
    "STATS_DIR = \"exp/stats_finetune\"\n",
    "\n",
    "trainer = ez.Trainer(\n",
    "    task='tts',\n",
    "    train_config=finetune_config,\n",
    "    train_dump_dir=\"dump/ljspeech/train\",\n",
    "    valid_dump_dir=\"dump/ljspeech/test\",\n",
    "    build_model_fn=build_model_fn, # provide the pre-trained model\n",
    "    data_info=data_info,\n",
    "    output_dir=EXP_DIR,\n",
    "    stats_dir=STATS_DIR,\n",
    "    ngpu=1\n",
    ")\n",
    "trainer.collect_stats()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we are ready to start finetune!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
