#!/bin/bash

# Copyright 2019 Nagoya University (Takenori Yoshimura)
#  Apache 2.0  (http://www.apache.org/licenses/LICENSE-2.0)

. ./path.sh
. ./cmd.sh

# general configuration
backend=pytorch
stage=0        # start from 0 if you need to start from data preparation
stop_stage=100
ngpu=0         # number of gpus ("0" uses cpu, otherwise use gpu)
verbose=1      # verbose option

# feature configuration
do_delta=false
cmvn=cmvn.ark

# rnnlm related
use_wordlm=false     # false means to use a character LM
lang_model=rnnlm.model.best

# decoding parameter
lm_weight=0
beam_size=20
penalty=0.0
maxlenratio=0.9
minlenratio=0.1
ctc_weight=0.3
streaming_mode=segment
min_blank_dur=10
onset_margin=4
offset_margin=4
recog_model=model.acc.best
decode_dir=decode

. utils/parse_options.sh || exit 1;

wav=$1

if [ $# != 1 ]; then
    echo "Usage: $0 <wav>"
    exit 1;
fi

# Set bash to 'debug' mode, it will exit on :
# -e 'error', -u 'undefined variable', -o ... 'error in pipeline', -x 'print commands',
set -e
set -u
set -o pipefail

# existence check
if [ ! -f "${cmvn}" ]; then
    echo "No such CMVN file: ${cmvn}"
    exit 1
fi
if [ ! -f "${lang_model}" -a `echo "${lm_weight} > 0.0" | bc` -eq 1 ]; then
    echo "No such language model: ${lang_model}"
    exit 1
fi
if [ ! -f "${recog_model}" ]; then
    echo "No such E2E model: ${recog_model}"
    exit 1
fi
if [ ! -f "${wav}" ]; then
    echo "No such wav file: ${wav}"
    exit 1
fi

base=`basename $wav .wav`
decode_dir=${decode_dir}/${base}

if [ ${stage} -le 0 ] && [ ${stop_stage} -ge 0 ]; then
    echo "stage 0: Data preparation"
    mkdir -p ${decode_dir}/data
    echo "$base $wav" > ${decode_dir}/data/wav.scp
    echo "X $base" > ${decode_dir}/data/spk2utt
    echo "$base X" > ${decode_dir}/data/utt2spk
    echo "$base X" > ${decode_dir}/data/text
fi

if [ ${stage} -le 1 ] && [ ${stop_stage} -ge 1 ]; then
    echo "stage 1: Feature Generation"
    steps/make_fbank_pitch.sh --cmd "$train_cmd" --nj 1 --write_utt2num_frames true \
        ${decode_dir}/data ${decode_dir}/log ${decode_dir}/fbank

    feat_recog_dir=${decode_dir}/dump; mkdir -p ${feat_recog_dir}
    dump.sh --cmd "$train_cmd" --nj 1 --do_delta ${do_delta} \
        ${decode_dir}/data/feats.scp ${cmvn} ${decode_dir}/log \
        ${feat_recog_dir}
fi

if [ ${stage} -le 2 ] && [ ${stop_stage} -ge 2 ]; then
    echo "stage 2: Json Data Preparation"
    dict=${decode_dir}/dict
    echo "<unk> 1" > ${dict}
    feat_recog_dir=${decode_dir}/dump
    data2json.sh --feat ${feat_recog_dir}/feats.scp \
        ${decode_dir}/data ${dict} > ${feat_recog_dir}/data.json
    rm -f ${dict}
fi

if [ ${stage} -le 3 ] && [ ${stop_stage} -ge 3 ]; then
    echo "stage 3: Decoding"

    if [ ${use_wordlm} = true ]; then
        recog_opts="--word-rnnlm ${lang_model}"
    else
        recog_opts="--rnnlm ${lang_model}"
    fi
    if [ ${lm_weight} == 0 ]; then
        recog_opts=""
    fi
    feat_recog_dir=${decode_dir}/dump

    ${decode_cmd} ${decode_dir}/log/decode.log \
        asr_recog.py \
        --ngpu ${ngpu} \
        --backend ${backend} \
        --verbose ${verbose} \
        --recog-json ${feat_recog_dir}/data.json \
        --result-label ${decode_dir}/result.json \
        --model ${recog_model} \
        --beam-size ${beam_size} \
        --penalty ${penalty} \
        --maxlenratio ${maxlenratio} \
        --minlenratio ${minlenratio} \
        --ctc-weight ${ctc_weight} \
        --lm-weight ${lm_weight} \
        --streaming-mode ${streaming_mode} \
        --streaming-min-blank-dur ${min_blank_dur} \
        --streaming-onset-margin ${onset_margin} \
        --streaming-offset-margin ${offset_margin} \
        --batchsize 0 \
        ${recog_opts}

    echo ""
    recog_text=`grep rec_text ${decode_dir}/result.json | sed -e 's/.*: "\(.*\)<eos>.*/\1/'`
    echo "Recognized text: ${recog_text}"
    echo ""

    echo "Finished"
fi
